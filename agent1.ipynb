{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package utilisé\n",
    "# pytorch : https://pytorch.org/\n",
    "# numpy : https://numpy.org/\n",
    "# matplotlib : https://matplotlib.org/\n",
    "# pandas : https://pandas.pydata.org/\n",
    "# scikit-learn : https://scikit-learn.org/stable/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.metadata import version\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Pour torch si vous avez un GPU\n",
    "device = \"cpu\" if not torch.cuda.is_available() else \"cuda\"\n",
    "# device = \"cpu\" # Pour forcer l'utilisation du CPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environement potentielement tester\n",
    "from environnement.environnement import Environnement as env # mother class\n",
    "from environnement.environnement1 import Environnement1 as env1\n",
    "from environnement.environnement2Str import Environnement2 as env2Str\n",
    "from environnement.environnement3Str import Environnement3 as env3Str\n",
    "from environnement.environnement6Str import Environnement6 as env6Str\n",
    "from environnement.small_loop import small_loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L'agent qui prédit l'avenir\n",
    "Dans ce notebook nous allons implémenter un agent dévellopementale qui aura comme simple but de prédire le prochain feedback de son environement.\n",
    "\n",
    "## Mécanisme de prédiction\n",
    "Dans se notebook nous allons implémenté deux mécanismes de machine learning, un decision tree et un deep neural network. L'entrainement des deux modèls se fera sur la \"vie\" de l'agent. C'est à dire que les modèls s'entrainerons seulement sur les interactions que l'agents aura faites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Définition de l'agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent1:\n",
    "    def __init__(self, model):\n",
    "        \"\"\" \n",
    "        Création de l'agent.\n",
    "        \n",
    "        - self._action : action précédente\n",
    "        - self._predicted_outcome : prédiction de l'outcome précédent\n",
    "        \"\"\"\n",
    "        self._action = None\n",
    "        self._predicted_outcome = None\n",
    "        self._model = model\n",
    "\n",
    "    def fit(self, action, outcome):\n",
    "        \"\"\"\n",
    "        Fonction d'entrainement de l'agent\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self._model.train()\n",
    "        except: # Si le model n'a pas de fonction \n",
    "            pass\n",
    "        self._model.fit([action], [outcome])\n",
    "\n",
    "    def predict(self, action):\n",
    "        \"\"\"\n",
    "        Funciton de prédiction\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self._model.eval()\n",
    "        except: # Si le model n'a pas de fonction eval\n",
    "            pass\n",
    "        self._model.predict(action)\n",
    "\n",
    "    def action(self, _outcome, env:env):\n",
    "        \"\"\" \n",
    "        Fonction qui choisit l'action a faire en fonction de la dernière \\\n",
    "        intéraction avec l'environnement. \\n\n",
    "        C'est ici que nous allons implémenter un mécanisme de ML \\\n",
    "        pour choisir la prochaine action.\n",
    "\n",
    "        :param: **_outcome** feedback de la dernière intéraction avec l'environnement\n",
    "\n",
    "        :return: **action** action à effectuer\n",
    "        \"\"\"\n",
    "        if self._action is not None:\n",
    "            print(f\"Action: {self._action}, Prediction: {self._predicted_outcome}, Outcome: {_outcome}, \" \n",
    "                  f\"Satisfaction: {self._predicted_outcome == _outcome}\")\n",
    "            # Nous entrainons le model sur la dernière action et son outcome\n",
    "            self.fit(self._action, _outcome)\n",
    "            # Nous faisons une prédiction sur une action aléatoire\n",
    "            self._action = np.random.choice(env.get_actions())\n",
    "            self._predicted_outcome = self.predict(self._action)\n",
    "        else:\n",
    "            # Au début de la vie de l'agent, nous prennons la première action possible\n",
    "            self._action = env.get_actions()[0]\n",
    "            print(f\"Action de base : {self._action} aucune prédiciton pour la première action\")\n",
    "        \n",
    "        return self._action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep neural network"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Stage (torch)",
   "language": "python",
   "name": "dpt_transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
