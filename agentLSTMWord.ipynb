{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import pandas as pd\n",
    "# Pour torch si vous avez un GPU\n",
    "device = \"cpu\" if not torch.cuda.is_available() else \"cuda\"\n",
    "device = \"cpu\" # Pour forcer l'utilisation du CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from environnement.environnement import Environnement as env # mother class\n",
    "from environnement.small_loop import small_loop\n",
    "from environnement.gridWord import gridWord\n",
    "\n",
    "# model machine learning\n",
    "from model.Tokenizer import *\n",
    "from model.RNN import *\n",
    "from model.CustomDataSet import CustomDataSet, CustomDataSetRNN\n",
    "from outil import *\n",
    "from inter.simpleInteraction import simpleInteraction as inter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent word\n",
    "Agent qui va créer des words sur les patterns composé de 2 interactions. Ces 'mots' peuvent a leur tour créer des mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentLSTM:\n",
    "    def __init__(self, valence:dict[inter], model:nn.Module, maxDepth:int,\n",
    "                 seuil:float, optimizer, loss_fn, gap:int=11, nb_epochs:int=50, \n",
    "                 data_val:tuple=None, device=\"cpu\"):\n",
    "        \"\"\"\n",
    "        Create an agent with a LSTM model and spesific decision making.\n",
    "        data_val is composed by list of all actions and outcomes. And \n",
    "        is not useful to train the model. It's just to have a monitoring\n",
    "        of the model. \\n\n",
    "        valence: dict of interactions, is use to know what is a good \n",
    "        comportment \\n\n",
    "        model: the model to train, this agent was create for LSTM model \n",
    "        \\n\n",
    "        \n",
    "        \"\"\"\n",
    "        self.model:nn.Module = model\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.valence:dict[inter] = valence\n",
    "        self.maxDepth:int = maxDepth\n",
    "        self.seuil:float = seuil\n",
    "        self.gap:int = gap\n",
    "        self.nbEpochs:int = nb_epochs\n",
    "        self.force_fit:bool = False\n",
    "        self.device = device\n",
    "        self.last_train = 0\n",
    "        self.proba = 0\n",
    "        \n",
    "        self.seq_to_exe = [] # Sequence choice by Decide\n",
    "        self.history_act = [] # History of all actions\n",
    "        self.history_fb = [] # History of all feedback\n",
    "        self.history_inter = [] # History of all interactions\n",
    "        \n",
    "        self.all_outcomes = set()\n",
    "        self.all_act = set()\n",
    "        key:inter = None\n",
    "        for key in valence.keys():\n",
    "            self.all_outcomes.add(key.getOutcome())\n",
    "            self.all_act.add(key.getAction())\n",
    "            \n",
    "        self.all_outcomes = list(self.all_outcomes)\n",
    "        self.all_act = list(self.all_act)\n",
    "        \n",
    "        self.tokenizer = SimpleTokenizerV1(\n",
    "            vocab={key: i for i, key in enumerate(self.all_outcomes + self.all_act)})\n",
    "        \n",
    "        self.seq_explo = []\n",
    "        self.valence_explo = -np.inf\n",
    "        \n",
    "        self.action_choice = self.all_act[0] # Default action, because developpemental start with action\n",
    "        self.history_act.append(self.action_choice)\n",
    "        self.outcome_prediction = None\n",
    "        \n",
    "        self.memory = {}\n",
    "        \n",
    "        # Variable to monitor the model\n",
    "        self.loss_train:list = []\n",
    "        self.acc_train:list = []\n",
    "        self.loss_test:list = []\n",
    "        self.acc_test:list = []\n",
    "        self.time_train:list = []\n",
    "        self.time_expected_val:list = []\n",
    "        self.time_train:list = []\n",
    "        self.time_expected_val:list = []\n",
    "        self.predictExplor:list = []\n",
    "        if data_val is not None:\n",
    "            dataset_test = CustomDataSetRNN(actions=data_val[0], outcomes=data_val[1], context_lenght=self.gap, \n",
    "                                    dim_out=len(self.all_outcomes), tokenizer=self.tokenizer)\n",
    "            self.data_loader_test = DataLoader(dataset_test, batch_size=32, shuffle=True)\n",
    "        else:\n",
    "            self.data_loader_test = None\n",
    "        number_patern = 200000\n",
    "        self.prealloc_df = pd.DataFrame(np.empty((number_patern, 5)), \n",
    "                                    columns=[\"proposition\", \"valence\", \"action\", \"probability\", \"val_sucess\"])\n",
    "        self.prealloc_df = self.prealloc_df.astype({\"proposition\": \"U20\", \"valence\": float, \"action\": \"U20\", \"probability\": float, \"val_sucess\": float})\n",
    "        \n",
    "        self.current_index = 0\n",
    "        self.visu_explo = pd.DataFrame(np.empty((number_patern, 2)), columns=[\"seqence\", \"valence\"])\n",
    "        self.visu_explo = self.visu_explo.astype({\"seqence\": \"U20\", \"valence\": float})\n",
    "        self.current_index_explo = 0\n",
    "        \n",
    "        if data_val is not None:\n",
    "            self.visu_val = pd.DataFrame(np.empty((len(data_val[0]), 3)), \n",
    "                                        columns=[\"seqence\", \"probablility\", \"good\"])\n",
    "            self.visu_val = self.visu_val.astype({\"seqence\": \"U20\", \"probablility\": float, \"good\": bool})\n",
    "            self.current_index_val = 0\n",
    "        \n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        train model\n",
    "        \"\"\"\n",
    "        dataset = CustomDataSetRNN(actions=self.history_act, outcomes=self.history_fb, \n",
    "                                 context_lenght=self.gap, dim_out=len(self.all_outcomes),\n",
    "                                 tokenizer=self.tokenizer)\n",
    "        \n",
    "        data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "        time_train = time.time()\n",
    "        \n",
    "        for i in range(self.nbEpochs):\n",
    "            self.model.train()\n",
    "            steps = 0\n",
    "            train_acc = 0\n",
    "            training_loss = []\n",
    "            for tmp, (x,t) in enumerate(data_loader):\n",
    "                x = x.to(self.device)\n",
    "                t = t.to(self.device)\n",
    "                bs = t.shape[0]\n",
    "                h = torch.zeros(self.model.num_layers, bs, self.model.hidden_size, device=self.device)\n",
    "                cell = torch.zeros(self.model.num_layers, bs, self.model.hidden_size, device=self.device)\n",
    "\n",
    "                pred, h, cell = self.model(x, h, cell)\n",
    "\n",
    "                loss = self.loss_fn(pred[:, -1, :], t)\n",
    "                training_loss.append(loss.item())\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                train_acc += sum((pred[:, -1, :].argmax(1) == t).cpu().numpy())\n",
    "                steps += bs\n",
    "            \n",
    "            self.acc_train.append(train_acc / steps)\n",
    "            if self.data_loader_test is not None:\n",
    "                self.model.eval()\n",
    "                steps = 0\n",
    "                test_acc = 0\n",
    "                loss_test = []\n",
    "                \n",
    "                for text, label in self.data_loader_test:\n",
    "                    text = text.to(self.device)\n",
    "                    label = label.to(self.device)\n",
    "                    bs = label.shape[0]\n",
    "\n",
    "                    # Initialize hidden and memory states\n",
    "                    hidden = torch.zeros(self.model.num_layers, bs, self.model.hidden_size, device=self.device)\n",
    "                    memory = torch.zeros(self.model.num_layers, bs, self.model.hidden_size, device=self.device)\n",
    "                    \n",
    "                    # Forward pass through the model\n",
    "                    pred, hidden, memory = self.model(text, hidden, memory)\n",
    "                    \n",
    "                    for i in range(bs):\n",
    "                        self.visu_val.iloc[steps + i] = [str(self.tokenizer.decode(text[i].cpu().tolist())), \n",
    "                                                         float(torch.nn.functional.softmax(pred[i, -1, :], dim=-1).max().item()), \n",
    "                                                         int(pred[i, -1, :].argmax().item() == label[i])]\n",
    "\n",
    "                    # Calculate the loss\n",
    "                    loss = self.loss_fn(pred[:, -1, :], label)\n",
    "                    loss_test.append(loss.item())\n",
    "\n",
    "                    # Calculate test accuracy\n",
    "                    test_acc +=  sum((pred[:, -1, :].argmax(1) == label).cpu().numpy())\n",
    "                    steps += bs\n",
    "                    \n",
    "                loss_test.append(loss_test)\n",
    "                self.acc_test.append(test_acc / steps)\n",
    "                # print(f\"Validation time: {time.time() - time_val_epoch}\")    \n",
    "            self.loss_train.append(training_loss)\n",
    "            # If acc is 100% we stop the training\n",
    "            if self.acc_train[-1] >= 0.99:\n",
    "                for _ in range(i, self.nbEpochs):\n",
    "                    self.acc_train.append(self.acc_train[-1])\n",
    "                    if self.data_loader_test is not None:\n",
    "                        self.loss_test.append(self.loss_test[-1])\n",
    "                break\n",
    "            \n",
    "        print(f\"Training time: {time.time() - time_train}\")\n",
    "        self.time_train.append(time.time() - time_train)\n",
    "        \n",
    "    def predict(self, action):\n",
    "        \"\"\"\n",
    "        Predict the feedback of the action, use the last gap actions/outcomes\n",
    "        \"\"\"        \n",
    "        x = []\n",
    "        for i in range(-(self.gap - 1) // 2, 0, 1):\n",
    "            x.append(self.history_act[i])\n",
    "            x.append(self.history_fb[i])\n",
    "        x.append(action)\n",
    "        seq_to_pred = self.tokenizer.encode(x)\n",
    "        # On simule un batch de taille 1\n",
    "        seq_to_pred = torch.tensor([seq_to_pred], device=self.device)\n",
    "        h = torch.zeros(self.model.num_layers, 1, self.model.hidden_size, device=self.device)\n",
    "        cell = torch.zeros(self.model.num_layers, 1, self.model.hidden_size, device=self.device)\n",
    "        probs, _, _ = self.model(seq_to_pred, h, cell)\n",
    "        \n",
    "        pred_feedback = torch.argmax(probs[:, -1, :]).item()\n",
    "        pred_feedback = self.tokenizer.decode(pred_feedback)\n",
    "        \n",
    "        return pred_feedback\n",
    "    \n",
    "    def fill_valance_explo(self, max_depth:int, seq_predi:list = [], valence_succes_pred:float = 0):\n",
    "        max_depth -= 1\n",
    "        inter_max, value = max(self.valence.items(), key=lambda y: y[1])\n",
    "        for _ in range(max_depth):\n",
    "            seq_predi += [inter_max.getAction(), inter_max.getOutcome()]\n",
    "            valence_succes_pred += value\n",
    "        self.visu_explo.iloc[self.current_index_explo] = [str(seq_predi), valence_succes_pred]\n",
    "        self.current_index_explo += 1\n",
    "        if valence_succes_pred > self.valence_explo:\n",
    "            self.seq_explo = seq_predi\n",
    "            self.valence_explo = valence_succes_pred                    \n",
    "    \n",
    "    def recursif_expective_valance(self, context:list, max_depth:int, seuil:float=0.5, proba:float = 1,\n",
    "                                   seq_predi:list = [], valence_pred:float = 0, valence_succes_pred:float = 0):\n",
    "        \"\"\"\n",
    "        Create the list of proposed sequences\n",
    "        \"\"\"\n",
    "        max_depth -= 1\n",
    "        self.model.eval()\n",
    "        # Compute the expected valence of each action\n",
    "        for act in self.all_act:\n",
    "            new_seq = seq_predi + [act]\n",
    "            seq_to_predict = context + [self.tokenizer.encode(act)]\n",
    "\n",
    "            sub_list = subfinder(self.history_inter, seq_to_predict[-3:])\n",
    "            if sub_list == []:\n",
    "                # print('i want explore')\n",
    "                # Get max valence and outcome associate by act\n",
    "                inter_max, value = max([(inter(act, out), self.valence[inter(act, out)]) for out in self.all_outcomes], key=lambda y: y[1])\n",
    "                # print(\"debug\")\n",
    "                # print('act :', act)\n",
    "                # print(inter_max)\n",
    "                # print(value)\n",
    "                # print('valence_succes_pred :', valence_succes_pred)\n",
    "                # print('goal :', self.valence_explo)\n",
    "                new_seq += [inter_max.getOutcome()]\n",
    "                tmp_value = valence_succes_pred + value\n",
    "                self.visu_explo.iloc[self.current_index_explo] = [str(new_seq), valence_succes_pred]\n",
    "                self.current_index_explo += 1\n",
    "                if tmp_value > self.valence_explo:\n",
    "                    # print('start new sequence')\n",
    "                    # print(new_seq)\n",
    "                    # print('valence')\n",
    "                    # print(valence_succes_pred)\n",
    "                    self.seq_explo = new_seq\n",
    "                    self.valence_explo = valence_succes_pred\n",
    "                # Nous n'avons jamais vue la séquence, nous choisisont d'imaginer le meilleur sénario\n",
    "                # print('sequence not seen')\n",
    "                self.fill_valance_explo(max_depth=max_depth, seq_predi=new_seq, \n",
    "                                            valence_succes_pred=tmp_value)\n",
    "                continue\n",
    "            # print('sequence already seen')\n",
    "            \n",
    "            seq_to_predict = torch.tensor([seq_to_predict], dtype=torch.int).to(device)\n",
    "\n",
    "            hidden = torch.zeros(self.model.num_layers, 1, self.model.hidden_size, device=device)\n",
    "            memory = torch.zeros(self.model.num_layers, 1, self.model.hidden_size, device=device)\n",
    "\n",
    "            x, _, _ = self.model(seq_to_predict, hidden, memory)\n",
    "            x = x[0, -1, :]\n",
    "            # Transforme x into list proba\n",
    "            probs = torch.nn.functional.softmax(x, dim=0).tolist()\n",
    "            # for each outcome, record the expected valence\n",
    "            expected_valence = valence_pred\n",
    "            for i, out in enumerate(self.all_outcomes):\n",
    "                tmp_proba = probs[i] * proba\n",
    "                expected_valence += float(np.round(self.valence[inter(act, out)] * tmp_proba, decimals=4))\n",
    "            \n",
    "            for i, out in enumerate(self.all_outcomes):\n",
    "                visu_val = None\n",
    "                tmp_new_seq = new_seq + [out]\n",
    "                tmp_proba = probs[i] * proba\n",
    "                # If the probability is above a threshold\n",
    "                sucess_valence = self.valence[inter(act, out)] + valence_succes_pred\n",
    "                if tmp_proba > seuil:\n",
    "                    visu_val = expected_valence\n",
    "                    # If the max_depth is not reached \n",
    "                    if max_depth > 0: \n",
    "                        # Recursively look for longer sequences\n",
    "                        new_context = context + self.tokenizer.encode([act, out])\n",
    "                        self.recursif_expective_valance(context=new_context[2:], max_depth=max_depth, seuil=seuil, \n",
    "                            proba=tmp_proba, seq_predi=tmp_new_seq.copy(), valence_pred=expected_valence, valence_succes_pred=sucess_valence)\n",
    "                    else:\n",
    "                        self.prealloc_df.iloc[self.current_index] = [str(tmp_new_seq), visu_val, tmp_new_seq[0], tmp_proba, sucess_valence]\n",
    "                        self.current_index += 1\n",
    "    \n",
    "    def expective_valance(self, verbose:bool=False):\n",
    "        \"\"\"\n",
    "        Permet de calculer l'expective valance d'une séquence d'interaction\n",
    "\n",
    "        Args:\n",
    "            max_depth (int): _description_\n",
    "            seuil (float, optional): _description_. Defaults to 0.2.\n",
    "            verbose (bool, optional): _description_. Defaults to False.\n",
    "        \"\"\"\n",
    "        \n",
    "        x = []\n",
    "        for i in range(-(self.gap - 1) // 2, 0, 1):\n",
    "            x.append(self.history_act[i])\n",
    "            x.append(self.history_fb[i])\n",
    "        seq_to_pred = self.tokenizer.encode(x)\n",
    "        self.prealloc_df[:] = np.empty((len(self.prealloc_df), 5))\n",
    "        self.prealloc_df[\"valence\"] = -np.inf\n",
    "        self.current_index = 0\n",
    "        self.seq_explo = []\n",
    "        self.valence_explo = -np.inf\n",
    "        self.visu_explo[:] = np.empty((len(self.visu_explo), 2))\n",
    "        self.current_index_explo = 0\n",
    "        if str(x) in self.memory.keys():\n",
    "            if self.memory[str(x)] [\"iteraction_update\"] >= self.last_fit:\n",
    "                self.prealloc_df = self.memory[str(x)] [\"prealloc_df\"]\n",
    "                return\n",
    "    \n",
    "        self.recursif_expective_valance(context=seq_to_pred,\n",
    "                                        max_depth=self.maxDepth,\n",
    "                                        proba=1, seq_predi=[],\n",
    "                                        seuil=self.seuil)\n",
    "        df = self.prealloc_df.sort_values(by=\"valence\", ascending=False).iloc[0].copy()\n",
    "        seq = df.proposition\n",
    "        if seq is not None and seq != 0.0 and seq  is type(str):\n",
    "            seq = eval(seq)[:-1]\n",
    "            df.proposition = str(seq)\n",
    "            self.memory[str(x)] = {\n",
    "                \"prealloc_df\": df,\n",
    "                \"iteraction_update\": len(self.history_act)\n",
    "            }\n",
    "\n",
    "    def decide(self):\n",
    "        if self.seq_to_exe and len(self.seq_to_exe) > 1:\n",
    "            out = self.seq_to_exe.pop(0)\n",
    "            if out == self.history_fb[-1]:\n",
    "                self.predictExplor.append(self.predictExplor[-1])\n",
    "                act = self.seq_to_exe.pop(0)\n",
    "                self.time_expected_val.append(0)\n",
    "                return act\n",
    "            else:\n",
    "                self.force_fit = True\n",
    "        self.seq_to_exe = []        \n",
    "\n",
    "        time_compute_expective_val = time.time()\n",
    "\n",
    "        self.expective_valance()\n",
    "        print(f\"Time to compute expective valance: {time.time() - time_compute_expective_val}\")\n",
    "        self.time_expected_val.append(time.time() - time_compute_expective_val)\n",
    "\n",
    "        self.seq_to_exe = self.prealloc_df.sort_values(by=\"valence\", ascending=False).iloc[0].proposition\n",
    "        expected_val = self.prealloc_df.sort_values(by=\"valence\", ascending=False).iloc[0].valence\n",
    "\n",
    "        print(f\"expected valence : {expected_val:.2f} valence explo : {self.valence_explo:.2f} model predict : {self.seq_to_exe}, explo want : {self.seq_explo}\")\n",
    "        # tempo\n",
    "        if self.seq_to_exe is not None and expected_val > self.valence_explo:\n",
    "            self.seq_to_exe = eval(self.seq_to_exe)\n",
    "            print(\"\\033[0;35m after compute ... \\033[0m\", self.seq_to_exe)\n",
    "            self.proba = self.prealloc_df.sort_values(by=\"valence\", ascending=False).iloc[0].probability\n",
    "            self.predictExplor.append(1)\n",
    "        else:\n",
    "            print(\"\\033[0;36m explo ... \\033[0m\", self.seq_explo)\n",
    "            self.seq_to_exe = self.seq_explo\n",
    "            self.force_fit = True\n",
    "            self.proba = 1\n",
    "            self.predictExplor.append(0)\n",
    "        act = self.seq_to_exe.pop(0)\n",
    "        return act\n",
    "        \n",
    "    def action(self, real_outcome, verbose=False):\n",
    "        \"\"\"\n",
    "        La fonction action permet à l'agent de choisir une action en fonction de l'outcome réel.\n",
    "        Cette fonction entraine le modèle a prévoir les outcomes futurs en fonction des actions passées.\n",
    "\n",
    "        Args:\n",
    "            real_outcome : L'outcome réel suite à l'action de l'agent\n",
    "            verbose : Affiche les informations sur l'entrainement ou non\n",
    "        \"\"\"\n",
    "        # La première étape est de sauvegarder l'outcome réel\n",
    "        self.history_fb.append(real_outcome)\n",
    "        self.history_inter.append(self.tokenizer.encode(real_outcome))\n",
    "        good_pred:bool = self.outcome_prediction == real_outcome\n",
    "        if verbose :\n",
    "            print(f\"\\033[0;31m Action: {self.action_choice} \\033[0m, Prediction: {self.outcome_prediction}, Outcome: {real_outcome}, \\033[0;31m Satisfaction: {good_pred} \\033[0m\")\n",
    "        \n",
    "        # Ensuite nous regardons si nous devons entrainer le modèle\n",
    "        # not(explore) and \n",
    "        if (not(good_pred) or self.force_fit) and (len(self.history_fb) + len(self.history_fb) > self.gap) and (self.proba > 0.6 or self.proba < 0.4):\n",
    "            print(\"fit because probability is \", self.proba)\n",
    "            self.fit()\n",
    "            self.last_fit = len(self.history_act)\n",
    "            self.force_fit = False\n",
    "            \n",
    "        elif len(self.history_fb) + len(self.history_fb) > self.gap:\n",
    "            for _ in range(self.nbEpochs):\n",
    "                self.acc_train.append(self.acc_train[-1])\n",
    "                if self.data_loader_test is not None:\n",
    "                    self.loss_test.append(self.loss_test[-1])\n",
    "\n",
    "        # Nous devons maintenant choisir une action\n",
    "        if len(self.history_fb) + len(self.history_fb) > self.gap:\n",
    "            self.action_choice = self.decide()\n",
    "            self.outcome_prediction = self.predict(self.action_choice)\n",
    "        else:\n",
    "            inter_max, value = max(self.valence.items(), key=lambda y: y[1])\n",
    "            self.action_choice = inter_max.getAction()\n",
    "        # self.action_choice = np.random.choice(self.all_act)\n",
    "        self.history_act.append(self.action_choice)\n",
    "        self.history_inter.append(self.tokenizer.encode(self.action_choice))\n",
    "        \n",
    "        return self.action_choice, self.outcome_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection de l'environement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environenment = small_loop(x=1, y=1, theta=0, world=np.array([\n",
    "#                 [1, 1, 1, 1, 1],\n",
    "#                 [1, 0, 0, 0, 1],\n",
    "#                 [1, 0, 1, 0, 1],\n",
    "#                 [1, 0, 0, 0, 1],\n",
    "#                 [1, 1, 1, 1, 1],\n",
    "#             ]))\n",
    "\n",
    "environenment = small_loop(x=1, y=1, theta=0, world=np.array([\n",
    "                [1, 1, 1, 1, 1, 1],\n",
    "                [1, 0, 0, 0, 1, 1],\n",
    "                [1, 0, 1, 0, 0, 1],\n",
    "                [1, 0, 1, 1, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 1],\n",
    "                [1, 1, 1, 1, 1, 1],\n",
    "            ]))\n",
    "\n",
    "# environenment = small_loop(x=1, y=1, theta=0, world=np.array([\n",
    "#                 [1, 1, 1, 1, 1, 1],\n",
    "#                 [1, 0, 0, 0, 0, 1],\n",
    "#                 [1, 0, 0, 0, 0, 1],\n",
    "#                 [1, 0, 0, 0, 0, 1],\n",
    "#                 [1, 0, 0, 0, 0, 1],\n",
    "#                 [1, 1, 1, 1, 1, 1],\n",
    "#             ]))\n",
    "\n",
    "\n",
    "valence = {\n",
    "    inter('forward', 'empty') : 10,\n",
    "    inter('forward', 'wall') : -100,\n",
    "    inter('turn_left', 'empty') : -41,\n",
    "    inter('turn_left', 'wall') : -100,\n",
    "    inter('turn_right', 'empty') : -41,\n",
    "    inter('turn_right', 'wall') : -100,\n",
    "    inter('feel_front', 'wall') : -25,\n",
    "    inter('feel_front', 'empty') : -22,\n",
    "}\n",
    "\n",
    "environenment = gridWord(x=1, y=1, theta=0, world=np.array([\n",
    "                [1, 1, 1, 1, 1, 1],\n",
    "                [1, 0, 0, 0, 1, 1],\n",
    "                [1, 0, 1, 0, 0, 1],\n",
    "                [1, 0, 1, 1, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 1],\n",
    "                [1, 1, 1, 1, 1, 1],\n",
    "            ]))\n",
    "\n",
    "valence = {\n",
    "    inter('forward', 'empty') : 10,\n",
    "    inter('forward', 'wall') : -100,\n",
    "    inter('turn_left', 'empty') : -21,\n",
    "    inter('turn_left', 'wall') : -100,\n",
    "    inter('turn_right', 'empty') : -21,\n",
    "    inter('turn_right', 'wall') : -100,\n",
    "    inter('feel_front', 'wall') : -15,\n",
    "    inter('feel_front', 'empty') : -12,\n",
    "    inter('feel_right', 'wall') : -15,\n",
    "    inter('feel_right', 'empty') : -12,\n",
    "    inter('feel_left', 'wall') : -15,\n",
    "    inter('feel_left', 'empty') : -12   \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Définition du modèl et ses paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pe/Documents/stage/Dpt_transformers/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# torch.manual_seed(0)\n",
    "# np.random.seed(0)\n",
    "hidden_size = 16\n",
    "num_layers = 1\n",
    "len_vocab = len(environenment.get_outcomes() + environenment.get_actions())\n",
    "\n",
    "# Create the LSTM classifier model\n",
    "lstm_classifier = LSTM_Classifeur(num_emb=len_vocab, output_size=2, \n",
    "                       num_layers=num_layers, hidden_size=hidden_size, dropout=0.5).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(lstm_classifier.parameters(), lr=0.001)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "tokenizer = SimpleTokenizerV1(create_dico_numerate_word(environenment.get_outcomes() + environenment.get_actions()))\n",
    "\n",
    "# Le warning est normal si num_layers = 1 et que dropout > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Définition de l'agent et ses paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AgentLSTM(valence=valence, model=lstm_classifier, optimizer=optimizer, loss_fn=loss_func,\n",
    "    gap_predi=7, gap_train=7, max_depth=5, seuil=0.3, nb_epoch=20,\n",
    "    data_validate=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_good = []\n",
    "history_good_inter = []\n",
    "history_bad_inter = []\n",
    "hisrory_val = []\n",
    "pourcent_by_10  = []\n",
    "by_10_good_inter  = []\n",
    "by_10_bad_inter  = []\n",
    "mean_val = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff14efb3ea245e49062332b30636b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: None, Outcome: empty, \u001b[0;31m Satisfaction: False \u001b[0m\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: None, Outcome: wall, \u001b[0;31m Satisfaction: False \u001b[0m\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: None, Outcome: wall, \u001b[0;31m Satisfaction: False \u001b[0m\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: None, Outcome: wall, \u001b[0;31m Satisfaction: False \u001b[0m\n",
      "Training time: 0.04914975166320801\n",
      "Time to compute expective valance: 0.04341244697570801\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.0023651123046875\n",
      "Time to compute expective valance: 0.06628847122192383\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.0027151107788085938\n",
      "Time to compute expective valance: 0.06020641326904297\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.0027866363525390625\n",
      "Time to compute expective valance: 0.06460690498352051\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.002980947494506836\n",
      "Time to compute expective valance: 0.06333351135253906\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.002942323684692383\n",
      "Time to compute expective valance: 0.06314444541931152\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.003309965133666992\n",
      "Time to compute expective valance: 0.06345701217651367\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.003322601318359375\n",
      "Time to compute expective valance: 0.06680870056152344\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.003210306167602539\n",
      "Time to compute expective valance: 0.06187915802001953\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.0033104419708251953\n",
      "Time to compute expective valance: 0.06397056579589844\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.004065752029418945\n",
      "Time to compute expective valance: 0.07305645942687988\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.003130674362182617\n",
      "Time to compute expective valance: 0.08000564575195312\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.003267526626586914\n",
      "Time to compute expective valance: 0.06903386116027832\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.0029380321502685547\n",
      "Time to compute expective valance: 0.06331491470336914\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.002830982208251953\n",
      "Time to compute expective valance: 0.06418204307556152\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.0031919479370117188\n",
      "Time to compute expective valance: 0.06219053268432617\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.0036563873291015625\n",
      "Time to compute expective valance: 0.06435227394104004\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.0027883052825927734\n",
      "Time to compute expective valance: 0.06381487846374512\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.0028259754180908203\n",
      "Time to compute expective valance: 0.06430625915527344\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.0029249191284179688\n",
      "Time to compute expective valance: 0.06302142143249512\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.0031599998474121094\n",
      "Time to compute expective valance: 0.06586313247680664\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.0034313201904296875\n",
      "Time to compute expective valance: 0.06741595268249512\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.002877473831176758\n",
      "Time to compute expective valance: 0.06693673133850098\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.0029959678649902344\n",
      "Time to compute expective valance: 0.06471467018127441\n",
      "expected valence : -inf valence explo : 18.00 model predict : 0.0, explo want : ['feel_front', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['feel_front', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: feel_front \u001b[0m, Prediction: wall, Outcome: empty, \u001b[0;31m Satisfaction: False \u001b[0m\n",
      "Training time: 0.03655576705932617\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Time to compute expective valance: 0.059362173080444336\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.03786301612854004\n",
      "Time to compute expective valance: 0.05842852592468262\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.03696727752685547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14181/1156575444.py:276: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['forward', 'wall', 'forward', 'wall', 'forward', 'wall', 'forward', 'wall', 'forward', 'wall']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  self.prealloc_df.iloc[self.current_index] = [str(tmp_new_seq), visu_val, tmp_new_seq[0], tmp_proba, sucess_valence]\n",
      "/tmp/ipykernel_14181/1156575444.py:276: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'forward' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  self.prealloc_df.iloc[self.current_index] = [str(tmp_new_seq), visu_val, tmp_new_seq[0], tmp_proba, sucess_valence]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compute expective valance: 0.20203590393066406\n",
      "expected valence : -371.75 valence explo : 18.00 model predict : ['forward', 'wall', 'forward', 'wall', 'forward', 'wall', 'forward', 'wall', 'feel_front', 'wall'], explo want : ['feel_left', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['feel_left', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: feel_left \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.0371556282043457\n",
      "Time to compute expective valance: 0.06490969657897949\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.03829145431518555\n",
      "Time to compute expective valance: 0.06547737121582031\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.03487110137939453\n",
      "Time to compute expective valance: 0.06458592414855957\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.0338287353515625\n",
      "Time to compute expective valance: 0.3840961456298828\n",
      "expected valence : -247.65 valence explo : 18.00 model predict : ['feel_left', 'wall', 'forward', 'wall', 'forward', 'wall', 'forward', 'wall', 'feel_front', 'wall'], explo want : ['feel_right', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['feel_right', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: feel_right \u001b[0m, Prediction: wall, Outcome: empty, \u001b[0;31m Satisfaction: False \u001b[0m\n",
      "Training time: 0.05265927314758301\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Time to compute expective valance: 0.07139945030212402\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.055121421813964844\n",
      "Time to compute expective valance: 0.06765985488891602\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.004996061325073242\n",
      "Time to compute expective valance: 0.9901683330535889\n",
      "expected valence : -163.33 valence explo : 18.00 model predict : ['feel_right', 'empty', 'forward', 'wall', 'forward', 'wall', 'forward', 'wall', 'feel_front', 'empty'], explo want : ['feel_left', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['feel_left', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: feel_left \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.004065752029418945\n",
      "Time to compute expective valance: 0.36033105850219727\n",
      "expected valence : -349.78 valence explo : 18.00 model predict : ['forward', 'wall', 'forward', 'wall', 'forward', 'wall', 'feel_right', 'empty', 'forward', 'wall'], explo want : ['feel_front', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['feel_front', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: feel_front \u001b[0m, Prediction: empty, Outcome: empty, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.004198551177978516\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Time to compute expective valance: 0.06686258316040039\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.0046138763427734375\n",
      "Time to compute expective valance: 0.7290477752685547\n",
      "expected valence : -209.75 valence explo : 18.00 model predict : ['forward', 'wall', 'feel_left', 'wall', 'feel_front', 'empty', 'forward', 'wall', 'forward', 'wall'], explo want : ['feel_front', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['feel_front', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: feel_front \u001b[0m, Prediction: empty, Outcome: empty, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.005195140838623047\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Time to compute expective valance: 0.6125223636627197\n",
      "expected valence : -245.56 valence explo : 18.00 model predict : ['forward', 'wall', 'feel_front', 'empty', 'forward', 'wall', 'forward', 'wall', 'feel_front', 'empty'], explo want : ['feel_front', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['feel_front', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: feel_front \u001b[0m, Prediction: empty, Outcome: empty, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.0048122406005859375\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Time to compute expective valance: 0.8757374286651611\n",
      "expected valence : -171.25 valence explo : 18.00 model predict : ['feel_front', 'empty', 'forward', 'wall', 'feel_front', 'empty', 'forward', 'wall', 'forward', 'wall'], explo want : ['feel_left', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['feel_left', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: feel_left \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.005292654037475586\n",
      "Time to compute expective valance: 0.06715011596679688\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.004910469055175781\n",
      "Time to compute expective valance: 0.5877475738525391\n",
      "expected valence : -265.77 valence explo : 18.00 model predict : ['forward', 'wall', 'forward', 'wall', 'feel_left', 'wall', 'feel_front', 'empty', 'forward', 'wall'], explo want : ['feel_front', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['feel_front', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: feel_front \u001b[0m, Prediction: empty, Outcome: empty, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.004759311676025391\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Time to compute expective valance: 1.3080360889434814\n",
      "expected valence : -138.67 valence explo : 18.00 model predict : ['feel_front', 'empty', 'forward', 'wall', 'feel_front', 'empty', 'forward', 'wall', 'feel_front', 'empty'], explo want : ['feel_left', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['feel_left', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: feel_left \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.005353689193725586\n",
      "Time to compute expective valance: 0.4920821189880371\n",
      "expected valence : -229.31 valence explo : 18.00 model predict : ['forward', 'wall', 'feel_front', 'empty', 'forward', 'wall', 'feel_front', 'empty', 'forward', 'wall'], explo want : ['feel_front', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['feel_front', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: feel_front \u001b[0m, Prediction: empty, Outcome: empty, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.005115985870361328\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Time to compute expective valance: 0.7735087871551514\n",
      "expected valence : -193.50 valence explo : 18.00 model predict : ['forward', 'wall', 'feel_front', 'empty', 'forward', 'wall', 'feel_left', 'wall', 'feel_front', 'empty'], explo want : ['feel_front', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['feel_front', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: feel_front \u001b[0m, Prediction: empty, Outcome: empty, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.005320072174072266\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Time to compute expective valance: 1.495478630065918\n",
      "expected valence : -115.02 valence explo : 18.00 model predict : ['feel_left', 'wall', 'feel_front', 'empty', 'forward', 'wall', 'feel_front', 'empty', 'forward', 'wall'], explo want : ['feel_right', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['feel_right', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: feel_right \u001b[0m, Prediction: empty, Outcome: empty, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.004446268081665039\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Time to compute expective valance: 0.6549313068389893\n",
      "expected valence : -272.18 valence explo : 18.00 model predict : ['forward', 'wall', 'forward', 'wall', 'feel_left', 'wall', 'feel_front', 'empty', 'forward', 'wall'], explo want : ['feel_front', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['feel_front', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: feel_front \u001b[0m, Prediction: empty, Outcome: empty, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.004483222961425781\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Time to compute expective valance: 2.0488483905792236\n",
      "expected valence : -120.52 valence explo : 15.00 model predict : ['feel_left', 'wall', 'feel_front', 'empty', 'forward', 'wall', 'feel_front', 'empty', 'forward', 'wall'], explo want : ['feel_right', 'wall', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['feel_right', 'wall', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: feel_right \u001b[0m, Prediction: empty, Outcome: empty, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.005898475646972656\n",
      "Time to compute expective valance: 0.5764610767364502\n",
      "expected valence : -190.28 valence explo : 18.00 model predict : ['forward', 'wall', 'feel_front', 'empty', 'forward', 'wall', 'feel_left', 'wall', 'feel_front', 'empty'], explo want : ['feel_front', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['feel_front', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: feel_front \u001b[0m, Prediction: empty, Outcome: empty, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.005510568618774414\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Time to compute expective valance: 0.07477211952209473\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.004763364791870117\n",
      "Time to compute expective valance: 1.7118933200836182\n",
      "expected valence : -134.34 valence explo : 18.00 model predict : ['feel_front', 'empty', 'forward', 'wall', 'feel_right', 'empty', 'feel_front', 'empty', 'forward', 'wall'], explo want : ['feel_left', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['feel_left', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: feel_left \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.005742788314819336\n",
      "Time to compute expective valance: 0.9845101833343506\n",
      "expected valence : -157.66 valence explo : 18.00 model predict : ['feel_front', 'empty', 'forward', 'wall', 'feel_front', 'empty', 'forward', 'wall', 'feel_front', 'empty'], explo want : ['feel_left', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['feel_left', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: feel_left \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.0052835941314697266\n",
      "Time to compute expective valance: 0.06375718116760254\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.005360603332519531\n",
      "Time to compute expective valance: 0.06508326530456543\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.006311178207397461\n",
      "Time to compute expective valance: 1.226715326309204\n",
      "expected valence : -194.90 valence explo : 18.00 model predict : ['forward', 'wall', 'feel_left', 'wall', 'feel_front', 'empty', 'forward', 'wall', 'feel_front', 'empty'], explo want : ['feel_front', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['feel_front', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: feel_front \u001b[0m, Prediction: empty, Outcome: empty, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.006417512893676758\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Time to compute expective valance: 2.530867338180542\n",
      "expected valence : -136.37 valence explo : 9.00 model predict : ['feel_right', 'empty', 'feel_front', 'empty', 'forward', 'wall', 'forward', 'wall', 'feel_front', 'empty'], explo want : ['turn_right', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['turn_right', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: turn_right \u001b[0m, Prediction: wall, Outcome: empty, \u001b[0;31m Satisfaction: False \u001b[0m\n",
      "Training time: 0.04223346710205078\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: empty, \u001b[0;31m Satisfaction: False \u001b[0m\n",
      "Training time: 0.08164548873901367\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: empty, \u001b[0;31m Satisfaction: False \u001b[0m\n",
      "Training time: 0.0837407112121582\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: empty, \u001b[0;31m Satisfaction: False \u001b[0m\n",
      "Training time: 0.04923367500305176\n",
      "Time to compute expective valance: 0.06589913368225098\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.006346225738525391\n",
      "Time to compute expective valance: 0.06415367126464844\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.007123231887817383\n",
      "Time to compute expective valance: 0.06703352928161621\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.006512880325317383\n",
      "Time to compute expective valance: 2.759610176086426\n",
      "expected valence : -165.56 valence explo : 9.00 model predict : ['feel_front', 'empty', 'forward', 'wall', 'turn_right', 'empty', 'forward', 'empty', 'forward', 'empty'], explo want : ['turn_right', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['turn_right', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: turn_right \u001b[0m, Prediction: empty, Outcome: empty, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.006275177001953125\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: empty, Outcome: empty, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: empty, Outcome: empty, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: empty, Outcome: empty, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Time to compute expective valance: 0.4626932144165039\n",
      "expected valence : -302.40 valence explo : 18.00 model predict : ['forward', 'wall', 'forward', 'wall', 'forward', 'wall', 'feel_left', 'wall', 'feel_front', 'empty'], explo want : ['feel_front', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['feel_front', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: feel_front \u001b[0m, Prediction: empty, Outcome: empty, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.0063097476959228516\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Time to compute expective valance: 0.06671261787414551\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.007205009460449219\n",
      "Time to compute expective valance: 2.719228744506836\n",
      "expected valence : -155.34 valence explo : 18.00 model predict : ['feel_front', 'empty', 'forward', 'wall', 'turn_right', 'empty', 'forward', 'empty', 'forward', 'empty'], explo want : ['feel_right', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['feel_right', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: feel_right \u001b[0m, Prediction: empty, Outcome: empty, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.00735783576965332\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Time to compute expective valance: 1.5847649574279785\n",
      "expected valence : -145.48 valence explo : 18.00 model predict : ['feel_front', 'empty', 'forward', 'wall', 'turn_right', 'empty', 'forward', 'empty', 'forward', 'empty'], explo want : ['feel_left', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['feel_left', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: feel_left \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.0063478946685791016\n",
      "Time to compute expective valance: 0.06649470329284668\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.00622248649597168\n",
      "Time to compute expective valance: 1.9437434673309326\n",
      "expected valence : -141.81 valence explo : 18.00 model predict : ['feel_front', 'empty', 'forward', 'wall', 'turn_right', 'empty', 'forward', 'empty', 'forward', 'empty'], explo want : ['feel_left', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['feel_left', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: feel_left \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.006987571716308594\n",
      "Time to compute expective valance: 0.06662464141845703\n",
      "expected valence : -inf valence explo : 40.00 model predict : 0.0, explo want : ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.006257057189941406\n",
      "Time to compute expective valance: 2.466754913330078\n",
      "expected valence : -137.34 valence explo : 18.00 model predict : ['feel_front', 'empty', 'forward', 'wall', 'turn_right', 'empty', 'forward', 'empty', 'forward', 'empty'], explo want : ['feel_right', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['feel_right', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: feel_right \u001b[0m, Prediction: empty, Outcome: empty, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.00683140754699707\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Time to compute expective valance: 2.308082342147827\n",
      "expected valence : -133.63 valence explo : 18.00 model predict : ['feel_front', 'empty', 'forward', 'wall', 'turn_right', 'empty', 'forward', 'empty', 'forward', 'empty'], explo want : ['feel_right', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['feel_right', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: feel_right \u001b[0m, Prediction: empty, Outcome: empty, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.0067386627197265625\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Time to compute expective valance: 3.0743296146392822\n",
      "expected valence : -132.88 valence explo : 9.00 model predict : ['feel_front', 'empty', 'forward', 'wall', 'turn_right', 'empty', 'forward', 'empty', 'forward', 'empty'], explo want : ['turn_right', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['turn_right', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: turn_right \u001b[0m, Prediction: empty, Outcome: empty, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.007517814636230469\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: empty, Outcome: empty, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: empty, Outcome: empty, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: empty, Outcome: wall, \u001b[0;31m Satisfaction: False \u001b[0m\n",
      "Training time: 0.11633753776550293\n",
      "Time to compute expective valance: 0.9782781600952148\n",
      "expected valence : -225.96 valence explo : 18.00 model predict : ['forward', 'wall', 'forward', 'wall', 'turn_right', 'empty', 'forward', 'empty', 'forward', 'empty'], explo want : ['feel_front', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['feel_front', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty']\n",
      "\u001b[0;31m Action: feel_front \u001b[0m, Prediction: empty, Outcome: empty, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.08789396286010742\n",
      "\u001b[0;31m Action: forward \u001b[0m, Prediction: wall, Outcome: wall, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Time to compute expective valance: 4.386522054672241\n",
      "expected valence : -40.54 valence explo : 9.00 model predict : ['turn_right', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'feel_front', 'empty'], explo want : ['turn_right', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'feel_left', 'empty']\n",
      "\u001b[0;36m explo ... \u001b[0m ['turn_right', 'empty', 'forward', 'empty', 'forward', 'empty', 'forward', 'empty', 'feel_left', 'empty']\n"
     ]
    }
   ],
   "source": [
    "# torch.manual_seed(0)\n",
    "# np.random.seed(0)\n",
    "\n",
    "outcome = environenment.outcome(agent.action_choice)\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    action, predi = agent.action(outcome, verbose=True)\n",
    "    \n",
    "    outcome = environenment.outcome(action)\n",
    "    history_good.append(outcome == predi)\n",
    "    history_good_inter.append((action == 'forward' and outcome == 'empty'))\n",
    "    history_bad_inter.append((action == 'forward' and outcome == 'wall'))\n",
    "    hisrory_val.append(valence[inter(action, outcome)])\n",
    "    pourcent_by_10.append(sum(history_good[-10:]) if len(history_good) >= 10 else 0)\n",
    "    by_10_good_inter.append(sum(history_good_inter[-10:]) if len(history_good_inter) >= 10 else 0)\n",
    "    by_10_bad_inter.append(sum(history_bad_inter[-10:]) if len(history_bad_inter) >= 10 else 0)\n",
    "    mean_val.append(np.mean(hisrory_val[-10:]) / 10 if len(hisrory_val) >= 10 else 0)\n",
    "    environenment.save_world(path=\"imgToGif2\")\n",
    "    \n",
    "\n",
    "agent.prealloc_df.to_csv(\"prealloc_df.csv\")\n",
    "agent.visu_explo.to_csv(\"df_explo.csv\")\n",
    "\n",
    "pourcent_by_10 = pourcent_by_10[10:]\n",
    "by_10_good_inter = by_10_good_inter[10:]\n",
    "by_10_bad_inter = by_10_bad_inter[10:]\n",
    "mean_val = mean_val[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94a10bd8823405586d4878b2772842a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31m Action: turn_right \u001b[0m, Prediction: empty, Outcome: empty, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "Training time: 0.15497088432312012\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AgentLSTM' object has no attribute 'visu_val'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m action, predi \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39maction(outcome, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m df2 \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mprealloc_df\n\u001b[0;32m----> 4\u001b[0m df_val2 \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisu_val\u001b[49m\n\u001b[1;32m      5\u001b[0m df_explo2 \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mvisu_explo\n\u001b[1;32m      6\u001b[0m outcome \u001b[38;5;241m=\u001b[39m environenment\u001b[38;5;241m.\u001b[39moutcome(action)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AgentLSTM' object has no attribute 'visu_val'"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(200)):\n",
    "    action, predi = agent.action(outcome, verbose=True)\n",
    "    df2 = agent.prealloc_df\n",
    "    df_val2 = agent.visu_val\n",
    "    df_explo2 = agent.visu_explo\n",
    "    outcome = environenment.outcome(action)\n",
    "    history_good.append(outcome == predi)\n",
    "    history_good_inter.append((action == 'forward' and outcome == 'empty'))\n",
    "    history_bad_inter.append((action == 'forward' and outcome == 'wall'))\n",
    "    hisrory_val.append(valence[inter(action, outcome)])\n",
    "    pourcent_by_10.append(sum(history_good[-10:]) if len(history_good) >= 10 else 0)\n",
    "    by_10_good_inter.append(sum(history_good_inter[-10:]) if len(history_good_inter) >= 10 else 0)\n",
    "    by_10_bad_inter.append(sum(history_bad_inter[-10:]) if len(history_bad_inter) >= 10 else 0)\n",
    "    mean_val.append(np.mean(hisrory_val[-10:]) / 10 if len(hisrory_val) >= 10 else 0)\n",
    "    environenment.save_world(\"imgToGif2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "see_evolued_loss(agent.loss_train)\n",
    "see_evolued_loss(agent.loss_val)\n",
    "see_evolued_acc(agent.acc_train)\n",
    "see_evolued_acc(agent.acc_val)\n",
    "\n",
    "see_evolued_acc(agent.time_train)\n",
    "see_evolued_acc(agent.time_compute_expected_valence)\n",
    "\n",
    "def int_to_color(value):\n",
    "    if value == 0:\n",
    "        return \"yellow\"\n",
    "    return \"gray\"\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i, value in enumerate(agent.predictExplo):\n",
    "    ax.add_patch(plt.Rectangle((i, 0), width=0, height=10, color=int_to_color(value), alpha=0.4))\n",
    "\n",
    "# Plot the data\n",
    "plt.plot(by_10_bad_inter, label='bad inter', color='red')\n",
    "plt.plot(by_10_good_inter, label='good inter', color='green')\n",
    "plt.plot(pourcent_by_10, label='global', color='blue')\n",
    "plt.plot(mean_val, label='mean valence', color='black')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as py\n",
    "\n",
    "# Get weights\n",
    "embds = agent.model.embedding.weight.detach().cpu().numpy()\n",
    "\n",
    "# Plotting function\n",
    "def plot_words(data, start, stop, step):\n",
    "    trace = go.Scatter(\n",
    "        x = data[start:stop:step, 0], \n",
    "        y = data[start:stop:step, 1],\n",
    "        mode = 'markers',\n",
    "        text = [tokenizer.decode(i) for i in range(start, stop, step)]\n",
    "    )\n",
    "    layout = dict(title= 't-SNE 1 vs t-SNE 2',\n",
    "                  yaxis = dict(title='t-SNE 2'),\n",
    "                  xaxis = dict(title='t-SNE 1'),\n",
    "                  hovermode= 'closest')\n",
    "    fig = dict(data = [trace], layout= layout)\n",
    "    py.iplot(fig)\n",
    "\n",
    "# Visualize words in two dimensions \n",
    "# Set perplexity to a value less than the number of samples\n",
    "perplexity_value = min(30, len(embds) - 1)  # Ensure perplexity is less than the number of samples\n",
    "conv_tsne_embds = TSNE(n_components=2, perplexity=5).fit_transform(embds)\n",
    "plot_words(conv_tsne_embds, 0, len(embds), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Stage (torch)",
   "language": "python",
   "name": "dpt_transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
