{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d59b7cdc-406b-4a5f-b3c4-a72fd97bf7b2",
   "metadata": {},
   "source": [
    "# COMPARAISON DNN - LSTM \n",
    "\n",
    "Notebook généré par ChatGPT à partir du prompt :\n",
    "\n",
    "`Quel est l'avantage des LSTM plutot qu'un simple DNN pour classifier des séquences ?.`\n",
    "\n",
    "https://chatgpt.com/share/68021a99-a804-8012-92d7-6d621f1642a0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0b3e6b",
   "metadata": {},
   "source": [
    "\n",
    "# 🧠 Comparaison entre DNN et LSTM pour la classification de séquences\n",
    "\n",
    "Ce notebook montre pourquoi un **LSTM** est souvent **plus adapté qu’un réseau dense (DNN)** pour des tâches de **classification de séquences**, surtout quand l’ordre des éléments est important.\n",
    "\n",
    "## 🎯 Objectif :\n",
    "Créer deux modèles :\n",
    "- Un **DNN** (réseau entièrement connecté) qui ne tient pas compte de l’ordre.\n",
    "- Un **LSTM** qui prend en compte la structure séquentielle.\n",
    "\n",
    "On comparera leurs performances sur deux tâches :\n",
    "1. Classification basée sur la somme des éléments (pas de dépendance à la position).\n",
    "2. Classification basée sur des critères **positionnels**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c281aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d9f2a4",
   "metadata": {},
   "source": [
    "## 📦 Définition du modèle DNN (entrée aplatie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e98c40fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DNNClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(5, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))  # x: [batch_size, 5]\n",
    "        return self.fc2(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d169eb",
   "metadata": {},
   "source": [
    "## 🔁 Définition du modèle LSTM (entrée séquentielle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fac543e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=16, batch_first=True)\n",
    "        self.fc = nn.Linear(16, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (hn, _) = self.lstm(x)  # hn: [1, batch_size, hidden_size]\n",
    "        return self.fc(hn.squeeze(0))  # [batch_size, 2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd1fb7e",
   "metadata": {},
   "source": [
    "## 🧪 Génération de données (tâche simple - somme des éléments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a267160a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_batch(batch_size=32):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for _ in range(batch_size):\n",
    "        seq = torch.rand(5)\n",
    "        label = 1 if seq.sum() > 2 else 0\n",
    "        data.append(seq)\n",
    "        labels.append(label)\n",
    "    return torch.stack(data), torch.tensor(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a6582e",
   "metadata": {},
   "source": [
    "## 🔄 Génération de données (tâche positionnelle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e53525c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_positional_batch(batch_size=32):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for _ in range(batch_size):\n",
    "        seq = torch.rand(5)\n",
    "        condition = (seq[0] > 0.8) and (seq[-1] + seq[-2] < 0.5)\n",
    "        label = 1 if condition else 0\n",
    "        data.append(seq)\n",
    "        labels.append(label)\n",
    "    return torch.stack(data), torch.tensor(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a42d7e9",
   "metadata": {},
   "source": [
    "## 🏋️‍♂️ Fonction d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64807c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, is_lstm=False, use_positional_data=False, epochs=30):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        if use_positional_data:\n",
    "            X, y = generate_positional_batch()\n",
    "        else:\n",
    "            X, y = generate_batch()\n",
    "\n",
    "        if is_lstm:\n",
    "            X = X.unsqueeze(2)  # [batch, seq_len, features]\n",
    "\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc = (outputs.argmax(1) == y).float().mean().item()\n",
    "        print(f\"Epoch {epoch+1:02d} - Loss: {loss.item():.4f} - Acc: {acc*100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0e9bb9",
   "metadata": {},
   "source": [
    "## 🚀 Testons sur les deux tâches !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae5eeed",
   "metadata": {},
   "source": [
    "### 🧪 Tâche 1 : somme des éléments — avec DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20ccc011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 - Loss: 0.7257 - Acc: 21.9%\n",
      "Epoch 02 - Loss: 0.6716 - Acc: 78.1%\n",
      "Epoch 03 - Loss: 0.6254 - Acc: 75.0%\n",
      "Epoch 04 - Loss: 0.6126 - Acc: 68.8%\n",
      "Epoch 05 - Loss: 0.5607 - Acc: 71.9%\n",
      "Epoch 06 - Loss: 0.5914 - Acc: 62.5%\n",
      "Epoch 07 - Loss: 0.3303 - Acc: 96.9%\n",
      "Epoch 08 - Loss: 0.3599 - Acc: 87.5%\n",
      "Epoch 09 - Loss: 0.3783 - Acc: 84.4%\n",
      "Epoch 10 - Loss: 0.6570 - Acc: 62.5%\n",
      "Epoch 11 - Loss: 0.4452 - Acc: 78.1%\n",
      "Epoch 12 - Loss: 0.2683 - Acc: 90.6%\n",
      "Epoch 13 - Loss: 0.4258 - Acc: 81.2%\n",
      "Epoch 14 - Loss: 0.5497 - Acc: 71.9%\n",
      "Epoch 15 - Loss: 0.4045 - Acc: 81.2%\n",
      "Epoch 16 - Loss: 0.4592 - Acc: 78.1%\n",
      "Epoch 17 - Loss: 0.5258 - Acc: 75.0%\n",
      "Epoch 18 - Loss: 0.4028 - Acc: 81.2%\n",
      "Epoch 19 - Loss: 0.4519 - Acc: 78.1%\n",
      "Epoch 20 - Loss: 0.3337 - Acc: 84.4%\n",
      "Epoch 21 - Loss: 0.5388 - Acc: 71.9%\n",
      "Epoch 22 - Loss: 0.4399 - Acc: 78.1%\n",
      "Epoch 23 - Loss: 0.2806 - Acc: 87.5%\n",
      "Epoch 24 - Loss: 0.2934 - Acc: 87.5%\n",
      "Epoch 25 - Loss: 0.4167 - Acc: 78.1%\n",
      "Epoch 26 - Loss: 0.5127 - Acc: 71.9%\n",
      "Epoch 27 - Loss: 0.4266 - Acc: 75.0%\n",
      "Epoch 28 - Loss: 0.6511 - Acc: 59.4%\n",
      "Epoch 29 - Loss: 0.5447 - Acc: 65.6%\n",
      "Epoch 30 - Loss: 0.3828 - Acc: 81.2%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dnn = DNNClassifier()\n",
    "train(dnn, is_lstm=False, use_positional_data=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c9b7f5",
   "metadata": {},
   "source": [
    "### 🧪 Tâche 1 : somme des éléments — avec LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87ba878b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 - Loss: 0.6394 - Acc: 71.9%\n",
      "Epoch 02 - Loss: 0.6003 - Acc: 78.1%\n",
      "Epoch 03 - Loss: 0.6277 - Acc: 68.8%\n",
      "Epoch 04 - Loss: 0.5781 - Acc: 75.0%\n",
      "Epoch 05 - Loss: 0.4881 - Acc: 84.4%\n",
      "Epoch 06 - Loss: 0.5873 - Acc: 71.9%\n",
      "Epoch 07 - Loss: 0.5130 - Acc: 78.1%\n",
      "Epoch 08 - Loss: 0.4281 - Acc: 84.4%\n",
      "Epoch 09 - Loss: 0.4169 - Acc: 84.4%\n",
      "Epoch 10 - Loss: 0.6642 - Acc: 71.9%\n",
      "Epoch 11 - Loss: 0.7102 - Acc: 68.8%\n",
      "Epoch 12 - Loss: 0.4671 - Acc: 81.2%\n",
      "Epoch 13 - Loss: 0.5538 - Acc: 75.0%\n",
      "Epoch 14 - Loss: 0.5931 - Acc: 71.9%\n",
      "Epoch 15 - Loss: 0.5827 - Acc: 71.9%\n",
      "Epoch 16 - Loss: 0.4334 - Acc: 84.4%\n",
      "Epoch 17 - Loss: 0.5759 - Acc: 71.9%\n",
      "Epoch 18 - Loss: 0.5322 - Acc: 75.0%\n",
      "Epoch 19 - Loss: 0.4878 - Acc: 81.2%\n",
      "Epoch 20 - Loss: 0.5877 - Acc: 68.8%\n",
      "Epoch 21 - Loss: 0.5338 - Acc: 75.0%\n",
      "Epoch 22 - Loss: 0.5075 - Acc: 78.1%\n",
      "Epoch 23 - Loss: 0.4867 - Acc: 81.2%\n",
      "Epoch 24 - Loss: 0.4948 - Acc: 78.1%\n",
      "Epoch 25 - Loss: 0.4776 - Acc: 78.1%\n",
      "Epoch 26 - Loss: 0.3794 - Acc: 87.5%\n",
      "Epoch 27 - Loss: 0.3605 - Acc: 87.5%\n",
      "Epoch 28 - Loss: 0.4236 - Acc: 81.2%\n",
      "Epoch 29 - Loss: 0.4830 - Acc: 78.1%\n",
      "Epoch 30 - Loss: 0.4761 - Acc: 78.1%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lstm = LSTMClassifier()\n",
    "train(lstm, is_lstm=True, use_positional_data=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402fc443",
   "metadata": {},
   "source": [
    "### 🧪 Tâche 2 : dépendance à la position — avec DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18c22218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 - Loss: 0.6156 - Acc: 100.0%\n",
      "Epoch 02 - Loss: 0.5265 - Acc: 100.0%\n",
      "Epoch 03 - Loss: 0.4454 - Acc: 100.0%\n",
      "Epoch 04 - Loss: 0.3879 - Acc: 96.9%\n",
      "Epoch 05 - Loss: 0.3269 - Acc: 96.9%\n",
      "Epoch 06 - Loss: 0.2392 - Acc: 100.0%\n",
      "Epoch 07 - Loss: 0.2380 - Acc: 96.9%\n",
      "Epoch 08 - Loss: 0.2072 - Acc: 96.9%\n",
      "Epoch 09 - Loss: 0.1050 - Acc: 100.0%\n",
      "Epoch 10 - Loss: 0.1568 - Acc: 96.9%\n",
      "Epoch 11 - Loss: 0.0687 - Acc: 100.0%\n",
      "Epoch 12 - Loss: 0.1275 - Acc: 96.9%\n",
      "Epoch 13 - Loss: 0.0292 - Acc: 100.0%\n",
      "Epoch 14 - Loss: 0.2523 - Acc: 93.8%\n",
      "Epoch 15 - Loss: 0.1282 - Acc: 96.9%\n",
      "Epoch 16 - Loss: 0.1308 - Acc: 96.9%\n",
      "Epoch 17 - Loss: 0.5318 - Acc: 87.5%\n",
      "Epoch 18 - Loss: 0.0102 - Acc: 100.0%\n",
      "Epoch 19 - Loss: 0.0139 - Acc: 100.0%\n",
      "Epoch 20 - Loss: 0.0086 - Acc: 100.0%\n",
      "Epoch 21 - Loss: 0.0108 - Acc: 100.0%\n",
      "Epoch 22 - Loss: 0.1483 - Acc: 96.9%\n",
      "Epoch 23 - Loss: 0.1459 - Acc: 96.9%\n",
      "Epoch 24 - Loss: 0.1491 - Acc: 96.9%\n",
      "Epoch 25 - Loss: 0.0077 - Acc: 100.0%\n",
      "Epoch 26 - Loss: 0.1427 - Acc: 96.9%\n",
      "Epoch 27 - Loss: 0.1306 - Acc: 96.9%\n",
      "Epoch 28 - Loss: 0.1321 - Acc: 96.9%\n",
      "Epoch 29 - Loss: 0.1267 - Acc: 96.9%\n",
      "Epoch 30 - Loss: 0.0064 - Acc: 100.0%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dnn = DNNClassifier()\n",
    "train(dnn, is_lstm=False, use_positional_data=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fe12e9",
   "metadata": {},
   "source": [
    "### 🧪 Tâche 2 : dépendance à la position — avec LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f0b47bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 - Loss: 0.7287 - Acc: 3.1%\n",
      "Epoch 02 - Loss: 0.6830 - Acc: 93.8%\n",
      "Epoch 03 - Loss: 0.6387 - Acc: 93.8%\n",
      "Epoch 04 - Loss: 0.5939 - Acc: 93.8%\n",
      "Epoch 05 - Loss: 0.5209 - Acc: 100.0%\n",
      "Epoch 06 - Loss: 0.4763 - Acc: 96.9%\n",
      "Epoch 07 - Loss: 0.3981 - Acc: 100.0%\n",
      "Epoch 08 - Loss: 0.3336 - Acc: 100.0%\n",
      "Epoch 09 - Loss: 0.3032 - Acc: 96.9%\n",
      "Epoch 10 - Loss: 0.2507 - Acc: 96.9%\n",
      "Epoch 11 - Loss: 0.1563 - Acc: 100.0%\n",
      "Epoch 12 - Loss: 0.1128 - Acc: 100.0%\n",
      "Epoch 13 - Loss: 0.0757 - Acc: 100.0%\n",
      "Epoch 14 - Loss: 0.0521 - Acc: 100.0%\n",
      "Epoch 15 - Loss: 0.1369 - Acc: 96.9%\n",
      "Epoch 16 - Loss: 0.1393 - Acc: 96.9%\n",
      "Epoch 17 - Loss: 0.1412 - Acc: 96.9%\n",
      "Epoch 18 - Loss: 0.0129 - Acc: 100.0%\n",
      "Epoch 19 - Loss: 0.1541 - Acc: 96.9%\n",
      "Epoch 20 - Loss: 0.1593 - Acc: 96.9%\n",
      "Epoch 21 - Loss: 0.4723 - Acc: 90.6%\n",
      "Epoch 22 - Loss: 0.1637 - Acc: 96.9%\n",
      "Epoch 23 - Loss: 0.3227 - Acc: 93.8%\n",
      "Epoch 24 - Loss: 0.0064 - Acc: 100.0%\n",
      "Epoch 25 - Loss: 0.0067 - Acc: 100.0%\n",
      "Epoch 26 - Loss: 0.0065 - Acc: 100.0%\n",
      "Epoch 27 - Loss: 0.0066 - Acc: 100.0%\n",
      "Epoch 28 - Loss: 0.0066 - Acc: 100.0%\n",
      "Epoch 29 - Loss: 0.0066 - Acc: 100.0%\n",
      "Epoch 30 - Loss: 0.0065 - Acc: 100.0%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lstm = LSTMClassifier()\n",
    "train(lstm, is_lstm=True, use_positional_data=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcb5c18-df21-433c-8ae6-7b5f121ef0a9",
   "metadata": {},
   "source": [
    "# Evaluons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0506e706-22d4-4251-a7e2-d4642be10ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, is_lstm=False):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_test, y_test = generate_positional_batch()\n",
    "        if is_lstm:\n",
    "            X_test = X_test.unsqueeze(2)\n",
    "\n",
    "        outputs = model(X_test)\n",
    "        acc = (outputs.argmax(1) == y_test).float().mean().item()\n",
    "        print(f\"✅ Test Accuracy: {acc * 100:.2f}%\")\n",
    "    model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3fcace9-6f6d-4da7-be5c-6185f1f703d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Test Accuracy: 96.88%\n"
     ]
    }
   ],
   "source": [
    "evaluate(dnn, is_lstm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43c47193-bfb0-4b67-bc15-efa2aa6af92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Test Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "evaluate(lstm, is_lstm=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0c34f1-716a-48bc-8fbd-175c8a5befe5",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Le modèle LSTM est censé mieux fonctionner pour classer les séquence selon un critère dans lequel l'ordre est important mais ce n'est pas visible dans cet exemple. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bada5f-db25-4501-87e3-16c846109afc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
