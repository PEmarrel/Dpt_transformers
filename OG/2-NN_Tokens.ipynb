{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9834986-aeda-4d68-915a-b8ac06c0d821",
   "metadata": {},
   "source": [
    "# RESEAU DE NEURONES POUR PREDICTION DE TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461dc2b7-95d8-4cdd-aa91-0b46160d9a48",
   "metadata": {},
   "source": [
    "Dans ce tutoriel nous utilisons deux sorties pour prédire la probabilité des tokens `0` ou `1`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a4ed3b-fee2-4b83-b84d-796c5d855496",
   "metadata": {},
   "source": [
    "# On crée le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3988795-fb33-4960-86ec-a77691114669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Define a neural network with two outputs (representing token probabilities)\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear = nn.Linear(1, 2)  # One inputs → Two outputs (for two tokens)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)  # No softmax here (included in loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fd48683-f4ee-4167-ba61-65104a5a030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf5a223-bc0b-439f-92df-e12933064401",
   "metadata": {},
   "source": [
    "# On définit les paramètres d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7459,
   "id": "f70661bc-6dec-4884-a864-5a07479ed00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7460,
   "id": "1e0b948e-c632-432b-8e92-8b13c4a89189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Cross-entropy for classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)  # Adam optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa60a6f-69d7-4da6-b71b-99612c4f7131",
   "metadata": {},
   "source": [
    "# La fonction fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7461,
   "id": "36cef7fc-85a1-464a-b7ab-b8298ebb6250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def fit(input, target):\n",
    "    input_tensor = torch.tensor(input, dtype=torch.float)\n",
    "    target_tensor = torch.tensor(target, dtype=torch.long)\n",
    "    labels = torch.nn.functional.one_hot(target_tensor, num_classes=2).to(torch.float)\n",
    "    #labels = torch.argmax(target_tensor, dim=1)  # Convert one-hot to class indices\n",
    "\n",
    "    optimizer.zero_grad()  # Reset gradients\n",
    "    outputs = model(input_tensor)  # Forward pass\n",
    "    loss = criterion(outputs, labels)  # Compute loss\n",
    "    loss.backward()  # Backpropagation\n",
    "    optimizer.step()  # Update weights\n",
    "\n",
    "    print(f\"Loss: {loss.item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6948bcfd-e0a3-4c39-8046-da04708491be",
   "metadata": {},
   "source": [
    "# On entraine le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f65ad6-3088-484b-a7f3-eb6e6fc791b1",
   "metadata": {},
   "source": [
    "Entrainer jusqu'a avoir une loss < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7462,
   "id": "ec36e57d-0229-4f64-8ff7-0bfb968eb703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.769202\n",
      "Loss: 1.099631\n"
     ]
    }
   ],
   "source": [
    "fit([2], 1)\n",
    "fit([3], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b897b4-310a-43ce-9138-2f05383f1c02",
   "metadata": {},
   "source": [
    "# La fonction predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7463,
   "id": "8248b22d-69fb-409a-b554-9ae7770f1572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input):\n",
    "    input_tensor = torch.tensor(input, dtype=torch.float)\n",
    "    output_tensor = model(input_tensor)\n",
    "    print(\"logits:\", output_tensor.detach().numpy())\n",
    "    probs = torch.nn.functional.softmax(output_tensor, dim=0)  # Convert logits to probabilities\n",
    "    print(\"probabilités:\", probs.detach().numpy())\n",
    "    return torch.argmax(output_tensor, dim=0).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7464,
   "id": "e2e20fff-1c64-45de-b7c3-1f58e4f83738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits: [0.6245817  0.91014135]\n",
      "probabilités: [0.42909127 0.5709087 ]\n",
      "Prediction pour 2: 1\n",
      "logits: [0.87807   1.3371849]\n",
      "probabilités: [0.3871958 0.6128042]\n",
      "Prediction pour 3: 1\n"
     ]
    }
   ],
   "source": [
    "predicted_outcome = predict([2])\n",
    "print(\"Prediction pour 2:\", predicted_outcome)\n",
    "predicted_outcome = predict([3])\n",
    "print(\"Prediction pour 3:\", predicted_outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75525d02-48b6-4a7e-a22c-c2536102ddea",
   "metadata": {},
   "source": [
    "# TEST MODELE AVEC DEUX ENTREES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7465,
   "id": "cd146045-7068-4d3b-a0df-19acb6dfb9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a neural network with two outputs (representing token probabilities)\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear = nn.Linear(2, 2)  # Two inputs → Two outputs (for two tokens)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)  # No softmax here (included in loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7466,
   "id": "fdcb118d-59ee-4145-9afd-52e154efb9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)  # Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7467,
   "id": "e0179222-36c2-4fb7-8d19-d02a4bdcfc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.307905\n",
      "Loss: 0.118523\n",
      "Loss: 0.612002\n",
      "Loss: 1.232157\n"
     ]
    }
   ],
   "source": [
    "fit([2, 2], 0)\n",
    "fit([2, 3], 1)\n",
    "fit([3, 2], 1)\n",
    "fit([3, 3], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf25addf-8154-41ae-bec6-bbf05294dc13",
   "metadata": {},
   "source": [
    "On voit que la loss se stabilise vers 0.7. Le modèle n'apprend pas correctement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7455,
   "id": "a772025d-6a40-417e-acd4-23f08e5b7cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits: [ 0.00850408 -0.23773761]\n",
      "probabilités: [0.5612512  0.43874875]\n",
      "Prediction pour 2: 0\n",
      "logits: [-0.07946078  0.16243005]\n",
      "probabilités: [0.4398204  0.56017953]\n",
      "Prediction pour 3: 1\n",
      "logits: [-0.44530684  0.19091642]\n",
      "probabilités: [0.34610078 0.65389925]\n",
      "Prediction pour 2: 1\n",
      "logits: [ 0.07588916 -0.33085382]\n",
      "probabilités: [0.60030663 0.39969334]\n",
      "Prediction pour 3: 0\n"
     ]
    }
   ],
   "source": [
    "predicted_outcome = predict([2, 2])\n",
    "print(\"Prediction pour 2:\", predicted_outcome)\n",
    "predicted_outcome = predict([2, 3])\n",
    "print(\"Prediction pour 3:\", predicted_outcome)\n",
    "predicted_outcome = predict([3, 2])\n",
    "print(\"Prediction pour 2:\", predicted_outcome)\n",
    "predicted_outcome = predict([3, 3])\n",
    "print(\"Prediction pour 3:\", predicted_outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ea08d8-24c7-4f85-afd2-3ef67ce37187",
   "metadata": {},
   "source": [
    "Les probabilités sont proches de 0.5 et les prédictions sont erronnées. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80983ab4-a37e-4e43-8a77-31332b3684e1",
   "metadata": {},
   "source": [
    "# TEST MODELE AVEC UNE COUCHE CACHEE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eff54b4-9107-4f99-8e28-54fcbaa1dbb3",
   "metadata": {},
   "source": [
    "Modèle avec une couche cachée.\n",
    "\n",
    "6 neurones cachés semble un bon compromis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12217,
   "id": "9ea8d9bc-cd69-46e0-abd5-3db95a931718",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 6)\n",
    "        self.fc2 = nn.Linear(6, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.fc1(x))  # Apply non-linearity\n",
    "        return self.fc2(x)  # Logits (CrossEntropyLoss handles softmax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e97ce1a-64d9-401d-bf78-1e73e3473fb1",
   "metadata": {},
   "source": [
    "ChatGPT recommande d'utiliser SGD optimizer (Stochasit Gradient Descent, best for online training).\n",
    "\n",
    "Learning rate de 0.2 semble le mieux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12218,
   "id": "135476ca-c317-4c31-ac5d-0e525677acc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.2)  # SGD optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad65591-0af7-4856-b90b-656df0b715bb",
   "metadata": {},
   "source": [
    "On calcule l'accuracy après chaque passe d'entrainement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12219,
   "id": "2a200cab-1c3f-4de8-9f26-14f22a3191ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(inputs, targets):\n",
    "    input_tensor = torch.tensor(inputs, dtype=torch.float)\n",
    "    # input_tensor = torch.randn_like(input_tensor) * 0.01 (voir si le modèle apprend des tendances)\n",
    "    target_tensor = torch.tensor(targets, dtype=torch.long)\n",
    "    labels = torch.nn.functional.one_hot(target_tensor, num_classes=2).to(torch.float)\n",
    "    #labels = torch.argmax(target_tensor, dim=1)  # Convert one-hot to class indices\n",
    "\n",
    "    optimizer.zero_grad()  # Reset gradients\n",
    "    outputs = model(input_tensor)  # Forward pass\n",
    "    loss = criterion(outputs, labels)  # Compute loss\n",
    "    loss.backward()  # Backpropagation\n",
    "    optimizer.step()  # Update weights\n",
    "\n",
    "    # Check accuracy (we expect 100% accuracy)\n",
    "    predictions = torch.argmax(outputs, dim=1)\n",
    "    accuracy = (predictions == target_tensor).float().mean().item()\n",
    "\n",
    "    print(f\"Loss: {loss.item():.6f}, Accuracy: {accuracy * 100:.0f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673860c1-d633-4bbb-b8dd-50b2aa47a287",
   "metadata": {},
   "source": [
    "Entrainer le modèle jusqu'a obtenir une accuracy de 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12220,
   "id": "1568b236-37bf-4f6f-b08d-a0d4be404da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12441,
   "id": "9c37ae04-8181-4efd-8e66-1ac957d22534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 221\n",
      "Loss: 0.050310, Accuracy: 100%\n"
     ]
    }
   ],
   "source": [
    "print(\"Iteration:\", iteration)\n",
    "fit([[2, 2], [2, 3], [3, 2],[3, 3]], [0, 1, 1, 0])\n",
    "iteration += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1612ca99-8189-4fdc-ad96-122b7544d459",
   "metadata": {},
   "source": [
    "On atteint une accuracy de 100% la plupart des fois en moins de 200 iterations avec 6 neurones cachés. \n",
    "Il reste cependant des fois ou il ne converge pas.\n",
    "\n",
    "4 neurones semblent insuffisant, 8 semblent trop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3498ae7d-9d2d-40c2-bea6-be0eb73e7e90",
   "metadata": {},
   "source": [
    "On atteint une accuracy de 100% la plupart des fois en moins de 200 iterations avec 6 neurones cachés. \n",
    "Cependant, certaines fois il ne converge pas.\n",
    "\n",
    "4 neurones semblent insuffisant, 8 semblent trop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0713b3c6-ec80-4ac5-87df-9c4f9ab5450a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
