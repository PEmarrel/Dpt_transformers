{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9834986-aeda-4d68-915a-b8ac06c0d821",
   "metadata": {},
   "source": [
    "# RESEAU DE NEURONE PROFOND POUR HISTORIQUE T-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d5f463-59d4-40dc-a0e6-68f3d4fb1222",
   "metadata": {},
   "source": [
    "Le modèle a trois entrées: previous_action, previous_outcome, action.  Mais le previous outcome ne change pas la prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e6f2a1-5b5c-4447-897a-0533bc65003e",
   "metadata": {},
   "source": [
    "# On crée le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e7e629-1698-4602-8596-bba03afa8c1a",
   "metadata": {},
   "source": [
    "On initialise la seed pytorch CPU pour reproductibilité de l'entrainement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1294,
   "id": "4e13c8b7-622d-4cdd-9859-68713c032a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1c12155f7f0>"
      ]
     },
     "execution_count": 1294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eff54b4-9107-4f99-8e28-54fcbaa1dbb3",
   "metadata": {},
   "source": [
    "Modèle avec une couche cachée.\n",
    "\n",
    "L'initialisation poids et bias des layers facilite beaucoup l'apprentissage !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1295,
   "id": "9ea8d9bc-cd69-46e0-abd5-3db95a931718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 6)\n",
    "        # Apply He Initialization recommended for ReLU\n",
    "        nn.init.kaiming_normal_(self.fc1.weight, mode='fan_in', nonlinearity='relu')\n",
    "        \n",
    "        self.fc2 = nn.Linear(6, 2)\n",
    "        # Apply Xavier initialisation recommended for linear activation\n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        nn.init.zeros_(self.fc2.bias)  # Biases are usually set to zero\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.fc1(x))  # Apply non-linearity\n",
    "        return self.fc2(x)  # Logits (CrossEntropyLoss handles softmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1296,
   "id": "d8b689a6-39d9-43b1-860b-2414472e9562",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7305b56a-0919-48ce-adc4-85a40b416b82",
   "metadata": {},
   "source": [
    "# On définit les paramètres d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1297,
   "id": "135476ca-c317-4c31-ac5d-0e525677acc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # Cross-entropy for classification\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.3)  # SGD optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292bdeed-4934-4a2b-94cd-8a3d93a82385",
   "metadata": {},
   "source": [
    "# La fonction fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1298,
   "id": "2a200cab-1c3f-4de8-9f26-14f22a3191ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(inputs, targets):\n",
    "    input_tensor = torch.tensor(inputs, dtype=torch.float)\n",
    "    # input_tensor = torch.randn_like(input_tensor) * 0.01 (voir si le modèle apprend des tendances)\n",
    "    target_tensor = torch.tensor(targets, dtype=torch.long)\n",
    "    labels = torch.nn.functional.one_hot(target_tensor, num_classes=2).to(torch.float)\n",
    "    #labels = torch.argmax(target_tensor, dim=1)  # Convert one-hot to class indices\n",
    "\n",
    "    optimizer.zero_grad()  # Reset gradients\n",
    "    outputs = model(input_tensor)  # Forward pass\n",
    "    loss = criterion(outputs, labels)  # Compute loss\n",
    "    loss.backward()  # Backpropagation\n",
    "    optimizer.step()  # Update weights\n",
    "\n",
    "    # Check accuracy (we expect 100% accuracy)\n",
    "    predictions = torch.argmax(outputs, dim=1)\n",
    "    accuracy = (predictions == target_tensor).float().mean().item()\n",
    "\n",
    "    print(f\"Loss: {loss.item():.6f}, Accuracy: {accuracy * 100:.0f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575d229a-6a16-499b-bfa9-0eeda8fee8e5",
   "metadata": {},
   "source": [
    "# On entraine le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1299,
   "id": "1568b236-37bf-4f6f-b08d-a0d4be404da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1340,
   "id": "4cb50ab1-08e1-488c-bcaf-e1b1519a81ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 41\n",
      "Loss: 0.282971, Accuracy: 100%\n"
     ]
    }
   ],
   "source": [
    "print(\"Iteration:\", iteration)\n",
    "fit([[2, 0, 2], [2, 0, 3], [3, 0, 2],[3, 0, 3], [2, 1, 2], [2, 1, 3], [3, 1, 2],[3, 1, 3]], [0, 1, 1, 0, 0, 1, 1, 0])\n",
    "iteration += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1450550-a130-414b-bcf2-ad3a72b7ac05",
   "metadata": {},
   "source": [
    "On obtient souvent une accuracy de 100% apres environ 100 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83696d85-6aaf-484c-acb1-0dba0380548d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
