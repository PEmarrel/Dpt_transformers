{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following file was inspired by the following tutorial:\n",
    "# https://colab.research.google.com/drive/1SiF0KZJp75rUeetKOWqpsA8clmHP6jMg?usp=sharing#scrollTo=d7utFz27cO9q\n",
    "\n",
    "# And use this cource for explanation:\n",
    "# https://bruno-yun.notion.site/The-Transformer-Model-for-NLG-c4413bd5a8044325a7658cb8ff5535f2\n",
    "# https://web.stanford.edu/~jurafsky/slp3/9.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.metadata import version\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from matplotlib import pyplot as plt\n",
    "from graphviz import Digraph\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from environnement.environnement1 import Environnement1 as env1\n",
    "from environnement.environnement2Str import Environnement2 as env2Str\n",
    "from environnement.environnement3Str import Environnement3 as env3Str\n",
    "from environnement.environnement6Str import Environnement6 as env6Str\n",
    "\n",
    "from environnement.small_loop import small_loop\n",
    "\n",
    "from inter.interactions import Interaction as inter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intro, bla bla bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporaire\n",
    "VOCAB_SIZE = 2 # For now we are only using binary data (0, 1) later can be modify by 12\n",
    "CONTEXT_LENGHT = 3 # And we are using a context of 3 bits (may be changed later)\n",
    "device = \"cpu\" if not torch.cuda.is_available() else \"cuda\"\n",
    "# device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads,\n",
    "                 qkv_bias = False, device = 'cpu'):\n",
    "        \n",
    "        super().__init__()\n",
    "        assert(d_out % num_heads == 0), \"d_out should be divisible by num_heads\"\n",
    "        \n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "        \n",
    "        # self.W_query = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
    "        # self.W_key = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
    "        # self.W_value = nn.Linear(d_in, d_out, bias = qkv_bias) \n",
    "        # Don't use this because we want to have only one projection to optimize\n",
    "        # To have only one projection we use the following line\n",
    "        self.W_qkv = nn.Linear(d_in, 3 * d_out, bias=qkv_bias).to(device)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout).to(device)\n",
    "        self.out_proj = nn.Linear(d_out, d_out).to(device)\n",
    "        # If we want to see past\n",
    "        mask = torch.triu(torch.ones(context_length,context_length), diagonal=1).to(device)\n",
    "        \n",
    "        # if we want to see future\n",
    "        # mask = torch.tril(torch.ones(context_length,context_length), diagonal=-1).to(device)\n",
    "        \n",
    "        # If we want to see all the context\n",
    "        # mask = torch.zeros(context_length, context_length, device=device)\n",
    "        self.register_buffer('mask', mask)\n",
    "        \n",
    "    def forward(self,x: torch.Tensor):\n",
    "        queries: torch.Tensor\n",
    "        keys: torch.Tensor\n",
    "        values: torch.Tensor\n",
    "        b, num_tokens, d_in = x.shape # b, num_token, d_in\n",
    "\n",
    "        # self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        # self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        # self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        # Use one projection to get queries, keys and values\n",
    "        # self.W_qkv(x) -> b, num_token, 3*d_out (is a tensor)\n",
    "        # chunk(3, dim=-1) -> b, num_token, d_out we split the tensor in 3 parts\n",
    "        queries, keys, values= self.W_qkv(x).chunk(3, dim=-1)\n",
    "        \n",
    "        # b, num_token, numheads, head_dim\n",
    "        queries = queries.reshape(b,\n",
    "                                num_tokens,\n",
    "                                self.num_heads,\n",
    "                                self.head_dim\n",
    "                            ).transpose(1, 2)\n",
    "        keys = keys.reshape(b,\n",
    "                            num_tokens,\n",
    "                            self.num_heads,\n",
    "                            self.head_dim\n",
    "                        ).transpose(1, 2)\n",
    "        values = values.reshape(b,\n",
    "                                num_tokens,\n",
    "                                self.num_heads,\n",
    "                                self.head_dim\n",
    "                            ).transpose(1, 2)\n",
    "        \n",
    "        # b, num_heads, num_token, num_token\n",
    "        attn_scores = torch.einsum('bhqd, bhkd -> bhqk', queries, keys)\n",
    "        \n",
    "        attn_scores = attn_scores.masked_fill(\n",
    "            self.mask[:num_tokens, :num_tokens].unsqueeze(0).unsqueeze(0).bool() == 1, \n",
    "            float('-inf')\n",
    "        )\n",
    "\n",
    "        attn_weights = nn.functional.softmax(attn_scores, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        \n",
    "        context = torch.einsum('bhqk, bhkd -> bhqd', \n",
    "                               attn_weights, \n",
    "                               values\n",
    "                            ).transpose(1, 2).reshape(b, num_tokens, self.d_out)\n",
    "        \n",
    "        \n",
    "        return self.out_proj(context)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explain of class MultiHeadAttention\n",
    "In transformers model, the **MultiHeadAttention** class is used to apply attention mechanisms to input sequences. Understanding how this class works requires first exploring **single-head** attention before generalizing to **multi-head attention**.\n",
    "\n",
    "## Single-Head Attention\n",
    "Attention in Transformers relies on measuring the similarity between tokens in a sequence. This measurement is performed using three distinct transformations:\n",
    "\n",
    "- Query (Q): Represents the current tokenâ€™s focus when comparing it to all other tokens.\n",
    "- Key (K): Represents a token being compared to the query.\n",
    "- Value (V): Represents the actual information to be aggregated based on attention scores.\n",
    "\n",
    "These three representations are obtained by applying linear transformations to the input sequence. The transformed matrices allow us to compute the attention scores using the scaled dot-product attention formula:\n",
    "\n",
    "$ \n",
    "score(x_i, x_j) = \\frac{q_i \\cdot k_j}{\\sqrt{d_k}} \n",
    "$\n",
    "\n",
    "Where $q_i$ is the query representation of token $i$, $k_j$ is the key representation of token $j$, and $d_k$ is the dimension of the key representation. \n",
    "\n",
    "In forward function is :\n",
    "```python\n",
    "attn_scores = torch.einsum('bhqd, bhkd -> bhqk', queries, keys)\n",
    "```\n",
    "\n",
    "To prevent a token from attending to future tokens (as in autoregressive models like GPT), we apply a mask to the attention scores. This ensures that each token only attends to itself and previous tokens:\n",
    "\n",
    "$\n",
    "a_i = \\sum_{j \\leq i} \\alpha_{ij}v_j\n",
    "$\n",
    "\n",
    "In forward function is :\n",
    "```python\n",
    "attn_scores = attn_scores.masked_fill(self.mask[:num_tokens, :num_tokens] == 0,\n",
    "                                float('-inf'))\n",
    "```\n",
    "\n",
    "Once the attention scores are computed and masked, they are normalized using the softmax function to produce attention weights:\n",
    "\n",
    "$\n",
    "\\alpha_{ij} = \\frac{\\exp(score(x_i,x_j))}{\\sum_j \\exp(score(x_i,x_j))}\n",
    "$\n",
    "\n",
    "In forward function is :\n",
    "```python\n",
    "attn_scores = nn.fonctional.softmax(attn_scores, dim=-1)\n",
    "```\n",
    "\n",
    "To prevent overfitting, a dropout layer is applied to the attention weights (self.dropout) before computing the context vector.\n",
    "\n",
    "To compute the context vector, we multiply the attention weights by the Value (V) representations to obtain the context vector.\n",
    "\n",
    "In forward function is :\n",
    "\n",
    "```python\n",
    "context = torch.einsum('bhqk, bhkd -> bhqd', attn_weights, values)\n",
    "```\n",
    "\n",
    "To resume we have done this :\n",
    "\n",
    "![explain one head](./img/ExplainOneHeadAttention.png)\n",
    "*Source: [Speech and Language Processing](https://web.stanford.edu/~jurafsky/slp3/9.pdf)*\n",
    "\n",
    "## Multi-Head Attention\n",
    "Single-head attention allows each token to focus on others, but it has limitations: it can only capture one type of relationship at a time. Multi-head attention improves this by using multiple attention heads in parallel.\n",
    "Instead of computing attention once, we split the input into multiple heads, each with a different representation of the sequence. This allows the model to capture diverse patterns.\n",
    "All heads are concatenated and linearly transformed to produce the final output. This process is implemented in the **MultiHeadAttention**, is why we use self.head_dim or 'd' in code.\n",
    "\n",
    "This figure resume compute with matrix :\n",
    "\n",
    "![Compute](./img/ExplainCompute.png)\n",
    "*Source: [Speech and Language Processing](https://web.stanford.edu/~jurafsky/slp3/9.pdf)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        # TODO fct FFN we can change the number of layers\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], cfg[\"emb_dim\"] // 2, bias=cfg[\"qkv_bias\"]),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(cfg[\"emb_dim\"] // 2, cfg[\"emb_dim\"], bias=cfg[\"qkv_bias\"])\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The FeedForward in transformer\n",
    "The **FeedForward** class is used to apply a feedforward neural network to the output of the multi-head attention layer. The feedforward network consists of two linear transformations with a GELU (or RELU) activation function in between.\n",
    "\n",
    "## GELU and RELU\n",
    "GELU and RELU are activation functions used in neural networks after linear transformations. GELU is a smoother version of RELU that has been shown to improve performance in transformer models. \n",
    "\n",
    "The GELU function is defined as:\n",
    "\n",
    "$\n",
    "GELU(x) = 0.5x(1 + tanh(\\sqrt{2/\\pi}(x + 0.044715x^3)))\n",
    "$\n",
    "\n",
    "RELU is a simpler activation function that sets all negative values to zero:\n",
    "\n",
    "$\n",
    "RELU(x) = max(0, x)\n",
    "$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(cfg[\"emb_dim\"]).to(cfg[\"device\"])\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in = cfg[\"emb_dim\"],\n",
    "            d_out = cfg[\"emb_dim\"],\n",
    "            context_length = cfg[\"context_length\"],\n",
    "            dropout = cfg[\"drop_rate\"],\n",
    "            num_heads = cfg[\"n_heads\"],\n",
    "            qkv_bias = cfg[\"qkv_bias\"],\n",
    "            device=cfg[\"device\"]\n",
    "        )\n",
    "        self.ff = FeedForward(cfg).to(cfg[\"device\"])\n",
    "        self.norm2 = nn.LayerNorm(cfg[\"emb_dim\"]).to(cfg[\"device\"])\n",
    "        self.dropout = nn.Dropout(cfg[\"drop_rate\"]).to(cfg[\"device\"])\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # print(\"we are in one transformer block\")\n",
    "        # print(x.shape)\n",
    "        # print(x)\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        # print(\"after att\", x.shape)\n",
    "        # print(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = x + shortcut\n",
    "        \n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x+ shortcut\n",
    "        # print(x.shape)\n",
    "        # print(x)\n",
    "        # print('end trs block')\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explain of class TransformerBlock\n",
    "The **TransformerBlock** class is the core building block of the transformer model. It consists of three main components: the **MultiHeadAttention**, the **FeedForward** layers and **LayerNorm**. The **MultiHeadAttention** layer is used to capture the relationships between tokens, while the **FeedForward** layer is used to apply non-linear transformations to the output of the attention layer. We use **LayerNorm** to normalize X and for normalize the output of the **FeedForward** layer.\n",
    "\n",
    "![image.png](./img/ExplainArchiTrans.png)\n",
    "*Source: [Speech and Language Processing](https://web.stanford.edu/~jurafsky/slp3/9.pdf)*\n",
    "\n",
    "In this figure we can see the Residual Stream. In the forward funciton it's name shortcut. It's a way to avoid the vanishing gradient problem. The output of the **FeedForward** layer is added to the input of the **MultiHeadAttention** layer. This allows the model to learn the difference between the input and output of the block, which helps to improve performance.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        # Embeddings\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"]).to(cfg[\"device\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"]).to(cfg[\"device\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"]).to(cfg[\"device\"])\n",
    "        \n",
    "        # Transformer Blocks\n",
    "        self.trf_blocks = nn.ModuleList(\n",
    "                [TransformerBlock(cfg) for _ in range(cfg[\"n_leayers\"])]\n",
    "            )\n",
    "        \n",
    "        # Normalization & Output layer\n",
    "        self.final_norm = nn.LayerNorm(cfg[\"emb_dim\"]).to(cfg[\"device\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"out_vocab_size\"], bias=False).to(cfg[\"device\"])\n",
    "        \n",
    "        # Weight tying: Share weights between embedding and output projection\n",
    "        self.tok_emb.weight = self.out_head.weight\n",
    "        \n",
    "        # Initialize weights (If we need)\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "        # Special initialization for transformer projection layers\n",
    "        for pn, p in self.named_parameters():\n",
    "            if pn.endswith('c_proj.weight'):\n",
    "                torch.nn.init.normal_(p,\n",
    "                                    mean=0.0,\n",
    "                                    std=0.02 / math.sqrt(2 * self.cfg[\"n_layers\"]))\n",
    "                \n",
    "    def forward(self, x: torch.Tensor, return_full_sequence=False):\n",
    "        b, seq_len = x.shape\n",
    "        device = x.device\n",
    "        # assert device != self.cfg['device'], \"Input tensor device does not match model device\"\n",
    "\n",
    "        # print(\"in GPT, forward \",x)\n",
    "        \n",
    "        # Token & Positional Embeddings\n",
    "        # (b, seq_len, emb_dim)\n",
    "        tok_embeds = self.tok_emb(x)\n",
    "        # print(\"tok_embeds \",tok_embeds)\n",
    "        # (seq_len, emb_dim)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=device))\n",
    "        # print(\"pos_embeds \",pos_embeds)\n",
    "        \n",
    "        x = tok_embeds + pos_embeds\n",
    "        # print(\"tok_embeds + pos_embeds \",x)\n",
    "        x = self.drop_emb(x)\n",
    "        # print(\"self.drop_emb(x) \",x)\n",
    "        \n",
    "        # Pass through Transformer Blocks\n",
    "        deleteme = 0\n",
    "        for block_ in self.trf_blocks:\n",
    "            deleteme += 1\n",
    "            x = block_(x)\n",
    "            # print(f\"block(x) nÂ°{deleteme} : {x}\")\n",
    "        \n",
    "        # Final normalization & output projection\n",
    "        x = self.final_norm(x)\n",
    "        # print(\"self.final_norm(x) \",x)\n",
    "        logits = self.out_head(x)\n",
    "\n",
    "        # print(\"logits \",logits)\n",
    "        \n",
    "        if not return_full_sequence:\n",
    "            logits = logits[:, -1, :]  # (b, vocab_size)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_val, y_val):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(x_val, False)\n",
    "        loss = nn.functional.cross_entropy(logits, y_val)\n",
    "    return loss.item()\n",
    "\n",
    "def train_simple(model, optimizer, inputs, targets, n_iter, x_val=None, y_val=None, verbose=True):\n",
    "    all_train_loss, all_val_loss = [], []\n",
    "    for i in range(n_iter):\n",
    "        logits = model(inputs, False)\n",
    "        loss = nn.functional.cross_entropy(logits, targets)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            all_train_loss.append(loss.item())\n",
    "            if x_val is not None:\n",
    "                val_loss = evaluate_model(model, x_val, y_val)\n",
    "                all_val_loss.append(val_loss)\n",
    "                if verbose:\n",
    "                    print(f'for {i} epochs, loss is {loss.item()} and val_loss is {val_loss}')\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f'for {i} epochs, loss is {loss.item()}')\n",
    "                \n",
    "\n",
    "    return all_train_loss, all_val_loss\n",
    "\n",
    "def train_for_one_seq(model, optimizer, inputs, targets, n_iter, x_val=None, y_val=None, verbose=True):\n",
    "    \"\"\" \n",
    "    Train the model for one sequence\n",
    "    \"\"\"\n",
    "    all_train_loss, all_val_loss = [], []\n",
    "    model.train()\n",
    "    for i in range(n_iter):\n",
    "        logits = model(inputs, False)\n",
    "        loss = nn.functional.cross_entropy(logits, targets)\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        for g in optimizer.param_groups:\n",
    "            tmp = g['lr']\n",
    "            break\n",
    "        if predictions != targets:\n",
    "            for g in optimizer.param_groups:\n",
    "                g['lr'] /= 10\n",
    "            \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        for g in optimizer.param_groups:\n",
    "            g['lr'] = tmp\n",
    "\n",
    "        # if i % 10 == 0:\n",
    "        all_train_loss.append(loss.item())\n",
    "        if x_val is not None:\n",
    "            val_loss = evaluate_model(model, x_val, y_val)\n",
    "            all_val_loss.append(val_loss)\n",
    "            if verbose:\n",
    "                print(f'for {i} epochs, loss is {loss.item()} and val_loss is {val_loss}')\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(f'for {i} epochs, loss is {loss.item()}')\n",
    "                \n",
    "    if len(all_val_loss) == 0:\n",
    "        all_val_loss = [20]\n",
    "\n",
    "    if len(all_train_loss) == 0:\n",
    "        all_train_loss = [20]\n",
    "    return all_train_loss, all_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequence(model, context, n_tokens):\n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_tokens):\n",
    "            logits = model(context, False)\n",
    "            probas = torch.softmax(logits, dim=-1)\n",
    "            next_token = torch.argmax(probas, dim=-1).unsqueeze(0)\n",
    "            context = torch.cat([context, next_token], dim=-1).to(device)\n",
    "    return context\n",
    "\n",
    "CONFIG_TEST = {\n",
    "    \"vocab_size\": 2,\n",
    "    \"context_length\": 15,\n",
    "    \"emb_dim\": 16,\n",
    "    \"n_heads\": 4,\n",
    "    \"n_leayers\": 4,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False,\n",
    "    \"device\": device,\n",
    "    \"out_vocab_size\": 2\n",
    "}\n",
    "\n",
    "model_test = GPTModel(CONFIG_TEST)\n",
    "generate_sequence(model_test, torch.randint(0, CONFIG_TEST[\"vocab_size\"], (1, 3)).to(CONFIG_TEST[\"device\"]), 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M_small = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_leayers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False,\n",
    "    \"device\": device\n",
    "}\n",
    "\n",
    "OUR_CONFIG = {\n",
    "    \"vocab_size\": VOCAB_SIZE,\n",
    "    \"context_length\": CONTEXT_LENGHT,\n",
    "    \"emb_dim\": 16,\n",
    "    \"n_heads\": 4,\n",
    "    \"n_leayers\": 4,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False,\n",
    "    \"device\": device\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_possible(n, k):\n",
    "    \"\"\"\n",
    "    Generate all possible combination of n elements taken k by k\n",
    "    \"\"\"\n",
    "    if k == 0:\n",
    "        yield []\n",
    "    else:\n",
    "        for i in range(n):\n",
    "            for c in all_possible(n, k - 1):\n",
    "                yield [i] + c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model(gpt, token_to = None, graph = True):\n",
    "    \"\"\"\n",
    "    Plot the transition graph of the GPT model\n",
    "    \"\"\"\n",
    "    dot = Digraph(comment='Baby GPT', engine='circo')\n",
    "\n",
    "    for xi in all_possible(gpt.cfg[\"vocab_size\"], gpt.cfg[\"context_length\"]):\n",
    "        \n",
    "        # forward the GPT and get probabilities for next token\n",
    "        x = torch.tensor(xi, dtype=torch.long)[None, ...]\n",
    "        x = x.to(gpt.cfg[\"device\"])\n",
    "        # turn the list into a torch tensor and add a batch dimension\n",
    "        logits = gpt(x, False) # forward the gpt neural net\n",
    "\n",
    "        # print('logits :', logits)\n",
    "        probs = nn.functional.softmax(logits, dim=-1) # get the probabilities\n",
    "        y = probs[0].tolist() # remove the batch dimension and unpack the tensor into simple list\n",
    "        if token_to:\n",
    "            print(f\"input {token_to(xi)} ---> {y}\")\n",
    "        else:\n",
    "            print(f\"input {xi} ---> {y}\")\n",
    "\n",
    "        if graph:\n",
    "            # also build up the transition graph for plotting later\n",
    "            current_node_signature = \"\".join(str(d) for d in xi)\n",
    "            dot.node(current_node_signature)\n",
    "            # input(\"Press Enter to continue...\")\n",
    "\n",
    "            for t in range(gpt.cfg[\"vocab_size\"]):\n",
    "                next_node = xi[1:] + [t] # crop the context and append the next character\n",
    "                next_node_signature = \"\".join(str(d) for d in next_node)\n",
    "                p = y[t]\n",
    "\n",
    "                label=f\"{t}({p*100:.0f}%)\"\n",
    "                dot.edge(current_node_signature, next_node_signature, label=label)\n",
    "    \n",
    "    return dot\n",
    "\n",
    "# gpt = GPTModel(OUR_CONFIG)\n",
    "# plot_model(gpt)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_TRAIN = {\n",
    "    \"vocab_size\": 2,\n",
    "    \"context_length\": 3,\n",
    "    \"emb_dim\": 16,\n",
    "    \"n_heads\": 4,\n",
    "    \"n_leayers\": 4,\n",
    "    \"drop_rate\": 0.0,\n",
    "    \"qkv_bias\": False,\n",
    "    \"device\": device\n",
    "}\n",
    "\n",
    "# inputs = torch.tensor([[0, 1, 1],\n",
    "#                        [1, 0, 0],\n",
    "#                        [1, 1, 0],\n",
    "#                        [0, 0, 1]]).to(CONFIG_TRAIN[\"device\"])\n",
    "\n",
    "# targets = torch.tensor([[1, 1, 1],\n",
    "#                         [0, 0, 1],\n",
    "#                         [1, 0, 1],\n",
    "#                         [0, 1, 0]]).to(CONFIG_TRAIN[\"device\"])\n",
    "\n",
    "\n",
    "# probas = torch.softmax(model_test(inputs), dim=-1)\n",
    "\n",
    "# print(probas)\n",
    "\n",
    "# output = torch.argmax(probas, dim=-1)\n",
    "\n",
    "# print(output)\n",
    "\n",
    "\n",
    "# text_prob1= probas[0, targets[0]]\n",
    "# print(\"proba text1\", text_prob1)\n",
    "# print(\"proba text1 - what we obtained\", probas[0, output[0].flatten()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's train our baby GPT on this sequence\n",
    "seq = list(map(int, \"111101111011110\"))\n",
    "print('seq', seq)\n",
    "\n",
    "# convert the sequence to a tensor holding all the individual examples in that sequence\n",
    "X, Y = [], []\n",
    "# iterate over the sequence and grab every consecutive 3 bits\n",
    "# the correct label for what's next is the next bit at each position\n",
    "# for i in range(len(seq) - 3):\n",
    "#     X.append(seq[i:i+3])\n",
    "#     Y.append(seq[i+3])\n",
    "#     print(f\"example {i+1:2d}: {X[-1]} --> {Y[-1]}\")\n",
    "# X = torch.tensor(X, dtype=torch.long).to(CONFIG_TRAIN[\"device\"])\n",
    "# Y = torch.tensor(Y, dtype=torch.long).to(CONFIG_TRAIN[\"device\"])\n",
    "# print(X.shape, Y.shape)\n",
    "# torch.manual_seed(1337)\n",
    "\n",
    "\n",
    "# config = GPTConfig(\n",
    "#     block_size = 3,\n",
    "#     vocab_size = 2,\n",
    "#     n_layer = 4,\n",
    "#     n_head = 4,\n",
    "#     n_embd = 16,\n",
    "#     bias = False,\n",
    "# )\n",
    "# gpt = GPT(config)\n",
    "\n",
    "# optimizer = torch.optim.AdamW(gpt.parameters(), lr=1e-3, weight_decay=1e-1)\n",
    "\n",
    "# for i in range(50):\n",
    "#     logits = gpt(X)\n",
    "#     loss = nn.functional.cross_entropy(logits, Y)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     optimizer.zero_grad()\n",
    "#     print(i, loss.item())\n",
    "\n",
    "\n",
    "# print(\"Training data sequence, as a reminder:\", seq)\n",
    "# plot_model()\n",
    "\n",
    "\n",
    "\n",
    "CONFIG_TRAIN = {\n",
    "    \"vocab_size\": 2,\n",
    "    \"context_length\": 3,\n",
    "    \"emb_dim\": 16,\n",
    "    \"n_heads\": 4,\n",
    "    \"n_leayers\": 4,\n",
    "    \"drop_rate\": 0.000,\n",
    "    \"qkv_bias\": False,\n",
    "    \"device\": device\n",
    "}\n",
    "# model = GPTModel(CONFIG_TRAIN)\n",
    "\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-1)\n",
    "\n",
    "# for i in range(10):\n",
    "#     logits = model(X, False)\n",
    "#     print(\"logits\", logits)\n",
    "#     loss = nn.functional.cross_entropy(logits, Y)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     optimizer.zero_grad()\n",
    "#     print(i, loss.item())\n",
    "\n",
    "\n",
    "# print(\"Training data sequence, as a reminder:\", seq)\n",
    "# plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = GPTModel(CONFIG_TRAIN)\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-1)\n",
    "\n",
    "# inputs = torch.tensor([[0, 1, 1, 1],\n",
    "#                        [1, 0, 0, 1],\n",
    "#                        [1, 1, 0, 0]])\n",
    "\n",
    "# targets = torch.tensor([1, 1, 1])\n",
    "\n",
    "# # train the GPT for some number of iterations\n",
    "# for i in range(3):\n",
    "\n",
    "#     logits = model(inputs, False)\n",
    "#     print(logits)\n",
    "#     loss = nn.functional.cross_entropy(logits, targets)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     optimizer.zero_grad()\n",
    "#     print(i, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment 1\n",
    "# Action 0 => 0\n",
    "# Action 1 => 1\n",
    "\n",
    "# history_action = []\n",
    "# hystory_fb = []\n",
    "# history_pred = []\n",
    "\n",
    "# env = env1()\n",
    "# model = GPTModel(\n",
    "#     {\n",
    "#         \"vocab_size\": 2,\n",
    "#         \"context_length\": 1,\n",
    "#         \"emb_dim\": 16,\n",
    "#         \"n_heads\": 4,\n",
    "#         \"n_leayers\": 4,\n",
    "#         \"drop_rate\": 0.1,\n",
    "#         \"qkv_bias\": False,\n",
    "#         \"device\": device\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# action = 0\n",
    "# inputs = torch.tensor([[action]]).t\n",
    "# targets = torch.tensor([0])\n",
    "\n",
    "# for i in range(100):\n",
    "#     action = i%2\n",
    "#     history_action.append(action)\n",
    "#     feedback = env.outcome(action)\n",
    "#     hystory_fb.append(feedback)\n",
    "\n",
    "#     inputs = torch.tensor([[action]]).to(device)\n",
    "#     targets = torch.tensor([feedback]).to(device)\n",
    "#     logits = model(inputs, False)\n",
    "#     print(logits)\n",
    "#     history_pred.append(torch.argmax(logits).item())\n",
    "#     loss = nn.functional.cross_entropy(logits, targets)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     optimizer.zero_grad()\n",
    "#     print(i, loss.item())\n",
    "    \n",
    "# print(history_action)\n",
    "# print(hystory_fb)\n",
    "# print(history_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addapt_seq(seq, context_length):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(seq) - context_length):\n",
    "        X.append(seq[i:i+context_length])\n",
    "        Y.append(seq[i+context_length])\n",
    "    return torch.tensor(X, dtype=torch.long), torch.tensor(Y, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Environment 2, goal is predict outcome with action.\n",
    "# # X are all action\n",
    "# # For each X we associate Y, the outcome of the action\n",
    "# # X is context lenght action\n",
    "\n",
    "# history_action = []\n",
    "# hystory_fb = []\n",
    "# history_pred = []\n",
    "\n",
    "# env = env2Str()\n",
    "\n",
    "# action = 0\n",
    "# inputs = torch.tensor([[action]])\n",
    "# targets = torch.tensor([0])\n",
    "\n",
    "# for i in range(20):\n",
    "#     action = torch.randint(0, 2, (1,)).item()\n",
    "#     history_action.append(action)\n",
    "#     feedback = env.outcome(action)\n",
    "#     hystory_fb.append(feedback)\n",
    "\n",
    "# CONTEXT_LENGHT = 4\n",
    "# model = GPTModel(\n",
    "#     {\n",
    "#         \"vocab_size\": 2,\n",
    "#         \"context_length\": CONTEXT_LENGHT,\n",
    "#         \"emb_dim\": 16,\n",
    "#         \"n_heads\": 4,\n",
    "#         \"n_leayers\": 4,\n",
    "#         \"drop_rate\": 0.1,\n",
    "#         \"qkv_bias\": False,\n",
    "#         \"device\": device\n",
    "#     }\n",
    "# )\n",
    "\n",
    "\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-1)\n",
    "\n",
    "# inputs, targets = addapt_seq(history_action, CONTEXT_LENGHT)\n",
    "# # inputs, targets = addapt_seq(list(map(int, \"111101111011110\")), CONTEXT_LENGHT)\n",
    "# inputs = inputs.to(device)\n",
    "# targets = torch.tensor(hystory_fb[CONTEXT_LENGHT-1:-1]).to(device)\n",
    "\n",
    "# print(\"inputs\")\n",
    "# print(inputs)\n",
    "# print(targets)\n",
    "\n",
    "# for j in range(100):\n",
    "#     logits = model(inputs, False)\n",
    "#     loss = nn.functional.cross_entropy(logits, targets)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     optimizer.zero_grad()\n",
    "#     print(j, loss.item())\n",
    "\n",
    "# history_pred.append(torch.argmax(logits).item())\n",
    "    \n",
    "# print(history_action)\n",
    "# print(hystory_fb)\n",
    "# print(history_pred)\n",
    "\n",
    "# plot_model(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interaction_to_token(interaction, base=2):\n",
    "    return [int(f\"{a}{b}\", base) for a, b in interaction]\n",
    "    \n",
    "def token_to_interaction(token, base=2):\n",
    "    return [(i // base, i % base) for i in token]\n",
    "\n",
    "x = interaction_to_token([(0, 1), (1, 0), (1, 1), (0, 0)])\n",
    "print(x)\n",
    "y = token_to_interaction(x)\n",
    "print(y)\n",
    "\n",
    "x = interaction_to_token([(0, 3), (3, 0), (2, 1), (2, 0)], 4)\n",
    "print(x)\n",
    "y = token_to_interaction(x, 4)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # \n",
    "# history = []\n",
    "# history_action = []\n",
    "# hystory_fb = []\n",
    "# history_pred = []\n",
    "# context_lenght = 2\n",
    "\n",
    "# env = env3()\n",
    "\n",
    "# action = 0\n",
    "# inputs = torch.tensor([[action]])\n",
    "# targets = torch.tensor([0])\n",
    "\n",
    "# for i in range(1000):\n",
    "#     action = torch.randint(0, 2, (1,)).item()\n",
    "#     feedback = env.outcome(action)\n",
    "\n",
    "#     history_action.append(action)\n",
    "#     hystory_fb.append(feedback)\n",
    "\n",
    "#     history.append((action, feedback))\n",
    "\n",
    "# history_token = interaction_to_token(history)\n",
    "# voc = 4\n",
    "# inputs, targets = addapt_seq(history_token, context_lenght)\n",
    "\n",
    "# inputs = inputs.to(device)\n",
    "# targets = targets.to(device)\n",
    "\n",
    "# mymodel = GPTModel(\n",
    "#     {\n",
    "#         \"vocab_size\": voc,\n",
    "#         \"context_length\": context_lenght,\n",
    "#         \"emb_dim\": 16,\n",
    "#         \"n_heads\": 4,\n",
    "#         \"n_leayers\": 4,\n",
    "#         \"drop_rate\": 0.1,\n",
    "#         \"qkv_bias\": False,\n",
    "#         \"device\" : device\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# for j in range(100):\n",
    "#     logits = mymodel(inputs, False)\n",
    "#     loss = nn.functional.cross_entropy(logits, targets)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     optimizer.zero_grad()\n",
    "#     print(j, loss.item())\n",
    "\n",
    "# plot_model(mymodel, None, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = mymodel(torch.tensor([[1, 1]]).to(device), False)\n",
    "# probs = nn.functional.softmax(x, dim=-1)\n",
    "# print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_all_words(valence:dict, nb_diff:int):\n",
    "    vocab = []\n",
    "    for k in valence.keys():\n",
    "        for i in range(0, nb_diff + 1):\n",
    "            l, r = k\n",
    "            vocab.append(str(str(l) + str(r) + str(i)))\n",
    "    return vocab\n",
    "\n",
    "valence = {\n",
    "    (0, 0) : 0,\n",
    "    (0, 1) : -10,\n",
    "    (1, 0) : 10,\n",
    "    (1, 1) : 0\n",
    "}\n",
    "\n",
    "all_words = create_all_words(valence, 80)\n",
    "vocab = {token:integer for integer, token in enumerate(all_words)}\n",
    "\n",
    "def create_all_words_enumerate(valence:dict, nb_valance_possible:int):\n",
    "    all_words = create_all_words(valence, nb_valance_possible)\n",
    "    return {token:integer for integer, token in enumerate(all_words)}\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV1:\n",
    "    \n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "        \n",
    "    def encode(self, text):\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "        if type(text) == list:\n",
    "            return [self.str_to_int[word] for word in text]\n",
    "        else:\n",
    "            return self.str_to_int[text]\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        if type(ids) == list:\n",
    "            return [self.int_to_str[id] for id in ids]\n",
    "        else:\n",
    "            return self.int_to_str[ids]\n",
    "    \n",
    "# tokenizer = SimpleTokenizerV1(vocab)\n",
    "\n",
    "# print(tokenizer.encode([\"011\", \"102\", \"113\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tempo = [1, 2, 3, 4, 5, 6]\n",
    "print(list_tempo[2: 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valance_in_seq(seq:list, valence:dict):\n",
    "    \"\"\"\n",
    "    Sum all valences in a sequence\n",
    "    Exemple:\n",
    "    seq = [(1, 0), (0, 1), (0, 1)]\n",
    "    valence = {(0, 0) : 0, (0, 1) : -10, (1, 0) : 10, (1, 1) : 0}\n",
    "    get_valance_in_seq(seq, valence) => -10\n",
    "    \"\"\"\n",
    "    return sum(valence.get(tuple(pair), None) for pair in seq)\n",
    "\n",
    "def valance_seq(valence, seq, len_seq):\n",
    "    \"\"\"\n",
    "    Create a list of valences for all sequences of size len_seq in seq\n",
    "    Exemple:\n",
    "    seq = [(1, 0), (0, 1), (0, 1), (0, 1)]\n",
    "    valence = {(0, 0) : 0, (0, 1) : -10, (1, 0) : 10, (1, 1) : 0}\n",
    "    len_seq = 2\n",
    "    valance_seq(valence, seq, len_seq) => [0, -10, -10]\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    for i in range(0, len(seq) - len_seq + 1):\n",
    "        X.append(get_valance_in_seq(seq[i: i+len_seq], valence))\n",
    "    return X\n",
    "\n",
    "def inter_valance_by_nb_seq(valence:dict, seq:list, n_seq:int):\n",
    "    \"\"\"\n",
    "    Create \"word\" for each interaction. A \"word\" is interaction + valence of the next n_seq interactions\n",
    "    Exemple:\n",
    "    valence = {(0, 0) : 0, (0, 1) : -10, (1, 0) : 10, (1, 1) : 0}\n",
    "    sed = [(1, 0), (1, 0), (0, 1), (0, 1), (1, 0), (1, 0), (1, 0), (0, 1), (0, 1)]\n",
    "    n_seq = 2\n",
    "    inter_valance_by_nb_seq(valence, seq, n_seq) => ['1020', '100', '0120', '0140', '1040', '1020', '100']\n",
    "\n",
    "    This word can be tokenize\n",
    "    \"\"\"\n",
    "    seq_valance = []\n",
    "    valance_by_seq = valance_seq(valence, seq[1:], n_seq)\n",
    "    ajout  = n_seq * abs(min(valence.values()))\n",
    "    for i, val in enumerate(valance_by_seq):\n",
    "        l, r = seq[i]\n",
    "        seq_valance.append(str(l) + str(r) + str(val + ajout))\n",
    "    # seq_valance.pop()\n",
    "    return seq_valance\n",
    "\n",
    "    \n",
    "\n",
    "valence = {\n",
    "    (0, 0) : 0,\n",
    "    (0, 1) : -10,\n",
    "    (1, 0) : 10,\n",
    "    (1, 1) : 0\n",
    "}\n",
    "\n",
    "# print(\"teste :\", valance_seq(valence, [(1, 0), (1, 0), (0, 1), (0, 1), (1, 0), (1, 0), (1, 0), (0, 1), (0, 1)], 2))\n",
    "\n",
    "# inputs = inter_valance_by_nb_seq(valence, \n",
    "#                     [(1, 0), (1, 0), (0, 1), (0, 1), (1, 0), (1, 0), (1, 0), (0, 1), (0, 1)], 2)\n",
    "# print(inputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(valence.values())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "#     input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "#     logits = model(input_batch)\n",
    "#     return torch.nn.functional.cross_entropy(logits.flatten(0,1), target_batch.flatten())\n",
    "\n",
    "# def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         train_loss = calc_loss_batch(train_loader, model, device)\n",
    "#         val_loss = calc_loss_batch(val_loader, model, device, num_batches=eval_iter)\n",
    "#     model.train()\n",
    "#     return train_loss, val_loss\n",
    "\n",
    "# def train_batch(model,\n",
    "#                train_loader,\n",
    "#                val_lodaer,\n",
    "#                optimizer, \n",
    "#                device,\n",
    "#                num_epochs,\n",
    "#                eval_freq = 10):\n",
    "\n",
    "#     train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "#     token_seen, global_step = 0, -1\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         model.train()\n",
    "\n",
    "#         for input_batch, target_batch in train_loader:\n",
    "#             optimizer.zero_grad()\n",
    "#             loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             token_seen += input_batch.numel()\n",
    "#             global_step +=1 #nombre de batch vu\n",
    "\n",
    "#             if global_step % 10 == 0:\n",
    "#                 train_loss, val_loss = evaluate_model(model, train_loader, val_lodaer, device, eval_freq)            \n",
    "#                 train_losses.append(train_loss)\n",
    "#                 val_losses.append(val_loss)\n",
    "#                 track_tokens_seen.append(token_seen)\n",
    "#                 print(\"Epoch\", epoch+1, \"global step\", global_step, \"Train loss\", train_loss,\n",
    "#                       \"Val loss\", val_loss)\n",
    "\n",
    "#     return train_losses, val_losses, track_tokens_seen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # \n",
    "# history = []\n",
    "# history_action = []\n",
    "# hystory_fb = []\n",
    "# history_pred = []\n",
    "# context_lenght = 30\n",
    "# nb_seq_valance = 3\n",
    "\n",
    "# env = env2()\n",
    "\n",
    "# action = 0\n",
    "# inputs = torch.tensor([[action]])\n",
    "# targets = torch.tensor([0])\n",
    "\n",
    "# valence = {\n",
    "#     (0, 0) : 0,\n",
    "#     (0, 1) : -1,\n",
    "#     (1, 0) : 1,\n",
    "#     (1, 1) : 0\n",
    "# }\n",
    "\n",
    "\n",
    "# for i in range(100):\n",
    "#     action = torch.randint(0, 2, (1,)).item()\n",
    "#     feedback = env.outcome(action)\n",
    "#     history_action.append(action)\n",
    "#     hystory_fb.append(feedback)\n",
    "#     history.append((action, feedback))\n",
    "\n",
    "\n",
    "# nb_valence_possible = nb_seq_valance * (abs(min(valence.values())) + abs(max(valence.values())))\n",
    "# print('nb_valence_possible')\n",
    "# print(nb_valence_possible)\n",
    "                                                                         \n",
    "\n",
    "# all_world_enum = create_all_words_enumerate(valence=valence,\n",
    "#             nb_valance_possible=nb_valence_possible)\n",
    "\n",
    "# tokenizer = SimpleTokenizerV1(all_world_enum)\n",
    "# voc = len(all_world_enum)\n",
    "# print('voc size')\n",
    "# print(voc)\n",
    "\n",
    "# inputs = inter_valance_by_nb_seq(valence, history, nb_seq_valance)\n",
    "# inputs = tokenizer.encode(inputs)\n",
    "\n",
    "# inputs, targets = addapt_seq(inputs, context_lenght)\n",
    "# inputs = inputs.to(device)\n",
    "# targets = targets.to(device)\n",
    "\n",
    "# print('inputs done :')\n",
    "# print(inputs)\n",
    "# print(\"target done :\")\n",
    "# print(targets)\n",
    "\n",
    "\n",
    "# mymodel = GPTModel({\n",
    "#         \"vocab_size\": voc,\n",
    "#         \"context_length\": context_lenght,\n",
    "#         \"emb_dim\": 320,\n",
    "#         \"n_heads\": 4,\n",
    "#         \"n_leayers\": 4,\n",
    "#         \"drop_rate\": 0.1,\n",
    "#         \"qkv_bias\": False,\n",
    "#         \"device\": device\n",
    "#     })\n",
    "\n",
    "\n",
    "# optimizer = torch.optim.AdamW(mymodel.parameters(), lr=1e-2, weight_decay=1e-2)\n",
    "# mymodel.train()\n",
    "# # train_simple(mymodel, optimizer, inputs, targets, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def see_proba(probs, tokenizer = None):\n",
    "    plt.bar(range(len(probs)), probs)\n",
    "    plt.text(probs.index(max(probs)), max(probs), str(max(probs)), ha='center')\n",
    "    if tokenizer:\n",
    "        plt.text(probs.index(max(probs)), max(probs) + 0.5, tokenizer.decode(max(probs)), ha='center')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq = ['014']\n",
    "# mymodel.eval()\n",
    "# x = mymodel(torch.tensor([tokenizer.encode(seq)]).to(device), False)\n",
    "# probs = nn.functional.softmax(x, dim=-1)\n",
    "# predi = torch.argmax(probs)\n",
    "\n",
    "# see_proba(probs[0].tolist(), None)\n",
    "# print(tokenizer.decode([predi.item()]))\n",
    "# print(f'for seq {str(seq)} the next token is {tokenizer.decode([predi.item()])}')\n",
    "\n",
    "# seq_gen = generate_sequence(mymodel, torch.tensor([tokenizer.encode(seq)]).to(device), context_lenght)\n",
    "\n",
    "# print(tokenizer.decode(seq_gen[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input = ActionOutcomeAction\n",
    "# Output = ActionOutcomeAction**Outcome**\n",
    "# Word is Action and Outcome\n",
    "\n",
    "# All words\n",
    "def create_all_words_action_outcome(action:list, feedback:list):\n",
    "    return action + feedback\n",
    "\n",
    "def create_all_words_action_outcome_enumerate(action:list, feedback:list):\n",
    "    all_words = create_all_words_action_outcome(action, feedback)\n",
    "    return {word:integer for integer, word in enumerate(all_words)}\n",
    "\n",
    "# create_all_words_action_outcome([0, 1, 2, 3], ['A', 'B'])\n",
    "# create_all_words_action_outcome_enumerate([0, 1, 2, 3], ['A', 'B'])\n",
    "# tokenizer_act_ff = SimpleTokenizerV1(create_all_words_action_outcome_enumerate(['0', '1', '2', '3'], ['A', 'B']))\n",
    "# tempo = tokenizer_act_ff.encode(['0', 'A', '1', 'B'])\n",
    "# print(tempo)\n",
    "# print(tokenizer_act_ff.decode(tempo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "My_list = [[0, 1, 2, 3], ['A', 'B']]\n",
    "My_list[0]\n",
    "\n",
    "My_list[0] = [0, 3, 2, 3]\n",
    "print(My_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [(0, 'x'), (1, 'x'), (1, 'x'), (1, 'x'), (1, 'x'), (1, 'x'), (1, 'x'), (1, 'x')]\n",
    "# [[0], [0, x, 1], []\n",
    "def inter_action_and_feedback_size(history:list, size:int):\n",
    "    \"\"\"\n",
    "    Transform history into input and target.\n",
    "    history is a sequence of action and feedback.\n",
    "    We want to have all sequence of size size, associate with the feedback of the last action (targets).\n",
    "    Exemple:\n",
    "    history = [('0', 'x'), ('1', 'y'), ('0', 'x'), ('1', 'y'), ('0', 'x'), ('1', 'y'), ('0', 'x')]\n",
    "    size = 5\n",
    "    inter_action_and_feedback_size(history, size) => \n",
    "    inputs = [['0', 'x', '1', 'y', '0'], \n",
    "    ['1', 'y', '0', 'x', '1'],\n",
    "    ['0', 'x', '1', 'y', '0'],\n",
    "    ['1', 'y', '0', 'x', '1'],\n",
    "    ['0', 'x', '1', 'y', '0']]\n",
    "\n",
    "    targets = ['x', 'y', 'x', 'y', 'x']\n",
    "\n",
    "    \"\"\"\n",
    "    inputs, targets = [], []\n",
    "    for act, ff in history:\n",
    "        if inputs:\n",
    "            temp = inputs[-1][-int(size - 2):] + [targets[-1], act]\n",
    "            inputs.append(temp)\n",
    "        else:\n",
    "            inputs.append([act])\n",
    "        targets.append(ff)\n",
    "    return inputs[size - 1:], targets[size- 1:]\n",
    "\n",
    "inputs, targets = inter_action_and_feedback_size([('0', 'x'), ('1', 'y'), ('0', 'x')], 5)\n",
    "print(inputs)\n",
    "print(targets)\n",
    "\n",
    "# print(create_all_words_action_outcome_enumerate(['0', '1'], ['x', 'y']))\n",
    "# tokenizer = SimpleTokenizerV1(create_all_words_action_outcome_enumerate(['0', '1'], ['x', 'y']))\n",
    "# print(targets)\n",
    "# print(tokenizer.encode(targets))\n",
    "\n",
    "# print(inputs)\n",
    "# for i, one_input in enumerate(inputs):\n",
    "#     inputs[i] = tokenizer.encode(inputs[i])\n",
    "\n",
    "# print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_all_words_by_env(env):\n",
    "    vocab = []\n",
    "    action = env.get_actions()\n",
    "    feedback = env.get_outcomes()\n",
    "    for act in action:\n",
    "        for ff in feedback:\n",
    "            vocab.append(str(act) + str(ff))\n",
    "    return vocab\n",
    "\n",
    "def create_all_words_by_env_enumerate(env):\n",
    "    all_words = create_all_words_by_env(env)\n",
    "    return {word:integer for integer, word in enumerate(all_words)}\n",
    "\n",
    "env = env2Str()\n",
    "tokenizer = create_all_words_by_env_enumerate(env)\n",
    "print(tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "historyTest = []\n",
    "context_lenght = 21\n",
    "nb_seq_valance = 3\n",
    "\n",
    "env = env3Str()\n",
    "\n",
    "action = 0\n",
    "inputs = torch.tensor([[action]])\n",
    "targets = torch.tensor([0])\n",
    "\n",
    "valence = {\n",
    "    ('a', 'x') : 0,\n",
    "    ('a', 'y') : -1,\n",
    "    ('b', 'x') : 1,\n",
    "    ('b', 'y') : 0\n",
    "}\n",
    "\n",
    "# train\n",
    "for i in range(100):\n",
    "    action = np.random.choice(['a', 'b'])\n",
    "    feedback = env.outcome(action)\n",
    "    history.append((str(action), str(feedback)))\n",
    "\n",
    "# test\n",
    "for i in range(100):\n",
    "    action = np.random.choice(['a', 'b'])\n",
    "    feedback = env.outcome(action)\n",
    "    historyTest.append((str(action), str(feedback)))\n",
    "\n",
    "print(history)\n",
    "tmpInput, tmpTarget = inter_action_and_feedback_size(history, context_lenght)\n",
    "\n",
    "tokenizer = SimpleTokenizerV1(create_all_words_action_outcome_enumerate(['a', 'b', 'x', 'y'], []))\n",
    "\n",
    "inputs = []\n",
    "for i, one_input in enumerate(tmpInput):\n",
    "    inputs.append(tokenizer.encode(one_input))\n",
    "targets = tokenizer.encode(tmpTarget)\n",
    "\n",
    "inputs= torch.tensor(inputs, dtype=torch.long).to(device)\n",
    "targets = torch.tensor(targets, dtype=torch.long).to(device)\n",
    "\n",
    "tmpXtest, tmpYtest = inter_action_and_feedback_size(historyTest, context_lenght)\n",
    "\n",
    "x_test = []\n",
    "for i, one_input in enumerate(tmpXtest):\n",
    "    x_test.append(tokenizer.encode(one_input))\n",
    "y_test = tokenizer.encode(tmpYtest)\n",
    "\n",
    "x_test = torch.tensor(x_test, dtype=torch.long).to(device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "mymodel = GPTModel({\n",
    "        \"vocab_size\": len(['a', 'b', 'x', 'y']),\n",
    "        \"context_length\": context_lenght,\n",
    "        \"emb_dim\": 16,\n",
    "        \"n_heads\": 4,\n",
    "        \"n_leayers\": 4,\n",
    "        \"drop_rate\": 0.1,\n",
    "        \"qkv_bias\": False,\n",
    "        \"device\": device,\n",
    "        \"out_vocab_size\": len(['a', 'b', 'x', 'y'])\n",
    "    })\n",
    "\n",
    "optimizer = torch.optim.AdamW(mymodel.parameters(), lr=1e-2, weight_decay=1e-2)\n",
    "\n",
    "train_loss, val_loss = train_simple(mymodel, optimizer, inputs, targets, 200, x_test, y_test)\n",
    "\n",
    "plt.plot(train_loss, label='Train Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model \n",
    "\n",
    "seq =torch.tensor([[1, 2, 1, 2, 1, 2, 0, 3, 0, 2, 0, 2, 1, 3, 0, 2, 0, 2, 1, 2, 0]]).to(device)\n",
    "mymodel.eval()\n",
    "x = mymodel(seq, False)\n",
    "probs = nn.functional.softmax(x, dim=-1)\n",
    "predi = torch.argmax(probs)\n",
    "see_proba(probs[0].tolist(), None)\n",
    "print(f'for seq {str(seq)} the next token is {tokenizer.decode([predi.item()])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, x, y):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(x, False)\n",
    "        # loss = nn.functional.cross_entropy(logits, y)\n",
    "        pred = torch.argmax(logits, dim=-1)\n",
    "        acc = (pred == y).float().mean()\n",
    "    return acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "historyTest = []\n",
    "context_lenght = 21\n",
    "nb_seq_valance = 3\n",
    "\n",
    "env = env3Str()\n",
    "\n",
    "action = 0\n",
    "inputs = torch.tensor([[action]])\n",
    "targets = torch.tensor([0])\n",
    "\n",
    "valence = {\n",
    "    ('a', 'x') : 0,\n",
    "    ('a', 'y') : -1,\n",
    "    ('b', 'x') : 1,\n",
    "    ('b', 'y') : 0\n",
    "}\n",
    "\n",
    "# test\n",
    "for i in range(1000):\n",
    "    action = np.random.choice(['a', 'b'])\n",
    "    feedback = env.outcome(action)\n",
    "    historyTest.append((str(action), str(feedback)))\n",
    "\n",
    "# TODO lunch test to see evolued accuracy and loss in function of the number of training\n",
    "# train\n",
    "for i in range(100):\n",
    "    action = np.random.choice(['a', 'b'])\n",
    "    feedback = env.outcome(action)\n",
    "    history.append((str(action), str(feedback)))\n",
    "\n",
    "\n",
    "print(history)\n",
    "tmpInput, tmpTarget = inter_action_and_feedback_size(history, context_lenght)\n",
    "\n",
    "tokenizer = SimpleTokenizerV1(create_all_words_action_outcome_enumerate(['a', 'b', 'x', 'y'], []))\n",
    "\n",
    "inputs = []\n",
    "for i, one_input in enumerate(tmpInput):\n",
    "    inputs.append(tokenizer.encode(one_input))\n",
    "targets = tokenizer.encode(tmpTarget)\n",
    "\n",
    "inputs= torch.tensor(inputs, dtype=torch.long).to(device)\n",
    "targets = torch.tensor(targets, dtype=torch.long).to(device)\n",
    "\n",
    "tmpXtest, tmpYtest = inter_action_and_feedback_size(historyTest, context_lenght)\n",
    "\n",
    "x_test = []\n",
    "for i, one_input in enumerate(tmpXtest):\n",
    "    x_test.append(tokenizer.encode(one_input))\n",
    "y_test = tokenizer.encode(tmpYtest)\n",
    "\n",
    "x_test = torch.tensor(x_test, dtype=torch.long).to(device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "mymodel = GPTModel({\n",
    "        \"vocab_size\": len(['a', 'b', 'x', 'y']),\n",
    "        \"context_length\": context_lenght,\n",
    "        \"emb_dim\": 16 * 2,\n",
    "        \"n_heads\": 4,\n",
    "        \"n_leayers\": 4,\n",
    "        \"drop_rate\": 0.2,\n",
    "        \"qkv_bias\": False,\n",
    "        \"device\": device,\n",
    "        \"out_vocab_size\": len(['a', 'b', 'x', 'y'])\n",
    "    })\n",
    "\n",
    "optimizer = torch.optim.AdamW(mymodel.parameters(), lr=1e-2, weight_decay=1e-2)\n",
    "\n",
    "train_loss, val_loss = train_simple(mymodel, optimizer, inputs, targets, 100, x_test, y_test)\n",
    "\n",
    "print(accuracy(mymodel, x_test, y_test))\n",
    "\n",
    "plt.plot(train_loss, label='Train Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plot_loss(train_loss, val_loss, path:str=\"img_loss\", title:str=\"\"):\n",
    "    plt.plot(train_loss, label='Train Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    # if title == \"\" title = 'loss' + nb img save\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    \n",
    "    if title == \"\":\n",
    "        title = 'loss' + str(len(os.listdir(path)))\n",
    "    plt.savefig(path + '/' + title + '.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model \n",
    "# seq =torch.tensor([tokenizer.encode(['b', 'x', 'a', 'x', 'b', 'x', 'b', 'y', 'a', 'x', 'b', 'x', 'a', 'x', 'b', 'x', 'b', 'x', 'a', 'y', 'a'])]).to(device)\n",
    "# Context = 21\n",
    "seq =torch.tensor([tokenizer.encode(['b', 'x', 'a' , 'y', 'a', 'y', 'a', 'x', 'a', 'x', 'a', 'x', 'a', 'x', 'a', 'x', 'a', 'x', 'b', 'x', 'b'])]).to(device)\n",
    "#=============================================================^noise=================================================================^noise\n",
    "# Context = 5\n",
    "# seq =torch.tensor([tokenizer.encode(['b', 'x', 'a' , 'y', 'b'])]).to(device)\n",
    "\n",
    "# Second noise have an impact on the prediction\n",
    "# Not the first one\n",
    "mymodel.eval()\n",
    "x = mymodel(seq, False)\n",
    "probs = nn.functional.softmax(x, dim=-1)\n",
    "predi = torch.argmax(probs)\n",
    "see_proba(probs[0].tolist(), None)\n",
    "print(f'for seq {str(seq)} the next token is {tokenizer.decode([predi.item()])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def see_evolued_train_loss(train_loss):\n",
    "    for i, loss_list in enumerate(train_loss):\n",
    "        plt.plot(loss_list, label=f'Iteration {i}', color=plt.cm.viridis(i / len(train_loss)))\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise Exception(\"Stop here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_tree_prediction(model, env, max_deep:int, last_sequence:list, seq_predi:list=[]):\n",
    "#     if max_deep == 0:\n",
    "#         return []\n",
    "#     # input(f'{last_sequence} | {seq_predi}')\n",
    "#     max_deep -= 1\n",
    "    \n",
    "#     fake_tree = []\n",
    "#     model.eval()\n",
    "#     for act in env.get_actions():\n",
    "#         seq_to_predict = tokenizer.encode(last_sequence + [act])\n",
    "#         seq_to_predict = torch.tensor([seq_to_predict], dtype=torch.long).to(device)\n",
    "#         # input(f'seq to pass in model {seq_to_predict}')\n",
    "#         x = model(seq_to_predict, False)\n",
    "#         probs = nn.functional.softmax(x, dim=-1)\n",
    "#         predi = tokenizer.decode([torch.argmax(probs).item()])\n",
    "#         new__last_seq = last_sequence[2:] + [act, predi]\n",
    "#         new_seq_predi = seq_predi + [act, predi]\n",
    "#         # input(f'new last seq {new__last_seq} | new seq pred {new_seq_predi}')\n",
    "#         fake_tree.append(new_seq_predi) \n",
    "#         fake_tree += (make_tree_prediction(model, env, max_deep, new__last_seq, new_seq_predi))\n",
    "\n",
    "#     return fake_tree\n",
    "\n",
    "\n",
    "def make_tree_prediction(model, env, valence:dict, max_deep: int, last_sequence: list):\n",
    "    model.eval()\n",
    "    stack = [(last_sequence, [], 1)]\n",
    "    fake_tree = {}\n",
    "\n",
    "    while stack:\n",
    "        last_sequence, seq_predi, value = stack.pop()\n",
    "        # input(f'start wihle {stack} | \\n last seq {last_sequence} \\n seq predi {seq_predi}')\n",
    "        \n",
    "        if len(seq_predi) // 2 >= max_deep:\n",
    "            continue\n",
    "\n",
    "        for act in env.get_actions():\n",
    "            seq_to_predict = tokenizer.encode(last_sequence + [act])\n",
    "            seq_to_predict = torch.tensor([seq_to_predict], dtype=torch.long).to(device)\n",
    "            \n",
    "            x = model(seq_to_predict, False)\n",
    "            probs = nn.functional.softmax(x, dim=-1)\n",
    "            predi = tokenizer.decode([torch.argmax(probs).item()])\n",
    "            best_proba = probs[0][torch.argmax(probs)].item()\n",
    "            # print(f'best proba {best_proba}')\n",
    "            \n",
    "            new_last_seq = last_sequence[2:] + [act, predi]\n",
    "            new_seq_predi = seq_predi + [act, predi]\n",
    "            new_value = value + best_proba * valence[(act, predi)]\n",
    "            fake_tree[str(new_seq_predi)] = new_value\n",
    "            stack.append((new_last_seq, new_seq_predi, new_value))\n",
    "\n",
    "    return fake_tree\n",
    "\n",
    "\n",
    "def model_in_env(model, tokenizer:SimpleTokenizerV1, env, valance:dict, iter:int, rand_iter:int = 10, path_save = \"loss_\", _lr=1e-2, weight_decay=1e-2, max_depth=3):\n",
    "    history = []\n",
    "    context_lenght = model.cfg[\"context_length\"]\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=_lr, weight_decay=weight_decay)\n",
    "    evolued_train_loss = []\n",
    "    evolued_val_loss = []\n",
    "    all_predit = None\n",
    "    good_predicts:list[bool] = []\n",
    "    historyTest = []\n",
    "\n",
    "    for i in range(1000):\n",
    "        action = np.random.choice(env.get_actions())\n",
    "        feedback = env.outcome(action)\n",
    "        historyTest.append((str(action), str(feedback)))\n",
    "\n",
    "    tmpXtest, tmpYtest = inter_action_and_feedback_size(historyTest, context_lenght)\n",
    "\n",
    "    x_test = []\n",
    "    for i, one_input in enumerate(tmpXtest):\n",
    "        x_test.append(tokenizer.encode(one_input))\n",
    "    y_test = tokenizer.encode(tmpYtest)\n",
    "\n",
    "    x_val = torch.tensor(x_test, dtype=torch.long).to(device)\n",
    "    y_val = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "    for i in range(0, iter):\n",
    "        if i < rand_iter:\n",
    "            action = np.random.choice(env.get_actions())\n",
    "        else:\n",
    "            # train model\n",
    "            if i % 10 == 0:\n",
    "                model.apply(model._init_weights)\n",
    "                tmpInput, tmpTarget = inter_action_and_feedback_size(history, context_lenght)\n",
    "                inputs = []\n",
    "                for one_input in tmpInput:\n",
    "                    inputs.append(tokenizer.encode(one_input))\n",
    "                targets = tokenizer.encode(tmpTarget)\n",
    "\n",
    "                inputs= torch.tensor(inputs, dtype=torch.long).to(device)\n",
    "                targets = torch.tensor(targets, dtype=torch.long).to(device)\n",
    "                time_start = time.time()\n",
    "                train_loss, val_loss = train_simple(model, optimizer, inputs, targets, 1000, verbose=False, x_val=x_val, y_val=y_val)\n",
    "                save_plot_loss(train_loss, val_loss, path=path_save, title=f'loss_{i}')\n",
    "                time_end = time.time()\n",
    "                print(f'time to train {time_end - time_start}')\n",
    "                evolued_train_loss.append(train_loss)\n",
    "                evolued_val_loss.append(val_loss)\n",
    "\n",
    "            # predict next action\n",
    "            tmp = tmpInput[-1][2:] + [tmpTarget[-1]]\n",
    "            time_start = time.time()\n",
    "            all_predit:dict = make_tree_prediction(\n",
    "                    model=model, env=env, max_deep=max_depth, valence=valance,\n",
    "                    last_sequence= tmp)\n",
    "            print(f'for this sequence {tmp} all prediction {all_predit}')\n",
    "            interact_max_val = max(all_predit.items())[0]\n",
    "            interact_max_val = eval(interact_max_val)\n",
    "            # input(f'max is {interact_max_val}')\n",
    "            action = interact_max_val[0]\n",
    "            predict = interact_max_val[1]\n",
    "            # input(f'action {action}')\n",
    "            # input(f'predict {predict}')\n",
    "            # input(f'for this sequence {tmp} all prediction {test}')\n",
    "            time_end = time.time()\n",
    "            print(f'time to make tree {time_end - time_start}')\n",
    "            # print(f'for this sequence {tmp}')\n",
    "            # print(f'all prediction {test}')\n",
    "            # max_potentiel = -np.inf\n",
    "            # for act in env.get_actions():\n",
    "            #     seq_to_predict = tokenizer.encode(tmpInput[-1][2:] + [tmpTarget[-1], act])\n",
    "            #     seq_to_predict = torch.tensor([seq_to_predict], dtype=torch.long).to(device)\n",
    "            #     x = model(seq_to_predict, False)\n",
    "            #     probs = nn.functional.softmax(x, dim=-1)\n",
    "            #     predi = torch.argmax(probs)\n",
    "            #     val_predi = valance[(act, tokenizer.decode([predi.item()]))]\n",
    "            #     if val_predi > max_potentiel:\n",
    "            #         max_potentiel = val_predi\n",
    "            #         action = act\n",
    "            #     elif val_predi == max_potentiel:\n",
    "            #         action = np.random.choice([action, act])\n",
    "\n",
    "            # action = np.random.choice(env.get_actions()) # TODO delete this\n",
    "            \n",
    "\n",
    "        feedback = env.outcome(action)\n",
    "        if all_predit is not None:\n",
    "            list_keys = all_predit.keys()\n",
    "            # list_keys = [eval(key) for key in list_keys]\n",
    "            # input(f'I try to find if {str([str(action), feedback])} in {list_keys}')\n",
    "            good_predicts.append(str([str(action), feedback]) in list_keys)\n",
    "            print(f'% good predict : {sum(good_predicts[-10:]) * 10 if len(good_predicts) >= 10 else 0}')\n",
    "        print(f'iteration {i} action {action} feedback {feedback} predict {all_predit.keys() if all_predit else \"None\"}')\n",
    "        history.append((str(action), str(feedback)))\n",
    "\n",
    "    return evolued_train_loss, evolued_val_loss, good_predicts\n",
    "\n",
    "\n",
    "mymodel = GPTModel({\n",
    "        \"vocab_size\": len(['a', 'b', 'x', 'y']),\n",
    "        \"context_length\": 21,\n",
    "        \"emb_dim\": 16 *2,\n",
    "        \"n_heads\": 1, # 4\n",
    "        \"n_leayers\": 1, # 4\n",
    "        \"drop_rate\": 0.2,\n",
    "        \"qkv_bias\": False,\n",
    "        \"device\": device,\n",
    "        \"out_vocab_size\": len(['a', 'b', 'x', 'y'])\n",
    "    })\n",
    "\n",
    "\n",
    "valence = {\n",
    "    ('a', 'x') : -10,\n",
    "    ('a', 'y') : 10,\n",
    "    ('b', 'x') : -10,\n",
    "    ('b', 'y') : 10\n",
    "}\n",
    "\n",
    "env = env6Str()\n",
    "\n",
    "print(env.get_actions())\n",
    "\n",
    "tokenizer = SimpleTokenizerV1(create_all_words_action_outcome_enumerate(['a', 'b', 'x', 'y'], []))\n",
    "\n",
    "# evolued_train_loss, evolued_val_loss = model_in_env(mymodel, tokenizer, env, valence, 500, 100)\n",
    "\n",
    "# see_evolued_train_loss(evolued_train_loss)\n",
    "# see_evolued_train_loss(evolued_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicRt = {\n",
    "    str(['a',' b']): 1111\n",
    "}\n",
    "\n",
    "if str(['a',' c']) in dicRt:\n",
    "    print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see_evolued_train_loss(evolued_train_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = small_loop(1, 1, 0)\n",
    "\n",
    "mymodel = GPTModel({\n",
    "        \"vocab_size\": len(env.get_actions()) + len(env.get_outcomes()),\n",
    "        \"context_length\": 51,\n",
    "        \"emb_dim\": 16 * 4,\n",
    "        \"n_heads\": 1, # 4\n",
    "        \"n_leayers\": 1, # 4\n",
    "        \"drop_rate\": 0.2,\n",
    "        \"qkv_bias\": False,\n",
    "        \"device\": device,\n",
    "        \"out_vocab_size\": len(env.get_actions()) + len(env.get_outcomes())\n",
    "    })\n",
    "\n",
    "\n",
    "valence = {\n",
    "    ('forward', 'wall') : -10,\n",
    "    ('forward', 'empty') : 10,\n",
    "    ('turn_left', 'wall') : -1000000, # Can not produce\n",
    "    ('turn_left', 'empty') : -3,\n",
    "    ('turn_right', 'wall') : -1000000, # Can not produce\n",
    "    ('turn_right', 'empty') : -3,\n",
    "    ('feel_front', 'wall') : -3,\n",
    "    ('feel_front', 'empty') : -2,\n",
    "    ('feel_left', 'wall') : -3,\n",
    "    ('feel_left', 'empty') : -2,\n",
    "    ('feel_right', 'wall') : -3,\n",
    "    ('feel_right', 'empty') : -2\n",
    "\n",
    "}\n",
    "\n",
    "print(env.get_actions())\n",
    "\n",
    "tokenizer = SimpleTokenizerV1(create_all_words_action_outcome_enumerate(env.get_actions(), env.get_outcomes()))\n",
    "\n",
    "# evolued_train_loss, evolued_val_loss, _ = model_in_env(mymodel, tokenizer, env, valence, 500, 100, \"loss_SL_samll_embeding\", _lr=1e-3, weight_decay=1e-2, max_depth=4)\n",
    "\n",
    "# see_evolued_train_loss(evolued_train_loss)\n",
    "# see_evolued_train_loss(evolued_val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprentissage superviser\n",
    "## Decision tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "\n",
    "context_lenght = None\n",
    "\n",
    "def make_data_set(tokenizer, env, context_lenght:int, rand_iter:int = 100):\n",
    "    history = []\n",
    "\n",
    "    # Create data val\n",
    "    historyTest = []\n",
    "    for i in range(1000):\n",
    "        action = np.random.choice(env.get_actions())\n",
    "        feedback = env.outcome(action)\n",
    "        historyTest.append((str(action), str(feedback)))\n",
    "\n",
    "    tmpXtest, tmpYtest = inter_action_and_feedback_size(historyTest, context_lenght)\n",
    "    x_test = []\n",
    "    for i, one_input in enumerate(tmpXtest):\n",
    "        x_test.append(tokenizer.encode(one_input))\n",
    "    y_test = tokenizer.encode(tmpYtest)\n",
    "\n",
    "    # Create first rand sequence\n",
    "    for i in range(rand_iter):\n",
    "        action = np.random.choice(env.get_actions())\n",
    "        feedback = env.outcome(action)\n",
    "        history.append((str(action), str(feedback)))\n",
    "\n",
    "    tmpXfit, tmpYfit = inter_action_and_feedback_size(history, context_lenght)\n",
    "    x_fit = []\n",
    "    for i, one_input in enumerate(tmpXfit):\n",
    "        x_fit.append(tokenizer.encode(one_input))\n",
    "    y_fit = tokenizer.encode(tmpYfit)\n",
    "\n",
    "    return x_fit, y_fit, x_test, y_test\n",
    "\n",
    "\n",
    "# env = small_loop(1, 1, 0)\n",
    "env = env6Str()\n",
    "tokenizer = SimpleTokenizerV1(\n",
    "    create_all_words_action_outcome_enumerate(\n",
    "        env.get_actions(), env.get_outcomes()))\n",
    "\n",
    "valence = {\n",
    "    ('forward', 'wall') : -10,\n",
    "    ('forward', 'empty') : 10,\n",
    "    ('turn_left', 'wall') : -1000000, # Can not produce\n",
    "    ('turn_left', 'empty') : -3,\n",
    "    ('turn_right', 'wall') : -1000000, # Can not produce\n",
    "    ('turn_right', 'empty') : -3,\n",
    "    ('feel_front', 'wall') : -3,\n",
    "    ('feel_front', 'empty') : -2,\n",
    "    ('feel_left', 'wall') : -3,\n",
    "    ('feel_left', 'empty') : -2,\n",
    "    ('feel_right', 'wall') : -3,\n",
    "    ('feel_right', 'empty') : -2\n",
    "}\n",
    "\n",
    "x_fit, y_fit, x_val, y_val = make_data_set(env=env,\n",
    "              rand_iter=200,\n",
    "              tokenizer=tokenizer,\n",
    "              )\n",
    "\n",
    "# analyse data\n",
    "# Correlation Matrix\n",
    "df = pd.DataFrame(x_fit)\n",
    "df['target'] = y_fit\n",
    "corr = df.corr()\n",
    "print(corr)\n",
    "\n",
    "# Count y_fit\n",
    "print(\"Count y_fit \")\n",
    "print(pd.Series(y_fit).value_counts())\n",
    "\n",
    "\n",
    "# Test with decision tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(x_fit, y_fit)\n",
    "y_pred = clf.predict(x_val)\n",
    "\n",
    "print(f'Tree : accuracy {sk.metrics.accuracy_score(y_val, y_pred)}')\n",
    "# Confusion matrix\n",
    "print(sk.metrics.confusion_matrix(y_val, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Cette classe utilise plusieurs couche cachÃ©es\n",
    "    Pour dÃ©finir un rÃ©seau de neurones profonds\n",
    "    \n",
    "    - Il y a une couche d'entrÃ©e\n",
    "    - Plusieurs couches cachÃ©es dÃ©pendant de la liste hidden_size\n",
    "    - Une couche de sortie\n",
    "\n",
    "    les poids sont initialise de maniÃ¨re alÃ©atoire\n",
    "    \"\"\"\n",
    "    \n",
    "    name = \"DeepNetwork\"\n",
    "    \n",
    "    def __init__(self, input_size:int, hidden_size:list[int], output_size:int):\n",
    "        \"\"\"\n",
    "        Constructeur de la classe, applique le constructeur de la classe parent\n",
    "        Et crÃ©e les couches du rÃ©seau :\n",
    "        - 1 couche d'entrÃ©e\n",
    "        - Plusieurs couches cachÃ©es\n",
    "        - 1 couche de sortie\n",
    "        \n",
    "        Les couches cachÃ©es sont dÃ©finies mis en place avec nn.ModuleList, pour permettre\n",
    "        l'ajout dynamique de couches cachÃ©es. (Concretement nous pouvons passer le \n",
    "        modele.to(deviece) et la sauvgarde des poids par torch)\n",
    "\n",
    "        :param input_size: la taille des donnÃ©es d'entrÃ©e\n",
    "        :param output_size: la taille des donnÃ©es de sortie\n",
    "        :param hidden_size: la taille des couches cachÃ©es, \n",
    "        le nombre d'Ã©lÃ©ments dans la liste correspond au nombre de couches cachÃ©es       \n",
    "        \"\"\"\n",
    "        super(DeepNetwork, self).__init__()\n",
    "        # nn.Linear initialise les poids de maniÃ¨re alÃ©atoire\n",
    "        print(\"liste hidden init\",hidden_size)\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size[0])\n",
    "\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for size in range(len(hidden_size) - 1):\n",
    "            self.hidden_layers.append(nn.Linear(hidden_size[size], hidden_size[size + 1]))\n",
    "\n",
    "        self.fc4 = nn.Linear(hidden_size[-1], output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            x = nn.functional.relu(layer(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: nn.Module, test_loader: torch.utils.data.DataLoader, loss_funct) -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    MÃ©thode d'Ã©valuation du modÃ¨le\n",
    "\n",
    "    :param model: le modÃ¨le Ã  Ã©valuer\n",
    "    :param test_loader: le lecteur de donnÃ©es de test\n",
    "    :param loss_funct: la fonction de perte Ã  utiliser pour l'Ã©valuation\n",
    "    :param device: le device sur lequel effectuer les calculs\n",
    "    :return: une tuple contenant (le taux de rÃ©ussite, la perte moyenne)\n",
    "    \"\"\"\n",
    "    acc = 0.0\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    model.to(device)\n",
    "    model.eval()  # Pour dÃ©sactiver les couches dropout ou batchnorm\n",
    "    with torch.no_grad():  # Pas besoin de calculer les gradients en mode Ã©valuation\n",
    "        for x, t in test_loader:\n",
    "            x, t = x.to(device), t.to(device)\n",
    "            \n",
    "            # PrÃ©dictions\n",
    "            y = model(x)\n",
    "            \n",
    "            # Calcul de la loss\n",
    "            loss = loss_funct(y, t)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Calcul de la prÃ©cision\n",
    "            if len(t.shape) > 1 and t.shape[1] > 1:  # Si les labels sont one-hot encodÃ©s\n",
    "                t = torch.argmax(t, dim=1)  # On convertit en indices de classes\n",
    "            acc += (torch.argmax(y, 1) == t).sum().item()\n",
    "            \n",
    "            total_samples += t.size(0)\n",
    "\n",
    "    avg_acc = acc / total_samples\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "\n",
    "    return avg_acc, avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model:nn.Module,\n",
    "        train_loader:torch.utils.data.DataLoader,\n",
    "        validate_loader:torch.utils.data.DataLoader,\n",
    "        optimizer:torch.optim.SGD,\n",
    "        loss_func:torch.nn.MSELoss,\n",
    "        nb_epochs:int,\n",
    "        print_:bool=False\n",
    "        ) -> Tuple[float, nn.Module]:\n",
    "    \"\"\"\n",
    "    MÃ©thode d'entraÃ®nement du modÃ¨le\n",
    "\n",
    "    Pour chaque Ã©poque:\n",
    "    - on entraÃ®ne le modÃ¨le sur les donnÃ©es d'apprentissage\n",
    "    - Puis on Ã©value le modÃ¨le sur les donnÃ©es de validation\n",
    "\n",
    "    Au final nous renvoyons le modÃ¨le avec le meilleur taux de rÃ©ussite\n",
    "    (Nous Ã©vitons le sur-apprentissage tout en testant l'entiÃ¨retÃ© des Ã©poques)\n",
    "\n",
    "    :param model: le modÃ¨le Ã  entraÃ®ner\n",
    "    :param train_loader: le lecteur de donnÃ©es d'apprentissage\n",
    "    :param validate_loader: le lecteur de donnÃ©es de validation\n",
    "    :param optimizer: l'optimiseur liÃ© au modÃ¨le\n",
    "    :param loss_func: la fonction de loss\n",
    "    :param nb_epochs: le nombre d'Ã©poques\n",
    "    :param print_: afficher ou non les rÃ©sultats\n",
    "    :return: le taux de rÃ©ussite final et le meilleur modÃ¨le\n",
    "    \"\"\"\n",
    "    meilleur_acc:int = 0\n",
    "    meilleur_model = None\n",
    "    model.to(device)\n",
    "    loss_func.to(device)\n",
    "    for epoch in range(nb_epochs):\n",
    "        for x,t in train_loader:\n",
    "            x, t = x.to(device), t.to(device)\n",
    "            # on calcule la sortie du modÃ¨le\n",
    "            y = model(x)\n",
    "            # on met Ã  jour les poids\n",
    "            if t.dim() > 1 and t.shape[1] > 1:  # VÃ©rifie si t est en one-hot encoding\n",
    "                t = torch.argmax(t, dim=1)  # Convertit en indices de classes\n",
    "\n",
    "            loss:torch.Tensor = loss_func(y,t)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        acc, _ = evaluate(model=model, test_loader=validate_loader, loss_funct=loss_func)\n",
    "        if acc > meilleur_acc:\n",
    "            meilleur_acc = acc\n",
    "            meilleur_model = model\n",
    "\n",
    "        if print_:\n",
    "            print(f'Epoch {epoch+1}/{nb_epochs}, Accuracy: {acc}')\n",
    "    return meilleur_acc, meilleur_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = env6Str()\n",
    "tokenizer = SimpleTokenizerV1(\n",
    "    create_all_words_action_outcome_enumerate(\n",
    "        env.get_actions(), env.get_outcomes()))\n",
    "\n",
    "\n",
    "# CrÃ©ation des donnÃ©es\n",
    "x_fit, y_fit, x_val, y_val = make_data_set(env=env,\n",
    "              rand_iter=200,\n",
    "              tokenizer=tokenizer,\n",
    "              )\n",
    "\n",
    "x_fit = torch.tensor(x_fit, dtype=torch.float).to(device)\n",
    "y_fit = torch.tensor(y_fit, dtype=torch.long).to(device)\n",
    "\n",
    "# Transforme y_fit en one hot\n",
    "y_fit = torch.nn.functional.one_hot(y_fit.to(torch.int64), len(env.get_actions()) + len(env.get_outcomes())).to(torch.float)\n",
    "\n",
    "x_val = torch.tensor(x_val, dtype=torch.float).to(device)\n",
    "y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n",
    "\n",
    "\n",
    "# CrÃ©ation des DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(x_fit, y_fit), batch_size=32, shuffle=True\n",
    ")\n",
    "validate_loader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(x_val, y_val), batch_size=32, shuffle=False\n",
    ")\n",
    "\n",
    "# CrÃ©ation du modÃ¨le\n",
    "model = DeepNetwork(\n",
    "    input_size=len(x_fit[0]),\n",
    "    hidden_size=[10, 5],\n",
    "    output_size=len(env.get_actions()) + len(env.get_outcomes())\n",
    ")\n",
    "\n",
    "# CrÃ©ation de l'optimiseur\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "\n",
    "# CrÃ©ation de la fonction de perte\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# EntraÃ®nement du modÃ¨le\n",
    "best_acc, best_model = train(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    validate_loader=validate_loader,\n",
    "    optimizer=optimizer,\n",
    "    loss_func=loss_func,\n",
    "    nb_epochs=100,\n",
    "    print_=True\n",
    ")\n",
    "\n",
    "# Ã‰valuation du modÃ¨le\n",
    "acc, loss = evaluate(model=best_model, test_loader=validate_loader, loss_funct=loss_func)\n",
    "print(f'Accuracy: {acc}, Loss: {loss}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fin de la biffurcasion on reprend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_set(tokenizer, env, rand_iter:int, context_lenght:int):\n",
    "    \"\"\"\n",
    "    Create a data set from the environment, make action randomly \\\n",
    "    and store (action, feedback) in list of list of tuple for the model\n",
    "    :param tokenizer: the tokenizer to encode the data\n",
    "    :param env: the environment to interact with\n",
    "    :param rand_iter: the number of random iteration\n",
    "    :param context_lenght: the context lenght to use\n",
    "    \"\"\"\n",
    "    history = []\n",
    "    for i in range(rand_iter):\n",
    "        action = np.random.choice(env.get_actions())\n",
    "        feedback = env.outcome(action)\n",
    "        history.append((str(action), str(feedback)))\n",
    "\n",
    "    tmpXfit, tmpYfit = inter_action_and_feedback_size(history, context_lenght)\n",
    "    x_fit = []\n",
    "    for i, one_input in enumerate(tmpXfit):\n",
    "        x_fit.append(tokenizer.encode(one_input))\n",
    "    y_fit = tokenizer.encode(tmpYfit)\n",
    "\n",
    "    return x_fit, y_fit\n",
    "\n",
    "def tempo_recursif_expective_valance(model:nn.Module, env, seq:list,\n",
    "                                    max_depth:int, valance:dict, \n",
    "                                    seuil:float=0.2, proba:float = 1,\n",
    "                                    seq_predi:list = []):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if max_depth == 0:\n",
    "        return {}\n",
    "    max_depth -= 1\n",
    "\n",
    "    if proba < seuil:\n",
    "        return {}\n",
    "    \n",
    "    model.eval()\n",
    "    exceptive_valance = {}\n",
    "    for act in env.get_actions():\n",
    "        new_seq = seq_predi + [act]\n",
    "        seq_to_predict = seq + [tokenizer.encode(act)]\n",
    "        seq_to_predict = torch.tensor([seq_to_predict], dtype=torch.long).to(device)\n",
    "        x = model(seq_to_predict, False)\n",
    "        probs = nn.functional.softmax(x, dim=-1)\n",
    "        # for each outcomes we want proba with act\n",
    "        for out in env.get_outcomes():\n",
    "            tmp_new_seq = new_seq + [out]\n",
    "            tmp_proba = probs[0][tokenizer.encode(out)].item() * proba\n",
    "            if tmp_proba < seuil:\n",
    "                continue\n",
    "            tempo =np.round(valance[(act, out)] * tmp_proba, decimals=4)\n",
    "            # input(f'seq {seq_predi} act {act} out {out} proba {tmp_proba} valance {valance[(act, out)]} tempo {tempo}')\n",
    "\n",
    "            exceptive_valance.update(\n",
    "                tempo_recursif_expective_valance(model, env, \n",
    "                                            seq[2:] + [tokenizer.encode(act), tokenizer.encode(out)],\n",
    "                                            max_depth, valance, seuil, tmp_proba, tmp_new_seq.copy())\n",
    "            )\n",
    "            exceptive_valance[str(tmp_new_seq)] = tempo\n",
    "    return exceptive_valance\n",
    "\n",
    "def compute_expective_valance(model:nn.Module, env,\n",
    "                            seq:list, depth:int, valance:dict):\n",
    "    \"\"\" \n",
    "    Not implemented\n",
    "    \"\"\"\n",
    "    raise Exception(\"Not implemented\")\n",
    "\n",
    "def act_in_env(model: nn.Module, \n",
    "            tokenizer:SimpleTokenizerV1,\n",
    "            env, valance:dict, iter:int,\n",
    "            path_save = \"env\", _lr=1e-2, weight_decay=1e-2, max_depth=3):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    context_lenght = model.cfg[\"context_length\"]\n",
    "    device = model.cfg[\"device\"]\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=_lr, weight_decay=weight_decay)\n",
    "    evolued_train_loss = []\n",
    "    finish_evolued_train_loss = []\n",
    "    evolued_val_loss = []\n",
    "    good_predicts:list[bool] = []\n",
    "\n",
    "    # TODO delete validation\n",
    "    x_val, y_val = make_data_set(env=env,\n",
    "              rand_iter=1000,\n",
    "              tokenizer=tokenizer,\n",
    "              context_lenght=context_lenght\n",
    "              )\n",
    "\n",
    "    x_val = torch.tensor(x_val, dtype=torch.long).to(device)\n",
    "    y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n",
    "\n",
    "    x_train, y_train = make_data_set(env=env,\n",
    "                rand_iter=context_lenght,\n",
    "                tokenizer=tokenizer,\n",
    "                context_lenght=context_lenght\n",
    "                )\n",
    "    assert len(x_train) == 1 and len(y_train) == 1, \"We need to have only one sequence to first train the model\"\n",
    "    assert len(x_train[0]) == context_lenght, \"The context lenght is not correct\"\n",
    "\n",
    "    inputs= torch.tensor(x_train, dtype=torch.long).to(device)\n",
    "    targets = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "\n",
    "    for i in range(0, iter):\n",
    "        # train model\n",
    "        model.train()\n",
    "        # train_loss, val_loss = train_simple(model, optimizer, \n",
    "        #                         inputs, targets, 50, verbose=True, x_val=x_val, y_val=y_val)\n",
    "        train_loss, val_loss = train_for_one_seq(model, optimizer, \n",
    "                                inputs, targets, 2, verbose=True, x_val=x_val, y_val=y_val)\n",
    "        save_plot_loss(train_loss, val_loss, path=path_save, title=f'loss_{i}')\n",
    "        # We remove 2 word and add 1 word. Beacause compute_expective_valance give us the last word (each action)\n",
    "        seq_to_predict = x_train[0][2:] + [targets[-1]]\n",
    "        exceptive_valance = tempo_recursif_expective_valance(model, env, seq_to_predict, max_depth, valance, seuil=0.0001)\n",
    "        print(f'for seq {seq} all exceptive valance {exceptive_valance}')\n",
    "        try:\n",
    "            max_val_pred = eval(max(exceptive_valance, key=exceptive_valance.get))\n",
    "            act = max_val_pred[0]\n",
    "            predi = max_val_pred[1]\n",
    "        except Exception as e:\n",
    "            print(f'\\033[0;31m iterationerror dont find max val pred {e}')\n",
    "            print(\"act chose randomly\\033[0m iteration\")\n",
    "            act = np.random.choice(env.get_actions())\n",
    "\n",
    "        # input(f'for seq {seq} the next action is {act} and the next predi is {predi} in max val pred {max_val_pred}')\n",
    "\n",
    "        # act, predi = compute_expective_valance(model, seq=seq_to_predict, env=env,\n",
    "        #                                        depth=max_depth, valance=valance)\n",
    "        fb = env.outcome(act)\n",
    "        good_predicts.append(predi == fb)\n",
    "        x_train = [x_train[0][2:] + [tokenizer.encode(act)]]\n",
    "        y_train = [tokenizer.encode(fb)]\n",
    "        inputs= torch.tensor(x_train, dtype=torch.long).to(device)\n",
    "        targets= torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "        evolued_train_loss.append(train_loss)\n",
    "        evolued_val_loss.append(val_loss)\n",
    "        print(f'It s train loss {train_loss}')\n",
    "        finish_evolued_train_loss.append(train_loss[-1])\n",
    "\n",
    "        print(f'% good predict : {sum(good_predicts[-10:]) * 10 if len(good_predicts) >= 10 else -1}')\n",
    "        print(f'\\033[0;34miteration {i} action \\033[0;31m {act} \\033[0;35m feedback {fb} \\033[0;31m predict {predi} \\033[0m')\n",
    "\n",
    "\n",
    "    return evolued_train_loss, evolued_val_loss, good_predicts, finish_evolued_train_loss\n",
    "\n",
    "\n",
    "valence = {\n",
    "    ('a', 'x') : -10,\n",
    "    ('a', 'y') : 10,\n",
    "    ('b', 'x') : -10,\n",
    "    ('b', 'y') : 10\n",
    "}\n",
    "env = env3Str()\n",
    "\n",
    "tokenizer = SimpleTokenizerV1(\n",
    "    create_all_words_action_outcome_enumerate(env.get_actions(), env.get_outcomes()))\n",
    "\n",
    "mymodel = GPTModel({\n",
    "        \"vocab_size\": len(env.get_actions()) + len(env.get_outcomes()),\n",
    "        \"context_length\": 51,\n",
    "        \"emb_dim\": 16 * 2,\n",
    "        \"n_heads\": 1, # 4\n",
    "        \"n_leayers\": 1, # 4\n",
    "        \"drop_rate\": 0.1,\n",
    "        \"qkv_bias\": False,\n",
    "        \"device\": device,\n",
    "        \"out_vocab_size\": len(env.get_outcomes())\n",
    "    })\n",
    "\n",
    "evolued_train_loss, evolued_val_loss, good_predicts, finish = act_in_env(\n",
    "    mymodel, tokenizer, env, valence, 100, \"loss_act_in_env\", \n",
    "    _lr=1e-1, weight_decay=1e-2, max_depth=3)\n",
    "print(f'finish : {finish}')\n",
    "see_evolued_train_loss([finish])\n",
    "\n",
    "see_evolued_train_loss(evolued_train_loss)\n",
    "\n",
    "see_evolued_train_loss(evolued_val_loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Stage (torch)",
   "language": "python",
   "name": "dpt_transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
