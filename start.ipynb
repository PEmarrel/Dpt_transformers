{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following file was inspired by the following tutorial:\n",
    "# https://colab.research.google.com/drive/1SiF0KZJp75rUeetKOWqpsA8clmHP6jMg?usp=sharing#scrollTo=d7utFz27cO9q\n",
    "\n",
    "# And use this cource for explanation:\n",
    "# https://bruno-yun.notion.site/The-Transformer-Model-for-NLG-c4413bd5a8044325a7658cb8ff5535f2\n",
    "# https://web.stanford.edu/~jurafsky/slp3/9.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.metadata import version\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from matplotlib import pyplot as plt\n",
    "from graphviz import Digraph\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from environnement.environnement1 import Environment1 as env1\n",
    "from environnement.environnement2 import Environment2 as env2\n",
    "from environnement.environnement2Str import Environment2 as env2Str\n",
    "\n",
    "from environnement.environnement3 import Environment3 as env3\n",
    "from environnement.environnement3Str import Environment3 as env3Str\n",
    "\n",
    "from environnement.environnement6Str import Environment6 as env6Str\n",
    "\n",
    "from inter.interactions import Interaction as inter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intro, bla bla bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporaire\n",
    "VOCAB_SIZE = 2 # For now we are only using binary data (0, 1) later can be modify by 12\n",
    "CONTEXT_LENGHT = 3 # And we are using a context of 3 bits (may be changed later)\n",
    "device = \"cpu\" if not torch.cuda.is_available() else \"cuda\"\n",
    "# device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads,\n",
    "                 qkv_bias = False, device = 'cpu'):\n",
    "        \n",
    "        super().__init__()\n",
    "        assert( d_out % num_heads == 0), \"d_out should be divisible by num_heads\"\n",
    "        \n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "        \n",
    "        # self.W_query = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
    "        # self.W_key = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
    "        # self.W_value = nn.Linear(d_in, d_out, bias = qkv_bias) \n",
    "        # Don't use this because we want to have only one projection to optimize\n",
    "        # To have only one projection we use the following line\n",
    "        self.W_qkv = nn.Linear(d_in, 3 * d_out, bias=qkv_bias).to(device)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout).to(device)\n",
    "        self.out_proj = nn.Linear(d_out, d_out).to(device)\n",
    "        # If we want to see past\n",
    "        mask = torch.triu(torch.ones(context_length,context_length), diagonal=1).to(device)\n",
    "        \n",
    "        # if we want to see future\n",
    "        # mask = torch.tril(torch.ones(context_length,context_length), diagonal=-1).to(device)\n",
    "        \n",
    "        # mask = torch.zeros(context_length, context_length, device=device)\n",
    "        self.register_buffer('mask', mask)\n",
    "        \n",
    "    def forward(self,x: torch.Tensor):\n",
    "        queries: torch.Tensor\n",
    "        keys: torch.Tensor\n",
    "        values: torch.Tensor\n",
    "        b, num_tokens, d_in = x.shape # b, num_token, d_in\n",
    "\n",
    "        # self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        # self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        # self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        # Use one projection to get queries, keys and values\n",
    "        # self.W_qkv(x) -> b, num_token, 3*d_out (is a tensor)\n",
    "        # chunk(3, dim=-1) -> b, num_token, d_out we split the tensor in 3 parts\n",
    "        queries, keys, values= self.W_qkv(x).chunk(3, dim=-1)\n",
    "        \n",
    "        # b, num_token, numheads, head_dim\n",
    "        queries = queries.reshape(b,\n",
    "                                num_tokens,\n",
    "                                self.num_heads,\n",
    "                                self.head_dim\n",
    "                            ).transpose(1, 2)\n",
    "        keys = keys.reshape(b,\n",
    "                            num_tokens,\n",
    "                            self.num_heads,\n",
    "                            self.head_dim\n",
    "                        ).transpose(1, 2)\n",
    "        values = values.reshape(b,\n",
    "                                num_tokens,\n",
    "                                self.num_heads,\n",
    "                                self.head_dim\n",
    "                            ).transpose(1, 2)\n",
    "        \n",
    "        # b, num_heads, num_token, num_token\n",
    "        attn_scores = torch.einsum('bhqd, bhkd -> bhqk', queries, keys)\n",
    "        \n",
    "        attn_scores = attn_scores.masked_fill(\n",
    "            self.mask[:num_tokens, :num_tokens].unsqueeze(0).unsqueeze(0).bool() == 1, \n",
    "            float('-inf')\n",
    "        )\n",
    "\n",
    "        attn_weights = nn.functional.softmax(attn_scores, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        \n",
    "        context = torch.einsum('bhqk, bhkd -> bhqd', \n",
    "                               attn_weights, \n",
    "                               values\n",
    "                            ).transpose(1, 2).reshape(b, num_tokens, self.d_out)\n",
    "        \n",
    "        \n",
    "        return self.out_proj(context)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explain of class MultiHeadAttention\n",
    "In transformers model, the **MultiHeadAttention** class is used to apply attention mechanisms to input sequences. Understanding how this class works requires first exploring **single-head** attention before generalizing to **multi-head attention**.\n",
    "\n",
    "## Single-Head Attention\n",
    "Attention in Transformers relies on measuring the similarity between tokens in a sequence. This measurement is performed using three distinct transformations:\n",
    "\n",
    "- Query (Q): Represents the current tokenâ€™s focus when comparing it to all other tokens.\n",
    "- Key (K): Represents a token being compared to the query.\n",
    "- Value (V): Represents the actual information to be aggregated based on attention scores.\n",
    "\n",
    "These three representations are obtained by applying linear transformations to the input sequence. The transformed matrices allow us to compute the attention scores using the scaled dot-product attention formula:\n",
    "\n",
    "$ \n",
    "score(x_i, x_j) = \\frac{q_i \\cdot k_j}{\\sqrt{d_k}} \n",
    "$\n",
    "\n",
    "Where $q_i$ is the query representation of token $i$, $k_j$ is the key representation of token $j$, and $d_k$ is the dimension of the key representation. \n",
    "\n",
    "In forward function is :\n",
    "```python\n",
    "attn_scores = torch.einsum('bhqd, bhkd -> bhqk', queries, keys)\n",
    "```\n",
    "\n",
    "To prevent a token from attending to future tokens (as in autoregressive models like GPT), we apply a mask to the attention scores. This ensures that each token only attends to itself and previous tokens:\n",
    "\n",
    "$\n",
    "a_i = \\sum_{j \\leq i} \\alpha_{ij}v_j\n",
    "$\n",
    "\n",
    "In forward function is :\n",
    "```python\n",
    "attn_scores = attn_scores.masked_fill(self.mask[:num_tokens, :num_tokens] == 0,\n",
    "                                float('-inf'))\n",
    "```\n",
    "\n",
    "Once the attention scores are computed and masked, they are normalized using the softmax function to produce attention weights:\n",
    "\n",
    "$\n",
    "\\alpha_{ij} = \\frac{\\exp(score(x_i,x_j))}{\\sum_j \\exp(score(x_i,x_j))}\n",
    "$\n",
    "\n",
    "In forward function is :\n",
    "```python\n",
    "attn_scores = nn.fonctional.softmax(attn_scores, dim=-1)\n",
    "```\n",
    "\n",
    "To prevent overfitting, a dropout layer is applied to the attention weights (self.dropout) before computing the context vector.\n",
    "\n",
    "To compute the context vector, we multiply the attention weights by the Value (V) representations to obtain the context vector.\n",
    "\n",
    "In forward function is :\n",
    "\n",
    "```python\n",
    "context = torch.einsum('bhqk, bhkd -> bhqd', attn_weights, values)\n",
    "```\n",
    "\n",
    "To resume we have done this :\n",
    "\n",
    "![explain one head](./img/ExplainOneHeadAttention.png)\n",
    "*Source: [Speech and Language Processing](https://web.stanford.edu/~jurafsky/slp3/9.pdf)*\n",
    "\n",
    "## Multi-Head Attention\n",
    "Single-head attention allows each token to focus on others, but it has limitations: it can only capture one type of relationship at a time. Multi-head attention improves this by using multiple attention heads in parallel.\n",
    "Instead of computing attention once, we split the input into multiple heads, each with a different representation of the sequence. This allows the model to capture diverse patterns.\n",
    "All heads are concatenated and linearly transformed to produce the final output. This process is implemented in the **MultiHeadAttention**, is why we use self.head_dim or 'd' in code.\n",
    "\n",
    "This figure resume compute with matrix :\n",
    "\n",
    "![Compute](./img/ExplainCompute.png)\n",
    "*Source: [Speech and Language Processing](https://web.stanford.edu/~jurafsky/slp3/9.pdf)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"], bias=cfg[\"qkv_bias\"]),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"], bias=cfg[\"qkv_bias\"])\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The FeedForward in transformer\n",
    "The **FeedForward** class is used to apply a feedforward neural network to the output of the multi-head attention layer. The feedforward network consists of two linear transformations with a GELU (or RELU) activation function in between.\n",
    "\n",
    "## GELU and RELU\n",
    "GELU and RELU are activation functions used in neural networks after linear transformations. GELU is a smoother version of RELU that has been shown to improve performance in transformer models. \n",
    "\n",
    "The GELU function is defined as:\n",
    "\n",
    "$\n",
    "GELU(x) = 0.5x(1 + tanh(\\sqrt{2/\\pi}(x + 0.044715x^3)))\n",
    "$\n",
    "\n",
    "RELU is a simpler activation function that sets all negative values to zero:\n",
    "\n",
    "$\n",
    "RELU(x) = max(0, x)\n",
    "$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(cfg[\"emb_dim\"]).to(cfg[\"device\"])\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in = cfg[\"emb_dim\"],\n",
    "            d_out = cfg[\"emb_dim\"],\n",
    "            context_length = cfg[\"context_length\"],\n",
    "            dropout = cfg[\"drop_rate\"],\n",
    "            num_heads = cfg[\"n_heads\"],\n",
    "            qkv_bias = cfg[\"qkv_bias\"],\n",
    "            device=cfg[\"device\"]\n",
    "        )\n",
    "        self.ff = FeedForward(cfg).to(cfg[\"device\"])\n",
    "        self.norm2 = nn.LayerNorm(cfg[\"emb_dim\"]).to(cfg[\"device\"])\n",
    "        self.dropout = nn.Dropout(cfg[\"drop_rate\"]).to(cfg[\"device\"])\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # print(\"we are in one transformer block\")\n",
    "        # print(x.shape)\n",
    "        # print(x)\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        # print(\"after att\", x.shape)\n",
    "        # print(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = x + shortcut\n",
    "        \n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x+ shortcut\n",
    "        # print(x.shape)\n",
    "        # print(x)\n",
    "        # print('end trs block')\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explain of class TransformerBlock\n",
    "The **TransformerBlock** class is the core building block of the transformer model. It consists of three main components: the **MultiHeadAttention**, the **FeedForward** layers and **LayerNorm**. The **MultiHeadAttention** layer is used to capture the relationships between tokens, while the **FeedForward** layer is used to apply non-linear transformations to the output of the attention layer. We use **LayerNorm** to normalize X and for normalize the output of the **FeedForward** layer.\n",
    "\n",
    "![image.png](./img/ExplainArchiTrans.png)\n",
    "*Source: [Speech and Language Processing](https://web.stanford.edu/~jurafsky/slp3/9.pdf)*\n",
    "\n",
    "In this figure we can see the Residual Stream. In the forward funciton it's name shortcut. It's a way to avoid the vanishing gradient problem. The output of the **FeedForward** layer is added to the input of the **MultiHeadAttention** layer. This allows the model to learn the difference between the input and output of the block, which helps to improve performance.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        # Embeddings\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"]).to(cfg[\"device\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"]).to(cfg[\"device\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"]).to(cfg[\"device\"])\n",
    "        \n",
    "        # Transformer Blocks\n",
    "        self.trf_blocks = nn.ModuleList(\n",
    "                [TransformerBlock(cfg) for _ in range(cfg[\"n_leayers\"])]\n",
    "            )\n",
    "        \n",
    "        # Normalization & Output layer\n",
    "        self.final_norm = nn.LayerNorm(cfg[\"emb_dim\"]).to(cfg[\"device\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False).to(cfg[\"device\"])\n",
    "        \n",
    "        # Weight tying: Share weights between embedding and output projection\n",
    "        self.tok_emb.weight = self.out_head.weight\n",
    "        \n",
    "        # Initialize weights (If we need)\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "        # Special initialization for transformer projection layers\n",
    "        for pn, p in self.named_parameters():\n",
    "            if pn.endswith('c_proj.weight'):\n",
    "                torch.nn.init.normal_(p,\n",
    "                                    mean=0.0,\n",
    "                                    std=0.02 / math.sqrt(2 * self.cfg[\"n_layers\"]))\n",
    "                \n",
    "    def forward(self, x: torch.Tensor, return_full_sequence=False):\n",
    "        b, seq_len = x.shape\n",
    "        device = x.device\n",
    "        # assert device != self.cfg['device'], \"Input tensor device does not match model device\"\n",
    "\n",
    "        # print(\"in GPT, forward \",x)\n",
    "        \n",
    "        # Token & Positional Embeddings\n",
    "        # (b, seq_len, emb_dim)\n",
    "        tok_embeds = self.tok_emb(x)\n",
    "        # print(\"tok_embeds \",tok_embeds)\n",
    "        # (seq_len, emb_dim)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=device))\n",
    "        # print(\"pos_embeds \",pos_embeds)\n",
    "        \n",
    "        x = tok_embeds + pos_embeds\n",
    "        # print(\"tok_embeds + pos_embeds \",x)\n",
    "        x = self.drop_emb(x)\n",
    "        # print(\"self.drop_emb(x) \",x)\n",
    "        \n",
    "        # Pass through Transformer Blocks\n",
    "        deleteme = 0\n",
    "        for block_ in self.trf_blocks:\n",
    "            deleteme += 1\n",
    "            x = block_(x)\n",
    "            # print(f\"block(x) nÂ°{deleteme} : {x}\")\n",
    "        \n",
    "        # Final normalization & output projection\n",
    "        x = self.final_norm(x)\n",
    "        # print(\"self.final_norm(x) \",x)\n",
    "        logits = self.out_head(x)\n",
    "\n",
    "        # print(\"logits \",logits)\n",
    "        \n",
    "        if not return_full_sequence:\n",
    "            logits = logits[:, -1, :]  # (b, vocab_size)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_val, y_val):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(x_val, False)\n",
    "        loss = nn.functional.cross_entropy(logits, y_val)\n",
    "    return loss.item()\n",
    "\n",
    "def train_simple(model, optimizer, inputs, targets, n_iter, x_val=None, y_val=None, verbose=True):\n",
    "    all_train_loss, all_val_loss = [], []\n",
    "    for i in range(n_iter):\n",
    "        logits = model(inputs, False)\n",
    "        loss = nn.functional.cross_entropy(logits, targets)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            all_train_loss.append(loss.item())\n",
    "            if x_val is not None:\n",
    "                val_loss = evaluate_model(model, x_val, y_val)\n",
    "                all_val_loss.append(val_loss)\n",
    "                if verbose:\n",
    "                    print(f'for {i} iteration, loss is {loss.item()} and val_loss is {val_loss}')\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f'for {i} iteration, loss is {loss.item()}')\n",
    "                \n",
    "\n",
    "    return all_train_loss, all_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_sequence(model, context, n_tokens):\n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_tokens):\n",
    "            logits = model(context, False)\n",
    "            probas = torch.softmax(logits, dim=-1)\n",
    "            next_token = torch.argmax(probas, dim=-1).unsqueeze(0)\n",
    "            context = torch.cat([context, next_token], dim=-1).to(device)\n",
    "    return context\n",
    "\n",
    "CONFIG_TEST = {\n",
    "    \"vocab_size\": 2,\n",
    "    \"context_length\": 15,\n",
    "    \"emb_dim\": 16,\n",
    "    \"n_heads\": 4,\n",
    "    \"n_leayers\": 4,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False,\n",
    "    \"device\": device\n",
    "}\n",
    "\n",
    "model_test = GPTModel(CONFIG_TEST)\n",
    "generate_sequence(model_test, torch.randint(0, CONFIG_TEST[\"vocab_size\"], (1, 3)).to(CONFIG_TEST[\"device\"]), 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M_small = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_leayers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False,\n",
    "    \"device\": device\n",
    "}\n",
    "\n",
    "OUR_CONFIG = {\n",
    "    \"vocab_size\": VOCAB_SIZE,\n",
    "    \"context_length\": CONTEXT_LENGHT,\n",
    "    \"emb_dim\": 16,\n",
    "    \"n_heads\": 4,\n",
    "    \"n_leayers\": 4,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False,\n",
    "    \"device\": device\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_possible(n, k):\n",
    "    \"\"\"\n",
    "    Generate all possible combination of n elements taken k by k\n",
    "    \"\"\"\n",
    "    if k == 0:\n",
    "        yield []\n",
    "    else:\n",
    "        for i in range(n):\n",
    "            for c in all_possible(n, k - 1):\n",
    "                yield [i] + c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model(gpt, token_to = None, graph = True):\n",
    "    \"\"\"\n",
    "    Plot the transition graph of the GPT model\n",
    "    \"\"\"\n",
    "    dot = Digraph(comment='Baby GPT', engine='circo')\n",
    "\n",
    "    for xi in all_possible(gpt.cfg[\"vocab_size\"], gpt.cfg[\"context_length\"]):\n",
    "        \n",
    "        # forward the GPT and get probabilities for next token\n",
    "        x = torch.tensor(xi, dtype=torch.long)[None, ...]\n",
    "        x = x.to(gpt.cfg[\"device\"])\n",
    "        # turn the list into a torch tensor and add a batch dimension\n",
    "        logits = gpt(x, False) # forward the gpt neural net\n",
    "\n",
    "        # print('logits :', logits)\n",
    "        probs = nn.functional.softmax(logits, dim=-1) # get the probabilities\n",
    "        y = probs[0].tolist() # remove the batch dimension and unpack the tensor into simple list\n",
    "        if token_to:\n",
    "            print(f\"input {token_to(xi)} ---> {y}\")\n",
    "        else:\n",
    "            print(f\"input {xi} ---> {y}\")\n",
    "\n",
    "        if graph:\n",
    "            # also build up the transition graph for plotting later\n",
    "            current_node_signature = \"\".join(str(d) for d in xi)\n",
    "            dot.node(current_node_signature)\n",
    "            # input(\"Press Enter to continue...\")\n",
    "\n",
    "            for t in range(gpt.cfg[\"vocab_size\"]):\n",
    "                next_node = xi[1:] + [t] # crop the context and append the next character\n",
    "                next_node_signature = \"\".join(str(d) for d in next_node)\n",
    "                p = y[t]\n",
    "\n",
    "                label=f\"{t}({p*100:.0f}%)\"\n",
    "                dot.edge(current_node_signature, next_node_signature, label=label)\n",
    "    \n",
    "    return dot\n",
    "\n",
    "# gpt = GPTModel(OUR_CONFIG)\n",
    "# plot_model(gpt)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_TRAIN = {\n",
    "    \"vocab_size\": 2,\n",
    "    \"context_length\": 3,\n",
    "    \"emb_dim\": 16,\n",
    "    \"n_heads\": 4,\n",
    "    \"n_leayers\": 4,\n",
    "    \"drop_rate\": 0.0,\n",
    "    \"qkv_bias\": False,\n",
    "    \"device\": device\n",
    "}\n",
    "\n",
    "# inputs = torch.tensor([[0, 1, 1],\n",
    "#                        [1, 0, 0],\n",
    "#                        [1, 1, 0],\n",
    "#                        [0, 0, 1]]).to(CONFIG_TRAIN[\"device\"])\n",
    "\n",
    "# targets = torch.tensor([[1, 1, 1],\n",
    "#                         [0, 0, 1],\n",
    "#                         [1, 0, 1],\n",
    "#                         [0, 1, 0]]).to(CONFIG_TRAIN[\"device\"])\n",
    "\n",
    "\n",
    "# probas = torch.softmax(model_test(inputs), dim=-1)\n",
    "\n",
    "# print(probas)\n",
    "\n",
    "# output = torch.argmax(probas, dim=-1)\n",
    "\n",
    "# print(output)\n",
    "\n",
    "\n",
    "# text_prob1= probas[0, targets[0]]\n",
    "# print(\"proba text1\", text_prob1)\n",
    "# print(\"proba text1 - what we obtained\", probas[0, output[0].flatten()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq [1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "# let's train our baby GPT on this sequence\n",
    "seq = list(map(int, \"111101111011110\"))\n",
    "print('seq', seq)\n",
    "\n",
    "# convert the sequence to a tensor holding all the individual examples in that sequence\n",
    "X, Y = [], []\n",
    "# iterate over the sequence and grab every consecutive 3 bits\n",
    "# the correct label for what's next is the next bit at each position\n",
    "# for i in range(len(seq) - 3):\n",
    "#     X.append(seq[i:i+3])\n",
    "#     Y.append(seq[i+3])\n",
    "#     print(f\"example {i+1:2d}: {X[-1]} --> {Y[-1]}\")\n",
    "# X = torch.tensor(X, dtype=torch.long).to(CONFIG_TRAIN[\"device\"])\n",
    "# Y = torch.tensor(Y, dtype=torch.long).to(CONFIG_TRAIN[\"device\"])\n",
    "# print(X.shape, Y.shape)\n",
    "# torch.manual_seed(1337)\n",
    "\n",
    "\n",
    "# config = GPTConfig(\n",
    "#     block_size = 3,\n",
    "#     vocab_size = 2,\n",
    "#     n_layer = 4,\n",
    "#     n_head = 4,\n",
    "#     n_embd = 16,\n",
    "#     bias = False,\n",
    "# )\n",
    "# gpt = GPT(config)\n",
    "\n",
    "# optimizer = torch.optim.AdamW(gpt.parameters(), lr=1e-3, weight_decay=1e-1)\n",
    "\n",
    "# for i in range(50):\n",
    "#     logits = gpt(X)\n",
    "#     loss = nn.functional.cross_entropy(logits, Y)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     optimizer.zero_grad()\n",
    "#     print(i, loss.item())\n",
    "\n",
    "\n",
    "# print(\"Training data sequence, as a reminder:\", seq)\n",
    "# plot_model()\n",
    "\n",
    "\n",
    "\n",
    "CONFIG_TRAIN = {\n",
    "    \"vocab_size\": 2,\n",
    "    \"context_length\": 3,\n",
    "    \"emb_dim\": 16,\n",
    "    \"n_heads\": 4,\n",
    "    \"n_leayers\": 4,\n",
    "    \"drop_rate\": 0.000,\n",
    "    \"qkv_bias\": False,\n",
    "    \"device\": device\n",
    "}\n",
    "# model = GPTModel(CONFIG_TRAIN)\n",
    "\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-1)\n",
    "\n",
    "# for i in range(10):\n",
    "#     logits = model(X, False)\n",
    "#     print(\"logits\", logits)\n",
    "#     loss = nn.functional.cross_entropy(logits, Y)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     optimizer.zero_grad()\n",
    "#     print(i, loss.item())\n",
    "\n",
    "\n",
    "# print(\"Training data sequence, as a reminder:\", seq)\n",
    "# plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = GPTModel(CONFIG_TRAIN)\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-1)\n",
    "\n",
    "# inputs = torch.tensor([[0, 1, 1, 1],\n",
    "#                        [1, 0, 0, 1],\n",
    "#                        [1, 1, 0, 0]])\n",
    "\n",
    "# targets = torch.tensor([1, 1, 1])\n",
    "\n",
    "# # train the GPT for some number of iterations\n",
    "# for i in range(3):\n",
    "\n",
    "#     logits = model(inputs, False)\n",
    "#     print(logits)\n",
    "#     loss = nn.functional.cross_entropy(logits, targets)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     optimizer.zero_grad()\n",
    "#     print(i, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment 1\n",
    "# Action 0 => 0\n",
    "# Action 1 => 1\n",
    "\n",
    "# history_action = []\n",
    "# hystory_fb = []\n",
    "# history_pred = []\n",
    "\n",
    "# env = env1()\n",
    "# model = GPTModel(\n",
    "#     {\n",
    "#         \"vocab_size\": 2,\n",
    "#         \"context_length\": 1,\n",
    "#         \"emb_dim\": 16,\n",
    "#         \"n_heads\": 4,\n",
    "#         \"n_leayers\": 4,\n",
    "#         \"drop_rate\": 0.1,\n",
    "#         \"qkv_bias\": False,\n",
    "#         \"device\": device\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# action = 0\n",
    "# inputs = torch.tensor([[action]]).t\n",
    "# targets = torch.tensor([0])\n",
    "\n",
    "# for i in range(100):\n",
    "#     action = i%2\n",
    "#     history_action.append(action)\n",
    "#     feedback = env.outcome(action)\n",
    "#     hystory_fb.append(feedback)\n",
    "\n",
    "#     inputs = torch.tensor([[action]]).to(device)\n",
    "#     targets = torch.tensor([feedback]).to(device)\n",
    "#     logits = model(inputs, False)\n",
    "#     print(logits)\n",
    "#     history_pred.append(torch.argmax(logits).item())\n",
    "#     loss = nn.functional.cross_entropy(logits, targets)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     optimizer.zero_grad()\n",
    "#     print(i, loss.item())\n",
    "    \n",
    "# print(history_action)\n",
    "# print(hystory_fb)\n",
    "# print(history_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addapt_seq(seq, context_length):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(seq) - context_length):\n",
    "        X.append(seq[i:i+context_length])\n",
    "        Y.append(seq[i+context_length])\n",
    "    return torch.tensor(X, dtype=torch.long), torch.tensor(Y, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs\n",
      "tensor([[0, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 0],\n",
      "        [1, 1, 0, 0],\n",
      "        [1, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 1],\n",
      "        [0, 0, 1, 0],\n",
      "        [0, 1, 0, 1],\n",
      "        [1, 0, 1, 1],\n",
      "        [0, 1, 1, 0],\n",
      "        [1, 1, 0, 1],\n",
      "        [1, 0, 1, 0],\n",
      "        [0, 1, 0, 1]], device='cuda:0')\n",
      "tensor([0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0], device='cuda:0')\n",
      "0 0.7741307020187378\n",
      "1 0.7279297113418579\n",
      "2 0.7113488912582397\n",
      "3 0.7070985436439514\n",
      "4 0.7030940651893616\n",
      "5 0.7010554075241089\n",
      "6 0.6992748379707336\n",
      "7 0.6969112157821655\n",
      "8 0.6977940797805786\n",
      "9 0.6947720050811768\n",
      "10 0.6958208084106445\n",
      "11 0.693699836730957\n",
      "12 0.6941187381744385\n",
      "13 0.693254292011261\n",
      "14 0.6928310394287109\n",
      "15 0.6927074193954468\n",
      "16 0.6913651823997498\n",
      "17 0.6891593933105469\n",
      "18 0.688992440700531\n",
      "19 0.6893489956855774\n",
      "20 0.6868473291397095\n",
      "21 0.6836498975753784\n",
      "22 0.6787604689598083\n",
      "23 0.6725270748138428\n",
      "24 0.6564817428588867\n",
      "25 0.6363481879234314\n",
      "26 0.604235053062439\n",
      "27 0.584133505821228\n",
      "28 0.565952479839325\n",
      "29 0.5474206805229187\n",
      "30 0.535740315914154\n",
      "31 0.5202070474624634\n",
      "32 0.5081891417503357\n",
      "33 0.4937213063240051\n",
      "34 0.4804942011833191\n",
      "35 0.46767833828926086\n",
      "36 0.4536297917366028\n",
      "37 0.44051504135131836\n",
      "38 0.42681974172592163\n",
      "39 0.41586846113204956\n",
      "40 0.4047812819480896\n",
      "41 0.39231255650520325\n",
      "42 0.38003528118133545\n",
      "43 0.36956220865249634\n",
      "44 0.3581750690937042\n",
      "45 0.3492712080478668\n",
      "46 0.33833497762680054\n",
      "47 0.32750824093818665\n",
      "48 0.3174232542514801\n",
      "49 0.30802181363105774\n",
      "50 0.3007657527923584\n",
      "51 0.2898990213871002\n",
      "52 0.28232696652412415\n",
      "53 0.2736494243144989\n",
      "54 0.2662401795387268\n",
      "55 0.25737524032592773\n",
      "56 0.24970871210098267\n",
      "57 0.24309305846691132\n",
      "58 0.23620589077472687\n",
      "59 0.2301032990217209\n",
      "60 0.22286531329154968\n",
      "61 0.21463419497013092\n",
      "62 0.20980213582515717\n",
      "63 0.20283055305480957\n",
      "64 0.197674959897995\n",
      "65 0.19283394515514374\n",
      "66 0.1871691197156906\n",
      "67 0.18093854188919067\n",
      "68 0.1770940124988556\n",
      "69 0.17250649631023407\n",
      "70 0.16856242716312408\n",
      "71 0.16335424780845642\n",
      "72 0.1597275584936142\n",
      "73 0.1546967625617981\n",
      "74 0.15026983618736267\n",
      "75 0.1479213833808899\n",
      "76 0.14301349222660065\n",
      "77 0.13894593715667725\n",
      "78 0.1370396465063095\n",
      "79 0.13192303478717804\n",
      "80 0.12777750194072723\n",
      "81 0.1260228157043457\n",
      "82 0.12172810733318329\n",
      "83 0.11985531449317932\n",
      "84 0.1172662004828453\n",
      "85 0.2402750551700592\n",
      "86 0.11264942586421967\n",
      "87 0.10920830070972443\n",
      "88 0.10635697841644287\n",
      "89 0.10459888726472855\n",
      "90 0.10251790285110474\n",
      "91 0.10090119391679764\n",
      "92 0.09782954305410385\n",
      "93 0.09619520604610443\n",
      "94 0.09473159909248352\n",
      "95 0.0914541706442833\n",
      "96 0.09031490236520767\n",
      "97 0.08839432150125504\n",
      "98 0.0859314575791359\n",
      "99 0.08507287502288818\n",
      "[0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0]\n",
      "[1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1]\n",
      "[13]\n",
      "input [0, 0, 0, 0] ---> [0.0810379683971405, 0.9189620614051819]\n",
      "input [0, 0, 0, 1] ---> [0.9205837845802307, 0.07941626757383347]\n",
      "input [0, 0, 1, 0] ---> [0.08032020926475525, 0.9196797609329224]\n",
      "input [0, 0, 1, 1] ---> [0.9171121120452881, 0.08288790285587311]\n",
      "input [0, 1, 0, 0] ---> [0.08153706789016724, 0.918462872505188]\n",
      "input [0, 1, 0, 1] ---> [0.9215825796127319, 0.07841736823320389]\n",
      "input [0, 1, 1, 0] ---> [0.08387599885463715, 0.9161239266395569]\n",
      "input [0, 1, 1, 1] ---> [0.9207737445831299, 0.07922621816396713]\n",
      "input [1, 0, 0, 0] ---> [0.08035668730735779, 0.9196432828903198]\n",
      "input [1, 0, 0, 1] ---> [0.9209803938865662, 0.07901959866285324]\n",
      "input [1, 0, 1, 0] ---> [0.08009561151266098, 0.919904351234436]\n",
      "input [1, 0, 1, 1] ---> [0.9222072958946228, 0.07779263705015182]\n",
      "input [1, 1, 0, 0] ---> [0.08260609954595566, 0.9173939228057861]\n",
      "input [1, 1, 0, 1] ---> [0.9202134609222412, 0.07978649437427521]\n",
      "input [1, 1, 1, 0] ---> [0.0805056244134903, 0.9194943904876709]\n",
      "input [1, 1, 1, 1] ---> [0.9231626987457275, 0.07683728635311127]\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"828pt\" height=\"762pt\"\n",
       " viewBox=\"0.00 0.00 828.15 761.57\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 757.57)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-757.57 824.15,-757.57 824.15,4 -4,4\"/>\n",
       "<!-- 0000 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0000</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"724.7\" cy=\"-239.48\" rx=\"34.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"724.7\" y=\"-235.78\" font-family=\"Times,serif\" font-size=\"14.00\">0000</text>\n",
       "</g>\n",
       "<!-- 0000&#45;&gt;0000 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0000&#45;&gt;0000</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M756.71,-246.23C767.99,-246.34 777.15,-244.09 777.15,-239.48 777.15,-236.39 773.02,-234.36 766.88,-233.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"766.91,-229.89 756.71,-232.74 766.46,-236.87 766.91,-229.89\"/>\n",
       "<text text-anchor=\"middle\" x=\"798.65\" y=\"-235.78\" font-family=\"Times,serif\" font-size=\"14.00\">0(8%)</text>\n",
       "</g>\n",
       "<!-- 0001 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>0001</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"530.53\" cy=\"-45.31\" rx=\"34.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"530.53\" y=\"-41.61\" font-family=\"Times,serif\" font-size=\"14.00\">0001</text>\n",
       "</g>\n",
       "<!-- 0000&#45;&gt;0001 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0000&#45;&gt;0001</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M708.48,-223.26C674.13,-188.91 593.93,-108.71 553.99,-68.77\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"556.12,-65.95 546.57,-61.35 551.17,-70.9 556.12,-65.95\"/>\n",
       "<text text-anchor=\"middle\" x=\"605.24\" y=\"-149.82\" font-family=\"Times,serif\" font-size=\"14.00\">1(92%)</text>\n",
       "</g>\n",
       "<!-- 0010 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>0010</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"752.01\" cy=\"-376.78\" rx=\"34.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"752.01\" y=\"-373.08\" font-family=\"Times,serif\" font-size=\"14.00\">0010</text>\n",
       "</g>\n",
       "<!-- 0001&#45;&gt;0010 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>0001&#45;&gt;0010</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M542.13,-62.67C578.68,-117.37 691.63,-286.42 734.9,-351.18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"732.07,-353.23 740.53,-359.6 737.89,-349.34 732.07,-353.23\"/>\n",
       "<text text-anchor=\"middle\" x=\"612.52\" y=\"-210.72\" font-family=\"Times,serif\" font-size=\"14.00\">0(92%)</text>\n",
       "</g>\n",
       "<!-- 0011 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>0011</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"393.23\" cy=\"-18\" rx=\"34.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"393.23\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">0011</text>\n",
       "</g>\n",
       "<!-- 0001&#45;&gt;0011 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0001&#45;&gt;0011</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M497.99,-38.84C479.27,-35.11 455.54,-30.39 435.39,-26.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"436.03,-22.94 425.54,-24.43 434.66,-29.81 436.03,-22.94\"/>\n",
       "<text text-anchor=\"middle\" x=\"466.69\" y=\"-21.41\" font-family=\"Times,serif\" font-size=\"14.00\">1(8%)</text>\n",
       "</g>\n",
       "<!-- 0100 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>0100</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"724.7\" cy=\"-514.08\" rx=\"34.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"724.7\" y=\"-510.38\" font-family=\"Times,serif\" font-size=\"14.00\">0100</text>\n",
       "</g>\n",
       "<!-- 0010&#45;&gt;0100 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>0010&#45;&gt;0100</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M748.44,-394.73C743.82,-417.96 735.72,-458.69 730.28,-486.03\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"726.79,-485.64 728.27,-496.13 733.66,-487 726.79,-485.64\"/>\n",
       "<text text-anchor=\"middle\" x=\"717.86\" y=\"-444.18\" font-family=\"Times,serif\" font-size=\"14.00\">0(8%)</text>\n",
       "</g>\n",
       "<!-- 0101 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>0101</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"393.23\" cy=\"-735.57\" rx=\"34.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"393.23\" y=\"-731.87\" font-family=\"Times,serif\" font-size=\"14.00\">0101</text>\n",
       "</g>\n",
       "<!-- 0010&#45;&gt;0101 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>0010&#45;&gt;0101</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M735.67,-393.13C677.98,-450.82 483.82,-644.97 416.47,-712.33\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"413.86,-709.99 409.26,-719.53 418.81,-714.94 413.86,-709.99\"/>\n",
       "<text text-anchor=\"middle\" x=\"550.07\" y=\"-556.53\" font-family=\"Times,serif\" font-size=\"14.00\">1(92%)</text>\n",
       "</g>\n",
       "<!-- 0110 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>0110</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"61.76\" cy=\"-514.08\" rx=\"34.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"61.76\" y=\"-510.38\" font-family=\"Times,serif\" font-size=\"14.00\">0110</text>\n",
       "</g>\n",
       "<!-- 0011&#45;&gt;0110 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>0011&#45;&gt;0110</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M381.82,-35.08C332.51,-108.87 137.58,-400.6 78.69,-488.74\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"75.77,-486.82 73.12,-497.08 81.59,-490.71 75.77,-486.82\"/>\n",
       "<text text-anchor=\"middle\" x=\"204.26\" y=\"-265.71\" font-family=\"Times,serif\" font-size=\"14.00\">0(92%)</text>\n",
       "</g>\n",
       "<!-- 0111 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>0111</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"255.93\" cy=\"-45.31\" rx=\"34.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"255.93\" y=\"-41.61\" font-family=\"Times,serif\" font-size=\"14.00\">0111</text>\n",
       "</g>\n",
       "<!-- 0011&#45;&gt;0111 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>0011&#45;&gt;0111</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M360.69,-24.47C341.97,-28.2 318.23,-32.92 298.09,-36.92\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"297.36,-33.5 288.23,-38.88 298.73,-40.37 297.36,-33.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"329.39\" y=\"-19.5\" font-family=\"Times,serif\" font-size=\"14.00\">1(8%)</text>\n",
       "</g>\n",
       "<!-- 1000 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>1000</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"646.93\" cy=\"-123.09\" rx=\"34.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"646.93\" y=\"-119.39\" font-family=\"Times,serif\" font-size=\"14.00\">1000</text>\n",
       "</g>\n",
       "<!-- 0100&#45;&gt;1000 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>0100&#45;&gt;1000</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M721.11,-496.01C708.72,-433.74 667.75,-227.77 652.61,-151.67\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"655.96,-150.54 650.58,-141.42 649.09,-151.91 655.96,-150.54\"/>\n",
       "<text text-anchor=\"middle\" x=\"665.36\" y=\"-327.64\" font-family=\"Times,serif\" font-size=\"14.00\">0(8%)</text>\n",
       "</g>\n",
       "<!-- 1001 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>1001</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"646.93\" cy=\"-630.48\" rx=\"34.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"646.93\" y=\"-626.78\" font-family=\"Times,serif\" font-size=\"14.00\">1001</text>\n",
       "</g>\n",
       "<!-- 0100&#45;&gt;1001 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>0100&#45;&gt;1001</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M713.23,-531.26C700.25,-550.69 678.97,-582.52 664.03,-604.88\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"661.1,-602.98 658.45,-613.24 666.92,-606.87 661.1,-602.98\"/>\n",
       "<text text-anchor=\"middle\" x=\"662.63\" y=\"-571.87\" font-family=\"Times,serif\" font-size=\"14.00\">1(92%)</text>\n",
       "</g>\n",
       "<!-- 1010 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>1010</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"530.53\" cy=\"-708.26\" rx=\"34.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"530.53\" y=\"-704.56\" font-family=\"Times,serif\" font-size=\"14.00\">1010</text>\n",
       "</g>\n",
       "<!-- 0101&#45;&gt;1010 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>0101&#45;&gt;1010</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M427.97,-734.67C447.87,-731.78 472.84,-726.9 493.17,-721.95\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"494.19,-725.3 503.02,-719.44 492.47,-718.51 494.19,-725.3\"/>\n",
       "<text text-anchor=\"middle\" x=\"486.57\" y=\"-732.11\" font-family=\"Times,serif\" font-size=\"14.00\">0(92%)</text>\n",
       "</g>\n",
       "<!-- 1011 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>1011</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"255.93\" cy=\"-708.26\" rx=\"34.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"255.93\" y=\"-704.56\" font-family=\"Times,serif\" font-size=\"14.00\">1011</text>\n",
       "</g>\n",
       "<!-- 0101&#45;&gt;1011 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>0101&#45;&gt;1011</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M360.69,-729.09C341.97,-725.37 318.23,-720.65 298.09,-716.64\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"298.73,-713.2 288.23,-714.68 297.36,-720.07 298.73,-713.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"329.39\" y=\"-711.67\" font-family=\"Times,serif\" font-size=\"14.00\">1(8%)</text>\n",
       "</g>\n",
       "<!-- 1100 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>1100</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"34.45\" cy=\"-376.78\" rx=\"34.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34.45\" y=\"-373.08\" font-family=\"Times,serif\" font-size=\"14.00\">1100</text>\n",
       "</g>\n",
       "<!-- 0110&#45;&gt;1100 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>0110&#45;&gt;1100</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M58.19,-496.13C53.57,-472.9 45.47,-432.17 40.03,-404.84\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"43.4,-403.86 38.02,-394.74 36.54,-405.23 43.4,-403.86\"/>\n",
       "<text text-anchor=\"middle\" x=\"27.61\" y=\"-454.29\" font-family=\"Times,serif\" font-size=\"14.00\">0(8%)</text>\n",
       "</g>\n",
       "<!-- 1101 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>1101</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"139.53\" cy=\"-630.48\" rx=\"34.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"139.53\" y=\"-626.78\" font-family=\"Times,serif\" font-size=\"14.00\">1101</text>\n",
       "</g>\n",
       "<!-- 0110&#45;&gt;1101 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>0110&#45;&gt;1101</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M73.23,-531.26C86.21,-550.69 107.49,-582.52 122.43,-604.88\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"119.54,-606.87 128.01,-613.24 125.36,-602.98 119.54,-606.87\"/>\n",
       "<text text-anchor=\"middle\" x=\"71.83\" y=\"-571.87\" font-family=\"Times,serif\" font-size=\"14.00\">1(92%)</text>\n",
       "</g>\n",
       "<!-- 1110 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>1110</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"61.76\" cy=\"-239.48\" rx=\"34.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"61.76\" y=\"-235.78\" font-family=\"Times,serif\" font-size=\"14.00\">1110</text>\n",
       "</g>\n",
       "<!-- 0111&#45;&gt;1110 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>0111&#45;&gt;1110</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M239.71,-61.53C205.36,-95.88 125.16,-176.08 85.22,-216.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"82.39,-213.9 77.8,-223.44 87.34,-218.85 82.39,-213.9\"/>\n",
       "<text text-anchor=\"middle\" x=\"188.47\" y=\"-142.58\" font-family=\"Times,serif\" font-size=\"14.00\">0(92%)</text>\n",
       "</g>\n",
       "<!-- 1111 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>1111</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"139.53\" cy=\"-123.09\" rx=\"34.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"139.53\" y=\"-119.39\" font-family=\"Times,serif\" font-size=\"14.00\">1111</text>\n",
       "</g>\n",
       "<!-- 0111&#45;&gt;1111 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>0111&#45;&gt;1111</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M234.58,-59.58C216.32,-71.78 189.83,-89.47 169.46,-103.09\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"167.51,-100.18 161.14,-108.65 171.4,-106 167.51,-100.18\"/>\n",
       "<text text-anchor=\"middle\" x=\"180.52\" y=\"-85.13\" font-family=\"Times,serif\" font-size=\"14.00\">1(8%)</text>\n",
       "</g>\n",
       "<!-- 1000&#45;&gt;0000 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>1000&#45;&gt;0000</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M658.4,-140.26C671.39,-159.69 692.66,-191.53 707.6,-213.89\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"704.71,-215.87 713.18,-222.24 710.53,-211.98 704.71,-215.87\"/>\n",
       "<text text-anchor=\"middle\" x=\"661.5\" y=\"-180.87\" font-family=\"Times,serif\" font-size=\"14.00\">0(8%)</text>\n",
       "</g>\n",
       "<!-- 1000&#45;&gt;0001 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>1000&#45;&gt;0001</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M625.58,-108.82C607.32,-96.62 580.83,-78.92 560.46,-65.31\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"562.4,-62.39 552.14,-59.75 558.51,-68.21 562.4,-62.39\"/>\n",
       "<text text-anchor=\"middle\" x=\"567.02\" y=\"-90.86\" font-family=\"Times,serif\" font-size=\"14.00\">1(92%)</text>\n",
       "</g>\n",
       "<!-- 1001&#45;&gt;0010 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>1001&#45;&gt;0010</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M654.32,-612.64C672.44,-568.88 719.2,-456 740.79,-403.89\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"744.04,-405.18 744.63,-394.6 737.57,-402.5 744.04,-405.18\"/>\n",
       "<text text-anchor=\"middle\" x=\"671.55\" y=\"-497.06\" font-family=\"Times,serif\" font-size=\"14.00\">0(92%)</text>\n",
       "</g>\n",
       "<!-- 1001&#45;&gt;0011 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>1001&#45;&gt;0011</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M639.61,-612.81C603.88,-526.55 447.73,-149.58 404.41,-44.99\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"407.64,-43.64 400.58,-35.74 401.17,-46.32 407.64,-43.64\"/>\n",
       "<text text-anchor=\"middle\" x=\"500.51\" y=\"-332.7\" font-family=\"Times,serif\" font-size=\"14.00\">1(8%)</text>\n",
       "</g>\n",
       "<!-- 1010&#45;&gt;0100 -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>1010&#45;&gt;0100</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M546.75,-692.03C581.1,-657.68 661.3,-577.49 701.24,-537.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"704.07,-539.67 708.66,-530.12 699.12,-534.72 704.07,-539.67\"/>\n",
       "<text text-anchor=\"middle\" x=\"602.5\" y=\"-603.59\" font-family=\"Times,serif\" font-size=\"14.00\">0(8%)</text>\n",
       "</g>\n",
       "<!-- 1010&#45;&gt;0101 -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>1010&#45;&gt;0101</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M495.79,-709.15C475.89,-712.04 450.92,-716.93 430.59,-721.88\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"429.57,-718.53 420.74,-724.38 431.29,-725.31 429.57,-718.53\"/>\n",
       "<text text-anchor=\"middle\" x=\"437.19\" y=\"-704.32\" font-family=\"Times,serif\" font-size=\"14.00\">1(92%)</text>\n",
       "</g>\n",
       "<!-- 1011&#45;&gt;0110 -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>1011&#45;&gt;0110</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M239.71,-692.03C205.36,-657.68 125.16,-577.49 85.22,-537.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"87.34,-534.72 77.8,-530.12 82.39,-539.67 87.34,-534.72\"/>\n",
       "<text text-anchor=\"middle\" x=\"188.47\" y=\"-603.59\" font-family=\"Times,serif\" font-size=\"14.00\">0(92%)</text>\n",
       "</g>\n",
       "<!-- 1011&#45;&gt;0111 -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>1011&#45;&gt;0111</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M255.93,-690.18C255.93,-598.6 255.93,-185.81 255.93,-73.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"259.43,-73.37 255.93,-63.37 252.43,-73.37 259.43,-73.37\"/>\n",
       "<text text-anchor=\"middle\" x=\"234.43\" y=\"-385.67\" font-family=\"Times,serif\" font-size=\"14.00\">1(8%)</text>\n",
       "</g>\n",
       "<!-- 1100&#45;&gt;1000 -->\n",
       "<g id=\"edge25\" class=\"edge\">\n",
       "<title>1100&#45;&gt;1000</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M61.55,-365.55C159.87,-324.83 497.83,-184.84 610.24,-138.28\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"611.89,-141.39 619.79,-134.33 609.21,-134.92 611.89,-141.39\"/>\n",
       "<text text-anchor=\"middle\" x=\"314.4\" y=\"-255.72\" font-family=\"Times,serif\" font-size=\"14.00\">0(8%)</text>\n",
       "</g>\n",
       "<!-- 1100&#45;&gt;1001 -->\n",
       "<g id=\"edge26\" class=\"edge\">\n",
       "<title>1100&#45;&gt;1001</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M61.55,-388.01C159.87,-428.74 497.83,-568.72 610.24,-615.28\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"609.21,-618.65 619.79,-619.24 611.89,-612.18 609.21,-618.65\"/>\n",
       "<text text-anchor=\"middle\" x=\"309.9\" y=\"-505.45\" font-family=\"Times,serif\" font-size=\"14.00\">1(92%)</text>\n",
       "</g>\n",
       "<!-- 1101&#45;&gt;1010 -->\n",
       "<g id=\"edge27\" class=\"edge\">\n",
       "<title>1101&#45;&gt;1010</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M171.86,-636.91C242.25,-650.91 409.37,-684.16 488.11,-699.82\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"487.67,-703.3 498.16,-701.82 489.04,-696.43 487.67,-703.3\"/>\n",
       "<text text-anchor=\"middle\" x=\"303.99\" y=\"-672.17\" font-family=\"Times,serif\" font-size=\"14.00\">0(92%)</text>\n",
       "</g>\n",
       "<!-- 1101&#45;&gt;1011 -->\n",
       "<g id=\"edge28\" class=\"edge\">\n",
       "<title>1101&#45;&gt;1011</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M160.88,-644.75C179.14,-656.95 205.63,-674.65 226,-688.26\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"224.06,-691.17 234.32,-693.82 227.95,-685.35 224.06,-691.17\"/>\n",
       "<text text-anchor=\"middle\" x=\"171.94\" y=\"-670.3\" font-family=\"Times,serif\" font-size=\"14.00\">1(8%)</text>\n",
       "</g>\n",
       "<!-- 1110&#45;&gt;1100 -->\n",
       "<g id=\"edge29\" class=\"edge\">\n",
       "<title>1110&#45;&gt;1100</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M58.19,-257.43C53.57,-280.66 45.47,-321.39 40.03,-348.72\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"36.54,-348.34 38.02,-358.83 43.4,-349.7 36.54,-348.34\"/>\n",
       "<text text-anchor=\"middle\" x=\"27.61\" y=\"-306.88\" font-family=\"Times,serif\" font-size=\"14.00\">0(8%)</text>\n",
       "</g>\n",
       "<!-- 1110&#45;&gt;1101 -->\n",
       "<g id=\"edge30\" class=\"edge\">\n",
       "<title>1110&#45;&gt;1101</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M65.35,-257.56C77.74,-319.83 118.71,-525.79 133.85,-601.89\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"130.5,-603.02 135.89,-612.15 137.37,-601.66 130.5,-603.02\"/>\n",
       "<text text-anchor=\"middle\" x=\"73.6\" y=\"-433.53\" font-family=\"Times,serif\" font-size=\"14.00\">1(92%)</text>\n",
       "</g>\n",
       "<!-- 1111&#45;&gt;1110 -->\n",
       "<g id=\"edge31\" class=\"edge\">\n",
       "<title>1111&#45;&gt;1110</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M128.06,-140.26C115.07,-159.69 93.8,-191.53 78.86,-213.89\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"75.93,-211.98 73.28,-222.24 81.75,-215.87 75.93,-211.98\"/>\n",
       "<text text-anchor=\"middle\" x=\"77.46\" y=\"-180.87\" font-family=\"Times,serif\" font-size=\"14.00\">0(92%)</text>\n",
       "</g>\n",
       "<!-- 1111&#45;&gt;1111 -->\n",
       "<g id=\"edge32\" class=\"edge\">\n",
       "<title>1111&#45;&gt;1111</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M171.54,-129.83C182.82,-129.94 191.98,-127.69 191.98,-123.09 191.98,-119.99 187.85,-117.96 181.71,-116.99\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"181.74,-113.49 171.54,-116.34 181.29,-120.47 181.74,-113.49\"/>\n",
       "<text text-anchor=\"middle\" x=\"213.48\" y=\"-119.39\" font-family=\"Times,serif\" font-size=\"14.00\">1(8%)</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fba7244f310>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Environment 2, goal is predict outcome with action.\n",
    "# X are all action\n",
    "# For each X we associate Y, the outcome of the action\n",
    "# X is context lenght action\n",
    "\n",
    "history_action = []\n",
    "hystory_fb = []\n",
    "history_pred = []\n",
    "\n",
    "env = env2()\n",
    "\n",
    "action = 0\n",
    "inputs = torch.tensor([[action]])\n",
    "targets = torch.tensor([0])\n",
    "\n",
    "for i in range(20):\n",
    "    action = torch.randint(0, 2, (1,)).item()\n",
    "    history_action.append(action)\n",
    "    feedback = env.outcome(action)\n",
    "    hystory_fb.append(feedback)\n",
    "\n",
    "CONTEXT_LENGHT = 4\n",
    "model = GPTModel(\n",
    "    {\n",
    "        \"vocab_size\": 2,\n",
    "        \"context_length\": CONTEXT_LENGHT,\n",
    "        \"emb_dim\": 16,\n",
    "        \"n_heads\": 4,\n",
    "        \"n_leayers\": 4,\n",
    "        \"drop_rate\": 0.1,\n",
    "        \"qkv_bias\": False,\n",
    "        \"device\": device\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-1)\n",
    "\n",
    "inputs, targets = addapt_seq(history_action, CONTEXT_LENGHT)\n",
    "# inputs, targets = addapt_seq(list(map(int, \"111101111011110\")), CONTEXT_LENGHT)\n",
    "inputs = inputs.to(device)\n",
    "targets = torch.tensor(hystory_fb[CONTEXT_LENGHT-1:-1]).to(device)\n",
    "\n",
    "print(\"inputs\")\n",
    "print(inputs)\n",
    "print(targets)\n",
    "\n",
    "for j in range(100):\n",
    "    logits = model(inputs, False)\n",
    "    loss = nn.functional.cross_entropy(logits, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    print(j, loss.item())\n",
    "\n",
    "history_pred.append(torch.argmax(logits).item())\n",
    "    \n",
    "print(history_action)\n",
    "print(hystory_fb)\n",
    "print(history_pred)\n",
    "\n",
    "plot_model(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 0]\n",
      "[(0, 1), (1, 0), (1, 1), (0, 0)]\n",
      "[3, 12, 9, 8]\n",
      "[(0, 3), (3, 0), (2, 1), (2, 0)]\n"
     ]
    }
   ],
   "source": [
    "def interaction_to_token(interaction, base=2):\n",
    "    return [int(f\"{a}{b}\", base) for a, b in interaction]\n",
    "    \n",
    "def token_to_interaction(token, base=2):\n",
    "    return [(i // base, i % base) for i in token]\n",
    "\n",
    "x = interaction_to_token([(0, 1), (1, 0), (1, 1), (0, 0)])\n",
    "print(x)\n",
    "y = token_to_interaction(x)\n",
    "print(y)\n",
    "\n",
    "x = interaction_to_token([(0, 3), (3, 0), (2, 1), (2, 0)], 4)\n",
    "print(x)\n",
    "y = token_to_interaction(x, 4)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.4146754741668701\n",
      "1 1.4150725603103638\n",
      "2 1.4164760112762451\n",
      "3 1.41588294506073\n",
      "4 1.416314721107483\n",
      "5 1.4180457592010498\n",
      "6 1.4157353639602661\n",
      "7 1.4169448614120483\n",
      "8 1.4173835515975952\n",
      "9 1.4175291061401367\n",
      "10 1.4141591787338257\n",
      "11 1.4158333539962769\n",
      "12 1.416425347328186\n",
      "13 1.4164841175079346\n",
      "14 1.41631019115448\n",
      "15 1.4164221286773682\n",
      "16 1.41587233543396\n",
      "17 1.4165105819702148\n",
      "18 1.4184596538543701\n",
      "19 1.4176687002182007\n",
      "20 1.4181286096572876\n",
      "21 1.4160184860229492\n",
      "22 1.4158456325531006\n",
      "23 1.4159015417099\n",
      "24 1.4155269861221313\n",
      "25 1.4188451766967773\n",
      "26 1.4169729948043823\n",
      "27 1.415008783340454\n",
      "28 1.4153109788894653\n",
      "29 1.4180614948272705\n",
      "30 1.4154036045074463\n",
      "31 1.4152717590332031\n",
      "32 1.4163157939910889\n",
      "33 1.4158871173858643\n",
      "34 1.415887713432312\n",
      "35 1.4160733222961426\n",
      "36 1.417881727218628\n",
      "37 1.4160829782485962\n",
      "38 1.4154218435287476\n",
      "39 1.4167554378509521\n",
      "40 1.4157954454421997\n",
      "41 1.4176521301269531\n",
      "42 1.4163111448287964\n",
      "43 1.418125033378601\n",
      "44 1.4160140752792358\n",
      "45 1.4155588150024414\n",
      "46 1.4162293672561646\n",
      "47 1.4172829389572144\n",
      "48 1.4165558815002441\n",
      "49 1.4168628454208374\n",
      "50 1.414219617843628\n",
      "51 1.4177916049957275\n",
      "52 1.416575312614441\n",
      "53 1.415234923362732\n",
      "54 1.4168039560317993\n",
      "55 1.4168999195098877\n",
      "56 1.4173495769500732\n",
      "57 1.4164098501205444\n",
      "58 1.4163042306900024\n",
      "59 1.4155302047729492\n",
      "60 1.4157413244247437\n",
      "61 1.4150029420852661\n",
      "62 1.416385293006897\n",
      "63 1.4170291423797607\n",
      "64 1.4170831441879272\n",
      "65 1.4166674613952637\n",
      "66 1.416159987449646\n",
      "67 1.4160854816436768\n",
      "68 1.417434811592102\n",
      "69 1.4156231880187988\n",
      "70 1.4166229963302612\n",
      "71 1.4171379804611206\n",
      "72 1.4163497686386108\n",
      "73 1.4163421392440796\n",
      "74 1.4168697595596313\n",
      "75 1.41642165184021\n",
      "76 1.4167723655700684\n",
      "77 1.4164451360702515\n",
      "78 1.417195439338684\n",
      "79 1.4164320230484009\n",
      "80 1.4143540859222412\n",
      "81 1.4153112173080444\n",
      "82 1.4170629978179932\n",
      "83 1.4172996282577515\n",
      "84 1.417755365371704\n",
      "85 1.4163248538970947\n",
      "86 1.4160709381103516\n",
      "87 1.4171518087387085\n",
      "88 1.4147014617919922\n",
      "89 1.416612982749939\n",
      "90 1.4167603254318237\n",
      "91 1.4175604581832886\n",
      "92 1.4164669513702393\n",
      "93 1.41657292842865\n",
      "94 1.4182038307189941\n",
      "95 1.4155821800231934\n",
      "96 1.4164483547210693\n",
      "97 1.4172803163528442\n",
      "98 1.4148781299591064\n",
      "99 1.4158326387405396\n",
      "input [0, 0] ---> [0.2987533509731293, 0.20617790520191193, 0.2318457067012787, 0.2632230222225189]\n",
      "input [0, 1] ---> [0.26864758133888245, 0.26843395829200745, 0.2457597702741623, 0.2171587198972702]\n",
      "input [0, 2] ---> [0.24957694113254547, 0.2288041114807129, 0.26390206813812256, 0.2577168643474579]\n",
      "input [0, 3] ---> [0.26784607768058777, 0.19372154772281647, 0.2270781248807907, 0.31135424971580505]\n",
      "input [1, 0] ---> [0.29799017310142517, 0.20266777276992798, 0.21873125433921814, 0.2806107699871063]\n",
      "input [1, 1] ---> [0.27079543471336365, 0.2487349808216095, 0.24393318593502045, 0.2365363985300064]\n",
      "input [1, 2] ---> [0.24545110762119293, 0.2368706315755844, 0.26773080229759216, 0.2499474734067917]\n",
      "input [1, 3] ---> [0.2674783170223236, 0.19885385036468506, 0.2238469421863556, 0.30982092022895813]\n",
      "input [2, 0] ---> [0.29481348395347595, 0.20977087318897247, 0.23078987002372742, 0.26462575793266296]\n",
      "input [2, 1] ---> [0.25138962268829346, 0.2838675379753113, 0.2550610303878784, 0.20968179404735565]\n",
      "input [2, 2] ---> [0.25774964690208435, 0.22934868931770325, 0.2589678466320038, 0.25393375754356384]\n",
      "input [2, 3] ---> [0.26821956038475037, 0.19287244975566864, 0.22844581305980682, 0.31046217679977417]\n",
      "input [3, 0] ---> [0.2784494161605835, 0.24656005203723907, 0.23996539413928986, 0.23502513766288757]\n",
      "input [3, 1] ---> [0.25331637263298035, 0.2882346510887146, 0.25278207659721375, 0.2056668996810913]\n",
      "input [3, 2] ---> [0.25387710332870483, 0.24057884514331818, 0.25875064730644226, 0.24679337441921234]\n",
      "input [3, 3] ---> [0.2636977434158325, 0.1969018280506134, 0.2271924465894699, 0.3122079372406006]\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"8pt\" height=\"8pt\"\n",
       " viewBox=\"0.00 0.00 8.00 8.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 4)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-4 4,-4 4,4 -4,4\"/>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fba724b4510>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "history = []\n",
    "history_action = []\n",
    "hystory_fb = []\n",
    "history_pred = []\n",
    "context_lenght = 2\n",
    "\n",
    "env = env3()\n",
    "\n",
    "action = 0\n",
    "inputs = torch.tensor([[action]])\n",
    "targets = torch.tensor([0])\n",
    "\n",
    "for i in range(1000):\n",
    "    action = torch.randint(0, 2, (1,)).item()\n",
    "    feedback = env.outcome(action)\n",
    "\n",
    "    history_action.append(action)\n",
    "    hystory_fb.append(feedback)\n",
    "\n",
    "    history.append((action, feedback))\n",
    "\n",
    "history_token = interaction_to_token(history)\n",
    "voc = 4\n",
    "inputs, targets = addapt_seq(history_token, context_lenght)\n",
    "\n",
    "inputs = inputs.to(device)\n",
    "targets = targets.to(device)\n",
    "\n",
    "mymodel = GPTModel(\n",
    "    {\n",
    "        \"vocab_size\": voc,\n",
    "        \"context_length\": context_lenght,\n",
    "        \"emb_dim\": 16,\n",
    "        \"n_heads\": 4,\n",
    "        \"n_leayers\": 4,\n",
    "        \"drop_rate\": 0.1,\n",
    "        \"qkv_bias\": False,\n",
    "        \"device\" : device\n",
    "    }\n",
    ")\n",
    "\n",
    "for j in range(100):\n",
    "    logits = mymodel(inputs, False)\n",
    "    loss = nn.functional.cross_entropy(logits, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    print(j, loss.item())\n",
    "\n",
    "plot_model(mymodel, None, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2513, 0.2843, 0.2535, 0.2108]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = mymodel(torch.tensor([[1, 1]]).to(device), False)\n",
    "probs = nn.functional.softmax(x, dim=-1)\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'000': 0, '001': 1, '002': 2, '003': 3, '004': 4, '005': 5, '006': 6, '007': 7, '008': 8, '009': 9, '0010': 10, '0011': 11, '0012': 12, '0013': 13, '0014': 14, '0015': 15, '0016': 16, '0017': 17, '0018': 18, '0019': 19, '0020': 20, '0021': 21, '0022': 22, '0023': 23, '0024': 24, '0025': 25, '0026': 26, '0027': 27, '0028': 28, '0029': 29, '0030': 30, '0031': 31, '0032': 32, '0033': 33, '0034': 34, '0035': 35, '0036': 36, '0037': 37, '0038': 38, '0039': 39, '0040': 40, '0041': 41, '0042': 42, '0043': 43, '0044': 44, '0045': 45, '0046': 46, '0047': 47, '0048': 48, '0049': 49, '0050': 50, '0051': 51, '0052': 52, '0053': 53, '0054': 54, '0055': 55, '0056': 56, '0057': 57, '0058': 58, '0059': 59, '0060': 60, '0061': 61, '0062': 62, '0063': 63, '0064': 64, '0065': 65, '0066': 66, '0067': 67, '0068': 68, '0069': 69, '0070': 70, '0071': 71, '0072': 72, '0073': 73, '0074': 74, '0075': 75, '0076': 76, '0077': 77, '0078': 78, '0079': 79, '0080': 80, '010': 81, '011': 82, '012': 83, '013': 84, '014': 85, '015': 86, '016': 87, '017': 88, '018': 89, '019': 90, '0110': 91, '0111': 92, '0112': 93, '0113': 94, '0114': 95, '0115': 96, '0116': 97, '0117': 98, '0118': 99, '0119': 100, '0120': 101, '0121': 102, '0122': 103, '0123': 104, '0124': 105, '0125': 106, '0126': 107, '0127': 108, '0128': 109, '0129': 110, '0130': 111, '0131': 112, '0132': 113, '0133': 114, '0134': 115, '0135': 116, '0136': 117, '0137': 118, '0138': 119, '0139': 120, '0140': 121, '0141': 122, '0142': 123, '0143': 124, '0144': 125, '0145': 126, '0146': 127, '0147': 128, '0148': 129, '0149': 130, '0150': 131, '0151': 132, '0152': 133, '0153': 134, '0154': 135, '0155': 136, '0156': 137, '0157': 138, '0158': 139, '0159': 140, '0160': 141, '0161': 142, '0162': 143, '0163': 144, '0164': 145, '0165': 146, '0166': 147, '0167': 148, '0168': 149, '0169': 150, '0170': 151, '0171': 152, '0172': 153, '0173': 154, '0174': 155, '0175': 156, '0176': 157, '0177': 158, '0178': 159, '0179': 160, '0180': 161, '100': 162, '101': 163, '102': 164, '103': 165, '104': 166, '105': 167, '106': 168, '107': 169, '108': 170, '109': 171, '1010': 172, '1011': 173, '1012': 174, '1013': 175, '1014': 176, '1015': 177, '1016': 178, '1017': 179, '1018': 180, '1019': 181, '1020': 182, '1021': 183, '1022': 184, '1023': 185, '1024': 186, '1025': 187, '1026': 188, '1027': 189, '1028': 190, '1029': 191, '1030': 192, '1031': 193, '1032': 194, '1033': 195, '1034': 196, '1035': 197, '1036': 198, '1037': 199, '1038': 200, '1039': 201, '1040': 202, '1041': 203, '1042': 204, '1043': 205, '1044': 206, '1045': 207, '1046': 208, '1047': 209, '1048': 210, '1049': 211, '1050': 212, '1051': 213, '1052': 214, '1053': 215, '1054': 216, '1055': 217, '1056': 218, '1057': 219, '1058': 220, '1059': 221, '1060': 222, '1061': 223, '1062': 224, '1063': 225, '1064': 226, '1065': 227, '1066': 228, '1067': 229, '1068': 230, '1069': 231, '1070': 232, '1071': 233, '1072': 234, '1073': 235, '1074': 236, '1075': 237, '1076': 238, '1077': 239, '1078': 240, '1079': 241, '1080': 242, '110': 243, '111': 244, '112': 245, '113': 246, '114': 247, '115': 248, '116': 249, '117': 250, '118': 251, '119': 252, '1110': 253, '1111': 254, '1112': 255, '1113': 256, '1114': 257, '1115': 258, '1116': 259, '1117': 260, '1118': 261, '1119': 262, '1120': 263, '1121': 264, '1122': 265, '1123': 266, '1124': 267, '1125': 268, '1126': 269, '1127': 270, '1128': 271, '1129': 272, '1130': 273, '1131': 274, '1132': 275, '1133': 276, '1134': 277, '1135': 278, '1136': 279, '1137': 280, '1138': 281, '1139': 282, '1140': 283, '1141': 284, '1142': 285, '1143': 286, '1144': 287, '1145': 288, '1146': 289, '1147': 290, '1148': 291, '1149': 292, '1150': 293, '1151': 294, '1152': 295, '1153': 296, '1154': 297, '1155': 298, '1156': 299, '1157': 300, '1158': 301, '1159': 302, '1160': 303, '1161': 304, '1162': 305, '1163': 306, '1164': 307, '1165': 308, '1166': 309, '1167': 310, '1168': 311, '1169': 312, '1170': 313, '1171': 314, '1172': 315, '1173': 316, '1174': 317, '1175': 318, '1176': 319, '1177': 320, '1178': 321, '1179': 322, '1180': 323}\n"
     ]
    }
   ],
   "source": [
    "def create_all_words(valence:dict, nb_diff:int):\n",
    "    vocab = []\n",
    "    for k in valence.keys():\n",
    "        for i in range(0, nb_diff + 1):\n",
    "            l, r = k\n",
    "            vocab.append(str(str(l) + str(r) + str(i)))\n",
    "    return vocab\n",
    "\n",
    "valence = {\n",
    "    (0, 0) : 0,\n",
    "    (0, 1) : -10,\n",
    "    (1, 0) : 10,\n",
    "    (1, 1) : 0\n",
    "}\n",
    "\n",
    "all_words = create_all_words(valence, 80)\n",
    "vocab = {token:integer for integer, token in enumerate(all_words)}\n",
    "\n",
    "def create_all_words_enumerate(valence:dict, nb_valance_possible:int):\n",
    "    all_words = create_all_words(valence, nb_valance_possible)\n",
    "    return {token:integer for integer, token in enumerate(all_words)}\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[82, 164, 246]\n"
     ]
    }
   ],
   "source": [
    "class SimpleTokenizerV1:\n",
    "    \n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "        \n",
    "    def encode(self, text):\n",
    "        # processed_text = [item.strip() for item in re.split(r'([,.:?_!\"()\\']|--|\\s)', text) if item.strip()]\n",
    "        # processed_text = [item if item in self.str_to_int else \"<|unk|>\" for item in text]\n",
    "        ids = [self.str_to_int[word] for word in text]\n",
    "        return ids\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[id] for id in ids])\n",
    "        return text\n",
    "    \n",
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "\n",
    "print(tokenizer.encode([\"011\", \"102\", \"113\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "list_tempo = [1, 2, 3, 4, 5, 6]\n",
    "print(list_tempo[2: 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valance_in_seq(seq:list, valence:dict):\n",
    "    \"\"\"\n",
    "    Sum all valences in a sequence\n",
    "    Exemple:\n",
    "    seq = [(1, 0), (0, 1), (0, 1)]\n",
    "    valence = {(0, 0) : 0, (0, 1) : -10, (1, 0) : 10, (1, 1) : 0}\n",
    "    get_valance_in_seq(seq, valence) => -10\n",
    "    \"\"\"\n",
    "    return sum(valence.get(tuple(pair), None) for pair in seq)\n",
    "\n",
    "def valance_seq(valence, seq, len_seq):\n",
    "    \"\"\"\n",
    "    Create a list of valences for all sequences of size len_seq in seq\n",
    "    Exemple:\n",
    "    seq = [(1, 0), (0, 1), (0, 1), (0, 1)]\n",
    "    valence = {(0, 0) : 0, (0, 1) : -10, (1, 0) : 10, (1, 1) : 0}\n",
    "    len_seq = 2\n",
    "    valance_seq(valence, seq, len_seq) => [0, -10, -10]\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    for i in range(0, len(seq) - len_seq + 1):\n",
    "        X.append(get_valance_in_seq(seq[i: i+len_seq], valence))\n",
    "    return X\n",
    "\n",
    "def inter_valance_by_nb_seq(valence:dict, seq:list, n_seq:int):\n",
    "    \"\"\"\n",
    "    Create \"word\" for each interaction. A \"word\" is interaction + valence of the next n_seq interactions\n",
    "    Exemple:\n",
    "    valence = {(0, 0) : 0, (0, 1) : -10, (1, 0) : 10, (1, 1) : 0}\n",
    "    sed = [(1, 0), (1, 0), (0, 1), (0, 1), (1, 0), (1, 0), (1, 0), (0, 1), (0, 1)]\n",
    "    n_seq = 2\n",
    "    inter_valance_by_nb_seq(valence, seq, n_seq) => ['1020', '100', '0120', '0140', '1040', '1020', '100']\n",
    "\n",
    "    This word can be tokenize\n",
    "    \"\"\"\n",
    "    seq_valance = []\n",
    "    valance_by_seq = valance_seq(valence, seq[1:], n_seq)\n",
    "    ajout  = n_seq * abs(min(valence.values()))\n",
    "    for i, val in enumerate(valance_by_seq):\n",
    "        l, r = seq[i]\n",
    "        seq_valance.append(str(l) + str(r) + str(val + ajout))\n",
    "    # seq_valance.pop()\n",
    "    return seq_valance\n",
    "\n",
    "    \n",
    "\n",
    "valence = {\n",
    "    (0, 0) : 0,\n",
    "    (0, 1) : -10,\n",
    "    (1, 0) : 10,\n",
    "    (1, 1) : 0\n",
    "}\n",
    "\n",
    "# print(\"teste :\", valance_seq(valence, [(1, 0), (1, 0), (0, 1), (0, 1), (1, 0), (1, 0), (1, 0), (0, 1), (0, 1)], 2))\n",
    "\n",
    "# inputs = inter_valance_by_nb_seq(valence, \n",
    "#                     [(1, 0), (1, 0), (0, 1), (0, 1), (1, 0), (1, 0), (1, 0), (0, 1), (0, 1)], 2)\n",
    "# print(inputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(valence.values())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "#     input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "#     logits = model(input_batch)\n",
    "#     return torch.nn.functional.cross_entropy(logits.flatten(0,1), target_batch.flatten())\n",
    "\n",
    "# def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         train_loss = calc_loss_batch(train_loader, model, device)\n",
    "#         val_loss = calc_loss_batch(val_loader, model, device, num_batches=eval_iter)\n",
    "#     model.train()\n",
    "#     return train_loss, val_loss\n",
    "\n",
    "# def train_batch(model,\n",
    "#                train_loader,\n",
    "#                val_lodaer,\n",
    "#                optimizer, \n",
    "#                device,\n",
    "#                num_epochs,\n",
    "#                eval_freq = 10):\n",
    "\n",
    "#     train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "#     token_seen, global_step = 0, -1\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         model.train()\n",
    "\n",
    "#         for input_batch, target_batch in train_loader:\n",
    "#             optimizer.zero_grad()\n",
    "#             loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             token_seen += input_batch.numel()\n",
    "#             global_step +=1 #nombre de batch vu\n",
    "\n",
    "#             if global_step % 10 == 0:\n",
    "#                 train_loss, val_loss = evaluate_model(model, train_loader, val_lodaer, device, eval_freq)            \n",
    "#                 train_losses.append(train_loss)\n",
    "#                 val_losses.append(val_loss)\n",
    "#                 track_tokens_seen.append(token_seen)\n",
    "#                 print(\"Epoch\", epoch+1, \"global step\", global_step, \"Train loss\", train_loss,\n",
    "#                       \"Val loss\", val_loss)\n",
    "\n",
    "#     return train_losses, val_losses, track_tokens_seen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_valence_possible\n",
      "6\n",
      "voc size\n",
      "28\n",
      "inputs done :\n",
      "tensor([[16, 16, 11,  ..., 11, 11, 18],\n",
      "        [16, 11, 11,  ..., 11, 18, 16],\n",
      "        [11, 11, 16,  ..., 18, 16,  9],\n",
      "        ...,\n",
      "        [13, 20, 18,  ..., 11, 13, 18],\n",
      "        [20, 18, 16,  ..., 13, 18, 16],\n",
      "        [18, 16, 16,  ..., 18, 16, 14]], device='cuda:0')\n",
      "target done :\n",
      "tensor([16,  9, 16, 11, 13, 20, 20, 18, 16, 16,  9,  9, 16, 11, 13, 20, 20, 18,\n",
      "        16, 14,  9, 11, 13, 18, 18, 18, 11, 18, 18, 11, 16, 14,  9, 11, 13, 20,\n",
      "        18, 16, 16,  9, 11, 16,  9, 16,  9,  9, 16, 11, 11, 16, 16,  9,  9, 14,\n",
      "         7,  9, 11, 13, 18, 16, 16, 11, 13, 18, 16, 14,  7], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(28, 320)\n",
       "  (pos_emb): Embedding(30, 320)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): ModuleList(\n",
       "    (0-3): 4 x TransformerBlock(\n",
       "      (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_qkv): Linear(in_features=320, out_features=960, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=320, out_features=1280, bias=False)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=1280, out_features=320, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "  (out_head): Linear(in_features=320, out_features=28, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "history = []\n",
    "history_action = []\n",
    "hystory_fb = []\n",
    "history_pred = []\n",
    "context_lenght = 30\n",
    "nb_seq_valance = 3\n",
    "\n",
    "env = env2()\n",
    "\n",
    "action = 0\n",
    "inputs = torch.tensor([[action]])\n",
    "targets = torch.tensor([0])\n",
    "\n",
    "valence = {\n",
    "    (0, 0) : 0,\n",
    "    (0, 1) : -1,\n",
    "    (1, 0) : 1,\n",
    "    (1, 1) : 0\n",
    "}\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    action = torch.randint(0, 2, (1,)).item()\n",
    "    feedback = env.outcome(action)\n",
    "    history_action.append(action)\n",
    "    hystory_fb.append(feedback)\n",
    "    history.append((action, feedback))\n",
    "\n",
    "\n",
    "nb_valence_possible = nb_seq_valance * (abs(min(valence.values())) + abs(max(valence.values())))\n",
    "print('nb_valence_possible')\n",
    "print(nb_valence_possible)\n",
    "                                                                         \n",
    "\n",
    "all_world_enum = create_all_words_enumerate(valence=valence,\n",
    "            nb_valance_possible=nb_valence_possible)\n",
    "\n",
    "tokenizer = SimpleTokenizerV1(all_world_enum)\n",
    "voc = len(all_world_enum)\n",
    "print('voc size')\n",
    "print(voc)\n",
    "\n",
    "inputs = inter_valance_by_nb_seq(valence, history, nb_seq_valance)\n",
    "inputs = tokenizer.encode(inputs)\n",
    "\n",
    "inputs, targets = addapt_seq(inputs, context_lenght)\n",
    "inputs = inputs.to(device)\n",
    "targets = targets.to(device)\n",
    "\n",
    "print('inputs done :')\n",
    "print(inputs)\n",
    "print(\"target done :\")\n",
    "print(targets)\n",
    "\n",
    "\n",
    "mymodel = GPTModel({\n",
    "        \"vocab_size\": voc,\n",
    "        \"context_length\": context_lenght,\n",
    "        \"emb_dim\": 320,\n",
    "        \"n_heads\": 4,\n",
    "        \"n_leayers\": 4,\n",
    "        \"drop_rate\": 0.1,\n",
    "        \"qkv_bias\": False,\n",
    "        \"device\": device\n",
    "    })\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(mymodel.parameters(), lr=1e-2, weight_decay=1e-2)\n",
    "mymodel.train()\n",
    "# train_simple(mymodel, optimizer, inputs, targets, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def see_proba(probs, tokenizer = None):\n",
    "    plt.bar(range(len(probs)), probs)\n",
    "    plt.text(probs.index(max(probs)), max(probs), str(max(probs)), ha='center')\n",
    "    if tokenizer:\n",
    "        plt.text(probs.index(max(probs)), max(probs) + 0.5, tokenizer.decode(max(probs)), ha='center')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAMkpJREFUeJzt3X9clfXdx/E3P89BEvxBcsBUNH+gSTB/QLiW6xETvN2K2ozclkbMtm5tNhpLnEnObVR3Ot1k83a3tq07xbnbqNRhjIVbk3SCPoxVpi6HqQe0bqFwocH3/qO7004czIPp+YKv5+NxPRbf6/O9zvd7dT3Gu+91XYcgY4wRAACAxYIDPQAAAIBPQmABAADWI7AAAADrEVgAAID1CCwAAMB6BBYAAGA9AgsAALAegQUAAFgvNNAD+DS0t7fr2LFj6t27t4KCggI9HAAAcB6MMXrnnXcUHx+v4OBzr6H0iMBy7NgxDRo0KNDDAAAAXXDkyBFdddVV56zpEYGld+/ekj6YcFRUVIBHAwAAzkdzc7MGDRrk+T1+Lj0isHx4GygqKorAAgBAN3M+j3Pw0C0AALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWGCNkpISJSQkyOl0Ki0tTbt27Tpn/caNG5WYmCin06mkpCRt3bq1Q82rr76qm2++WdHR0YqMjNTEiRNVX1/foc4Yo6lTpyooKEhlZWVe++rr6zVt2jT16tVLAwYMUEFBgd5//33P/k2bNukLX/iCrrzySkVFRSk9PV3btm3zOsY777yj+++/X0OGDFFERIQmTZqkv/71r141Dz/8sBITExUZGam+ffsqIyNDO3fu7DDWLVu2KC0tTREREerbt6+ys7O99gcFBXXYSktLPfvvuusunzXXXHONpyYhIcFnzZw5cyRJhw8f9rk/KChIGzdu9BynsrJSkyZNUu/eveVyufTggw96nbsPz/3jjz+ukSNHyuFwaODAgfrRj37kVVNSUqLRo0crIiJCo0aN0m9+8xuv/Zs2bdKECRPUp08fRUZGKiUlRU8++WSHc3e+1wMAC5keoKmpyUgyTU1NgR4Kuqi0tNSEh4ebtWvXmr/97W9m9uzZpk+fPqahocFn/V/+8hcTEhJiHnvsMfPKK6+YhQsXmrCwMPPyyy97ag4ePGj69etnCgoKTG1trTl48KB55plnfB5z2bJlZurUqUaSefrppz3t77//vhk7dqzJyMgwe/bsMVu3bjUxMTGmsLDQUzNv3jzz6KOPml27dpnXX3/dFBYWmrCwMFNbW+upuf32282YMWPM9u3bzYEDB0xRUZGJiooyb775pqfmqaeeMhUVFebQoUOmrq7O5OXlmaioKNPY2Oip+d3vfmf69u1rfvGLX5j9+/ebv/3tb2bDhg1ec5FknnjiCXP8+HHP9s9//tOz/9SpU177jhw5Yvr162eKioo8NY2NjV41FRUVRpJ54YUXPOflX/cfP37cLF682FxxxRXmnXfeMcYYs3fvXhMeHm4WL15sDhw4YKqqqkxiYqJ54IEHvMZ73333mVGjRplnnnnG/P3vfze7d+82zz//vGf/z3/+c9O7d29TWlpqDh06ZNavX2+uuOIK8+yzz3pqXnjhBbNp0ybzyiuvmIMHD5rly5ebkJAQU15e3qXrAcCl4c/vbwILrJCammrmzJnj+bmtrc3Ex8eb4uJin/W33367mTZtmldbWlqa+eY3v+n5OScnx3z961//xM/es2ePGThwoDl+/HiHwLJ161YTHBxs3G63p+0Xv/iFiYqKMq2trZ0ec8yYMWbx4sXGGGNOnz5tQkJCzObNm71qxo0bZ77//e93eowPr+s//OEPxhhjzp49awYOHGj+67/+65zz+fgcPsnTTz9tgoKCzOHDhzutmTdvnrn66qtNe3t7pzUpKSnm7rvv9vxcWFhoJkyY4FXz7LPPGqfTaZqbm40xxrzyyismNDTUvPbaa50eNz093Xz3u9/1asvPzzef/exnzzmvz3zmM2bhwoWen8/3egBw6fjz+5tbQgi4M2fOqKamRhkZGZ624OBgZWRkqLq62mef6upqr3pJyszM9NS3t7dry5YtGjlypDIzMzVgwAClpaV1uN1z+vRpffWrX1VJSYlcLpfPz0lKSlJsbKzX5zQ3N+tvf/ubz7G1t7frnXfeUb9+/SRJ77//vtra2uR0Or3qIiIi9OKLL3Z6TlavXq3o6GglJydLkmpra3X06FEFBwfrM5/5jOLi4jR16lTV1dV16D9nzhzFxMQoNTVVa9eulTHG5+dI0po1a5SRkaEhQ4Z0Opb//u//1t13393plzvV1NRo7969ysvL87S1trb6nPN7772nmpoaSdJzzz2nYcOGafPmzRo6dKgSEhL0jW98Q2+//fYnHmfXrl06e/Zsh7EYY1RZWan9+/frhhtukHT+1wMAi130+HQJsMLSvR09etRIMjt27PBqLygoMKmpqT77hIWFmXXr1nm1lZSUmAEDBhhjjGe1pFevXmbZsmVmz549pri42AQFBZmqqipPn3vuucfk5eV5ftbHVidmz55tpkyZ4vU5LS0tRpLZunWrz7E9+uijpm/fvl63GtLT083kyZPN0aNHzfvvv2+efPJJExwcbEaOHOnV97nnnjORkZEmKCjIxMfHm127dnn2rV+/3kgygwcPNr/73e/M7t27zYwZM0z//v3NW2+95an7wQ9+YF588UVTW1trHnnkEeNwOMyKFSt8jvXo0aMmJCSkw22lf7VhwwYTEhJijh492mnNvffea0aPHu3Vtm3bNhMcHGzWrVtn3n//ffPmm2+az33uc0aS59/dN7/5TeNwOExaWpr505/+ZF544QWTkpJibrzxRs9xCgsLjcvlMrt37zbt7e3mr3/9q4mNjTWSzLFjxzx1p06dMpGRkSY0NNQ4HA6zZs0az77zvR4AXFrcEkK3cjECy4fHnDFjhlfNl770JXPHHXcYY4x55plnzPDhwz3PXBhz4YHlqaeeMr169TIVFRVe7QcPHjQ33HCDkWRCQkLMxIkTzde+9jWTmJjoVffuu++aAwcOmOrqanP33XebhIQET/B56qmnjCTzn//5n5769957z8TExJhVq1b5PE/GGPPQQw+Zq666yue+H//4x6Z///7nvL01ZcoU88UvfrHT/adPnzbR0dHm8ccf77Bv6dKlJioqyoSEhJhevXqZ4uJiI8mUlpYaYz44v5LM/v37PX1qamqMJM9totOnT5vc3FwTGhpqQkJCTHx8vPne975nJHndqmtrazMHDhwwe/bsMY8//riJjo72PHNzPtcDgEuPW0LoVmJiYhQSEqKGhgav9oaGBp+3aSTJ5XKdsz4mJkahoaEaM2aMV83o0aM9b4X88Y9/1KFDh9SnTx+FhoYqNPSDP6315S9/WZ///OfP+Tkf7vtXpaWl+sY3vqHf/va3HW5XXX311dq+fbveffddHTlyxHM7Y9iwYV51kZGRGj58uK677jqtWbNGoaGhWrNmjSQpLi5Okrzm5HA4NGzYsHO+6ZKWlqY333xTra2tXu3GGK1du1Z33nmnwsPDffb9xz/+oT/84Q/6xje+0enxf/e73+n06dOaOXNmh335+fk6deqU6uvrdfLkSd1yyy2S5Jl3XFycQkNDNXLkSE+f0aNHS5JnThEREVq7dq1Onz6tw4cPq76+XgkJCerdu7euvPJKT7/g4GANHz5cKSkpeuCBB/SVr3xFxcXFks7vegBgNwILAi48PFzjx49XZWWlp629vV2VlZVKT0/32Sc9Pd2rXpIqKio89eHh4Zo4caL279/vVfP66697ntWYP3++9u3bp71793o2SfrJT36iJ554wvM5L7/8shobG70+JyoqyuuX3/r165Wbm6v169dr2rRpnc41MjJScXFx+t///V9t27bN8wu8M+3t7Z6gMX78eDkcDq85nT17VocPH+70+RNJ2rt3r/r27SuHw+HVvn37dh08eNDruZOPe+KJJzRgwIBzzmnNmjW6+eabvcLDvwoKClJ8fLwiIiK0fv16DRo0SOPGjZMkffazn9X777+vQ4cOeepff/11Seowp7CwMF111VUKCQlRaWmpvvjFLyo4uPP/C/vXc3c+1wMAy138BZ+Lj1tC3V9paalxOBzmV7/6lXnllVfMPffcY/r06eNZ8r/zzjvN/PnzPfV/+ctfTGhoqHn88cfNq6++aoqKijq81rxp0yYTFhZmVq9ebQ4cOGB+9rOfmZCQEPPnP/+503Gok9eap0yZYvbu3WvKy8vNlVde6fVa81NPPWVCQ0NNSUmJ12u+p06d8tSUl5eb3//+9+bvf/+7ef75501ycrJJS0szZ86cMcZ8cCuosLDQVFdXm8OHD5vdu3eb3Nxc43A4TF1dnec48+bNMwMHDjTbtm0zr732msnLyzMDBgwwb7/9tjHmg7dwfvnLX5qXX37ZHDhwwPz85z83vXr1MosWLeow169//esmLS2t03PR1tZmBg8ebB588MFOaw4cOGCCgoLM73//e5/7H3vsMbNv3z5TV1dnfvCDH5iwsDCv89vW1mbGjRtnbrjhBlNbW2t2795t0tLSzBe+8AVPzf79+82TTz5pXn/9dbNz506Tk5Nj+vXrZ9544w1PzY9//GPz/PPPm0OHDplXXnnFPP744yY0NNT88pe/9NR05XoAcHHxDAu6pZ/97Gdm8ODBJjw83KSmppqXXnrJs2/y5Mlm1qxZXvW//e1vzciRI014eLi55pprzJYtWzocc82aNWb48OHG6XSa5ORkU1ZWds4xfDywGGPM4cOHzdSpU01ERISJiYkxDzzwgDl79qzX2CR12P51vBs2bDDDhg0z4eHhxuVymTlz5ngFmn/+85/m1ltvNfHx8SY8PNzExcWZm2++2euh2yEPbjaDv1tmoibeaoJ79TFB4RHGOSTFxN1dYoY8uNkMeXCzGTB9sQkbMMwEhUeYoLAP5rxq1SrT1tbmNadTp06ZiIgIs3r16k7PxbZt2zo8X/JxhYWFZtCgQR2O/6Ebb7zRREdHG6fTadLS0nw+93P06FFz2223mSuuuMLExsaau+66y+sh4ldeecWkpKSYiIgIExUVZW655ZYOr0F///vf9/x77tu3r0lPT/c8J/Ov/L0eAFxc/vz+DjLmHO87dhPNzc2Kjo5WU1OToqKiAj0c4KJImL/F7z6HH+n8Vg4ABJo/v795hgUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHoEFgAAYD0CCwAAsB6BBQAAWI/AAgAArEdgAQAA1iOwAAAA6xFYAACA9QgsAADAegQWAABgPQILAACwXpcCS0lJiRISEuR0OpWWlqZdu3ads37jxo1KTEyU0+lUUlKStm7d2qHm1Vdf1c0336zo6GhFRkZq4sSJqq+v78rwAABAD+N3YNmwYYPy8/NVVFSk2tpaJScnKzMzU42NjT7rd+zYoRkzZigvL0979uxRdna2srOzVVdX56k5dOiQrr/+eiUmJqqqqkr79u3TQw89JKfT2fWZAQCAHiPIGGP86ZCWlqaJEydq5cqVkqT29nYNGjRI9913n+bPn9+hPicnRy0tLdq8ebOn7brrrlNKSopWrVolSbrjjjsUFhamJ598skuTaG5uVnR0tJqamhQVFdWlYwC2S5i/xe8+hx+ZdhFGAgCfDn9+f/u1wnLmzBnV1NQoIyPjowMEBysjI0PV1dU++1RXV3vVS1JmZqanvr29XVu2bNHIkSOVmZmpAQMGKC0tTWVlZZ2Oo7W1Vc3NzV4bAADoufwKLCdPnlRbW5tiY2O92mNjY+V2u332cbvd56xvbGzUu+++q0ceeURZWVl6/vnndeutt+q2227T9u3bfR6zuLhY0dHRnm3QoEH+TAMAAHQzAX9LqL29XZJ0yy236Dvf+Y5SUlI0f/58ffGLX/TcMvq4wsJCNTU1ebYjR45cyiEDAIBLLNSf4piYGIWEhKihocGrvaGhQS6Xy2cfl8t1zvqYmBiFhoZqzJgxXjWjR4/Wiy++6POYDodDDofDn6EDAIBuzK8VlvDwcI0fP16VlZWetvb2dlVWVio9Pd1nn/T0dK96SaqoqPDUh4eHa+LEidq/f79Xzeuvv64hQ4b4MzwAANBD+bXCIkn5+fmaNWuWJkyYoNTUVC1fvlwtLS3Kzc2VJM2cOVMDBw5UcXGxJGnevHmaPHmyli5dqmnTpqm0tFS7d+/W6tWrPccsKChQTk6ObrjhBt14440qLy/Xc889p6qqqk9nlgAAoFvzO7Dk5OToxIkTWrRokdxut1JSUlReXu55sLa+vl7BwR8t3EyaNEnr1q3TwoULtWDBAo0YMUJlZWUaO3asp+bWW2/VqlWrVFxcrG9/+9saNWqU/ud//kfXX3/9pzBFAADQ3fn9PSw24ntYcDnge1gA9DQX7XtYAAAAAoHAAgAArEdgAQAA1vP7oVt0Tzz/AADozlhhAQAA1iOwAAAA6xFYAACA9QgsAADAegQWAABgPQILAACwHoEFAABYj8ACAACsR2ABAADWI7AAAADrEVgAAID1CCwAAMB6BBYAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOuFBnoAwPlImL/F7z6HH5l2EUYCAAgEVlgAAID1CCwAAMB6BBYAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHoEFgAAYD0CCwAAsB6BBQAAWI/AAgAArEdgAQAA1iOwAAAA6xFYAACA9QgsAADAegQWAABgPQILAACwHoEFAABYr0uBpaSkRAkJCXI6nUpLS9OuXbvOWb9x40YlJibK6XQqKSlJW7du9dp/1113KSgoyGvLysrqytAAAEAP5Hdg2bBhg/Lz81VUVKTa2lolJycrMzNTjY2NPut37NihGTNmKC8vT3v27FF2drays7NVV1fnVZeVlaXjx497tvXr13dtRgAAoMfxO7AsW7ZMs2fPVm5ursaMGaNVq1apV69eWrt2rc/6FStWKCsrSwUFBRo9erSWLFmicePGaeXKlV51DodDLpfLs/Xt27drMwIAAD2OX4HlzJkzqqmpUUZGxkcHCA5WRkaGqqurffaprq72qpekzMzMDvVVVVUaMGCARo0apXvvvVdvvfVWp+NobW1Vc3Oz1wYAAHquUH+KT548qba2NsXGxnq1x8bG6rXXXvPZx+12+6x3u92en7OysnTbbbdp6NChOnTokBYsWKCpU6equrpaISEhHY5ZXFysxYsX+zN0AJ+ChPlb/O5z+JFpF2EkAC43fgWWi+WOO+7w/HNSUpKuvfZaXX311aqqqtJNN93Uob6wsFD5+fmen5ubmzVo0KBLMlYAAHDp+XVLKCYmRiEhIWpoaPBqb2hokMvl8tnH5XL5VS9Jw4YNU0xMjA4ePOhzv8PhUFRUlNcGAAB6Lr8CS3h4uMaPH6/KykpPW3t7uyorK5Wenu6zT3p6ule9JFVUVHRaL0lvvvmm3nrrLcXFxfkzPAAA0EP5/ZZQfn6+fvnLX+rXv/61Xn31Vd17771qaWlRbm6uJGnmzJkqLCz01M+bN0/l5eVaunSpXnvtNT388MPavXu35s6dK0l69913VVBQoJdeekmHDx9WZWWlbrnlFg0fPlyZmZmf0jQBAEB35vczLDk5OTpx4oQWLVokt9utlJQUlZeXex6sra+vV3DwRzlo0qRJWrdunRYuXKgFCxZoxIgRKisr09ixYyVJISEh2rdvn37961/r1KlTio+P15QpU7RkyRI5HI5PaZoAAKA769JDt3PnzvWskHxcVVVVh7bp06dr+vTpPusjIiK0bdu2rgwDAABcJvhbQgAAwHoEFgAAYD0CCwAAsB6BBQAAWI/AAgAArEdgAQAA1iOwAAAA6xFYAACA9QgsAADAegQWAABgPQILAACwHoEFAABYj8ACAACsR2ABAADWI7AAAADrEVgAAID1CCwAAMB6BBYAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHoEFgAAYL3QQA8AAIDLTcL8LX7VH35k2kUaSffBCgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOvxlhAA4JLy9w0ZibdkwAoLAADoBggsAADAegQWAABgPZ5hwWWD++YA0H2xwgIAAKzHCgtwibDCAwBdxwoLAACwHissAIBuhdXKyxMrLAAAwHoEFgAAYD1uCV0CLF8CAHBhurTCUlJSooSEBDmdTqWlpWnXrl3nrN+4caMSExPldDqVlJSkrVu3dlr7rW99S0FBQVq+fHlXhgYAAHogvwPLhg0blJ+fr6KiItXW1io5OVmZmZlqbGz0Wb9jxw7NmDFDeXl52rNnj7Kzs5Wdna26uroOtU8//bReeuklxcfH+z8TAADQY/kdWJYtW6bZs2crNzdXY8aM0apVq9SrVy+tXbvWZ/2KFSuUlZWlgoICjR49WkuWLNG4ceO0cuVKr7qjR4/qvvvu01NPPaWwsLCuzQYAAPRIfgWWM2fOqKamRhkZGR8dIDhYGRkZqq6u9tmnurraq16SMjMzverb29t15513qqCgQNdcc80njqO1tVXNzc1eGwAA6Ln8CiwnT55UW1ubYmNjvdpjY2Pldrt99nG73Z9Y/+ijjyo0NFTf/va3z2scxcXFio6O9myDBg3yZxoAAKCbCfhrzTU1NVqxYoV+9atfKSgo6Lz6FBYWqqmpybMdOXLkIo8SAAAEkl+BJSYmRiEhIWpoaPBqb2hokMvl8tnH5XKds/7Pf/6zGhsbNXjwYIWGhio0NFT/+Mc/9MADDyghIcHnMR0Oh6Kiorw2AADQc/kVWMLDwzV+/HhVVlZ62trb21VZWan09HSffdLT073qJamiosJTf+edd2rfvn3au3evZ4uPj1dBQYG2bdvm73wAAEAP5PcXx+Xn52vWrFmaMGGCUlNTtXz5crW0tCg3N1eSNHPmTA0cOFDFxcWSpHnz5mny5MlaunSppk2bptLSUu3evVurV6+WJPXv31/9+/f3+oywsDC5XC6NGjXqQucHAAB6AL8DS05Ojk6cOKFFixbJ7XYrJSVF5eXlngdr6+vrFRz80cLNpEmTtG7dOi1cuFALFizQiBEjVFZWprFjx356swAAnBe+eRvdVZe+mn/u3LmaO3euz31VVVUd2qZPn67p06ef9/EPHz7clWEBAIAeKuBvCQEAAHwSAgsAALAegQUAAFiPwAIAAKzXpYduAXQ/vB0CoDtjhQUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHoEFgAAYD2+hwUAAD/wnUaBwQoLAACwHissALoN/ssWuHyxwgIAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHoEFgAAYD0CCwAAsB6BBQAAWI/AAgAArEdgAQAA1iOwAAAA6/G3hAAAuMx0x7/LxQoLAACwHoEFAABYj8ACAACsR2ABAADW46HbbqA7PhwFAMCniRUWAABgPQILAACwHoEFAABYj8ACAACsR2ABAADW4y0hAPADb+0BgcEKCwAAsB6BBQAAWI/AAgAArEdgAQAA1iOwAAAA6xFYAACA9boUWEpKSpSQkCCn06m0tDTt2rXrnPUbN25UYmKinE6nkpKStHXrVq/9Dz/8sBITExUZGam+ffsqIyNDO3fu7MrQAABAD+R3YNmwYYPy8/NVVFSk2tpaJScnKzMzU42NjT7rd+zYoRkzZigvL0979uxRdna2srOzVVdX56kZOXKkVq5cqZdfflkvvviiEhISNGXKFJ04caLrMwMAAD2G34Fl2bJlmj17tnJzczVmzBitWrVKvXr10tq1a33Wr1ixQllZWSooKNDo0aO1ZMkSjRs3TitXrvTUfPWrX1VGRoaGDRuma665RsuWLVNzc7P27dvX9ZkBAIAew69vuj1z5oxqampUWFjoaQsODlZGRoaqq6t99qmurlZ+fr5XW2ZmpsrKyjr9jNWrVys6OlrJyck+a1pbW9Xa2ur5ubm52Z9pAADQrV2O37js1wrLyZMn1dbWptjYWK/22NhYud1un33cbvd51W/evFlXXHGFnE6nfvKTn6iiokIxMTE+j1lcXKzo6GjPNmjQIH+mAQAAuhlr3hK68cYbtXfvXu3YsUNZWVm6/fbbO30uprCwUE1NTZ7tyJEjl3i0AADgUvIrsMTExCgkJEQNDQ1e7Q0NDXK5XD77uFyu86qPjIzU8OHDdd1112nNmjUKDQ3VmjVrfB7T4XAoKirKawMAAD2XX8+whIeHa/z48aqsrFR2drYkqb29XZWVlZo7d67PPunp6aqsrNT999/vaauoqFB6evo5P6u9vd3rORUA3d/leN8dwKfDr8AiSfn5+Zo1a5YmTJig1NRULV++XC0tLcrNzZUkzZw5UwMHDlRxcbEkad68eZo8ebKWLl2qadOmqbS0VLt379bq1aslSS0tLfrRj36km2++WXFxcTp58qRKSkp09OhRTZ8+/VOcKgAA6K78Diw5OTk6ceKEFi1aJLfbrZSUFJWXl3serK2vr1dw8Ed3miZNmqR169Zp4cKFWrBggUaMGKGysjKNHTtWkhQSEqLXXntNv/71r3Xy5En1799fEydO1J///Gddc801n9I0AQBAd+Z3YJGkuXPndnoLqKqqqkPb9OnTO10tcTqd2rRpU1eGAQAALhPWvCUEAADQGQILAACwHoEFAABYj8ACAACs16WHbgEAgcF32Vw4zmH3xAoLAACwHoEFAABYj8ACAACsR2ABAADWI7AAAADrEVgAAID1CCwAAMB6BBYAAGA9vjgOlwRf1AQAuBCssAAAAOsRWAAAgPUILAAAwHoEFgAAYD0CCwAAsB6BBQAAWI/XmgEA542vKECgsMICAACsR2ABAADWI7AAAADrEVgAAID1eOgW54UH7QAAgcQKCwAAsB6BBQAAWI/AAgAArMczLAAuGzyLBXRfrLAAAADrEVgAAID1CCwAAMB6BBYAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHoEFgAAYD0CCwAAsB6BBQAAWK9LgaWkpEQJCQlyOp1KS0vTrl27zlm/ceNGJSYmyul0KikpSVu3bvXsO3v2rB588EElJSUpMjJS8fHxmjlzpo4dO9aVoQEAgB7I78CyYcMG5efnq6ioSLW1tUpOTlZmZqYaGxt91u/YsUMzZsxQXl6e9uzZo+zsbGVnZ6uurk6SdPr0adXW1uqhhx5SbW2tNm3apP379+vmm2++sJkBAIAew+/AsmzZMs2ePVu5ubkaM2aMVq1apV69emnt2rU+61esWKGsrCwVFBRo9OjRWrJkicaNG6eVK1dKkqKjo1VRUaHbb79do0aN0nXXXaeVK1eqpqZG9fX1FzY7AADQI4T6U3zmzBnV1NSosLDQ0xYcHKyMjAxVV1f77FNdXa38/HyvtszMTJWVlXX6OU1NTQoKClKfPn187m9tbVVra6vn5+bm5vOfBAAEUML8LX73OfzItIswEqB78WuF5eTJk2pra1NsbKxXe2xsrNxut88+brfbr/r33ntPDz74oGbMmKGoqCifNcXFxYqOjvZsgwYN8mcaAACgm7HqLaGzZ8/q9ttvlzFGv/jFLzqtKywsVFNTk2c7cuTIJRwlAAC41Py6JRQTE6OQkBA1NDR4tTc0NMjlcvns43K5zqv+w7Dyj3/8Q3/84x87XV2RJIfDIYfD4c/QAQBAN+bXCkt4eLjGjx+vyspKT1t7e7sqKyuVnp7us096erpXvSRVVFR41X8YVg4cOKA//OEP6t+/vz/DAgAAPZxfKyySlJ+fr1mzZmnChAlKTU3V8uXL1dLSotzcXEnSzJkzNXDgQBUXF0uS5s2bp8mTJ2vp0qWaNm2aSktLtXv3bq1evVrSB2HlK1/5impra7V582a1tbV5nm/p16+fwsPDP625AgCAbsrvwJKTk6MTJ05o0aJFcrvdSklJUXl5uefB2vr6egUHf7RwM2nSJK1bt04LFy7UggULNGLECJWVlWns2LGSpKNHj+rZZ5+VJKWkpHh91gsvvKDPf/7zXZwaAADoKfwOLJI0d+5czZ071+e+qqqqDm3Tp0/X9OnTfdYnJCTIGNOVYQAAgMuEVW8JAQAA+EJgAQAA1iOwAAAA6xFYAACA9QgsAADAegQWAABgPQILAACwXpe+hwW4HCXM3+J3n8OPTLsIIwGAyw8rLAAAwHoEFgAAYD0CCwAAsB6BBQAAWI+Hbs8DD1sCABBYrLAAAADrEVgAAID1CCwAAMB6BBYAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHoEFgAAYD0CCwAAsB6BBQAAWI/AAgAArEdgAQAA1iOwAAAA6xFYAACA9QgsAADAegQWAABgPQILAACwHoEFAABYj8ACAACsR2ABAADWI7AAAADrEVgAAID1CCwAAMB6BBYAAGA9AgsAALAegQUAAFiPwAIAAKzXpcBSUlKihIQEOZ1OpaWladeuXees37hxoxITE+V0OpWUlKStW7d67d+0aZOmTJmi/v37KygoSHv37u3KsAAAQA/ld2DZsGGD8vPzVVRUpNraWiUnJyszM1ONjY0+63fs2KEZM2YoLy9Pe/bsUXZ2trKzs1VXV+epaWlp0fXXX69HH3206zMBAAA9lt+BZdmyZZo9e7Zyc3M1ZswYrVq1Sr169dLatWt91q9YsUJZWVkqKCjQ6NGjtWTJEo0bN04rV6701Nx5551atGiRMjIyuj4TAADQY/kVWM6cOaOamhqvYBEcHKyMjAxVV1f77FNdXd0hiGRmZnZafz5aW1vV3NzstQEAgJ7Lr8By8uRJtbW1KTY21qs9NjZWbrfbZx+32+1X/fkoLi5WdHS0Zxs0aFCXjwUAAOzXLd8SKiwsVFNTk2c7cuRIoIcEAAAuolB/imNiYhQSEqKGhgav9oaGBrlcLp99XC6XX/Xnw+FwyOFwdLk/AADoXvxaYQkPD9f48eNVWVnpaWtvb1dlZaXS09N99klPT/eql6SKiopO6wEAAD7OrxUWScrPz9esWbM0YcIEpaamavny5WppaVFubq4kaebMmRo4cKCKi4slSfPmzdPkyZO1dOlSTZs2TaWlpdq9e7dWr17tOebbb7+t+vp6HTt2TJK0f/9+SR+szlzISgwAAOgZ/A4sOTk5OnHihBYtWiS3262UlBSVl5d7Hqytr69XcPBHCzeTJk3SunXrtHDhQi1YsEAjRoxQWVmZxo4d66l59tlnPYFHku644w5JUlFRkR5++OGuzg0AAPQQfgcWSZo7d67mzp3rc19VVVWHtunTp2v69OmdHu+uu+7SXXfd1ZWhAACAy0C3fEsIAABcXggsAADAegQWAABgPQILAACwHoEFAABYj8ACAACsR2ABAADWI7AAAADrEVgAAID1CCwAAMB6BBYAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHoEFgAAYD0CCwAAsB6BBQAAWI/AAgAArEdgAQAA1iOwAAAA6xFYAACA9QgsAADAegQWAABgPQILAACwHoEFAABYj8ACAACsR2ABAADWI7AAAADrEVgAAID1CCwAAMB6BBYAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHoEFgAAYD0CCwAAsF6XAktJSYkSEhLkdDqVlpamXbt2nbN+48aNSkxMlNPpVFJSkrZu3eq13xijRYsWKS4uThEREcrIyNCBAwe6MjQAANAD+R1YNmzYoPz8fBUVFam2tlbJycnKzMxUY2Ojz/odO3ZoxowZysvL0549e5Sdna3s7GzV1dV5ah577DH99Kc/1apVq7Rz505FRkYqMzNT7733XtdnBgAAegy/A8uyZcs0e/Zs5ebmasyYMVq1apV69eqltWvX+qxfsWKFsrKyVFBQoNGjR2vJkiUaN26cVq5cKemD1ZXly5dr4cKFuuWWW3TttdfqN7/5jY4dO6aysrILmhwAAOgZQv0pPnPmjGpqalRYWOhpCw4OVkZGhqqrq332qa6uVn5+vldbZmamJ4y88cYbcrvdysjI8OyPjo5WWlqaqqurdccdd3Q4Zmtrq1pbWz0/NzU1SZKam5v9mc55a2897Xeffx1LoPvbMIZA97dhDN29vw1jCHR/G8bQ3fvbMIZA9+/KMWw7h5+WD49pjPnkYuOHo0ePGklmx44dXu0FBQUmNTXVZ5+wsDCzbt06r7aSkhIzYMAAY4wxf/nLX4wkc+zYMa+a6dOnm9tvv93nMYuKiowkNjY2NjY2th6wHTly5BMziF8rLLYoLCz0WrVpb2/X22+/rf79+ysoKOiSjaO5uVmDBg3SkSNHFBUVdck+tyfhHF44zuGF4xxeOM7hhbscz6ExRu+8847i4+M/sdavwBITE6OQkBA1NDR4tTc0NMjlcvns43K5zln/4f82NDQoLi7OqyYlJcXnMR0OhxwOh1dbnz59/JnKpyoqKuqyubguFs7hheMcXjjO4YXjHF64y+0cRkdHn1edXw/dhoeHa/z48aqsrPS0tbe3q7KyUunp6T77pKene9VLUkVFhad+6NChcrlcXjXNzc3auXNnp8cEAACXF79vCeXn52vWrFmaMGGCUlNTtXz5crW0tCg3N1eSNHPmTA0cOFDFxcWSpHnz5mny5MlaunSppk2bptLSUu3evVurV6+WJAUFBen+++/XD3/4Q40YMUJDhw7VQw89pPj4eGVnZ396MwUAAN2W34ElJydHJ06c0KJFi+R2u5WSkqLy8nLFxsZKkurr6xUc/NHCzaRJk7Ru3TotXLhQCxYs0IgRI1RWVqaxY8d6ar73ve+ppaVF99xzj06dOqXrr79e5eXlcjqdn8IULx6Hw6GioqIOt6dw/jiHF45zeOE4hxeOc3jhOIfnFmTM+bxLBAAAEDj8LSEAAGA9AgsAALAegQUAAFiPwAIAAKxHYOmikpISJSQkyOl0Ki0tTbt27Qr0kLqNhx9+WEFBQV5bYmJioIdltT/96U/60pe+pPj4eAUFBXX4w6DGGC1atEhxcXGKiIhQRkaGDhw4EJjBWuyTzuNdd93V4drMysoKzGAtVFxcrIkTJ6p3794aMGCAsrOztX//fq+a9957T3PmzFH//v11xRVX6Mtf/nKHLw+9nJ3POfz85z/f4Tr81re+FaAR24PA0gUbNmxQfn6+ioqKVFtbq+TkZGVmZqqxsTHQQ+s2rrnmGh0/ftyzvfjii4EektVaWlqUnJyskpISn/sfe+wx/fSnP9WqVau0c+dORUZGKjMzU++9994lHqndPuk8SlJWVpbXtbl+/fpLOEK7bd++XXPmzNFLL72kiooKnT17VlOmTFFLS4un5jvf+Y6ee+45bdy4Udu3b9exY8d02223BXDUdjmfcyhJs2fP9roOH3vssQCN2CKf+NeG0EFqaqqZM2eO5+e2tjYTHx9viouLAziq7qOoqMgkJycHehjdliTz9NNPe35ub283LpfL/Md//Ien7dSpU8bhcJj169cHYITdw8fPozHGzJo1y9xyyy0BGU931NjYaCSZ7du3G2M+uO7CwsLMxo0bPTWvvvqqkWSqq6sDNUyrffwcGmPM5MmTzbx58wI3KEuxwuKnM2fOqKamRhkZGZ624OBgZWRkqLq6OoAj614OHDig+Ph4DRs2TF/72tdUX18f6CF1W2+88YbcbrfXNRkdHa20tDSuyS6oqqrSgAEDNGrUKN1777166623Aj0kazU1NUmS+vXrJ0mqqanR2bNnva7FxMREDR48mGuxEx8/hx966qmnFBMTo7Fjx6qwsFCnT58OxPCs0i3/WnMgnTx5Um1tbZ5v9v1QbGysXnvttQCNqntJS0vTr371K40aNUrHjx/X4sWL9bnPfU51dXXq3bt3oIfX7bjdbknyeU1+uA/nJysrS7fddpuGDh2qQ4cOacGCBZo6daqqq6sVEhIS6OFZpb29Xffff78++9nPer653O12Kzw8vMMfo+Va9M3XOZSkr371qxoyZIji4+O1b98+Pfjgg9q/f782bdoUwNEGHoEFl9zUqVM9/3zttdcqLS1NQ4YM0W9/+1vl5eUFcGS43N1xxx2ef05KStK1116rq6++WlVVVbrpppsCODL7zJkzR3V1dTx/dgE6O4f33HOP55+TkpIUFxenm266SYcOHdLVV199qYdpDW4J+SkmJkYhISEdnnpvaGiQy+UK0Ki6tz59+mjkyJE6ePBgoIfSLX143XFNfvqGDRummJgYrs2PmTt3rjZv3qwXXnhBV111lafd5XLpzJkzOnXqlFc912JHnZ1DX9LS0iTpsr8OCSx+Cg8P1/jx41VZWelpa29vV2VlpdLT0wM4su7r3Xff1aFDhxQXFxfooXRLQ4cOlcvl8romm5ubtXPnTq7JC/Tmm2/qrbfe4tr8f8YYzZ07V08//bT++Mc/aujQoV77x48fr7CwMK9rcf/+/aqvr+da/H+fdA592bt3ryRd9tcht4S6ID8/X7NmzdKECROUmpqq5cuXq6WlRbm5uYEeWrfw3e9+V1/60pc0ZMgQHTt2TEVFRQoJCdGMGTMCPTRrvfvuu17/dfXGG29o79696tevnwYPHqz7779fP/zhDzVixAgNHTpUDz30kOLj45WdnR24QVvoXOexX79+Wrx4sb785S/L5XLp0KFD+t73vqfhw4crMzMzgKO2x5w5c7Ru3To988wz6t27t+e5lOjoaEVERCg6Olp5eXnKz89Xv379FBUVpfvuu0/p6em67rrrAjx6O3zSOTx06JDWrVunf/u3f1P//v21b98+fec739ENN9yga6+9NsCjD7BAv6bUXf3sZz8zgwcPNuHh4SY1NdW89NJLgR5St5GTk2Pi4uJMeHi4GThwoMnJyTEHDx4M9LCs9sILLxhJHbZZs2YZYz54tfmhhx4ysbGxxuFwmJtuusns378/sIO20LnO4+nTp82UKVPMlVdeacLCwsyQIUPM7NmzjdvtDvSwreHr3EkyTzzxhKfmn//8p/n3f/9307dvX9OrVy9z6623muPHjwdu0Jb5pHNYX19vbrjhBtOvXz/jcDjM8OHDTUFBgWlqagrswC0QZIwxlzIgAQAA+ItnWAAAgPUILAAAwHoEFgAAYD0CCwAAsB6BBQAAWI/AAgAArEdgAQAA1iOwAAAA6xFYAACA9QgsAADAegQWAABgPQILAACw3v8ByrfG1Q+l7zkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "013\n",
      "for seq ['014'] the next token is 013\n",
      "014 013 013 010 114 114 114 114 114 010 010 010 010 010 010 010 010 010 010 010 010 010 010 010 010 010 010 010 010 010 010\n"
     ]
    }
   ],
   "source": [
    "seq = ['014']\n",
    "mymodel.eval()\n",
    "x = mymodel(torch.tensor([tokenizer.encode(seq)]).to(device), False)\n",
    "probs = nn.functional.softmax(x, dim=-1)\n",
    "predi = torch.argmax(probs)\n",
    "\n",
    "see_proba(probs[0].tolist(), None)\n",
    "print(tokenizer.decode([predi.item()]))\n",
    "print(f'for seq {str(seq)} the next token is {tokenizer.decode([predi.item()])}')\n",
    "\n",
    "seq_gen = generate_sequence(mymodel, torch.tensor([tokenizer.encode(seq)]).to(device), context_lenght)\n",
    "\n",
    "print(tokenizer.decode(seq_gen[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input = ActionOutcomeAction\n",
    "# Output = ActionOutcomeAction**Outcome**\n",
    "# Word is Action and Outcome\n",
    "\n",
    "# All words\n",
    "def create_all_words_action_outcome(action:list, feedback:list):\n",
    "    return action + feedback\n",
    "\n",
    "def create_all_words_action_outcome_enumerate(action:list, feedback:list):\n",
    "    all_words = create_all_words_action_outcome(action, feedback)\n",
    "    return {word:integer for integer, word in enumerate(all_words)}\n",
    "\n",
    "# create_all_words_action_outcome([0, 1, 2, 3], ['A', 'B'])\n",
    "# create_all_words_action_outcome_enumerate([0, 1, 2, 3], ['A', 'B'])\n",
    "# tokenizer_act_ff = SimpleTokenizerV1(create_all_words_action_outcome_enumerate(['0', '1', '2', '3'], ['A', 'B']))\n",
    "# tempo = tokenizer_act_ff.encode(['0', 'A', '1', 'B'])\n",
    "# print(tempo)\n",
    "# print(tokenizer_act_ff.decode(tempo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 3, 2, 3], ['A', 'B']]\n"
     ]
    }
   ],
   "source": [
    "My_list = [[0, 1, 2, 3], ['A', 'B']]\n",
    "My_list[0]\n",
    "\n",
    "My_list[0] = [0, 3, 2, 3]\n",
    "print(My_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# [(0, 'x'), (1, 'x'), (1, 'x'), (1, 'x'), (1, 'x'), (1, 'x'), (1, 'x'), (1, 'x')]\n",
    "# [[0], [0, x, 1], []\n",
    "def inter_action_and_feedback_size(history:list, size:int):\n",
    "    \"\"\"\n",
    "    Transform history into input and target.\n",
    "    history is a sequence of action and feedback.\n",
    "    We want to have all sequence of size size, associate with the feedback of the last action (targets).\n",
    "    Exemple:\n",
    "    history = [('0', 'x'), ('1', 'y'), ('0', 'x'), ('1', 'y'), ('0', 'x'), ('1', 'y'), ('0', 'x')]\n",
    "    size = 5\n",
    "    inter_action_and_feedback_size(history, size) => \n",
    "    inputs = [['0', 'x', '1', 'y', '0'], \n",
    "    ['1', 'y', '0', 'x', '1'],\n",
    "    ['0', 'x', '1', 'y', '0'],\n",
    "    ['1', 'y', '0', 'x', '1'],\n",
    "    ['0', 'x', '1', 'y', '0']]\n",
    "\n",
    "    targets = ['x', 'y', 'x', 'y', 'x']\n",
    "\n",
    "    \"\"\"\n",
    "    inputs, targets = [], []\n",
    "    for act, ff in history:\n",
    "        if inputs:\n",
    "            temp = inputs[-1][-int(size - 2):] + [targets[-1], act]\n",
    "            inputs.append(temp)\n",
    "        else:\n",
    "            inputs.append([act])\n",
    "        targets.append(ff)\n",
    "    return inputs[size - 1:], targets[size- 1:]\n",
    "\n",
    "inputs, targets = inter_action_and_feedback_size([('0', 'x'), ('1', 'y'), ('0', 'x')], 5)\n",
    "print(inputs)\n",
    "print(targets)\n",
    "\n",
    "# print(create_all_words_action_outcome_enumerate(['0', '1'], ['x', 'y']))\n",
    "# tokenizer = SimpleTokenizerV1(create_all_words_action_outcome_enumerate(['0', '1'], ['x', 'y']))\n",
    "# print(targets)\n",
    "# print(tokenizer.encode(targets))\n",
    "\n",
    "# print(inputs)\n",
    "# for i, one_input in enumerate(inputs):\n",
    "#     inputs[i] = tokenizer.encode(inputs[i])\n",
    "\n",
    "# print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ax': 0, 'ay': 1, 'bx': 2, 'by': 3}\n"
     ]
    }
   ],
   "source": [
    "def create_all_words_by_env(env):\n",
    "    vocab = []\n",
    "    action = env.get_actions()\n",
    "    feedback = env.get_outcomes()\n",
    "    for act in action:\n",
    "        for ff in feedback:\n",
    "            vocab.append(str(act) + str(ff))\n",
    "    return vocab\n",
    "\n",
    "def create_all_words_by_env_enumerate(env):\n",
    "    all_words = create_all_words_by_env(env)\n",
    "    return {word:integer for integer, word in enumerate(all_words)}\n",
    "\n",
    "env = env2Str()\n",
    "tokenizer = create_all_words_by_env_enumerate(env)\n",
    "print(tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('b', 'y'), ('a', 'y'), ('a', 'x'), ('a', 'x'), ('a', 'x'), ('b', 'y'), ('a', 'y'), ('b', 'y'), ('b', 'x'), ('a', 'y'), ('b', 'y'), ('a', 'y'), ('a', 'x'), ('a', 'x'), ('b', 'y'), ('b', 'x'), ('a', 'y'), ('b', 'y'), ('a', 'y'), ('a', 'x'), ('a', 'x'), ('b', 'y'), ('b', 'x'), ('a', 'y'), ('b', 'y'), ('b', 'x'), ('b', 'x'), ('a', 'y'), ('a', 'x'), ('b', 'y'), ('a', 'y'), ('b', 'y'), ('b', 'x'), ('a', 'y'), ('b', 'y'), ('b', 'x'), ('a', 'y'), ('b', 'y'), ('a', 'y'), ('b', 'y'), ('b', 'x'), ('a', 'y'), ('a', 'x'), ('b', 'y'), ('a', 'y'), ('b', 'y'), ('b', 'x'), ('b', 'x'), ('b', 'x'), ('b', 'x'), ('b', 'x'), ('a', 'y'), ('a', 'x'), ('b', 'y'), ('a', 'y'), ('a', 'x'), ('a', 'x'), ('a', 'x'), ('a', 'x'), ('b', 'y'), ('a', 'y'), ('a', 'x'), ('a', 'x'), ('b', 'y'), ('b', 'x'), ('a', 'y'), ('a', 'x'), ('b', 'y'), ('b', 'x'), ('a', 'y'), ('a', 'x'), ('b', 'y'), ('b', 'x'), ('b', 'x'), ('a', 'y'), ('b', 'y'), ('b', 'x'), ('b', 'x'), ('a', 'y'), ('a', 'x'), ('a', 'x'), ('b', 'y'), ('a', 'y'), ('a', 'x'), ('a', 'x'), ('b', 'y'), ('b', 'x'), ('a', 'y'), ('a', 'x'), ('b', 'y'), ('b', 'x'), ('b', 'x'), ('a', 'y'), ('b', 'y'), ('a', 'y'), ('a', 'x'), ('a', 'x'), ('b', 'y'), ('b', 'x'), ('b', 'x')]\n",
      "for 0 iteration, loss is 1.43644118309021 and val_loss is 1.3468244075775146\n",
      "for 10 iteration, loss is 0.7949601411819458 and val_loss is 0.7774068713188171\n",
      "for 20 iteration, loss is 0.7050449252128601 and val_loss is 0.6957331895828247\n",
      "for 30 iteration, loss is 0.695939838886261 and val_loss is 0.6919463872909546\n",
      "for 40 iteration, loss is 0.6943978667259216 and val_loss is 0.6922072172164917\n",
      "for 50 iteration, loss is 0.693901538848877 and val_loss is 0.6900160312652588\n",
      "for 60 iteration, loss is 0.6936988830566406 and val_loss is 0.6891549825668335\n",
      "for 70 iteration, loss is 0.693562388420105 and val_loss is 0.6890366673469543\n",
      "for 80 iteration, loss is 0.6935064792633057 and val_loss is 0.6889138221740723\n",
      "for 90 iteration, loss is 0.6933038234710693 and val_loss is 0.6887503266334534\n",
      "for 100 iteration, loss is 0.6920182108879089 and val_loss is 0.6864984035491943\n",
      "for 110 iteration, loss is 0.6954120993614197 and val_loss is 0.6945668458938599\n",
      "for 120 iteration, loss is 0.6855844259262085 and val_loss is 0.6826308369636536\n",
      "for 130 iteration, loss is 0.6348549127578735 and val_loss is 0.7144378423690796\n",
      "for 140 iteration, loss is 0.3986685276031494 and val_loss is 0.5093022584915161\n",
      "for 150 iteration, loss is 0.33418983221054077 and val_loss is 0.25799649953842163\n",
      "for 160 iteration, loss is 0.24119441211223602 and val_loss is 0.22284796833992004\n",
      "for 170 iteration, loss is 0.489604651927948 and val_loss is 1.0783638954162598\n",
      "for 180 iteration, loss is 0.7186481952667236 and val_loss is 0.6868013739585876\n",
      "for 190 iteration, loss is 0.6805642247200012 and val_loss is 0.6824293732643127\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAaBRJREFUeJzt3Xd8VHW+//HXmUmvhJIGgQDSS6hyEV1RUEAXwXJllRVQ1Lsuuuuy3nX5KWBZy9oua18b6LqKZQVdQVhAUUSUGkBBBITQkkCA9D5zfn9MZkggPVOSyfv5eMwjZ05O+RyGkA/f8vkapmmaiIiIiPgJi68DEBEREXEnJTciIiLiV5TciIiIiF9RciMiIiJ+RcmNiIiI+BUlNyIiIuJXlNyIiIiIXwnwdQDeZrfbOXbsGJGRkRiG4etwREREpB5M0yQvL4/ExEQsltrbZlpdcnPs2DGSkpJ8HYaIiIg0wuHDh+nUqVOtx7S65CYyMhJw/OFERUX5OBoRERGpj9zcXJKSkly/x2vT6pIbZ1dUVFSUkhsREZEWpj5DSjSgWERERPyKkhsRERHxK0puRERExK+0ujE3IiLSdDabjbKyMl+HIX4mKCiozmne9aHkRkRE6s00TTIyMsjOzvZ1KOKHLBYLXbt2JSgoqEnXUXIjIiL15kxsYmNjCQsLUzFUcRtnkd309HQ6d+7cpL9bSm5ERKRebDabK7Fp166dr8MRP9ShQweOHTtGeXk5gYGBjb6OBhSLiEi9OMfYhIWF+TgS8VfO7iibzdak6yi5ERGRBlFXlHiKu/5uKbkRERERv6LkRkRERPyKkhsREZEGSk5OZsGCBb4OQ2qg5MZNTNPkRF4J+0/k+zoUERGpYBhGra8HHnigUdfdtGkTt99+e5NiGz16NHfffXeTriHV01RwN1n70wluXriJ3vGRrLj7F74OR0REgPT0dNf2e++9x7x589izZ49rX0REhGvbNE1sNhsBAXX/auzQoYN7AxW3UsuNm3Ru65gaefhUIaZp+jgaERHPM02TwtJyn7zq++9sfHy86xUdHY1hGK73P/74I5GRkXz22WcMHTqU4OBgvv76a/bv38+kSZOIi4sjIiKC4cOHs3r16irXPbtbyjAMXnvtNa6++mrCwsLo0aMHn3zySZP+fP/1r3/Rr18/goODSU5O5umnn67y/RdffJEePXoQEhJCXFwc1113net7H374IQMGDCA0NJR27doxduxYCgoKmhRPS6KWGzfp2CYUw4CCUhsnC0ppHxHs65BERDyqqMxG33krfXLvXQ+NIyzIPb/C/vznP/PUU0/RrVs3YmJiOHz4MFdccQWPPPIIwcHBvPXWW0ycOJE9e/bQuXPnGq/z4IMP8sQTT/Dkk0/y3HPPMXXqVNLS0mjbtm2DY9qyZQvXX389DzzwAFOmTOGbb77ht7/9Le3atWPGjBls3ryZ3/3ud/zjH//gggsu4NSpU6xbtw5wtFbdcMMNPPHEE1x99dXk5eWxbt26VvUfbyU3bhISaCU+KoT0nGIOnSpUciMi0kI89NBDXHbZZa73bdu2JSUlxfX+4YcfZsmSJXzyySfceeedNV5nxowZ3HDDDQA8+uijPPvss2zcuJHx48c3OKZnnnmGMWPGMHfuXAB69uzJrl27ePLJJ5kxYwaHDh0iPDycX/7yl0RGRtKlSxcGDx4MOJKb8vJyrrnmGrp06QLAgAEDGhxDS6bkxo2S2oaRnlPM4VOFDOkc4+twREQ8KjTQyq6Hxvns3u4ybNiwKu/z8/N54IEHWLZsmStRKCoq4tChQ7VeZ+DAga7t8PBwoqKiOH78eKNi2r17N5MmTaqyb9SoUSxYsACbzcZll11Gly5d6NatG+PHj2f8+PGuLrGUlBTGjBnDgAEDGDduHJdffjnXXXcdMTGt5/eSxty4UZeKcTeHThb6OBIREc8zDIOwoACfvNxZJTk8PLzK+3vuuYclS5bw6KOPsm7dOlJTUxkwYAClpaW1XufstZAMw8But7stzsoiIyPZunUr7777LgkJCcybN4+UlBSys7OxWq2sWrWKzz77jL59+/Lcc8/Rq1cvDhw44JFYmiMlN27kHFR86JSSGxGRlmr9+vXMmDGDq6++mgEDBhAfH8/Bgwe9GkOfPn1Yv379OXH17NkTq9XRahUQEMDYsWN54okn2LFjBwcPHuTzzz8HHInVqFGjePDBB9m2bRtBQUEsWbLEq8/gSz7tlvrqq6948skn2bJlC+np6SxZsoTJkyfX69z169dz8cUX079/f1JTUz0aZ311budIbtKU3IiItFg9evTgo48+YuLEiRiGwdy5cz3WAnPixIlzfoclJCTwxz/+keHDh/Pwww8zZcoUNmzYwPPPP8+LL74IwKeffsrPP//ML37xC2JiYli+fDl2u51evXrx3XffsWbNGi6//HJiY2P57rvvOHHiBH369PHIMzRHPm25KSgoICUlhRdeeKFB52VnZzNt2jTGjBnjocgaJ6nSdHAREWmZnnnmGWJiYrjggguYOHEi48aNY8iQIR651zvvvMPgwYOrvF599VWGDBnC+++/z+LFi+nfvz/z5s3joYceYsaMGQC0adOGjz76iEsvvZQ+ffrw8ssv8+6779KvXz+ioqL46quvuOKKK+jZsyf3338/Tz/9NBMmTPDIMzRHhtlM5oYZhlHvlptf/epX9OjRA6vVytKlSxvUcpObm0t0dDQ5OTlERUU1PuBqZOWXMOwvqzEM2P3QeELcOOBNRMTXiouLOXDgAF27diUkJMTX4Ygfqu3vWEN+f7e4MTcLFy7k559/Zv78+fU6vqSkhNzc3CovT2kXHkR4kBXThKPZRR67j4iIiNSsRSU3e/fu5c9//jNvv/12vcpjAzz22GNER0e7XklJSR6LzzAMV9eUZkyJiIj4RotJbmw2GzfeeCMPPvggPXv2rPd5c+bMIScnx/U6fPiwB6PUjCkRERFfazFF/PLy8ti8eTPbtm1zVYi02+2YpklAQAD/+c9/uPTSS885Lzg4mOBg71ULVnIjIiLiWy0muYmKimLnzp1V9r344ot8/vnnfPjhh3Tt2tVHkVXlnA6u5EZERMQ3fJrc5Ofns2/fPtf7AwcOkJqaStu2bencuTNz5szh6NGjvPXWW1gsFvr371/l/NjYWEJCQs7Z70udNR1cRETEp3ya3GzevJlLLrnE9X727NkATJ8+nUWLFpGenl7nWh7NTeVuKdM03VoiXEREROrWbOrceIsn69wAlJTb6D13BaYJm+4bS4dIrQ4uIv5BdW7E01ptnZvmLjjASkKU4wPRuBsREf8wevRo7r77btf75ORkFixYUOs5hmGwdOnSJt/bXddpTZTceIBzULHG3YiI+NbEiRMZP358td9bt24dhmGwY8eOBl9306ZN3H777U0Nr4oHHniAQYMGnbM/PT3d40snLFq0iDZt2nj0Ht6k5MYDNB1cRKR5mDlzJqtWreLIkSPnfG/hwoUMGzaMgQMHNvi6HTp0ICwszB0h1ik+Pt6rJU38gZIbD3AmN2mqUiwi4lO//OUv6dChA4sWLaqyPz8/nw8++ICZM2dy8uRJbrjhBjp27EhYWBgDBgzg3XffrfW6Z3dL7d27l1/84heEhITQt29fVq1adc459957Lz179iQsLIxu3boxd+5cysrKAEfLyYMPPsj27dsxDAPDMFwxn90ttXPnTi699FJCQ0Np164dt99+O/n5+a7vz5gxg8mTJ/PUU0+RkJBAu3btmDVrlutejXHo0CEmTZpEREQEUVFRXH/99WRmZrq+v337di655BIiIyOJiopi6NChbN68GYC0tDQmTpxITEwM4eHh9OvXj+XLlzc6lvpoMXVuWhKtDi4irYJpQpmP/p0LDIN6zEYNCAhg2rRpLFq0iPvuu881g/WDDz7AZrNxww03kJ+fz9ChQ7n33nuJiopi2bJl3HTTTXTv3p3zzz+/znvY7XauueYa4uLi+O6778jJyakyPscpMjKSRYsWkZiYyM6dO7ntttuIjIzkT3/6E1OmTOH7779nxYoVrF69GoDo6OhzrlFQUMC4ceMYOXIkmzZt4vjx49x6663ceeedVRK4L774goSEBL744gv27dvHlClTGDRoELfddludz1Pd8zkTmy+//JLy8nJmzZrFlClTWLt2LQBTp05l8ODBvPTSS1itVlJTUwkMDARg1qxZlJaW8tVXXxEeHs6uXbuIiIhocBwNoeTGA9QtJSKtQlkhPJrom3v/v2MQFF6vQ2+55RaefPJJvvzyS0aPHg04uqSuvfZa17qD99xzj+v4u+66i5UrV/L+++/XK7lZvXo1P/74IytXriQx0fHn8eijj54zTub+++93bScnJ3PPPfewePFi/vSnPxEaGkpERAQBAQHEx8fXeK933nmH4uJi3nrrLcLDHc///PPPM3HiRP76178SFxcHQExMDM8//zxWq5XevXtz5ZVXsmbNmkYlN2vWrGHnzp0cOHDAtT7jW2+9Rb9+/di0aRPDhw/n0KFD/O///i+9e/cGoEePHq7zDx06xLXXXsuAAQMA6NatW4NjaCh1S7lLUTbsWwN7VtClneMvXEZuMcVlNt/GJSLSyvXu3ZsLLriAN954A4B9+/axbt06Zs6cCTjWLnz44YcZMGAAbdu2JSIigpUrV9a7ztru3btJSkpyJTYAI0eOPOe49957j1GjRhEfH09ERAT3339/g2u57d69m5SUFFdiAzBq1Cjsdjt79uxx7evXrx9Wq9X1PiEhgePHjzfoXpXvmZSUVGXh6b59+9KmTRt2794NOOrU3XrrrYwdO5bHH3+c/fv3u4793e9+x1/+8hdGjRrF/PnzGzWAu6HUcuMux7bC29dA+57EzBpHRHAA+SXlHDldxHmxnm1+ExHxicAwRwuKr+7dADNnzuSuu+7ihRdeYOHChXTv3p2LL74YgCeffJK//e1vLFiwgAEDBhAeHs7dd99NaWmp28LdsGEDU6dO5cEHH2TcuHFER0ezePFinn76abfdozJnl5CTYRjY7XaP3AscM71uvPFGli1bxmeffcb8+fNZvHgxV199Nbfeeivjxo1j2bJl/Oc//+Gxxx7j6aef5q677vJYPGq5cZd25zm+njqAYbe5xt0cOlXgw6BERDzIMBxdQ754NbD6+/XXX4/FYuGdd97hrbfe4pZbbnGNv1m/fj2TJk3i17/+NSkpKXTr1o2ffvqp3tfu06cPhw8fJj093bXv22+/rXLMN998Q5cuXbjvvvsYNmwYPXr0IC0trcoxQUFB2Gy1t/b36dOH7du3U1Bw5nfL+vXrsVgs9OrVq94xN4Tz+Q4fPuzat2vXLrKzs+nbt69rX8+ePfnDH/7Af/7zH6655hoWLlzo+l5SUhK/+c1v+Oijj/jjH//Iq6++6pFYnZTcuEtUJwgIBXsZZKfRuW0oAIc0Y0pExOciIiKYMmUKc+bMIT09nRkzZri+16NHD1atWsU333zD7t27+Z//+Z8qM4HqMnbsWHr27Mn06dPZvn0769at47777qtyTI8ePTh06BCLFy9m//79PPvssyxZsqTKMcnJya41FrOysigpKTnnXlOnTiUkJITp06fz/fff88UXX3DXXXdx0003ucbbNJbNZiM1NbXKa/fu3YwdO5YBAwYwdepUtm7dysaNG5k2bRoXX3wxw4YNo6ioiDvvvJO1a9eSlpbG+vXr2bRpE3369AHg7rvvZuXKlRw4cICtW7fyxRdfuL7nKUpu3MVigXbdHdsn91UaVFzkw6BERMRp5syZnD59mnHjxlUZH3P//fczZMgQxo0bx+jRo4mPj2fy5Mn1vq7FYmHJkiUUFRVx/vnnc+utt/LII49UOeaqq67iD3/4A3feeSeDBg3im2++Ye7cuVWOufbaaxk/fjyXXHIJHTp0qHY6elhYGCtXruTUqVMMHz6c6667jjFjxvD888837A+jGvn5+QwePLjKa+LEiRiGwccff0xMTAy/+MUvGDt2LN26deO9994DwGq1cvLkSaZNm0bPnj25/vrrmTBhAg8++CDgSJpmzZpFnz59GD9+PD179uTFF19scry10dpS7vT+NNj1MVz+CP+wTGTu0u8Z2yeO16YPc+99RER8QGtLiadpbanmqF3F1LdKLTeqdSMiIuJdSm7cyTmouEq3VCGtrHFMRETEp5TcuFP7My03HduEYhhQVGbjRP65g8JERETEM5TcuJNzQHFeOkG2AhKjHTOm1DUlIiLiPUpu3Ck0BsLaO7ZP7tcyDCLil9TVLp7irr9bSm7crbpxNyc1HVxEWj5n1dvCQv2HTTzDWRW68tIRjaHlF9yt/Xlw+FtHctNuEABpqlIsIn7AarXSpk0b1xpFYWFhriq/Ik1lt9s5ceIEYWFhBAQ0LT1RcuNuzpabrL0k9dB0cBHxL84Vqxu7CKNIbSwWC507d25y0qzkxt0q1brpMkJjbkTEvxiGQUJCArGxsZSVlfk6HPEzQUFBWCxNHzGj5MbdKo+5iXHMlsrMLaG4zEZIYNP6EEVEmgur1drkcREinqIBxe7WtisYFijNp439FJHBjvxRXVMiIiLeoeTG3QKCoU0XAIyT+0jSdHARERGvUnLjCa6uqb2qdSMiIuJlSm48wbUMw366tFNyIyIi4k1KbjzBuQxD1l5Xt5TG3IiIiHiHkhtPqDQd3NktlXZSyY2IiIg3KLnxBOeYm9MH6RztmC116FSh1mMRERHxAiU3nhCVCIFhYNpI5DgWA0rK7ZzIK/F1ZCIiIn5PyY0nGIZr3E3Q6f0ktnEU89OgYhEREc9TcuMp1Yy7UXIjIiLieUpuPKWaWjcaVCwiIuJ5Sm48pVKtG00HFxER8R4lN55SqdaNuqVERES8R8mNpzi7pQqO0zWyHFByIyIi4g1KbjwlJBrCYwHoYqYDcDyvhKJSmy+jEhER8XtKbjypYtxNRP5BIkMcxfwOn1brjYiIiCcpufGkiq4po/J0cM2YEhER8SglN55UzXRwjbsRERHxLCU3ntS+UiG/dkpuREREvEHJjSe5Wm720zkmBFCtGxEREU9TcuNJMclgWKGskPNC8wBIU3IjIiLiUUpuPMka6EhwgGTzGOBoubHbTR8GJSIi4t+U3Hhaxbib9iWHsVoMSsrtnMgv8XFQIiIi/sunyc1XX33FxIkTSUxMxDAMli5dWuvxH330EZdddhkdOnQgKiqKkSNHsnLlSu8E21gV426sp/aT2MYx7kaDikVERDzHp8lNQUEBKSkpvPDCC/U6/quvvuKyyy5j+fLlbNmyhUsuuYSJEyeybds2D0faBK5Bxap1IyIi4g0Bvrz5hAkTmDBhQr2PX7BgQZX3jz76KB9//DH//ve/GTx4cLXnlJSUUFJyphsoNze3UbE2WuVaN0lhrOekBhWLiIh4UIsec2O328nLy6Nt27Y1HvPYY48RHR3teiUlJXkxQs7Uusk+RJc2FUswKLkRERHxmBad3Dz11FPk5+dz/fXX13jMnDlzyMnJcb0OHz7sxQiBiDgIigDTTp+gk4DG3IiIiHiST7ulmuKdd97hwQcf5OOPPyY2NrbG44KDgwkODvZiZGcxDEfXVHoqyaQD4UpuREREPKhFttwsXryYW2+9lffff5+xY8f6Opy6VXRNxZY5Wo1O5JVQVGrzZUQiIiJ+q8UlN++++y4333wz7777LldeeaWvw6mfikHFobk/ExXiaCxT642IiIhn+DS5yc/PJzU1ldTUVAAOHDhAamoqhw4dAhzjZaZNm+Y6/p133mHatGk8/fTTjBgxgoyMDDIyMsjJyfFF+PXnnDGVpQU0RUREPM2nyc3mzZsZPHiwaxr37NmzGTx4MPPmzQMgPT3dlegAvPLKK5SXlzNr1iwSEhJcr9///vc+ib/eKk0H79I2HFByIyIi4ik+HVA8evRoTLPmdZYWLVpU5f3atWs9G5CnOJObwpP0iCoDNB1cRETEU1rcmJsWKTgCIhMA6BN4HIC0kwW+jEhERMRvKbnxlorWm65GOqBuKREREU9RcuMtFclNXMV08MOni7Dba+6SExERkcZRcuMtFbVuIgvSsFoMSsvtHM8rqeMkERERaSglN95S0XJjObmPjm1CAXVNiYiIeIKSG29xzpg6tZ8uMSGABhWLiIh4gpIbb2nTBSyBUF5M/8h8QNPBRUREPEHJjbdYA6BtVwD6BTumg6tbSkRExP2U3HhTO8eg4q4cA5TciIiIeIKSG29q1x2A+PIjABw6VeTLaERERPySkhtvqpgOHlWQBkBWfgkFJeW+jEhERMTvKLnxpooZU4HZ+4kODQTg8Gl1TYmIiLiTkhtvqhhzQ/ZherS1AnDopJIbERERd1Jy403h7SE4GjAZHHEa0KBiERERd1Ny402GAe0dXVN9gxzTwVXrRkRExL2U3HhbxbibbhWrg6cpuREREXErJTfeVjHu5sx0cCU3IiIi7qTkxtsqat20KXRMBz9yqgi73fRlRCIiIn5FyY23VdS6Ccr5mQCLQanNTmZesY+DEhER8R9KbrytbTcAjKLT9G1TBmg6uIiIiDspufG2oHCI6gTAsIiTgAYVi4iIuJOSG1+oGHfTN1jTwUVERNxNyY0vVIy76W5kAJoxJSIi4k5KbnyhYjp4gqaDi4iIuJ2SG1+oKOTXpsgxHVzdUiIiIu6j5MYXKpZgCM5Nw4KdrPxS8kvKfRyUiIg0C189BQsGQM4RX0fSYim58YXoJLAGY9hK6B2aDaj1RkREKuz8ELIPwe5PfR1Ji6XkxhcsVle9m/MjHdPBNe5GREQAyHdMNuHIJt/G0YIpufGViung/TUdXEREnMqKoei0Y1vJTaMpufGViung3SyODD1NVYpFRMTZagOQnQb5x30XSwum5MZXKmZMJWo6uIiIOOVlVn1/ZLNv4mjhlNz4SkWtm5iiQ4C6pUREBMhLr/peXVONouTGVypaboIL0wmlmCOni7DZTR8HJSIiPpVf0XJjWB1fldw0ipIbXwlvB6ExAHS3HqfUZiczt9jHQYmIiE85W266XOD4enQr2G2+i6eFUnLjSxWtN8MisgANKhYRafXyKgYUd7sYgiKhrACO7/ZtTC2Qkhtfqhh30z/4BKBxNyIirZ4zuYnqBB2HOLbVNdVgSm58qWIZhvOsWh1cREQ4k9xExkGn4Y5tzZhqMCU3vuScDm47Cii5ERFp9ZxjbiITKiU3arlpqABfB9CquaaDpwGmkhsRkdasrBiKsx3bkfEQ3sGxnbUHirIhtI2PAmt51HLjS227AgaBZXm0I1fJjYhIa+asTmwNhpA2EN7etQ4hR7f4LKyWSMmNLwWGQpskALoZ6ZwqKCWvuMzHQYmIiE+4xtvEg2E4tjXuplGU3Phaxbib/iHOGVNFvoxGRER8pXJy46RxN42i5MbXKsbdDAhxLI6mrikRkVaq2uRmmOPrkU1gqop9fSm58bV2VaeDq9aNiEgrVXmmlFNcfwgIcQw0PrnfJ2G1RD5Nbr766ismTpxIYmIihmGwdOnSOs9Zu3YtQ4YMITg4mPPOO49FixZ5PE6Pqqh107FiOnjaqQJfRiMiIr7iXFcqIu7MPmsgJA52bKtrqt58mtwUFBSQkpLCCy+8UK/jDxw4wJVXXskll1xCamoqd999N7feeisrV670cKQeVNFy06b4CFZsHNKYGxGR1qm6lhuo2jUl9eLTOjcTJkxgwoQJ9T7+5ZdfpmvXrjz99NMA9OnTh6+//pr/+7//Y9y4cZ4K07OiOkFACNbyYjoZJzh8KsrXEYmIiC9UN+YGNKi4EVrUmJsNGzYwduzYKvvGjRvHhg0bajynpKSE3NzcKq9mxWKBtt0Bx3TwI6cLsdk1aExEpNWpK7nJ/AFKNXShPlpUcpORkUFcXFyVfXFxceTm5lJUVH13zmOPPUZ0dLTrlZSU5I1QG6bSGlNlNpOM3GIfByQiIl5VVlS1OnFlUYkQ1RFMGxxL9XZkLVKLSm4aY86cOeTk5Lhehw8f9nVI53JOBw92TAdPO6nMXESkVXEOJg4IcVQnPptr3M1Gr4XUkrWo5CY+Pp7MzMwq+zIzM4mKiiI0NLTac4KDg4mKiqryanZc08Edz6bp4CIirYyzSyoi7kx14spUqbhBWlRyM3LkSNasWVNl36pVqxg5cqSPInKT9o6Wm072I4AK+YmItDo1zZRyqjyoWMX86uTT5CY/P5/U1FRSU1MBx1Tv1NRUDh06BDi6lKZNm+Y6/je/+Q0///wzf/rTn/jxxx958cUXef/99/nDH/7gi/Ddp51jQHFUWRZhFGs6uIhIa5NX0Stx9ngbp4QUsAQ4uq9ymuHwimbGp8nN5s2bGTx4MIMHOwoUzZ49m8GDBzNv3jwA0tPTXYkOQNeuXVm2bBmrVq0iJSWFp59+mtdee63lTgN3Co2BsPYAdDXS1XIjItLauFpuakhuAkMhfoBjW1PC6+TTOjejR4/GrKV5rbrqw6NHj2bbtm0ejMpH2p0HhVl0M9L5+mRPX0cjIiLeVNM08Mo6DYdj2xzjbvpf6524WqgWNebGr1VMB+9mpHO6sIzc4jIfByQiIl6T70xuahhzAyrm1wBKbpqLihlTvYM0Y0pEpNWpPFuqJs7p4OnbobzE8zG1YEpumouKWjc9tDq4iEjrU9dsKYCYrhDWDmylkLHTO3G1UEpumouKlptOtqOAqUHFIiKtRVkRFOc4tiNrabkxDHVN1ZOSm+aibVcwLISYRXQgm7STSm5ERFoFZ5dUTdWJK9MK4fWi5Ka5CAiGNp0B6G7RdHARkVaj8kyp6qoTV6aWm3pRctOcVIy76Wqka8yNiEhr4ZwpFVHLNHCnxCGAAdmHzhT+k3MouWlO2p2ZDn7kdBE2u0psi4j4vfrUuHEKiYLYvo7to1pnqiZKbpqTilo33S0ZlNtNjmVrGQYREb9Xn5lSlWncTZ2U3DQnmg4uItL6uNaVqmWmVGVaIbxOSm6ak4puqUQzgwDKNahYRKQ1aHDLTUVyc3Qr2Mo9E1MLp+SmOYlKhMAwrNjpbBxXciMi0hrk17Ei+Nna94TgKCgrgBO7PRdXC6bkpjkxDGjXHdDq4CIirYaz5aY+s6UALBboONSxrXE31VJy09xUjLvppuRGRMT/ValOXM/kBjTupg5KbpqbinE3arkREWkFXNWJQyEkuv7nqZhfrZTcNDftHS033S3pZBeWkVNU5uOARETEY1w1buLqrk5cmXM6eNZPUHTa/XG1cEpumpuKMTfdLZoOLiLi9xo6U8oprC20dfy+4MgW98bkB5TcNDcV3VLtySaCQiU3IiL+rKEzpSpT11SNlNw0NyHREB4LOAYVpym5ERHxXw2dKVWZKhXXSMlNc9T+zAKaGlQsIuLHGrKu1Nlcxfw2g93uvpj8gJKb5qhi3E03i1YHFxHxa67kpoFjbgDi+jlmWRXnwMl97o2rhVNy0xyp1o2ISOtQebZUQ1kDIXGwY1tdU1UouWmO2p9Jbo6eLqLcpuZGERG/1JSWG9C4mxoouWmOXIX8Mii320nPKfZxQCIi4nalhVBSUZ04ohEtN6BKxTVQctMcxSSDYSXMKCGeU+qaEhHxR/mNrE5cmTO5Of4DlOS7Jy4/oOSmObIGOhIcoKslQ8mNiIg/qjxTqiHViSuLSoCoTmDa4dg298XWwim5aa6cyzAYx5TciIj4o6ZMA69M427OoeSmuao07kbJjYiIH3JbcqNxN2dTctNcVSQ33YxjHDqp5EZExO/kN3GmlFPlZRhMs2nX8hONSm4OHz7MkSNHXO83btzI3XffzSuvvOK2wFo9tdyIiPg3Z8tNY2dKOSWkgCUQCo5D9qGmx+UHGpXc3HjjjXzxxRcAZGRkcNlll7Fx40buu+8+HnroIbcG2GpVjLlJMo5TVFRITmGZjwMSERG3auyK4GcLDIGEgY5tjbsBGpncfP/995x//vkAvP/++/Tv359vvvmGf/7znyxatMid8bVeEXEQFIHVMEkyjnP4tFpvRET8Sl4TVgQ/m8bdVNGo5KasrIzg4GAAVq9ezVVXXQVA7969SU9Pd190rZlhuLqmNGNKRMQPuWtAMVQddyONS2769evHyy+/zLp161i1ahXjx48H4NixY7Rr186tAbZqrkHF6aRpULGIiP+oXJ3YLclNxXTwjB1QXtL067VwjUpu/vrXv/L3v/+d0aNHc8MNN5CSkgLAJ5984uquEjeoGHejQcUiIn7GOVMqMAyCo5p+vTZdILwD2EohfUfTr9fCBTTmpNGjR5OVlUVubi4xMTGu/bfffjthYWFuC67Vc7bcWI7xbyU3IiL+o/JMqcZWJ67MMBxdU3uWO7qmkoY3/ZotWKNaboqKiigpKXElNmlpaSxYsIA9e/YQGxvr1gBbNU0HFxHxT+6aKVWZKhW7NCq5mTRpEm+99RYA2dnZjBgxgqeffprJkyfz0ksvuTXAVq0iuWlv5JKXfYJym93HAYmIiFu4c6aUk2ZMuTQqudm6dSsXXXQRAB9++CFxcXGkpaXx1ltv8eyzz7o1wFYtOAKzIqvvYqZzLLvYxwGJiIhbuFpu3JjcJA4GwwI5h850e7VSjUpuCgsLiYyMBOA///kP11xzDRaLhf/6r/8iLS3NrQG2dkblZRjUNSUi4h/cOQ3cKTgSYvs6tlt511SjkpvzzjuPpUuXcvjwYVauXMnll18OwPHjx4mKcsOobznDOe7GonE3IiJ+wzlbKsKNyQ1o3E2FRiU38+bN45577iE5OZnzzz+fkSNHAo5WnMGDB7s1wFavYjq4Wm5ERPyIJ1puQONuKjRqKvh1113HhRdeSHp6uqvGDcCYMWO4+uqr3RacUKmQXwbLThX4OBgREXEL14BiN86WgjPJzdGtYCsHa6N+zbd4jX7q+Ph44uPjXauDd+rUSQX8PKEiuUk2Mjh8Mt/HwYiISJOVFlSqTtzEFcHP1q4HBEc7rn/8B8eK4a1Qo7ql7HY7Dz30ENHR0XTp0oUuXbrQpk0bHn74Yex2TVd2qzZdMC2BhBqllJw64utoRESkqfLcXJ24MosFOg11bLficTeNSm7uu+8+nn/+eR5//HG2bdvGtm3bePTRR3nuueeYO3dug671wgsvkJycTEhICCNGjGDjxo21Hr9gwQJ69epFaGgoSUlJ/OEPf6C42I+nSFsDMGOSAYgtPUxOYZlv4xERkabJr1Tjxh3Vic+mcTeN65Z68803ee2111yrgQMMHDiQjh078tvf/pZHHnmkXtd57733mD17Ni+//DIjRoxgwYIFjBs3rsZKx++88w5//vOfeeONN7jgggv46aefmDFjBoZh8MwzzzTmUVoES/secHIvXY10Dp0qZEBYtK9DEhGRxnLWuHH3TCknrRDeuJabU6dO0bt373P29+7dm1OnTtX7Os888wy33XYbN998M3379uXll18mLCyMN954o9rjv/nmG0aNGsWNN95IcnIyl19+OTfccEOtrT0lJSXk5uZWebU4lVcH16BiEZGWzVMzpZw6VnRLndwHhfX/nexPGpXcpKSk8Pzzz5+z//nnn2fgwIH1ukZpaSlbtmxh7NixZ4KxWBg7diwbNmyo9pwLLriALVu2uJKZn3/+meXLl3PFFVfUeJ/HHnuM6Oho1yspKale8TUrFdPBu2s6uIhIy+dKbtw8U8oprK3rP8Uc3eKZezRzjeqWeuKJJ7jyyitZvXq1q8bNhg0bOHz4MMuXL6/XNbKysrDZbMTFVR0pHhcXx48//ljtOTfeeCNZWVlceOGFmKZJeXk5v/nNb/h//+//1XifOXPmMHv2bNf73NzclpfgVFpA876Nh7hmcCfio0N8HJSIiDSKK7lx80ypyjoNd7TcHNkEPS7z3H2aqUa13Fx88cX89NNPXH311WRnZ5Odnc0111zDDz/8wD/+8Q93x+iydu1aHn30UV588UW2bt3KRx99xLJly3j44YdrPCc4OJioqKgqrxannaPlpqMli+Oncpj62rdk5Zf4OCgREWkUT6wIfrZWXqm40XVuEhMTzxk4vH37dl5//XVeeeWVOs9v3749VquVzMzMKvszMzOJj6++H3Lu3LncdNNN3HrrrQAMGDCAgoICbr/9du677z4slkblas1feHsIjsZSksPwyNN8fSKIm17fyOLb/ovosEBfRyciIg2R74EVwc/mGlS8Bex2xxTxVsRnTxsUFMTQoUNZs2aNa5/dbmfNmjWurq6zFRYWnpPAWK1WAEzT9FywvmYY0N7RNfX0mAjaRwSzOz2X6Qs3kl9S7uPgRESkQfI8tK5UZbH9HHV0SnLg5F7P3aeZ8mkqN3v2bF599VXefPNNdu/ezR133EFBQQE333wzANOmTWPOnDmu4ydOnMhLL73E4sWLOXDgAKtWrWLu3LlMnDjRleT4rYpxN3Glafzz1hG0CQsk9XA2MxdtoqjU5uPgRESkXkoLoKRi1q4nW26sAZA4xLHdCrumfLroxJQpUzhx4gTz5s0jIyODQYMGsWLFCtcg40OHDlVpqbn//vsxDIP777+fo0eP0qFDByZOnFjvujotWvxA2PEefP03enW+gH/cMoIbX/2W7w6c4jdvb+GVaUMJDvDzBE9EpKVzVScOh+BIz96r0zBI+9qR3Az+tWfv1cwYZgP6c6655ppav5+dnc2XX36JzdZ8WxJyc3OJjo4mJyenZQ0uLi2Ad6bAwXUQEAq/+iebAgYz7fWNFJXZGN8vnudvHEyAtXX1q4qItCgH18OiK6BtN/jdNs/ea/en8N5UiOsPd6z37L28oCG/vxv0m7ByvZjqXl26dGHatGlNCl5qEBQOUz+AHpdDeRG8+yuGF33Dq9OGEWS1sOKHDP73wx3Y7X489khEpKXzxkwpJ+eMqeO7oCTP8/drRhrULbVw4UJPxSH1ERgKU/4JH90Kuz6G96dx4dV/58Wpv+A3b29hybajhAZZeWRyfwxPrFciIiJN442ZUk6R8RDdGXIOwbFt0PUXnr9nM6E+jJYmIAiufQNSbgTTBh/dxtiiz/i/KYMwDHjnu0M8smy3f88eExFpqTy9rtTZWmm9GyU3LZE1ACa9AMNmAib8+/dMLFzKX69xLH3x2tcHWLC69U39ExFp9vK82HIDrXaFcCU3LZXFAlc+DRf8zvF+5RyuL1rMA7/sA8Df1uzl71/u92GAIiJyDteYG28nN5ugFbXoK7lpyQwDLnsILrnP8f7zvzCj6E3+NK4nAI999iP/2HDQd/GJiEhVnl4R/GwJA8EaBAUn4PRB79yzGVBy09IZBlz8J7i8otbP+gX8tvDv3Dm6GwBzP/6BD7cc8WGAIiLi4hpQ7IXZUgABwY46adCquqaU3PiLC+6EXy4ADNj0Kn8sfpZbLnCsfv6nD7ezfGe6T8MTEWn1SvLPVCeO8OCK4Ger3DXVSii58SfDboar/w6GFSP1HeaWPMPUofHYTfjdu9v4/MfMuq8hIiKe4Wy18UZ14spa4YwpJTf+JmUKXP8mWAIxfljCX0r/yrUD21FuN/nN21v5Zl+WryMUEWmdKo+38WYtMmfLTcYOKCvy3n19SMmNP+ozEW5YDAEhGHtX8mTpI0zsHUVpuZ1b39rMlrTTvo5QRKT18fZMKac2nSE8FuzlkL7Du/f2ESU3/qrHWPj1vyAoAsvBr/hb+UOM6x5CYamNGQs38v3RHF9HKCLSunh7ppSTYbS6cTdKbvxZ8oUw7WMIicZyZCMvlT/AmM5W8orLmfbGRvZmtq61RkREfCrfmdx4aaZUZa1s3I2SG3/XaRjMWAZh7bFk7uAV+zwuSSjnVEEpU1/7joNZBb6OUESkdXC23HhzppRTpUrFezLy2HzwlF8v06PkpjWIHwC3rIDIRKxZe3jNnMcvYos4nlfC1Ne+42h26xhgJiINUFoI2Yd8HYV/yfNhy03iYDAskHuE/3nx31z38gYm/G0d728+TEm5zfvxeJiSm9aifQ+45TNo0wVr9kEWmvP4RdtsjmYX8evXvuN4XrGvIxQRXzNNOLgePp4FT/WEBQPgp5W+jsp/+GrMDUBwBMT2A6BX+R4AfszI408f7mDU41/w7Jq9nMwv8X5cHqLkpjWJSXa04LTviTXvKAuZzy+ij3Mgq4CbXtvI6YJSX0coIr5w6gB88Rj8LQUWXQHb3obSijF56//m29j8iS+TG3CNuxls2ccfL+vJnAm9SYgOISu/hGdW/cQFj3/OnI92+MV4TMP05063auTm5hIdHU1OTg5RUVG+Dsc38k/A21dDxk5sITHcUv5nvsxPond8JOP6xRMfHUJ8VAhxUSHER4cQExaI4c2aDCLiecW5sGsppL4Lh745sz8oEvpNgh7j4IMZYNrgjm8grp+vIvUPJfnwWEfH9pwj3i3iV+HoF6/R8cs/ssnem/PuXUdMeBBlNjvLd6bz+tcH2HHkzCza0b06MPPCrlx4Xvtm8+9/Q35/B3gpJmlOIjrA9H/D29dhPbqZhYEPc2vYvXye0Z0fM87N2IMCLMRHVSQ80SHERwUTFxVCQnQo8dGO7djIEIIC1BAo0qzZbfDzWtj+Luz+FMqd4+0M6DYaBt0IvX8JQWGO3b2vhN2fwKbX4Jf/56Og/YSzOnFQhE8SG4CPT3bkt0CK9QBBIY6EJdBqYdKgjlyVksjmtNO8tu5n/rMrk7V7TrB2zwl6x0dyy4VdmTQokeAAq0/ibgy13LRmJXnw7g1wcB32gBA+6f0k3xmDyMwrISOnmMzcYk42oKuqfUSQo7WnosXnTDLkeN8mNJAAqwWrxSDQahBgsRBgMbBYmsf/CkT81ok9kPoO7Hgf8o6d2d++J6TcAAOnQHTHc8878BW8OdGxXMAfd0NItPdi9jcHv4ZFV0Lb7vC7rV6/fZnNzshHVrHadjNtjAK4/UtIHFTtsWknC1i4/iDvbz5MYaljsHH7iGCmjezC1BGdaRcR7MXIz2jI728lN61dWRG8dxPsW1Wxw4DAMAgKh6Aw7IFhlFnCKDaCKSKEfDOYnPJAsssDOVUWSFZJACdKrOTZgygwQygkmCIzhAKCKSKYQtd2CGUEACYGJobrbiZWwyTQYiHAahBggUCLQaCFiiTIQqAVAiwQYLEQaIEAi1FxbEWSZDj2mZYA7NZA7ARiWAwMw8BigAFYDMd7w6Bin4HF4ojAYlCx38CASsc53lssjq/OoA0MV+V013NUXNO5Xfl7GEaV42q7BhX3P1vl887dV/V95ePq25pcV7NzXZepHIvzWlXic+6j7j8D48wftOt6ziQ4wGJgrfLVgqXi70aV/VYDq3HmGKv1zPeshlHlvWlCcZmNwlIbRWU2ikptFJed2S4qs1X5frHzuDIbRaV2bCWFBBZnEVxygvDSk0SUniSi/BTR9lPE2E5Tag0hOySJ4sgumDFdCepwHm1jE0loE0Zim1DahQd5JsEvPAXf/8uR1Byr9Ms0pA0MuA5SboSOQ2r/S2Ka8OJ/wYkfYcITMOJ/3B9na7HzQ/jXTOhyIdy8zOu3X7Urk9ve2sw/Q59glJkKVzwF599W6zk5RWUs3niIRd8cJD3HMekkOMDCNUM6csuorvSI824LlLqlpP4CQ+FX78And8KO9wATygocrwLHiPPgileN/2ezVrzcxV7xaoISM4AyAiil4qsZSGnl9wRSZga49pWeta+MAEoIrDjX8d6GBTsGdizYsVS8d+yzYcHEwGaeOaby953vzYpjqzu+MrNSOlF1u/7HmFVSktqvUdc96hNDdcefHUtN+53xOf+rVfl4E1yfmfOzMj08F8KCnbbkEWucpoORQwcjmw44viYZ2Y59OL5GGYU1X8jA8Xe5sOKVCfwI+WYIh8w4NplxHCGe7NBOFEd2gZhuhLVPIiEmjMToUBLbhJLQJoSokMD6BW4rg72rYPs7sGcF2MsqHigAzrsMBt0APcdDQD3/520YMPxWWH6Po2vq/Nu9uyaSP3ENJvZBjRvgX1uOAFCeMAyOpcKRzXUmN9GhgfzPxd255cKufPZ9Bq+t+5kdR3J4d+Nh3t14mIt7duDWi5rXuBwntdzIGSX5UFqR2JQWOOpclFV8de0/a7usEErza9iuuI7zH1gRNynHShmBlBmOBLTMlficSUhLnEmqGUiJGUCpaaXYrHpcCQEEYqMD2cRZcuhgcSQtMeRibUCGXW4JpjSkPaWhsdjCOmAPj4WIOIyIWMoKsynL+pmA7IOE5acRVZqJhZr/2S0xAzlkxnLQjOOQGcdBM47MgERKIztjielCXEwEidGhJLQJpVNMKEOS2hCU9b1jYPDOD6Cw0uK48QMcLTQD/tsx1q4xinPhmT6On+1pHzvG5kjDrbwPNjwPI++EcY949danCkoZ8ehqymwmX11jo/PymxxrTQ27xTFF3DkOKCii+veBYWAYmKbJ5rTTvL7uACt3Zbj+M9IrLpKZF3XlqpREQgI9Ny5HLTfSOMEVf5HdzVbm+IfR7iwUZZzVh2Kctc84s6/e38exKJytFMpLHV9tJY57l1d8tZVU3a5ybMWrtu+bdsczmLZK2/Yzr3O+Z5713rntPOes6wBV2kXMqm0kZ3+7+mPru88D+8++n1nX9+v53rQ5PttKArARgI1Qsx71mSr9VWkYA8I7OP6nHeF8xZ711bEdEBxFgGEQVp/Llpc4iuOd+hnbyZ8pzNiLLWs/ATkHCS04QjBl9DCO0oOjVc/Lh/I8C0fSOlQkP/F8RwQdgrbS3Z525rjwWBh4vWMsTXz/xjx4VSFRkPIrR8vNxleV3DSWc0CxD6aBf5J6lDKbSf+OUXQe0B9WBELBcfjy8fpdwLBAUCRGcATDgyIYHhxBUfdQDuZZ+CnbJOdkCCeXhvD68gj6JXdkWM/ORHRIgu6XevbBaqHkRjzPGgihMd65T2Co5+8j3mea5yafVbZLz0pIz952JrklVRPW8hJHl81ZyQoRcRDWDqwe+CcyINhRVLN9D6xAlVELtnLIPeKoO3PqZzj1M+Unf8aW9TMBOQcJsBWTbGSSTCa/YKfjHLujG3ZHxCi6XHIrsYOvcH/cw291JDd7lkPOEYju5N7rtwaupRe8n9x8uNXRJXXdkE6Of4t/9U/HAOfS/IoW+3zHBJPq3oPjP18lOY5XhVCgD9DH4EwmYQd+drwOh/Yh4Z5vCLD6ZhatkhsRaf4Mw5EU1HesSEtlDXAU24xJhu6XAI5/pAPAkeDlZbiSHk4foOz0EVbndea+vT05dTKcoKUWfnNqP3eMPo/QIDd2D8T2geSL4OA62LwQxsx137Vbi7x0x1cvt9z8mJHL90dzCbQaXDWoYkZcz3GOV13sdscQhLoSoJJ8bCV5HMk4zuH045QV5VJs7UaSjxIbUHIjItIyGAZEJTheyaMACAQmAD2O5/HAJ7v4el8Wz36+j39tPcp9V/ZhQv949w30HH6rI7nZ+iZc/Cf/TzTdLc/ZLeXddaWcA4kv7R1L2/Cghp1ssTjG3tSjLo8V6AJ0Nk22pJ2mrQ8TG9DyCyIiLd55sZH8Y+b5vPzrIXRsE8rR7CJ++8+t/Pr179xXSr/3lY5fzAUnYNcn7rlma1GSd2Y5Cy/Oliqz2VmyzVHX6LqhSV65p2EYDEtuS0pSG6/cryZKbkRE/IBhGIzvn8Dq2RfzuzE9CAqwsH7fSSb8bR1/+XQXecVNnLVoDYShNzu2N73W9IBbE2erjZerE3/10wmy8ktoFx7E6F6NnC3XQim5ERHxI6FBVmZf1pPVf7iYy/rGUW43ee3rA1zy1Jf8a8sR7PYmVP8YOt0xAPvwt5Cx031B+7t83yyY+WFFl9TkwR0J9HE3kbe1rqcVEWklOrcL49Vpw1h083C6tg8nK7+EP36wnf/++wa+P5pT9wWqExkPfa5ybG981X3B+jsfzJQ6XVDK6t2OFqNrh7S+2W1KbkRE/NjoXrGsuPsi7h3fm7AgK1vSTjPx+a+5b8lOTjdg7TgXZ1XbnR9AUbZbY/VbPpgp9e8dxyizmfRNiKJvYusrWKvkRkTEzwUHWLljdHc+/+NorkpJxDThn98d4pKn1/L2t2nYGtJV1XkkxPZzVCFPfcdzQfuTPO93Szm7pK4b2vpabUDJjYhIqxEfHcKzNwxm8e3/Re/4SLILy7h/6fdc9fzXbEk7Vb+LGAacf6tje9NrjlooUjsvJzd7MvLYcSSHAIvBpEGJXrlnc6PkRkSklfmvbu349K4LefCqfkSFBPDDsVyufWkDs99L5XhuPZa0GHA9BEfBqf3w8xeeD7ilcyU33qlx86+tZ2rbtItonfWIlNyIiLRCAVYL0y9I5ot7RvOr4UkYBny07SiXPv0lr371M2W2WlpkgiMca1eBpoXXhxdnS5Xb7Hy01bEu2bWttEsKlNyIiLRq7SKCefzagSz97ShSktqQX1LOI8t3M+Fv6/h6b1bNJw6v6Jr6aYVjIVCpmRdnS63bm0VWfgltw4O4pFesx+/XXCm5ERERUpLasOSOC3ji2oG0Cw9i3/F8fv36d6zbe6L6Ezr0hK4XOxZV3PyGd4NtSSovQOmF6sTOgcSTBiUSFNB6f8W33icXEZEqLBaD64cn8fk9oxnXz/GL+B8b0mo+wTktfOtbUFaPsTqtkas6cf3WaGqK7MJSVu1y3K+1zpJyUnIjIiJVRIcGMvuyXgB8sed4zfVwek6AqE5QeBJ2LfVegC2Jq8aN51tt/r39GKU2O30SouiXGO3x+zVnSm5EROQcveIj6ZMQRZnN5NOd6dUfZA2AYTMc26pYXL18760G7uySunZIR4/fq7lTciMiItW6ZrDjl+SSiqnF1RoyHSyBcHQzHNvmpchaEGfLTYRnW272ZuaxvaK2zeTBSm6U3IiISLUmDUrEYsDWQ9kczCqo/qCIWOg32bG9UdPCz+GlAn4fViSgo3vF0r6V1rapTMmNiIhUKzYqhFHntQdgybajNR84vGJg8fcfQmE9Kx23Fl4o4Fdus7OkorZNax9I7OTz5OaFF14gOTmZkJAQRowYwcaNG2s9Pjs7m1mzZpGQkEBwcDA9e/Zk+fLlXopWRKR1uaZi/MbS1KOYZg1rUCWdD/EDoLwYtr3txehaAC+03Kzbl8XxvBJiwgK5tHfrrW1TmU+Tm/fee4/Zs2czf/58tm7dSkpKCuPGjeP48ePVHl9aWspll13GwYMH+fDDD9mzZw+vvvoqHTuqf1FExBPG9YsnLMhK2slCth46Xf1BhnGm9Wbz61pvqjIvrAh+prZNx1Zd26Yyn/4pPPPMM9x2223cfPPN9O3bl5dffpmwsDDeeKP6glBvvPEGp06dYunSpYwaNYrk5GQuvvhiUlJSvBy5iEjrEBYUwPh+jl/MtXZNDfhvCImG0wdh32rvBNcSeHi2VE5hmWrbVMNnyU1paSlbtmxh7NixZ4KxWBg7diwbNmyo9pxPPvmEkSNHMmvWLOLi4ujfvz+PPvooNputxvuUlJSQm5tb5SUiIvV3dUXX1Kc70iktr6FVJigMBv3asb1J08KBqtWJPTRb6t87jlFabqd3fCT9EqM8co+WyGfJTVZWFjabjbi4qh94XFwcGRkZ1Z7z888/8+GHH2Kz2Vi+fDlz587l6aef5i9/+UuN93nssceIjo52vZKSktz6HCIi/u6C7u2Jiwomu7CML/ZUP2wAgOEzHV/3roJTB7wTXHPmHG8TFOlYbNQDnF1S1w3thGEYHrlHS9SiOufsdjuxsbG88sorDB06lClTpnDffffx8ssv13jOnDlzyMnJcb0OHz7sxYhFRFo+q8Vg0iBnzZtauqbadYfuYwDTMfamtfPwYOJ9x/NIPZxd5fMRB58lN+3bt8dqtZKZmVllf2ZmJvHx1f9FSEhIoGfPnlitVte+Pn36kJGRQWlp9eXBg4ODiYqKqvISEZGGubqiMNznPx4np7Cs5gOd601texvKirwQWTPm4eTmwy2ORPOSXh3oEKnaNpX5LLkJCgpi6NChrFmzxrXPbrezZs0aRo4cWe05o0aNYt++fdgrjcT/6aefSEhIICgoyOMxi4i0Vn0SougdH0mpzc6nO4/VfGCPyyG6MxSdhu//5b0Am6N8zyU3NrvJkm3O5RY0kPhsPu2Wmj17Nq+++ipvvvkmu3fv5o477qCgoICbb74ZgGnTpjFnzhzX8XfccQenTp3i97//PT/99BPLli3j0UcfZdasWb56BBGRVuPqwfXomrJYYfgtju2Nr0JNtXFaAw+23Hy9L4vM3BLahAVyaR/VtjmbT5ObKVOm8NRTTzFv3jwGDRpEamoqK1ascA0yPnToEOnpZxZsS0pKYuXKlWzatImBAwfyu9/9jt///vf8+c9/9tUjiIi0GpMGdcQwYHPaaQ6dLKz5wMHTwBoM6alwdIvX4mt2XOtKuT+5cdW2SUkkOMBax9GtT4CvA7jzzju58847q/3e2rVrz9k3cuRIvv32Ww9HJSIiZ4uPDmFU9/Z8vS+LJduO8vuxPao/MLwd9L8Gtr/raL3pNMy7gTYXec4aN+5NbnKKylj5g6NV6LqhmgFcnRY1W0pERHzL1TW17UjNyzHAmYrFP3wEBVleiKwZclUndm8Bv2UV9YZ6xUXSv6MmyVRHyY2IiNTb+P7xhAZaOXiykNTD2TUf2GkoJA4GWylsfctr8TUrHhpz8+EWR0mTa4d2VG2bGii5ERGRegsPDmBcP8e4yFqXY4BK600tBHvNleT9UkkelBU4tt1YnXj/iXy2HnLUtpms2jY1UnIjIiINcnXF1ON/bz9W83IM4Bh3ExoDOYfgp5Veiq6Z8FB14n9VDCS+uGcHYqNC3HZdf6PkRkREGmRU93Z0iAzmdGEZX/50ouYDA0Nh8E2O7da23pQHVgO32U0+qpiGr0Uya6fkRkREGiTAamFSSiKAq5BcjYbPBAzY/zlk7fN8cM2FB2ZKfbM/i4zcYqJDAxmj2ja1UnIjIiIN5lwpfPXu4+QU1bIcQ0yyo2oxtK71pjzQcuOqbTNItW3qouRGREQarG9CFL3iIiktt7N8Z3rtB7vWm/onlBZ4PrjmwM0zpXKLy1jxveOaWm6hbkpuRESkwQzDYHJ9lmMAx0rhMclQkgM7P/B8cM2Ba10p99S4WbYjnZJyOz1iIxjYKdot1/RnSm5ERKRRJg9OxDBg48FTHD5Vy3IMFgsMm+nY3vha61hvytly46Zp4M4uqeuGdlJtm3pQciMiIo2SEB3KyG7tAFhaV82bwb+GgBDI3AmHv/NCdD7mxurEB7IK2JJ2GotxpkK01E7JjYiINJprOYbUo7UvxxDWFvpf59je6OfTwk3TrbOlVNum4ZTciIhIo00YkEBIoIWfTxSw40hO7Qeff6vj666PIf+454PzlcrViZuY3NjsJv/a6khurlVtm3pTciMiIo0WERzA5X0dv8DrXI4hcTB0HAb2Mtjyphei85H8ilab4CgICm/SpTbsP0l6TjFRIQGM7eO+ZRz8nZIbERFpEmfNm39vP0aZrZblGODMtPAtC8FW7uHIfMSNNW6ci2ReNSiRkEDVtqkvJTciItIkF53XnvYRwZwsKOWr2pZjAOg7GcLaQe5R2LPcK/F5nZtmSuUVl7HiB8e1rhua1NSoWhUlNyIi0iQBVgtXVSzH8FFdXVOBITBkmmPbX9ebynNPjZvlO9MpLrNzXmwEKapt0yBKbkREpMmuqeiaWrUrk9ziWpZjABh2CxgWOPAVnPrZC9F5mZuqEztr21w7RLVtGkrJjYiINFm/xCh6xEZQWm7ns7qWY2jTGbr+wrH9/UeeD87b3DDm5mBWAZsOqrZNYym5ERGRJqu8HMNHdS3HANDvGsfXH5Z4MCofyW96jRvn9O+LenQgPlq1bRpKyY2IiLiFM7n57sApjpyuZTkGgD4TwRIAmd/DiT1eiM6Lmlid2G43XQnidapt0yhKbkRExC06tgnlv7q1BeDj1GO1HxzWFrpf6tj2p64p02zybKlvfz7J0ewiIkMCuKyvats0hpIbERFxm2sGO1oalmyrYzkGqNQ19ZH/LKZZkgdlFa1WjeyWcg4knpii2jaNpeRGRETcZsKAeIIDLOw7ns/3R3NrP7j3FWANhqyfIPMH7wToac5Wm0ZWJy4qtbGyorbNtUM0kLixlNyIiIjbRIYEurpSPtp2pPaDQ6Khx2WO7e//5eHIvKSJM6W+2HOcglIbHduEMqRzjBsDa12U3IiIiFtdU2k5hvK6lmPod7Xjq790TTVxptQnFWOVJqYkqrZNEyi5ERERt7qoRwfahQeRlV/Kur1ZtR/cawIEhsHpg3Bsm1fi8yhny01Ew5ObvOIyPt/jWC3dWfFZGkfJjYiIuFWg1cLE+i7HEBQOPcc5tn/wg1lTTahOvGpXJqXldrp3CKdPQqSbA2tdlNyIiIjbObum/vNDBnl1LcfgnDX1/RKw19GN1dw1YV2pT7arS8pdlNyIiIjbDegYTfcO4ZSU2/ns+4zaD+5xGQRFQu4ROLLJOwF6iiu5aVh9mlMFpXxd0YU3UV1STabkRkRE3M4wDK4ZUlHzpq7lGAJDHdPCoeV3TeU3ruVmxfcZlNtN+iVG0b1DhAcCa12U3IiIiEc4B8V+e+Akx7KLaj+48lpTdpuHI/OQytWJGzjm5pPtjgRQrTbuoeRGREQ8IqltGOd3bYtp1mM5hu6XOure5GdC2jfeCdDdSnLPVCduwGypzNxivjtwCoBfDmzcelRSlZIbERHxmGsqFtNcsu1I7csxBAQ5FtOElts1lVdR4yY4GoLC6n3ash3pmCYM7RJDp5j6nyc1U3IjIiIeM2FAAkEBFn7KzOeHY3Usx+Dsmtr1MdjKPR+cuzWyOrFrlpRabdxGyY2IiHhMdGggl/VxzBxaUlfNm64XQ1g7KDwJB770QnRu1oiZUodPFZJ6OBuLAVcouXEbJTciIuJRV1d0TX2cWsdyDNYA6DvJsd0Su6YaMVPq3zscrTYju7cjNjLEE1G1SkpuRETEoy7u1YG24UFk5Zfw9b46lmNwdk3t/jeUl3o+OHdqxEwp11pSAzVLyp2U3IiIiEcFWi2u8SR1dk11uQAi4qA4B/Z/7oXo3KiB60rtzczjx4w8Aq0G4/s3bqFNqZ6SGxER8birKwr6rfwhg/ySWgYLW6xVVwpvSfIatiL4v3c4kqFf9OhAm7AgT0XVKim5ERERj0vpFE239uEUl9lZUddyDM6uqR+XQVkdxf+akwbMljJNk39XWktK3EvJjYiIeJxhGK6BxUvr6prqNByiOkFpPuxd5YXo3KCB1Yl/OJbLgawCQgItXNa3YetQSd2U3IiIiFdMrkhu1u/PIiOnuOYDLRbo38K6pkpyobyilakeY26crTZjescRHhzgychaJSU3IiLiFUltwxieHFOxHEMdrTfOrqk9K6Ak3/PBNZWz1aYe1Ynt9spdUqpt4wnNIrl54YUXSE5OJiQkhBEjRrBx48Z6nbd48WIMw2Dy5MmeDVBERNzi6sEVK4XX1TWVOBhikh2tIT+t8HxgTdWA8TZbD53mWE4xEcEBjO4V6+HAWiefJzfvvfces2fPZv78+WzdupWUlBTGjRvH8ePHaz3v4MGD3HPPPVx00UVeilRERJrqygEJBFkt/JiRx67almMwDOh/rWP7hyXeCa4pGjBTytlqc3m/OEICrZ6MqtXyeXLzzDPPcNttt3HzzTfTt29fXn75ZcLCwnjjjTdqPMdmszF16lQefPBBunXr5sVoRUSkKaLDAhnTx9FasWTbkdoPdnZN7V3lqHvTnNWz5abcZmfZTsexmiXlOT5NbkpLS9myZQtjx4517bNYLIwdO5YNGzbUeN5DDz1EbGwsM2fOrPMeJSUl5ObmVnmJiIjvuGZNpR7jRF5JzQfG9YP2PcFWAj8u91J0jZRfv5abb38+RVZ+KTFhgVx4XnsvBNY6+TS5ycrKwmazERdXdRpcXFwcGRnV10H4+uuvef3113n11VfrdY/HHnuM6Oho1yspKanJcYuISOON7hVLXFQwJ/JKuPLZdWzYf7L6A6t0TTXzWVOulpvaBwg7u6QmDEgg0OrzzhO/1aL+ZPPy8rjpppt49dVXad++fhnvnDlzyMnJcb0OHz7s4ShFRKQ2QQEW3p45gh6xERzPK2Hqa9/y3Jq92O3muQc7u6b2fw6Fp7wbaEM4Z0tF1FyzpqTcxmffO5Kgq9Ql5VE+nVzfvn17rFYrmZmZVfZnZmYSH39u097+/fs5ePAgEydOdO2z2x0rzAYEBLBnzx66d+9e5Zzg4GCCg4M9EL2IiDRWj7hIPr5zFHOX/sC/th7h6VU/sfHgKRZMGUS7iEr/ZnfoCXH9IfN7x2KaQ6f7Luja5NW9Ivi6n7LILS4nLiqY4cltvRRY6+TTlpugoCCGDh3KmjVrXPvsdjtr1qxh5MiR5xzfu3dvdu7cSWpqqut11VVXcckll5CamqouJxGRFiQsKICnr0/hyesGEhJoYd3eLK54dh3f/XxWN1X/itab5to1Vc/qxP/e4eiSunJAIlaL4Y3IWi2fd0vNnj2bV199lTfffJPdu3dzxx13UFBQwM033wzAtGnTmDNnDgAhISH079+/yqtNmzZERkbSv39/goK08JiISEvz38OS+HjWhXTvEE5mbgk3vPotL3yx70w3lbNr6sBXkH/Cd4HWpDjnTHXiGpKbolIbq3Y5eimuGqQuKU/zeXIzZcoUnnrqKebNm8egQYNITU1lxYoVrkHGhw4dIj093cdRioiIJ/WKj+STOy/k6sEdsZvw5Mo93LxoEyfzS6BtV0dRP9MOu5b6OtRzOWdKhURDYGi1h6z5MZPCUhtJbUNJ6RTtxeBaJ8M0zWpGcPmv3NxcoqOjycnJISoqytfhiIhIJaZp8v7mw8z7+AdKyu3ER4Xw3I2DGX70bVg1F7qMgpub2bTwn9fCW5OgQ2+Y9V21h/zPPzaz8odMfju6O38a39u78fmJhvz+9nnLjYiIiJNhGEwZ3pmP7xxFtw7hZOQW86tXvuUfeUMcB6R9A7nHfBvk2eqYKZVbXMYXexzdaeqS8g4lNyIi0uz0jo/ikzsvZNKgRGx2k7lrc9gb3Bcw4Yelvg6vqjpmSv3nh0xKy+30iI2gV1ykFwNrvZTciIhIsxQRHMCCKYN47JoBBAVY+Gf+MADyt77v48jOUsdMqTMrgCdiGJol5Q1KbkREpNkyDIMbzu/M0t+O4vvoS7CbBhEntvHPFeuqL/rnC7WsK3Uyv4Sv92UBWkvKm5TciIhIs9c3MYpFv7+KfWEpABxa909ue2szpwtKfRwZta4r9dn3GdjsJgM6RtO1fbiXA2u9lNyIiEiLEBEcQI9LpwEwMeBb1vx4nCufXcfWQ6d9G5iz5Sbi3OTmTJdU7WtOiXspuRERkRbD6DsJDCv9jQOMisnhWE4x17+8gVe/+hmfVDappTpxRk4xGw861sP65UB1SXmTkhsREWk5wttDt4sBeGP4Ya4cmEC53eSR5bu57a0tZBd6uZuqOAfKix3bZyU3n+44hmnC8OQYEttUX9xPPEPJjYiItCwVyzEE/7iU528YzMOT+xNktbB6dyZXPvs127zZTeVstammOnHlWVLiXUpuRESkZenzS7AEwvFdGCf2cNN/deGj315Al3ZhHM0u4vq/b+D1rw94p5sqv/oaN2knC9h+JAeLAVcM0Hgbb1NyIyIiLUtoDJw3xrFdsVJ4/47R/PuuC7liQDxlNpOHP93FH95Lxebp6eI1jLf5dIdjkPGo89rTPiLYszHIOZTciIhIy+NcKfz7fzkG9QJRIYG8cOMQHprUj0CrwdLUY8z9+HvPtuDUMFPqk9SKLikNJPYJJTciItLy9JoAASFwch9k7HTtNgyDaSOTWTBlMIYB73x3iGdW/eS5OPLOrXGzJyOPPZl5BFoNxvWvvmqxeJaSGxERaXlCoqDHZY7tiq6pyq4cmMBfJvcH4LnP9/H61wc8E4erOvGZcTWf7nC02lzcM5bo0EDP3FdqpeRGRERapmq6piqbOqIL/zuuFwAPf7qLj7YecX8MrjE3jhXBTdPkExXu8zklNyIi0jL1HAeBYZB9CI5urfaQ347uzswLuwLwvx/uYPWuTPfGcNZsqZ1Hc0g7WUhooJXL+sa5915Sb0puRESkZQoKd4y9gWq7psAxBue+K/pwzZCO2Owms97ZysYDp9xz/2qqEztr24zpE0tYUIB77iMNpuRGRERaLlfX1Edgt1d7iMVi8NdrBzK2Tywl5XZmLtrED8dymn7v4uwz1Ykj4rHbTdcUcBXu8y0lNyIi0nKdNxaCoyDvGBz+rsbDAq0Wnr9xCOcntyWvpJzpb2ziYFZB0+7tnCkV0gYCQ9icdpr0nGIiQwIY3atD064tTaLkRkREWq7AEOh9pWO7hq4pp5BAK6/NGEafhCiy8kv49evfkZlb3Ph7nzVTytklNa5fPMEB1sZfV5pMyY2IiLRszq6pH5aC3VbroVEhgbx1y/kktwvjyOkipr2+kZzCssbdt9JMqXKbneU71SXVXCi5ERGRlq3baEfXUMFxOPh1nYd3iAzmHzNHEBsZzJ7MPG55cxOFpeUNv2+lmVLf7D/JyYJS2oYHMap7u4ZfS9xKyY2IiLRsAUHQ9yrHdh1dU05JbcP4x8wRRIUEsCXtNHe8vZXS8uoHJNfI2XITEefqkrpiQDwBVv1q9TV9AiIi0vI5u6Z2fQy2+nUz9YqPZOHN5xMaaOXLn05wzwfbsTdkoc2K5KY8PI4VPzi2tZZU86DkRkREWr7kiyCsPRSdhp+/rPdpQ7vE8NKvhxBgMfhk+zEe/PcP9V9osyK5+SEvjLzicuKjQhie3LYx0YubKbkREZGWzxoA/SY7tuvZNeU0ulcsT1+fgmHAmxvS+NuavfU7sWK21Jojjl+lvxyYgMViNOje4hlKbkRExD84u6Z2fwrlJQ06ddKgjjx0VT8AFqzey5vfHKz9BNOEfEedm+UVh141SF1SzYWSGxER8Q+dRzpqzpTkwL41DT79ppHJ/GFsTwDmf/IDH6cerfngStWJD5dF0qVdGAM6RjcmavEAJTciIuIfLBbod7Vju4FdU06/G3MeMy5IBuCP72/niz3Hqz+wYrxNgSWSEoKYODARw1CXVHOh5EZERPyHs2tqz2dQWtjg0w3DYN4v+zJpUCLldpM73t7ClrRqFtqsSG6O2hytNeqSal6U3IiIiP/oNAyiO0NpPuz9T6MuYbEYPPXfKYzu1YHiMjs3L9zEjxm5VQ+qSG4y7DH0ioukZ1xkUyMXN1JyIyIi/sMwzsya+voZOLjeMfi3gQKtFl6aOpRhXWLILS5n2usbOXSyUktQxUypE7RhYkqCGwIXd1JyIyIi/mXQVAgIgfTtsOgKeHEkfPcKFOc06DKhQVZenz6c3vGRHM8r4aY3vuN4nmMQcdFpR0XiTDNGa0k1Q0puRETEv8T2hts+hyHTIDAMTuyGz/4Xnu4Dn/zOkfTUU3SYY6HNpLahpJ0sZPobm8gpKuP40YMABEQn0KVduIceRBpLyY2IiPifuH5w1XPwxx9hwpPQoTeUFcDWN+Hvv4BXx0DqO1BWVOelYqNCeHvmCNpHBLM7PZdb39xE4ckjAHTr2t3TTyKNoORGRET8V0g0jLgdfvstzFgO/a8FSyAc3QxL74Cne8PK++Dk/lov06VdOG/dcj6RIQFsOnia8NIsAAb36+uNp5AGUnIjIiL+zzAgeRRc9wbM3gVj5jlmVRVnw4bn4bkh8NYk2PUJ2MqrvUTfxChenz6c4ACDOCMbgHbxnb33DFJvhlnvFcL8Q25uLtHR0eTk5BAVFeXrcERExFfsNti3Gja9XjFtvOLXYWQCDJkOQ6dD1LmDhb/e8RMXfjTc8ea+TAgM8V7MrVhDfn+r5UZERFonixV6joOp78Pvt8OFsyG8g2Oa95ePw//1h8VTYf/nYLe7Trsw3ubYCI1RYtNMKbkRERGJ6QJj58MfdsG1r0OXUWDa4MdP4R9Xw/ND4ZvnoPCUq8YNkapv01ypW0pERKQ6x3fD5jdg+2IoqahQbA12TDVP3w7dLoFpS30aYmuibikREZGmiu0DVzwJs3fDxL9B/ECwlZypk6OWm2YrwNcBiIiINGvBETB0hmOQ8dEtjgHIh7+FAdf5OjKpgZIbERGR+jAMx8KcnYb5OhKpg7qlRERExK80i+TmhRdeIDk5mZCQEEaMGMHGjRtrPPbVV1/loosuIiYmhpiYGMaOHVvr8SIiItK6+Dy5ee+995g9ezbz589n69atpKSkMG7cOI4fP17t8WvXruWGG27giy++YMOGDSQlJXH55Zdz9OhRL0cuIiIizZHPp4KPGDGC4cOH8/zzzwNgt9tJSkrirrvu4s9//nOd59tsNmJiYnj++eeZNm3aOd8vKSmhpKTE9T43N5ekpCRNBRcREWlBWsxU8NLSUrZs2cLYsWNd+ywWC2PHjmXDhg31ukZhYSFlZWW0bdu22u8/9thjREdHu15JSUluiV1ERESaJ58mN1lZWdhsNuLi4qrsj4uLIyMjo17XuPfee0lMTKySIFU2Z84ccnJyXK/Dhw83OW4RERFpvlr0VPDHH3+cxYsXs3btWkJCql/fIzg4mODgYC9HJiIiIr7i0+Smffv2WK1WMjMzq+zPzMwkPj6+1nOfeuopHn/8cVavXs3AgQM9GaaIiIi0ID7tlgoKCmLo0KGsWbPGtc9ut7NmzRpGjhxZ43lPPPEEDz/8MCtWrGDYMBVTEhERkTN83i01e/Zspk+fzrBhwzj//PNZsGABBQUF3HzzzQBMmzaNjh078thjjwHw17/+lXnz5vHOO++QnJzsGpsTERFBRESEz55DREREmgefJzdTpkzhxIkTzJs3j4yMDAYNGsSKFStcg4wPHTqExXKmgemll16itLSU666ruqbH/PnzeeCBB7wZuoiIiDRDPq9z420NmScvIiIizUOLqXMjIiIi4m5KbkRERMSv+HzMjbc5e+Fyc3N9HImIiIjUl/P3dn1G07S65CYvLw9AyzCIiIi0QHl5eURHR9d6TKsbUGy32zl27BiRkZEYhuHWazsX5Tx8+LDfD1bWs/qv1vS8elb/1Zqet7U8q2ma5OXlkZiYWGUWdXVaXcuNxWKhU6dOHr1HVFSUX/8Fq0zP6r9a0/PqWf1Xa3re1vCsdbXYOGlAsYiIiPgVJTciIiLiV5TcuFFwcDDz589vFauQ61n9V2t6Xj2r/2pNz9uanrW+Wt2AYhEREfFvarkRERERv6LkRkRERPyKkhsRERHxK0puRERExK8ouWmgF154geTkZEJCQhgxYgQbN26s9fgPPviA3r17ExISwoABA1i+fLmXIm28xx57jOHDhxMZGUlsbCyTJ09mz549tZ6zaNEiDMOo8goJCfFSxE3zwAMPnBN77969az2nJX6uAMnJyec8q2EYzJo1q9rjW9Ln+tVXXzFx4kQSExMxDIOlS5dW+b5pmsybN4+EhARCQ0MZO3Yse/furfO6Df2Z95banresrIx7772XAQMGEB4eTmJiItOmTePYsWO1XrMxPwveUNdnO2PGjHPiHj9+fJ3XbY6fbV3PWt3Pr2EYPPnkkzVes7l+rp6k5KYB3nvvPWbPns38+fPZunUrKSkpjBs3juPHj1d7/DfffMMNN9zAzJkz2bZtG5MnT2by5Ml8//33Xo68Yb788ktmzZrFt99+y6pVqygrK+Pyyy+noKCg1vOioqJIT093vdLS0rwUcdP169evSuxff/11jce21M8VYNOmTVWec9WqVQD893//d43ntJTPtaCggJSUFF544YVqv//EE0/w7LPP8vLLL/Pdd98RHh7OuHHjKC4urvGaDf2Z96banrewsJCtW7cyd+5ctm7dykcffcSePXu46qqr6rxuQ34WvKWuzxZg/PjxVeJ+9913a71mc/1s63rWys+Ynp7OG2+8gWEYXHvttbVetzl+rh5lSr2df/755qxZs1zvbTabmZiYaD722GPVHn/99debV155ZZV9I0aMMP/nf/7Ho3G62/Hjx03A/PLLL2s8ZuHChWZ0dLT3gnKj+fPnmykpKfU+3l8+V9M0zd///vdm9+7dTbvdXu33W+rnCphLlixxvbfb7WZ8fLz55JNPuvZlZ2ebwcHB5rvvvlvjdRr6M+8rZz9vdTZu3GgCZlpaWo3HNPRnwReqe9bp06ebkyZNatB1WsJnW5/PddKkSeall15a6zEt4XN1N7Xc1FNpaSlbtmxh7Nixrn0Wi4WxY8eyYcOGas/ZsGFDleMBxo0bV+PxzVVOTg4Abdu2rfW4/Px8unTpQlJSEpMmTeKHH37wRnhusXfvXhITE+nWrRtTp07l0KFDNR7rL59raWkpb7/9Nrfcckuti8i25M/V6cCBA2RkZFT53KKjoxkxYkSNn1tjfuabs5ycHAzDoE2bNrUe15CfheZk7dq1xMbG0qtXL+644w5OnjxZ47H+8tlmZmaybNkyZs6cWeexLfVzbSwlN/WUlZWFzWYjLi6uyv64uDgyMjKqPScjI6NBxzdHdrudu+++m1GjRtG/f/8aj+vVqxdvvPEGH3/8MW+//TZ2u50LLriAI0eOeDHaxhkxYgSLFi1ixYoVvPTSSxw4cICLLrqIvLy8ao/3h88VYOnSpWRnZzNjxowaj2nJn2tlzs+mIZ9bY37mm6vi4mLuvfdebrjhhloXVmzoz0JzMX78eN566y3WrFnDX//6V7788ksmTJiAzWar9nh/+WzffPNNIiMjueaaa2o9rqV+rk3R6lYFl4aZNWsW33//fZ39syNHjmTkyJGu9xdccAF9+vTh73//Ow8//LCnw2ySCRMmuLYHDhzIiBEj6NKlC++//369/kfUUr3++utMmDCBxMTEGo9pyZ+rOJSVlXH99ddjmiYvvfRSrce21J+FX/3qV67tAQMGMHDgQLp3787atWsZM2aMDyPzrDfeeIOpU6fWOci/pX6uTaGWm3pq3749VquVzMzMKvszMzOJj4+v9pz4+PgGHd/c3HnnnXz66ad88cUXdOrUqUHnBgYGMnjwYPbt2+eh6DynTZs29OzZs8bYW/rnCpCWlsbq1au59dZbG3ReS/1cnZ9NQz63xvzMNzfOxCYtLY1Vq1bV2mpTnbp+Fpqrbt260b59+xrj9ofPdt26dezZs6fBP8PQcj/XhlByU09BQUEMHTqUNWvWuPbZ7XbWrFlT5X+2lY0cObLK8QCrVq2q8fjmwjRN7rzzTpYsWcLnn39O165dG3wNm83Gzp07SUhI8ECEnpWfn8/+/ftrjL2lfq6VLVy4kNjYWK688soGnddSP9euXbsSHx9f5XPLzc3lu+++q/Fza8zPfHPiTGz27t3L6tWradeuXYOvUdfPQnN15MgRTp48WWPcLf2zBUfL69ChQ0lJSWnwuS31c20QX49obkkWL15sBgcHm4sWLTJ37dpl3n777WabNm3MjIwM0zRN86abbjL//Oc/u45fv369GRAQYD711FPm7t27zfnz55uBgYHmzp07ffUI9XLHHXeY0dHR5tq1a8309HTXq7Cw0HXM2c/64IMPmitXrjT3799vbtmyxfzVr35lhoSEmD/88IMvHqFB/vjHP5pr1641Dxw4YK5fv94cO3as2b59e/P48eOmafrP5+pks9nMzp07m/fee+8532vJn2teXp65bds2c9u2bSZgPvPMM+a2bdtcs4Mef/xxs02bNubHH39s7tixw5w0aZLZtWtXs6ioyHWNSy+91Hzuuedc7+v6mfel2p63tLTUvOqqq8xOnTqZqampVX6OS0pKXNc4+3nr+lnwldqeNS8vz7znnnvMDRs2mAcOHDBXr15tDhkyxOzRo4dZXFzsukZL+Wzr+ntsmqaZk5NjhoWFmS+99FK112gpn6snKblpoOeee87s3LmzGRQUZJ5//vnmt99+6/rexRdfbE6fPr3K8e+//77Zs2dPMygoyOzXr5+5bNkyL0fccEC1r4ULF7qOOftZ7777btefS1xcnHnFFVeYW7du9X7wjTBlyhQzISHBDAoKMjt27GhOmTLF3Ldvn+v7/vK5Oq1cudIEzD179pzzvZb8uX7xxRfV/r11Po/dbjfnzp1rxsXFmcHBweaYMWPO+TPo0qWLOX/+/Cr7avuZ96XanvfAgQM1/hx/8cUXrmuc/bx1/Sz4Sm3PWlhYaF5++eVmhw4dzMDAQLNLly7mbbfddk6S0lI+27r+Hpumaf797383Q0NDzezs7Gqv0VI+V08yTNM0Pdo0JCIiIuJFGnMjIiIifkXJjYiIiPgVJTciIiLiV5TciIiIiF9RciMiIiJ+RcmNiIiI+BUlNyIiIuJXlNyIiIiIX1FyIyKtkmEYLF261NdhiIgHKLkREa+bMWMGhmGc8xo/fryvQxMRPxDg6wBEpHUaP348CxcurLIvODjYR9GIiD9Ry42I+ERwcDDx8fFVXjExMYCjy+ill15iwoQJhIaG0q1bNz788MMq5+/cuZNLL72U0NBQ2rVrx+23305+fn6VY9544w369etHcHAwCQkJ3HnnnVW+n5WVxdVXX01YWBg9evTgk08+cX3v9OnTTJ06lQ4dOhAaGkqPHj3OScZEpHlSciMizdLcuXO59tpr2b59O1OnTuVXv/oVu3fvBqCgoIBx48YRExPDpk2b+OCDD1i9enWV5OWll15i1qxZ3H777ezcuZNPPvmE8847r8o9HnzwQa6//np27NjBFVdcwdSpUzl16pTr/rt27eKzzz5j9+7dvPTSS7Rv3957fwAi0ni+XpZcRFqf6dOnm1ar1QwPD6/yeuSRR0zTNE3A/M1vflPlnBEjRph33HGHaZqm+corr5gxMTFmfn6+6/vLli0zLRaLmZGRYZqmaSYmJpr33XdfjTEA5v333+96n5+fbwLmZ599ZpqmaU6cONG8+eab3fPAIuJVGnMjIj5xySWX8NJLL1XZ17ZtW9f2yJEjq3xv5MiRpKamArB7925SUlIIDw93fX/UqFHY7Xb27NmDYRgcO3aMMWPG1BrDwIEDXdvh4eFERUVx/PhxAO644w6uvfZatm7dyuWXX87kyZO54IILGvWsIuJdSm5ExCfCw8PP6SZyl9DQ0HodFxgYWOW9YRjY7XYAJkyYQFpaGsuXL2fVqlWMGTOGWbNm8dRTT7k9XhFxL425EZFm6dtvvz3nfZ8+fQDo06cP27dvp6CgwPX99evXY7FY6NWrF5GRkSQnJ7NmzZomxdChQwemT5/O22+/zYIFC3jllVeadD0R8Q613IiIT5SUlJCRkVFlX0BAgGvQ7gcffMCwYcO48MIL+ec//8nGjRt5/fXXAZg6dSrz589n+vTpPPDAA5w4cYK77rqLm266ibi4OAAeeOABfvOb3xAbG8uECRPIy8tj/fr13HXXXfWKb968eQwdOpR+/fpRUlLCp59+6kquRKR5U3IjIj6xYsUKEhISquzr1asXP/74I+CYybR48WJ++9vfkpCQwLvvvkvfvn0BCAsLY+XKlfz+979n+PDhhIWFce211/LMM8+4rjV9+nSKi4v5v//7P+655x7at2/PddddV+/4goKCmDNnDgcPHiQ0NJSLLrqIxYsXu+HJRcTTDNM0TV8HISJSmWEYLFmyhMmTJ/s6FBFpgTTmRkRERPyKkhsRERHxKxpzIyLNjnrLRaQp1HIjIiIifkXJjYiIiPgVJTciIiLiV5TciIiIiF9RciMiIiJ+RcmNiIiI+BUlNyIiIuJXlNyIiIiIX/n/COpZLrwdQ6cAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = []\n",
    "historyTest = []\n",
    "context_lenght = 21\n",
    "nb_seq_valance = 3\n",
    "\n",
    "env = env3Str()\n",
    "\n",
    "action = 0\n",
    "inputs = torch.tensor([[action]])\n",
    "targets = torch.tensor([0])\n",
    "\n",
    "valence = {\n",
    "    ('a', 'x') : 0,\n",
    "    ('a', 'y') : -1,\n",
    "    ('b', 'x') : 1,\n",
    "    ('b', 'y') : 0\n",
    "}\n",
    "\n",
    "# train\n",
    "for i in range(100):\n",
    "    action = np.random.choice(['a', 'b'])\n",
    "    feedback = env.outcome(action)\n",
    "    history.append((str(action), str(feedback)))\n",
    "\n",
    "# test\n",
    "for i in range(100):\n",
    "    action = np.random.choice(['a', 'b'])\n",
    "    feedback = env.outcome(action)\n",
    "    historyTest.append((str(action), str(feedback)))\n",
    "\n",
    "print(history)\n",
    "tmpInput, tmpTarget = inter_action_and_feedback_size(history, context_lenght)\n",
    "\n",
    "tokenizer = SimpleTokenizerV1(create_all_words_action_outcome_enumerate(['a', 'b', 'x', 'y'], []))\n",
    "\n",
    "inputs = []\n",
    "for i, one_input in enumerate(tmpInput):\n",
    "    inputs.append(tokenizer.encode(one_input))\n",
    "targets = tokenizer.encode(tmpTarget)\n",
    "\n",
    "inputs= torch.tensor(inputs, dtype=torch.long).to(device)\n",
    "targets = torch.tensor(targets, dtype=torch.long).to(device)\n",
    "\n",
    "tmpXtest, tmpYtest = inter_action_and_feedback_size(historyTest, context_lenght)\n",
    "\n",
    "x_test = []\n",
    "for i, one_input in enumerate(tmpXtest):\n",
    "    x_test.append(tokenizer.encode(one_input))\n",
    "y_test = tokenizer.encode(tmpYtest)\n",
    "\n",
    "x_test = torch.tensor(x_test, dtype=torch.long).to(device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "mymodel = GPTModel({\n",
    "        \"vocab_size\": len(['a', 'b', 'x', 'y']),\n",
    "        \"context_length\": context_lenght,\n",
    "        \"emb_dim\": 16,\n",
    "        \"n_heads\": 4,\n",
    "        \"n_leayers\": 4,\n",
    "        \"drop_rate\": 0.1,\n",
    "        \"qkv_bias\": False,\n",
    "        \"device\": device\n",
    "    })\n",
    "\n",
    "optimizer = torch.optim.AdamW(mymodel.parameters(), lr=1e-2, weight_decay=1e-2)\n",
    "\n",
    "train_loss, val_loss = train_simple(mymodel, optimizer, inputs, targets, 200, x_test, y_test)\n",
    "\n",
    "plt.plot(train_loss, label='Train Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for seq tensor([[1, 2, 1, 2, 1, 2, 0, 3, 0, 2, 0, 2, 1, 3, 0, 2, 0, 2, 1, 2, 0]],\n",
      "       device='cuda:0') the next token is y\n"
     ]
    }
   ],
   "source": [
    "# test model \n",
    "\n",
    "seq =torch.tensor([[1, 2, 1, 2, 1, 2, 0, 3, 0, 2, 0, 2, 1, 3, 0, 2, 0, 2, 1, 2, 0]]).to(device)\n",
    "mymodel.eval()\n",
    "x = mymodel(seq, False)\n",
    "probs = nn.functional.softmax(x, dim=-1)\n",
    "predi = torch.argmax(probs)\n",
    "see_proba(probs[0].tolist(), None)\n",
    "print(f'for seq {str(seq)} the next token is {tokenizer.decode([predi.item()])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, x, y):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(x, False)\n",
    "        # loss = nn.functional.cross_entropy(logits, y)\n",
    "        pred = torch.argmax(logits, dim=-1)\n",
    "        acc = (pred == y).float().mean()\n",
    "    return acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 'y'), ('a', 'x'), ('b', 'x'), ('b', 'y'), ('a', 'x'), ('b', 'x'), ('b', 'y'), ('b', 'x'), ('b', 'x'), ('b', 'x'), ('a', 'x'), ('a', 'y'), ('b', 'x'), ('a', 'x'), ('b', 'x'), ('a', 'x'), ('a', 'y'), ('b', 'x'), ('a', 'x'), ('a', 'y'), ('a', 'x'), ('a', 'x'), ('a', 'x'), ('a', 'x'), ('a', 'x'), ('b', 'x'), ('b', 'y'), ('a', 'x'), ('a', 'y'), ('a', 'x'), ('b', 'x'), ('a', 'x'), ('a', 'y'), ('b', 'x'), ('a', 'x'), ('a', 'y'), ('a', 'x'), ('b', 'x'), ('a', 'x'), ('a', 'y'), ('a', 'x'), ('b', 'x'), ('a', 'x'), ('b', 'x'), ('a', 'x'), ('b', 'x'), ('a', 'x'), ('b', 'x'), ('b', 'y'), ('a', 'x'), ('b', 'x'), ('b', 'y'), ('a', 'x'), ('a', 'y'), ('b', 'x'), ('a', 'x'), ('a', 'y'), ('b', 'x'), ('a', 'x'), ('a', 'y'), ('a', 'x'), ('b', 'x'), ('b', 'y'), ('a', 'x'), ('b', 'x'), ('a', 'x'), ('b', 'x'), ('b', 'y'), ('b', 'x'), ('b', 'x'), ('b', 'x'), ('b', 'x'), ('b', 'x'), ('b', 'x'), ('b', 'x'), ('b', 'x'), ('a', 'x'), ('b', 'x'), ('b', 'y'), ('b', 'x'), ('a', 'x'), ('a', 'y'), ('b', 'x'), ('b', 'y'), ('a', 'x'), ('a', 'y'), ('b', 'x'), ('b', 'y'), ('b', 'x'), ('a', 'x'), ('b', 'x'), ('b', 'y'), ('a', 'x'), ('a', 'y'), ('a', 'x'), ('a', 'x'), ('a', 'x'), ('a', 'x'), ('a', 'x'), ('b', 'x')]\n",
      "for 0 iteration, loss is 1.4855504035949707 and val_loss is 1.4560620784759521\n",
      "for 10 iteration, loss is 1.1685925722122192 and val_loss is 1.1573328971862793\n",
      "for 20 iteration, loss is 1.0778160095214844 and val_loss is 1.0784856081008911\n",
      "for 30 iteration, loss is 1.0454695224761963 and val_loss is 1.0490758419036865\n",
      "for 40 iteration, loss is 1.0251438617706299 and val_loss is 1.0295884609222412\n",
      "for 50 iteration, loss is 1.0058717727661133 and val_loss is 1.010900855064392\n",
      "for 60 iteration, loss is 0.9877369999885559 and val_loss is 0.9933832883834839\n",
      "for 70 iteration, loss is 0.9702039957046509 and val_loss is 0.9763094186782837\n",
      "for 80 iteration, loss is 0.9531196355819702 and val_loss is 0.9596298933029175\n",
      "for 90 iteration, loss is 0.9364646077156067 and val_loss is 0.943366527557373\n",
      "for 100 iteration, loss is 0.9202049374580383 and val_loss is 0.9275097846984863\n",
      "for 110 iteration, loss is 0.9043342471122742 and val_loss is 0.9120513796806335\n",
      "for 120 iteration, loss is 0.888841450214386 and val_loss is 0.8970028162002563\n",
      "for 130 iteration, loss is 0.8737102746963501 and val_loss is 0.8823840022087097\n",
      "for 140 iteration, loss is 0.8589102029800415 and val_loss is 0.8682217597961426\n",
      "for 150 iteration, loss is 0.8443899154663086 and val_loss is 0.8545485734939575\n",
      "for 160 iteration, loss is 0.8300310373306274 and val_loss is 0.8413888216018677\n",
      "for 170 iteration, loss is 0.815424919128418 and val_loss is 0.8285819888114929\n",
      "for 180 iteration, loss is 0.7989677786827087 and val_loss is 0.8151692152023315\n",
      "for 190 iteration, loss is 0.7692105174064636 and val_loss is 0.7928737998008728\n",
      "for 200 iteration, loss is 0.7204226851463318 and val_loss is 0.7456411719322205\n",
      "for 210 iteration, loss is 0.673998236656189 and val_loss is 0.6641173958778381\n",
      "for 220 iteration, loss is 0.5800462365150452 and val_loss is 0.6147214770317078\n",
      "for 230 iteration, loss is 0.5338255167007446 and val_loss is 0.5984536409378052\n",
      "for 240 iteration, loss is 0.5086182951927185 and val_loss is 0.5635010600090027\n",
      "for 250 iteration, loss is 0.4867539405822754 and val_loss is 0.5431907176971436\n",
      "for 260 iteration, loss is 0.46838903427124023 and val_loss is 0.528936505317688\n",
      "for 270 iteration, loss is 0.45166534185409546 and val_loss is 0.5107200741767883\n",
      "for 280 iteration, loss is 0.43607601523399353 and val_loss is 0.49702268838882446\n",
      "for 290 iteration, loss is 0.42137688398361206 and val_loss is 0.48370295763015747\n",
      "for 300 iteration, loss is 0.40750187635421753 and val_loss is 0.470503032207489\n",
      "for 310 iteration, loss is 0.39432913064956665 and val_loss is 0.4584882855415344\n",
      "for 320 iteration, loss is 0.3817954659461975 and val_loss is 0.4471292495727539\n",
      "for 330 iteration, loss is 0.3698429763317108 and val_loss is 0.4364737570285797\n",
      "for 340 iteration, loss is 0.358425110578537 and val_loss is 0.42636638879776\n",
      "for 350 iteration, loss is 0.34750232100486755 and val_loss is 0.4166884422302246\n",
      "for 360 iteration, loss is 0.3370412588119507 and val_loss is 0.40760356187820435\n",
      "for 370 iteration, loss is 0.3270125985145569 and val_loss is 0.39894264936447144\n",
      "for 380 iteration, loss is 0.3173908293247223 and val_loss is 0.3907134532928467\n",
      "for 390 iteration, loss is 0.3081529438495636 and val_loss is 0.3828708529472351\n",
      "for 400 iteration, loss is 0.299278199672699 and val_loss is 0.37542301416397095\n",
      "for 410 iteration, loss is 0.29074737429618835 and val_loss is 0.36832454800605774\n",
      "for 420 iteration, loss is 0.2825431525707245 and val_loss is 0.3615604043006897\n",
      "for 430 iteration, loss is 0.2746492028236389 and val_loss is 0.35511380434036255\n",
      "for 440 iteration, loss is 0.2670506238937378 and val_loss is 0.3489631712436676\n",
      "for 450 iteration, loss is 0.2597333788871765 and val_loss is 0.34309524297714233\n",
      "for 460 iteration, loss is 0.25268450379371643 and val_loss is 0.33748659491539\n",
      "for 470 iteration, loss is 0.24589142203330994 and val_loss is 0.33215612173080444\n",
      "for 480 iteration, loss is 0.23938393592834473 and val_loss is 0.32951515913009644\n",
      "for 490 iteration, loss is 0.23306076228618622 and val_loss is 0.32073676586151123\n",
      "0.9625000357627869\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = []\n",
    "historyTest = []\n",
    "context_lenght = 21\n",
    "nb_seq_valance = 3\n",
    "\n",
    "env = env6Str()\n",
    "\n",
    "action = 0\n",
    "inputs = torch.tensor([[action]])\n",
    "targets = torch.tensor([0])\n",
    "\n",
    "valence = {\n",
    "    ('a', 'x') : 0,\n",
    "    ('a', 'y') : -1,\n",
    "    ('b', 'x') : 1,\n",
    "    ('b', 'y') : 0\n",
    "}\n",
    "\n",
    "# train\n",
    "for i in range(100):\n",
    "    action = np.random.choice(['a', 'b'])\n",
    "    feedback = env.outcome(action)\n",
    "    history.append((str(action), str(feedback)))\n",
    "\n",
    "# test\n",
    "for i in range(100):\n",
    "    action = np.random.choice(['a', 'b'])\n",
    "    feedback = env.outcome(action)\n",
    "    historyTest.append((str(action), str(feedback)))\n",
    "\n",
    "print(history)\n",
    "tmpInput, tmpTarget = inter_action_and_feedback_size(history, context_lenght)\n",
    "\n",
    "tokenizer = SimpleTokenizerV1(create_all_words_action_outcome_enumerate(['a', 'b', 'x', 'y'], []))\n",
    "\n",
    "inputs = []\n",
    "for i, one_input in enumerate(tmpInput):\n",
    "    inputs.append(tokenizer.encode(one_input))\n",
    "targets = tokenizer.encode(tmpTarget)\n",
    "\n",
    "inputs= torch.tensor(inputs, dtype=torch.long).to(device)\n",
    "targets = torch.tensor(targets, dtype=torch.long).to(device)\n",
    "\n",
    "tmpXtest, tmpYtest = inter_action_and_feedback_size(historyTest, context_lenght)\n",
    "\n",
    "x_test = []\n",
    "for i, one_input in enumerate(tmpXtest):\n",
    "    x_test.append(tokenizer.encode(one_input))\n",
    "y_test = tokenizer.encode(tmpYtest)\n",
    "\n",
    "x_test = torch.tensor(x_test, dtype=torch.long).to(device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "mymodel = GPTModel({\n",
    "        \"vocab_size\": len(['a', 'b', 'x', 'y']),\n",
    "        \"context_length\": context_lenght,\n",
    "        \"emb_dim\": 16 * 2,\n",
    "        \"n_heads\": 4,\n",
    "        \"n_leayers\": 4,\n",
    "        \"drop_rate\": 0.2,\n",
    "        \"qkv_bias\": False,\n",
    "        \"device\": device\n",
    "    })\n",
    "\n",
    "optimizer = torch.optim.AdamW(mymodel.parameters(), lr=1e-4, weight_decay=1e-2)\n",
    "\n",
    "train_loss, val_loss = train_simple(mymodel, optimizer, inputs, targets, 500, x_test, y_test)\n",
    "\n",
    "print(accuracy(mymodel, x_test, y_test))\n",
    "\n",
    "plt.plot(train_loss, label='Train Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for seq tensor([[1, 2, 0, 2, 0, 3, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 1, 3, 1]],\n",
      "       device='cuda:0') the next token is x\n"
     ]
    }
   ],
   "source": [
    "# test model \n",
    "# seq =torch.tensor([tokenizer.encode(['b', 'x', 'a', 'x', 'b', 'x', 'b', 'y', 'a', 'x', 'b', 'x', 'a', 'x', 'b', 'x', 'b', 'x', 'a', 'y', 'a'])]).to(device)\n",
    "seq =torch.tensor([tokenizer.encode(['b', 'x', 'a' , 'x', 'a', 'y', 'a', 'x', 'a', 'x', 'a', 'x', 'a', 'x', 'a', 'x', 'a', 'x', 'b', 'y', 'b'])]).to(device)\n",
    "#=============================================================^noise=================================================================^noise\n",
    "# Second noise have an impact on the prediction\n",
    "# Not the first one\n",
    "mymodel.eval()\n",
    "x = mymodel(seq, False)\n",
    "probs = nn.functional.softmax(x, dim=-1)\n",
    "predi = torch.argmax(probs)\n",
    "see_proba(probs[0].tolist(), None)\n",
    "print(f'for seq {str(seq)} the next token is {tokenizer.decode([predi.item()])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def see_evolued_train_loss(train_loss):\n",
    "    for i, loss_list in enumerate(train_loss):\n",
    "        plt.plot(loss_list, label=f'Iteration {i}', color=plt.cm.viridis(i / len(train_loss)))\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b', 'y']\n"
     ]
    }
   ],
   "source": [
    "data = eval(\"['b', 'y']\")\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b']\n",
      "iteration 0 action b feedback y predict None\n",
      "iteration 1 action b feedback x predict None\n",
      "iteration 2 action a feedback y predict None\n",
      "iteration 3 action b feedback y predict None\n",
      "iteration 4 action b feedback x predict None\n",
      "iteration 5 action b feedback x predict None\n",
      "iteration 6 action a feedback y predict None\n",
      "iteration 7 action a feedback x predict None\n",
      "iteration 8 action b feedback y predict None\n",
      "iteration 9 action a feedback y predict None\n",
      "iteration 10 action a feedback x predict None\n",
      "iteration 11 action b feedback y predict None\n",
      "iteration 12 action b feedback x predict None\n",
      "iteration 13 action b feedback x predict None\n",
      "iteration 14 action b feedback x predict None\n",
      "iteration 15 action a feedback y predict None\n",
      "iteration 16 action a feedback x predict None\n",
      "iteration 17 action b feedback y predict None\n",
      "iteration 18 action a feedback y predict None\n",
      "iteration 19 action b feedback y predict None\n",
      "iteration 20 action b feedback x predict None\n",
      "iteration 21 action a feedback y predict None\n",
      "iteration 22 action a feedback x predict None\n",
      "iteration 23 action b feedback y predict None\n",
      "iteration 24 action b feedback x predict None\n",
      "iteration 25 action b feedback x predict None\n",
      "iteration 26 action a feedback y predict None\n",
      "iteration 27 action a feedback x predict None\n",
      "iteration 28 action b feedback y predict None\n",
      "iteration 29 action a feedback y predict None\n",
      "time to train 0.6518230438232422\n",
      "best proba 0.4198758900165558\n",
      "best proba 0.38337358832359314\n",
      "time to make tree 0.004081010818481445\n",
      "% good predict : 1.0\n",
      "iteration 30 action b feedback y predict y\n",
      "time to train 0.5777997970581055\n",
      "best proba 0.3918360769748688\n",
      "best proba 0.4157194495201111\n",
      "time to make tree 0.0038902759552001953\n",
      "% good predict : 0.5\n",
      "iteration 31 action a feedback y predict x\n",
      "time to train 0.5614511966705322\n",
      "best proba 0.4640623927116394\n",
      "best proba 0.38682955503463745\n",
      "time to make tree 0.004511356353759766\n",
      "% good predict : 0.6666666666666666\n",
      "iteration 32 action b feedback y predict y\n",
      "time to train 0.6091353893280029\n",
      "best proba 0.3872378170490265\n",
      "best proba 0.39046579599380493\n",
      "time to make tree 0.005149364471435547\n",
      "% good predict : 0.75\n",
      "iteration 33 action b feedback x predict x\n",
      "time to train 0.5897648334503174\n",
      "best proba 0.4089640974998474\n",
      "best proba 0.4860054850578308\n",
      "time to make tree 0.004514217376708984\n",
      "% good predict : 0.6\n",
      "iteration 34 action a feedback y predict x\n",
      "time to train 0.6000874042510986\n",
      "best proba 0.41143739223480225\n",
      "best proba 0.4507733881473541\n",
      "time to make tree 0.004302024841308594\n",
      "% good predict : 0.5\n",
      "iteration 35 action b feedback y predict x\n",
      "time to train 0.5967495441436768\n",
      "best proba 0.4392347037792206\n",
      "best proba 0.38001197576522827\n",
      "time to make tree 0.005210399627685547\n",
      "% good predict : 0.5714285714285714\n",
      "iteration 36 action a feedback y predict y\n",
      "time to train 0.5752964019775391\n",
      "best proba 0.4509574770927429\n",
      "best proba 0.40377163887023926\n",
      "time to make tree 0.004825115203857422\n",
      "% good predict : 0.5\n",
      "iteration 37 action a feedback x predict y\n",
      "time to train 0.5719888210296631\n",
      "best proba 0.44628211855888367\n",
      "best proba 0.4166007339954376\n",
      "time to make tree 0.00413966178894043\n",
      "% good predict : 0.4444444444444444\n",
      "iteration 38 action a feedback x predict y\n",
      "time to train 0.5900793075561523\n",
      "best proba 0.40547454357147217\n",
      "best proba 0.38870546221733093\n",
      "time to make tree 0.0042743682861328125\n",
      "% good predict : 0.5\n",
      "iteration 39 action b feedback y predict y\n",
      "time to train 0.559119701385498\n",
      "best proba 0.3941158652305603\n",
      "best proba 0.3849985897541046\n",
      "time to make tree 0.003972768783569336\n",
      "% good predict : 0.45454545454545453\n",
      "iteration 40 action a feedback y predict x\n",
      "time to train 0.5382895469665527\n",
      "best proba 0.4234926998615265\n",
      "best proba 0.3989761769771576\n",
      "time to make tree 0.0052487850189208984\n",
      "% good predict : 0.4166666666666667\n",
      "iteration 41 action a feedback x predict y\n",
      "time to train 0.6267647743225098\n",
      "best proba 0.4491024315357208\n",
      "best proba 0.43826332688331604\n",
      "time to make tree 0.004054546356201172\n",
      "% good predict : 0.46153846153846156\n",
      "iteration 42 action b feedback y predict y\n",
      "time to train 0.575721263885498\n",
      "best proba 0.4240504205226898\n",
      "best proba 0.4231370687484741\n",
      "time to make tree 0.004450798034667969\n",
      "% good predict : 0.5\n",
      "iteration 43 action a feedback y predict y\n",
      "time to train 0.6350290775299072\n",
      "best proba 0.44421425461769104\n",
      "best proba 0.42858847975730896\n",
      "time to make tree 0.0043222904205322266\n",
      "% good predict : 0.5333333333333333\n",
      "iteration 44 action b feedback y predict y\n",
      "time to train 0.5638129711151123\n",
      "best proba 0.48320940136909485\n",
      "best proba 0.47764816880226135\n",
      "time to make tree 0.0043430328369140625\n",
      "% good predict : 0.5625\n",
      "iteration 45 action a feedback y predict y\n",
      "time to train 0.5782508850097656\n",
      "best proba 0.4615050256252289\n",
      "best proba 0.459246426820755\n",
      "time to make tree 0.004059791564941406\n",
      "% good predict : 0.5294117647058824\n",
      "iteration 46 action a feedback x predict y\n",
      "time to train 0.5582029819488525\n",
      "best proba 0.4510195255279541\n",
      "best proba 0.4516184628009796\n",
      "time to make tree 0.00439763069152832\n",
      "% good predict : 0.5555555555555556\n",
      "iteration 47 action b feedback y predict y\n",
      "time to train 0.568566083908081\n",
      "best proba 0.45379334688186646\n",
      "best proba 0.4634573757648468\n",
      "time to make tree 0.004662036895751953\n",
      "% good predict : 0.5789473684210527\n",
      "iteration 48 action a feedback y predict y\n",
      "time to train 0.568598747253418\n",
      "best proba 0.47552719712257385\n",
      "best proba 0.47833168506622314\n",
      "time to make tree 0.005455493927001953\n",
      "% good predict : 0.55\n",
      "iteration 49 action a feedback x predict y\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 157\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28mprint\u001b[39m(env\u001b[38;5;241m.\u001b[39mget_actions())\n\u001b[1;32m    155\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m SimpleTokenizerV1(create_all_words_action_outcome_enumerate([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m], []))\n\u001b[0;32m--> 157\u001b[0m evolued_train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_in_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmymodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m see_evolued_train_loss(evolued_train_loss)\n",
      "Cell \u001b[0;32mIn[43], line 80\u001b[0m, in \u001b[0;36mmodel_in_env\u001b[0;34m(model, tokenizer, env, valance, iter, rand_iter)\u001b[0m\n\u001b[1;32m     78\u001b[0m targets \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(targets, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     79\u001b[0m time_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 80\u001b[0m train_loss, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_simple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m time_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime to train \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime_end\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mtime_start\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 13\u001b[0m, in \u001b[0;36mtrain_simple\u001b[0;34m(model, optimizer, inputs, targets, n_iter, x_val, y_val, verbose)\u001b[0m\n\u001b[1;32m     11\u001b[0m logits \u001b[38;5;241m=\u001b[39m model(inputs, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mcross_entropy(logits, targets)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/Documents/stage/Dpt_transformers/.venv/lib/python3.11/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/stage/Dpt_transformers/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/stage/Dpt_transformers/.venv/lib/python3.11/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# def make_tree_prediction(model, env, max_deep:int, last_sequence:list, seq_predi:list=[]):\n",
    "#     if max_deep == 0:\n",
    "#         return []\n",
    "#     # input(f'{last_sequence} | {seq_predi}')\n",
    "#     max_deep -= 1\n",
    "    \n",
    "#     fake_tree = []\n",
    "#     model.eval()\n",
    "#     for act in env.get_actions():\n",
    "#         seq_to_predict = tokenizer.encode(last_sequence + [act])\n",
    "#         seq_to_predict = torch.tensor([seq_to_predict], dtype=torch.long).to(device)\n",
    "#         # input(f'seq to pass in model {seq_to_predict}')\n",
    "#         x = model(seq_to_predict, False)\n",
    "#         probs = nn.functional.softmax(x, dim=-1)\n",
    "#         predi = tokenizer.decode([torch.argmax(probs).item()])\n",
    "#         new__last_seq = last_sequence[2:] + [act, predi]\n",
    "#         new_seq_predi = seq_predi + [act, predi]\n",
    "#         # input(f'new last seq {new__last_seq} | new seq pred {new_seq_predi}')\n",
    "#         fake_tree.append(new_seq_predi) \n",
    "#         fake_tree += (make_tree_prediction(model, env, max_deep, new__last_seq, new_seq_predi))\n",
    "\n",
    "#     return fake_tree\n",
    "\n",
    "\n",
    "def make_tree_prediction(model, env, valence:dict, max_deep: int, last_sequence: list):\n",
    "    model.eval()\n",
    "    stack = [(last_sequence, [], 1)]\n",
    "    fake_tree = {}\n",
    "\n",
    "    while stack:\n",
    "        last_sequence, seq_predi, value = stack.pop()\n",
    "        # input(f'start wihle {stack} | \\n last seq {last_sequence} \\n seq predi {seq_predi}')\n",
    "        \n",
    "        if len(seq_predi) // 2 >= max_deep:\n",
    "            continue\n",
    "\n",
    "        for act in env.get_actions():\n",
    "            seq_to_predict = tokenizer.encode(last_sequence + [act])\n",
    "            seq_to_predict = torch.tensor([seq_to_predict], dtype=torch.long).to(device)\n",
    "            \n",
    "            x = model(seq_to_predict, False)\n",
    "            probs = nn.functional.softmax(x, dim=-1)\n",
    "            predi = tokenizer.decode([torch.argmax(probs).item()])\n",
    "            best_proba = probs[0][torch.argmax(probs)].item()\n",
    "            print(f'best proba {best_proba}')\n",
    "            \n",
    "            new_last_seq = last_sequence[2:] + [act, predi]\n",
    "            new_seq_predi = seq_predi + [act, predi]\n",
    "            new_value = value + best_proba * valence[(act, predi)]\n",
    "            fake_tree[str(new_seq_predi)] = new_value\n",
    "            stack.append((new_last_seq, new_seq_predi, new_value))\n",
    "\n",
    "    return fake_tree\n",
    "\n",
    "\n",
    "def model_in_env(model, tokenizer:SimpleTokenizerV1, env, valance:dict, iter:int, rand_iter:int = 10):\n",
    "    history = []\n",
    "    context_lenght = model.cfg[\"context_length\"]\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-2)\n",
    "    evolued_train_loss = []\n",
    "    predict = None\n",
    "    good_predict = 0\n",
    "\n",
    "    for i in range(0, iter):\n",
    "        if i < rand_iter:\n",
    "            action = np.random.choice(env.get_actions())\n",
    "        else:\n",
    "            # train model\n",
    "            model.apply(model._init_weights)\n",
    "            tmpInput, tmpTarget = inter_action_and_feedback_size(history, context_lenght)\n",
    "            inputs = []\n",
    "            for one_input in tmpInput:\n",
    "                inputs.append(tokenizer.encode(one_input))\n",
    "            targets = tokenizer.encode(tmpTarget)\n",
    "\n",
    "            inputs= torch.tensor(inputs, dtype=torch.long).to(device)\n",
    "            targets = torch.tensor(targets, dtype=torch.long).to(device)\n",
    "            time_start = time.time()\n",
    "            train_loss, _ = train_simple(model, optimizer, inputs, targets, 100, verbose=False)\n",
    "            time_end = time.time()\n",
    "            print(f'time to train {time_end - time_start}')\n",
    "            evolued_train_loss.append(train_loss)\n",
    "\n",
    "            # predict next action\n",
    "            tmp = tmpInput[-1][2:] + [tmpTarget[-1]]\n",
    "            time_start = time.time()\n",
    "            test:dict = make_tree_prediction(\n",
    "                    model=model, env=env, max_deep=1, valence=valance,\n",
    "                    last_sequence= tmp)\n",
    "            # input(f'for this sequence {tmp} all prediction {test}')\n",
    "            interact_max_val = max(test.items())[0]\n",
    "            interact_max_val = eval(interact_max_val)\n",
    "            # input(f'max is {interact_max_val}')\n",
    "            action = interact_max_val[0]\n",
    "            predict = interact_max_val[1]\n",
    "            # input(f'action {action}')\n",
    "            # input(f'predict {predict}')\n",
    "            # input(f'for this sequence {tmp} all prediction {test}')\n",
    "            time_end = time.time()\n",
    "            print(f'time to make tree {time_end - time_start}')\n",
    "            # print(f'for this sequence {tmp}')\n",
    "            # print(f'all prediction {test}')\n",
    "            # max_potentiel = -np.inf\n",
    "            # for act in env.get_actions():\n",
    "            #     seq_to_predict = tokenizer.encode(tmpInput[-1][2:] + [tmpTarget[-1], act])\n",
    "            #     seq_to_predict = torch.tensor([seq_to_predict], dtype=torch.long).to(device)\n",
    "            #     x = model(seq_to_predict, False)\n",
    "            #     probs = nn.functional.softmax(x, dim=-1)\n",
    "            #     predi = torch.argmax(probs)\n",
    "            #     val_predi = valance[(act, tokenizer.decode([predi.item()]))]\n",
    "            #     if val_predi > max_potentiel:\n",
    "            #         max_potentiel = val_predi\n",
    "            #         action = act\n",
    "            #     elif val_predi == max_potentiel:\n",
    "            #         action = np.random.choice([action, act])\n",
    "\n",
    "            action = np.random.choice(env.get_actions())\n",
    "            \n",
    "\n",
    "        feedback = env.outcome(action)\n",
    "        if predict is not None:\n",
    "            if predict == feedback:\n",
    "                good_predict += 1\n",
    "            print(f'% good predict : {good_predict / (i - rand_iter + 1)}')\n",
    "        print(f'iteration {i} action {action} feedback {feedback} predict {predict}')\n",
    "        history.append((str(action), str(feedback)))\n",
    "\n",
    "    return evolued_train_loss\n",
    "\n",
    "\n",
    "mymodel = GPTModel({\n",
    "        \"vocab_size\": len(['a', 'b', 'x', 'y']),\n",
    "        \"context_length\": 21,\n",
    "        \"emb_dim\": 16 *2,\n",
    "        \"n_heads\": 4,\n",
    "        \"n_leayers\": 4,\n",
    "        \"drop_rate\": 0.2,\n",
    "        \"qkv_bias\": False,\n",
    "        \"device\": device\n",
    "    })\n",
    "\n",
    "\n",
    "valence = {\n",
    "    ('a', 'x') : -10,\n",
    "    ('a', 'y') : 10,\n",
    "    ('b', 'x') : -10,\n",
    "    ('b', 'y') : 10\n",
    "}\n",
    "\n",
    "env = env3Str()\n",
    "\n",
    "print(env.get_actions())\n",
    "\n",
    "tokenizer = SimpleTokenizerV1(create_all_words_action_outcome_enumerate(['a', 'b', 'x', 'y'], []))\n",
    "\n",
    "evolued_train_loss = model_in_env(mymodel, tokenizer, env, valence, 500, 30)\n",
    "\n",
    "see_evolued_train_loss(evolued_train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "see_evolued_train_loss(evolued_train_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Stage (torch)",
   "language": "python",
   "name": "dpt_transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
