{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.metadata import version\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from ipywidgets import Output\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "# Pour torch si vous avez un GPU\n",
    "# device = \"cpu\" if not torch.cuda.is_available() else \"cuda\"\n",
    "device = \"cpu\" # Pour forcer l'utilisation du CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environement potentielement testé\n",
    "from environnement.environnement import Environnement as env # mother class\n",
    "from environnement.environnement1 import Environnement1 as env1\n",
    "from environnement.environnement2Str import Environnement2 as env2Str\n",
    "from environnement.environnement3Str import Environnement3 as env3Str\n",
    "from environnement.environnement6Str import Environnement6 as env6Str\n",
    "from environnement.small_loop import small_loop\n",
    "\n",
    "# model machine learning\n",
    "from model.DeepNN import *\n",
    "from model.Tokenizer import *\n",
    "from model.RNN import *\n",
    "from model.CustomDataSet import CustomDataSet, CustomDataSetRNN\n",
    "from outil import *\n",
    "from inter.interactions import Interaction\n",
    "from inter.simpleInteraction import simpleInteraction as inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentLSTM:\n",
    "    def __init__(self, model, all_outcomes, all_actions, tokenizer, valence:dict,\n",
    "                optimizer, gap_train=11, gap_test=11, loss_func=None):\n",
    "        \"\"\" \n",
    "        Création de l'agent.\n",
    "        \n",
    "        - self._action : action précédente\n",
    "        - self._predicted_outcome : prédiction de l'outcome précédent\n",
    "        \"\"\"\n",
    "        self._action = None\n",
    "        self._predicted_outcome = None\n",
    "        self._model = model\n",
    "        self.optimizer = optimizer\n",
    "        self._loss_func = loss_func\n",
    "        self._tokenizer:SimpleTokenizerV1 = tokenizer\n",
    "        self._all_outcomes = all_outcomes\n",
    "        self._all_actions = all_actions\n",
    "        self._history_act = []\n",
    "        self._history_fb = []\n",
    "        self._valence = valence\n",
    "        self._gap_train = gap_train\n",
    "        self._gap_test = gap_test\n",
    "        self._boredom = 0\n",
    "\n",
    "    def fit(self, actions:list, outcomes:list, nb_epoch:int=25, context_lenght=5, validate_loader=None):\n",
    "        \"\"\"\n",
    "        Fonction d'entrainement de l'agent \n",
    "        Avec data set custom, le model prends en inputs plusieurs données\n",
    "        \"\"\"\n",
    "        \n",
    "        if len(actions) + len(outcomes) < context_lenght:\n",
    "            raise Exception(\"Not enough data to train model\")\n",
    "        \n",
    "        if isinstance(self._model, torch.nn.Module):\n",
    "            data_loarder = CustomDataSetRNN(actions=actions, outcomes=outcomes,\n",
    "                    context_lenght=context_lenght, dim_out=2, tokenizer=self._tokenizer)\n",
    "\n",
    "            data_loader = torch.utils.data.DataLoader(\n",
    "                data_loarder, batch_size=32, shuffle=True)\n",
    "            for e in range(nb_epoch):\n",
    "                for x,t in data_loader:\n",
    "                    bs = t.shape[0]\n",
    "                    h = torch.zeros(self._model.num_layers, bs, self._model.hidden_size, device=device)\n",
    "                    cell = torch.zeros(self._model.num_layers, bs, self._model.hidden_size, device=device)\n",
    "\n",
    "                    pred, h, cell = self._model(x, h, cell)\n",
    "\n",
    "                    loss = self._loss_func(pred[:, -1, :], t)\n",
    "                    self.optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "        else: # Si le model n'est pas un model pytorch\n",
    "            raise Exception('Not implemented')\n",
    "            self._model.fit(action, outcome)\n",
    "            pass\n",
    "\n",
    "    def predict(self, action, gap=5):\n",
    "        if len(self._history_act) + len(self._history_fb) < gap:\n",
    "            raise Exception(\"Not enough data to train model\")\n",
    "        x = []\n",
    "        for i in range(len(self._history_act) - gap, len(self._history_act)):\n",
    "            x.append(self._history_act[i])\n",
    "            x.append(self._history_fb[i])\n",
    "        x.append(action)\n",
    "        action = self._tokenizer.encode(x)\n",
    "\n",
    "        action = torch.tensor([action], dtype=torch.int).to(device)\n",
    "\n",
    "        h = torch.zeros(self._model.num_layers, 1, self._model.hidden_size, device=device)\n",
    "        cell = torch.zeros(self._model.num_layers, 1, self._model.hidden_size, device=device)\n",
    "        \n",
    "        with torch.no_grad():  # Pas de calcul de gradients en mode prédiction\n",
    "            pred, _, _ = self._model(action, h, cell)\n",
    "\n",
    "        pred_feedback = torch.argmax(pred[:, -1, :]).item()\n",
    "        pred_feedback = self._tokenizer.decode(pred_feedback)\n",
    "        \n",
    "        return pred_feedback\n",
    "    \n",
    "    def recursif_expective_valance(self, seq:list, max_depth:int, seuil:float=0.2, proba:float = 1,\n",
    "                                    seq_predi:list = []):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        if max_depth == 0:\n",
    "            return {}\n",
    "        max_depth -= 1\n",
    "\n",
    "        if proba < seuil:\n",
    "            return {}\n",
    "        \n",
    "        self._model.eval()\n",
    "        exceptive_valance = {}\n",
    "        for act in self._all_actions:\n",
    "            new_seq = seq_predi + [act]\n",
    "            seq_to_predict = seq + [self._tokenizer.encode(act)]\n",
    "            seq_to_predict = torch.tensor([seq_to_predict], dtype=torch.int).to(device)\n",
    "\n",
    "            hidden = torch.zeros(self._model.num_layers, 1, self._model.hidden_size, device=device)\n",
    "            memory = torch.zeros(self._model.num_layers, 1, self._model.hidden_size, device=device)\n",
    "\n",
    "            x, _, _ = self._model(seq_to_predict, hidden, memory)\n",
    "            x = x[0, -1, :]\n",
    "            # Transforme x into list proba\n",
    "            probs = torch.nn.functional.softmax(x, dim=0).tolist()\n",
    "            # for each outcomes we want proba with act\n",
    "            for i, out in enumerate(self._all_outcomes):\n",
    "                tmp_new_seq = new_seq + [out]\n",
    "                tmp_proba = probs[i] * proba\n",
    "                if tmp_proba < seuil:\n",
    "                    continue\n",
    "                tempo = float(np.round(self._valence[inter(act, out)] * tmp_proba, decimals=4))\n",
    "                # input(f'seq {seq_predi} act {act} out {out} proba {tmp_proba} valance {valance[(act, out)]} tempo {tempo}')\n",
    "                exceptive_valance.update(\n",
    "                    self.recursif_expective_valance(seq=seq[2:] + [self._tokenizer.encode(act), self._tokenizer.encode(out)],\n",
    "                                                max_depth=max_depth, seuil=seuil, \n",
    "                                                proba=tmp_proba, seq_predi=tmp_new_seq.copy())\n",
    "                )\n",
    "                exceptive_valance[str(tmp_new_seq)] = tempo\n",
    "        return exceptive_valance\n",
    "        \n",
    "    def decide(self):\n",
    "        x = []\n",
    "        for i in range(-self._gap_test//2, 0, 1):\n",
    "            x.append(self._history_act[i])\n",
    "            x.append(self._history_fb[i])\n",
    "        seq = self._tokenizer.encode(x)\n",
    "        res = self.recursif_expective_valance(seq=seq, max_depth=4, seuil=0.2)\n",
    "        top_5 = sorted(res.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "        # print(f\"Top 5 of sequences with the best expected valance for {x}\")\n",
    "        # for top in top_5:\n",
    "        #     print(f\"Sequence: {top[0]} Expected valance: {top[1]}\")\n",
    "        \n",
    "        # print(f\"Action choisie : {eval(top_5[0][0])[0]}\")\n",
    "        return eval(top_5[0][0])[0]\n",
    "\n",
    "    # Modifier\n",
    "    def action(self, outcome, fit=True, decide=True, validate_loader=None, force_fit=False):\n",
    "        \"\"\" \n",
    "        Fonction qui choisit l'action a faire en fonction de la dernière \\\n",
    "        intéraction avec l'environnement. \\n\n",
    "        C'est ici que nous allons implémenter un mécanisme de ML \\\n",
    "        pour choisir la prochaine action.\n",
    "\n",
    "        :param: **outcome** feedback de la dernière intéraction avec l'environnement\n",
    "\n",
    "        :return: **action** action à effectuer\n",
    "        \"\"\"\n",
    "        self._boredom += 1\n",
    "        description = None\n",
    "        if self._action is not None:\n",
    "            self._history_fb.append(outcome)\n",
    "            description = f\"Action: {self._action}, Prediction: {self._predicted_outcome}, Outcome: {outcome}, \\033[0;31m Satisfaction: {self._predicted_outcome == outcome} \\033[0m\"\n",
    "            if len(self._history_act) + len(self._history_fb) > self._gap_train:\n",
    "                # and self._predicted_outcome != outcome\n",
    "                if fit and self._predicted_outcome != outcome:\n",
    "                    self.fit(self._history_act, self._history_fb, validate_loader=validate_loader,\n",
    "                            nb_epoch=50, context_lenght=self._gap_train)\n",
    "                    self._boredom = 0\n",
    "                \n",
    "            if decide and len(self._history_act) + len(self._history_fb) > self._gap_test:\n",
    "                self._action = self.decide()\n",
    "            else :\n",
    "                self._action = str(np.random.choice(self._all_actions))\n",
    "                \n",
    "            if len(self._history_act) + len(self._history_fb) > self._gap_test:\n",
    "                self._predicted_outcome = self.predict(self._action, gap=self._gap_test)\n",
    "            \n",
    "            self._history_act.append(self._action)\n",
    "        else:\n",
    "            self._action = self._all_actions[0]\n",
    "            self._history_act.append(self._action)            \n",
    "            description = f\"Action de base : {self._action} Prediction: {self._predicted_outcome}\"\n",
    "        \n",
    "        return self._action, self._predicted_outcome, description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4281a5dfcbe64524be7118d8d23f06e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "725dd458c892484186e7a461399db842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m     pourcent_by_10\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28msum\u001b[39m(history_good[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m10\u001b[39m:]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(history_good) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;66;03m# env_test2.display_world(out)\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m     \u001b[43menv_test2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_world\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFin du training\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/stage/Dpt_transformers/environnement/small_loop.py:227\u001b[0m, in \u001b[0;36msmall_loop.save_world\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_box_feel:\n\u001b[1;32m    225\u001b[0m     world_seen[x, y] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m--> 227\u001b[0m \u001b[43m_save_world\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_seen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrobot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/stage/Dpt_transformers/environnement/small_loop.py:73\u001b[0m, in \u001b[0;36m_save_world\u001b[0;34m(world, robot, path)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Add number in plot\u001b[39;00m\n\u001b[1;32m     72\u001b[0m ax\u001b[38;5;241m.\u001b[39mtext(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, number, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhite\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 73\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m plt\u001b[38;5;241m.\u001b[39mclose(fig)\n",
      "File \u001b[0;32m~/Documents/stage/Dpt_transformers/.venv/lib/python3.11/site-packages/matplotlib/pyplot.py:1243\u001b[0m, in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1240\u001b[0m fig \u001b[38;5;241m=\u001b[39m gcf()\n\u001b[1;32m   1241\u001b[0m \u001b[38;5;66;03m# savefig default implementation has no return, so mypy is unhappy\u001b[39;00m\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;66;03m# presumably this is here because subclasses can return?\u001b[39;00m\n\u001b[0;32m-> 1243\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[func-returns-value]\u001b[39;00m\n\u001b[1;32m   1244\u001b[0m fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mdraw_idle()  \u001b[38;5;66;03m# Need this if 'transparent=True', to reset colors.\u001b[39;00m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/Documents/stage/Dpt_transformers/.venv/lib/python3.11/site-packages/matplotlib/figure.py:3490\u001b[0m, in \u001b[0;36mFigure.savefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   3488\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes:\n\u001b[1;32m   3489\u001b[0m         _recursively_make_axes_transparent(stack, ax)\n\u001b[0;32m-> 3490\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/stage/Dpt_transformers/.venv/lib/python3.11/site-packages/matplotlib/backend_bases.py:2183\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2179\u001b[0m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39m_cm_set(layout_engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m   2180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2181\u001b[0m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[1;32m   2182\u001b[0m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[0;32m-> 2183\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mcbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setattr_cm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   2184\u001b[0m         result \u001b[38;5;241m=\u001b[39m print_method(\n\u001b[1;32m   2185\u001b[0m             filename,\n\u001b[1;32m   2186\u001b[0m             facecolor\u001b[38;5;241m=\u001b[39mfacecolor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2189\u001b[0m             bbox_inches_restore\u001b[38;5;241m=\u001b[39m_bbox_inches_restore,\n\u001b[1;32m   2190\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2191\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.11/contextlib.py:289\u001b[0m, in \u001b[0;36mcontextmanager.<locals>.helper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhelper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_GeneratorContextManager\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.11/contextlib.py:105\u001b[0m, in \u001b[0;36m_GeneratorContextManagerBase.__init__\u001b[0;34m(self, func, args, kwds)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, args, kwds):\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds \u001b[38;5;241m=\u001b[39m func, args, kwds\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m# Issue 19330: ensure context manager instances have good docstrings\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env_test2 = small_loop(x=1, y=1, theta=0, world=np.array([\n",
    "                [1, 1, 1, 1, 1, 1],\n",
    "                [1, 0, 0, 0, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 1],\n",
    "                [1, 1, 1, 1, 1, 1],\n",
    "            ]))\n",
    "\n",
    "model_ML = LSTM(hidden_size=128, num_emb=len(env_test2.get_outcomes() + env_test2.get_actions()),\n",
    "                num_layers=2, output_size=2)\n",
    "optimizer = torch.optim.Adam(model_ML.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "tokenizer = SimpleTokenizerV1(create_dico_numerate_word(env_test2.get_outcomes() + env_test2.get_actions()))\n",
    "\n",
    "valence = {\n",
    "    inter('forward', 'empty') : 1,\n",
    "    inter('forward', 'wall') : -10,\n",
    "    inter('turn_left', 'empty') : -7,\n",
    "    inter('turn_left', 'wall') : -80,\n",
    "    inter('turn_right', 'empty') : -7,\n",
    "    inter('turn_right', 'wall') : -80,\n",
    "    inter('feel_front', 'wall') : -5,\n",
    "    inter('feel_front', 'empty') : -5,\n",
    "}\n",
    "\n",
    "agent_test2 = AgentLSTM(\n",
    "    model=model_ML,\n",
    "    all_outcomes= env_test2.get_outcomes(),\n",
    "    all_actions= env_test2.get_actions(),\n",
    "    valence=valence,\n",
    "    tokenizer=tokenizer,\n",
    "    optimizer=optimizer,\n",
    "    loss_func=loss_func,\n",
    "    gap_train=21,\n",
    "    gap_test=21)\n",
    "\n",
    "history_good = []\n",
    "pourcent_by_10 = []\n",
    "outcome = None\n",
    "\n",
    "out = Output()\n",
    "display(out)\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    # start_time = time.time()\n",
    "    action, predi, description = agent_test2.action(outcome, fit=False, decide=False)\n",
    "    outcome = env_test2.outcome(action)\n",
    "    history_good.append(outcome == predi)\n",
    "    pourcent_by_10.append(sum(history_good[-10:]) * 10 if len(history_good) >= 10 else 0)\n",
    "    # env_test2.display_world(out)\n",
    "    env_test2.save_world()\n",
    "raise Exception(\"Fin du training\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a5098fa97f5428aa8aaf1e9f4f60632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m)):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# print(f\"=======================\\033[0;32m iteration {i} \\033[0m=======================\")\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 10\u001b[0m     action, predi, description \u001b[38;5;241m=\u001b[39m \u001b[43magent_test2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutcome\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecide\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     outcome \u001b[38;5;241m=\u001b[39m env_test2\u001b[38;5;241m.\u001b[39moutcome(action)\n\u001b[1;32m     12\u001b[0m     history_good\u001b[38;5;241m.\u001b[39mappend(outcome \u001b[38;5;241m==\u001b[39m predi)\n",
      "Cell \u001b[0;32mIn[3], line 161\u001b[0m, in \u001b[0;36mAgentLSTM.action\u001b[0;34m(self, outcome, fit, decide, validate_loader, force_fit)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_boredom \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decide \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_history_act) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_history_fb) \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gap_test:\n\u001b[0;32m--> 161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecide\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m :\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_all_actions))\n",
      "Cell \u001b[0;32mIn[3], line 127\u001b[0m, in \u001b[0;36mAgentLSTM.decide\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m     x\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_history_fb[i])\n\u001b[1;32m    126\u001b[0m seq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer\u001b[38;5;241m.\u001b[39mencode(x)\n\u001b[0;32m--> 127\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecursif_expective_valance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseuil\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m top_5 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(res\u001b[38;5;241m.\u001b[39mitems(), key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[:\u001b[38;5;241m5\u001b[39m]\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# print(f\"Top 5 of sequences with the best expected valance for {x}\")\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# for top in top_5:\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m#     print(f\"Sequence: {top[0]} Expected valance: {top[1]}\")\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# print(f\"Action choisie : {eval(top_5[0][0])[0]}\")\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 114\u001b[0m, in \u001b[0;36mAgentLSTM.recursif_expective_valance\u001b[0;34m(self, seq, max_depth, seuil, proba, seq_predi)\u001b[0m\n\u001b[1;32m    111\u001b[0m         tempo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(np\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_valence[inter(act, out)] \u001b[38;5;241m*\u001b[39m tmp_proba, decimals\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;66;03m# input(f'seq {seq_predi} act {act} out {out} proba {tmp_proba} valance {valance[(act, out)]} tempo {tempo}')\u001b[39;00m\n\u001b[1;32m    113\u001b[0m         exceptive_valance\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m--> 114\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecursif_expective_valance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseq\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mact\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_depth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseuil\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseuil\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mproba\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtmp_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_predi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtmp_new_seq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m         )\n\u001b[1;32m    118\u001b[0m         exceptive_valance[\u001b[38;5;28mstr\u001b[39m(tmp_new_seq)] \u001b[38;5;241m=\u001b[39m tempo\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m exceptive_valance\n",
      "Cell \u001b[0;32mIn[3], line 114\u001b[0m, in \u001b[0;36mAgentLSTM.recursif_expective_valance\u001b[0;34m(self, seq, max_depth, seuil, proba, seq_predi)\u001b[0m\n\u001b[1;32m    111\u001b[0m         tempo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(np\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_valence[inter(act, out)] \u001b[38;5;241m*\u001b[39m tmp_proba, decimals\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;66;03m# input(f'seq {seq_predi} act {act} out {out} proba {tmp_proba} valance {valance[(act, out)]} tempo {tempo}')\u001b[39;00m\n\u001b[1;32m    113\u001b[0m         exceptive_valance\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m--> 114\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecursif_expective_valance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseq\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mact\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_depth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseuil\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseuil\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mproba\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtmp_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_predi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtmp_new_seq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m         )\n\u001b[1;32m    118\u001b[0m         exceptive_valance[\u001b[38;5;28mstr\u001b[39m(tmp_new_seq)] \u001b[38;5;241m=\u001b[39m tempo\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m exceptive_valance\n",
      "    \u001b[0;31m[... skipping similar frames: AgentLSTM.recursif_expective_valance at line 114 (1 times)]\u001b[0m\n",
      "Cell \u001b[0;32mIn[3], line 114\u001b[0m, in \u001b[0;36mAgentLSTM.recursif_expective_valance\u001b[0;34m(self, seq, max_depth, seuil, proba, seq_predi)\u001b[0m\n\u001b[1;32m    111\u001b[0m         tempo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(np\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_valence[inter(act, out)] \u001b[38;5;241m*\u001b[39m tmp_proba, decimals\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;66;03m# input(f'seq {seq_predi} act {act} out {out} proba {tmp_proba} valance {valance[(act, out)]} tempo {tempo}')\u001b[39;00m\n\u001b[1;32m    113\u001b[0m         exceptive_valance\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m--> 114\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecursif_expective_valance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseq\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mact\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_depth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseuil\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseuil\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mproba\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtmp_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_predi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtmp_new_seq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m         )\n\u001b[1;32m    118\u001b[0m         exceptive_valance[\u001b[38;5;28mstr\u001b[39m(tmp_new_seq)] \u001b[38;5;241m=\u001b[39m tempo\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m exceptive_valance\n",
      "Cell \u001b[0;32mIn[3], line 101\u001b[0m, in \u001b[0;36mAgentLSTM.recursif_expective_valance\u001b[0;34m(self, seq, max_depth, seuil, proba, seq_predi)\u001b[0m\n\u001b[1;32m     98\u001b[0m hidden \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mhidden_size, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     99\u001b[0m memory \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mhidden_size, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m--> 101\u001b[0m x, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq_to_predict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m x \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# Transforme x into list proba\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/stage/Dpt_transformers/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/stage/Dpt_transformers/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/stage/Dpt_transformers/model/RNN.py:42\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input_seq, hidden_in, mem_in)\u001b[0m\n\u001b[1;32m     39\u001b[0m input_embs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(input_seq)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Pass the embeddings through the LSTM layer\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m output, (hidden_out, mem_out) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_embs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmem_in\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Pass the LSTM output through the fully connected layer to get the final output\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_out(output), hidden_out, mem_out\n",
      "File \u001b[0;32m~/Documents/stage/Dpt_transformers/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/stage/Dpt_transformers/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/stage/Dpt_transformers/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:1124\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1121\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1124\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1128\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1129\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1138\u001b[0m         batch_sizes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[1;32m   1146\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "action, predi, description = agent_test2.action(outcome, fit=True, decide=True, force_fit=True)\n",
    "outcome = env_test2.outcome(action)\n",
    "history_good.append(outcome == predi)\n",
    "pourcent_by_10.append(sum(history_good[-10:]) * 10 if len(history_good) >= 10 else 0)\n",
    "env_test2.save_world()\n",
    "\n",
    "for i in tqdm(range(1000)):\n",
    "    # print(f\"=======================\\033[0;32m iteration {i} \\033[0m=======================\")\n",
    "    start_time = time.time()\n",
    "    action, predi, description = agent_test2.action(outcome, fit=True, decide=True)\n",
    "    outcome = env_test2.outcome(action)\n",
    "    history_good.append(outcome == predi)\n",
    "    pourcent_by_10.append(sum(history_good[-10:]) * 10 if len(history_good) >= 10 else 0)\n",
    "    # env_test2.display_world(out)\n",
    "    env_test2.save_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Fin de l'execution",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFin de l\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexecution\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m out \u001b[38;5;241m=\u001b[39m Output()\n\u001b[1;32m      3\u001b[0m out_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mException\u001b[0m: Fin de l'execution"
     ]
    }
   ],
   "source": [
    "raise Exception(\"Fin de l'execution\")\n",
    "out = Output()\n",
    "out_id = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env_test2 = small_loop(x=1, y=1, world=np.array([\n",
    "#                 [1, 1, 1, 1, 1],\n",
    "#                 [1, 0, 0, 0, 1],\n",
    "#                 [1, 1, 1, 0, 1],\n",
    "#                 [1, 0, 1, 0, 1],\n",
    "#                 [1, 0, 0, 0, 1],\n",
    "#                 [1, 1, 1, 1, 1],\n",
    "#             ]))\n",
    "env_test2 = small_loop(x=1, y=1, theta=0, world=np.array([\n",
    "                [1, 1, 1, 1, 1, 1, 1],\n",
    "                [1, 0, 0, 0, 0, 0, 1],\n",
    "                [1, 1, 1, 1, 1, 1, 1],\n",
    "            ]))\n",
    "\n",
    "\n",
    "agent_test2._history_act = []\n",
    "agent_test2._history_fb = []\n",
    "agent_test2._action = None\n",
    "\n",
    "# for i in tqdm(range(50)):\n",
    "#     action, predi, description = agent_test2.action(outcome, fit=True, decide=False)\n",
    "#     outcome = env_test2.outcome(action)\n",
    "#     env_test2.save_world()\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    action, predi, description = agent_test2.action(outcome, fit=True, decide=True)\n",
    "    outcome = env_test2.outcome(action)\n",
    "    env_test2.save_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = env_test2.outcome('forward')\n",
    "env_test2.display_world(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = env_test2.outcome('turn_left')\n",
    "env_test2.display_world(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = env_test2.outcome('turn_right')\n",
    "env_test2.display_world(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = env_test2.outcome('feel_front')\n",
    "env_test2.display_world(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception(\"Fin de l'execution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(100):\n",
    "    env_test2.display_world(out)\n",
    "    action, predi = agent_test2.action(outcome, decide=True)\n",
    "    outcome = env_test2.outcome(action)\n",
    "    history_good.append(outcome == predi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_proba_from_seq(_seg):\n",
    "    seq = tokenizer.encode(_seg)\n",
    "    seq = torch.tensor([seq], dtype=torch.int).to(device)\n",
    "    h = torch.zeros(agent_test2._model.num_layers, 1, agent_test2._model.hidden_size, device=device)\n",
    "    cell = torch.zeros(agent_test2._model.num_layers, 1, agent_test2._model.hidden_size, device=device)\n",
    "    predi, _, _ =  agent_test2._model(seq, h, cell)\n",
    "    predi = predi[0, -1, :]\n",
    "    prob = torch.nn.functional.softmax(predi, dim=0)\n",
    "    deocde = tokenizer.decode(torch.argmax(predi, dim=0).item())\n",
    "    print(f\"Prédiction de la séquence {_seg} :  probabilité {prob.tolist()}, decode {deocde}\")\n",
    "\n",
    "print(\"porba si on avance\")\n",
    "show_proba_from_seq(['forward', 'empty', 'forward'])\n",
    "show_proba_from_seq(['forward', 'wall', 'forward'])\n",
    "show_proba_from_seq(['turn_left', 'empty', 'forward'])\n",
    "show_proba_from_seq(['turn_right', 'empty', 'forward'])\n",
    "show_proba_from_seq(['feel_front', 'empty', 'forward'])\n",
    "show_proba_from_seq(['feel_front', 'wall', 'forward'])\n",
    "\n",
    "print(\"porba si on turn left\")\n",
    "show_proba_from_seq(['forward', 'empty', 'turn_left'])\n",
    "show_proba_from_seq(['forward', 'wall', 'turn_left'])\n",
    "show_proba_from_seq(['turn_left', 'empty', 'turn_left'])\n",
    "show_proba_from_seq(['turn_right', 'empty', 'turn_left'])\n",
    "show_proba_from_seq(['feel_front', 'empty', 'turn_left'])\n",
    "show_proba_from_seq(['feel_front', 'wall', 'turn_left'])\n",
    "\n",
    "print(\"porba si on turn right\")\n",
    "show_proba_from_seq(['forward', 'empty', 'turn_right'])\n",
    "show_proba_from_seq(['forward', 'wall', 'turn_right'])\n",
    "show_proba_from_seq(['turn_left', 'empty', 'turn_right'])\n",
    "show_proba_from_seq(['turn_right', 'empty', 'turn_right'])\n",
    "show_proba_from_seq(['feel_front', 'empty', 'turn_right'])\n",
    "show_proba_from_seq(['feel_front', 'wall', 'turn_right'])\n",
    "\n",
    "print(\"porba si on feel front\")\n",
    "show_proba_from_seq(['forward', 'empty', 'feel_front'])\n",
    "show_proba_from_seq(['forward', 'wall', 'feel_front'])\n",
    "show_proba_from_seq(['turn_left', 'empty', 'feel_front'])\n",
    "show_proba_from_seq(['turn_right', 'empty', 'feel_front'])\n",
    "show_proba_from_seq(['feel_front', 'empty', 'feel_front'])\n",
    "show_proba_from_seq(['feel_front', 'wall', 'feel_front'])\n",
    "\n",
    "def count_pattern(lst, pattern):\n",
    "    return sum(1 for i in range(len(lst) - len(pattern) + 1) if lst[i:i+len(pattern)] == pattern)\n",
    "\n",
    "list_act_out = []\n",
    "for act, out in zip(agent_test2._history_act, agent_test2._history_fb):\n",
    "    list_act_out.append(act)\n",
    "    list_act_out.append(out)\n",
    "\n",
    "print(\"count si on avance\")\n",
    "print(f\"pattern 'forward', 'empty', 'forward', 'empty' présent : {count_pattern(list_act_out, ['forward', 'empty', 'forward', 'empty'])}\")\n",
    "print(f\"pattern 'forward', 'empty', 'forward', 'wall' présent : {count_pattern(list_act_out, ['forward', 'empty', 'forward', 'wall'])}\")\n",
    "print(f\"pattern 'forward', 'wall', 'forward', 'empty' présent : {count_pattern(list_act_out, ['forward', 'wall', 'forward', 'empty'])}\")\n",
    "print(f\"pattern 'forward', 'wall', 'forward', 'wall' présent : {count_pattern(list_act_out, ['forward', 'wall', 'forward', 'wall'])}\")\n",
    "print(f\"pattern 'turn_left', 'empty', 'forward', 'empty' présent : {count_pattern(list_act_out, ['turn_left', 'empty', 'forward', 'empty'])}\")\n",
    "print(f\"pattern 'turn_left', 'empty', 'forward', 'wall' présent : {count_pattern(list_act_out, ['turn_left', 'empty', 'forward', 'wall'])}\")\n",
    "print(f\"pattern 'turn_right', 'empty', 'forward', 'empty' présent : {count_pattern(list_act_out, ['turn_right', 'empty', 'forward', 'empty'])}\")\n",
    "print(f\"pattern 'turn_right', 'empty', 'forward', 'wall' présent : {count_pattern(list_act_out, ['turn_right', 'empty', 'forward', 'wall'])}\")\n",
    "print(f\"pattern 'feel_front', 'empty', 'forward', 'empty' présent : {count_pattern(list_act_out, ['feel_front', 'empty', 'forward', 'empty'])}\")\n",
    "print(f\"pattern 'feel_front', 'empty', 'forward', 'wall' présent : {count_pattern(list_act_out, ['feel_front', 'empty', 'forward', 'wall'])}\")\n",
    "print(f\"pattern 'feel_front', 'wall', 'forward', 'empty' présent : {count_pattern(list_act_out, ['feel_front', 'wall', 'forward', 'empty'])}\")\n",
    "print(f\"pattern 'feel_front', 'wall', 'forward', 'wall' présent : {count_pattern(list_act_out, ['feel_front', 'wall', 'forward', 'wall'])}\")\n",
    "\n",
    "print(\"count si on feel_front\")\n",
    "print(f\"pattern 'forward', 'empty', 'feel_front', 'empty' présent : {count_pattern(list_act_out, ['forward', 'empty', 'feel_front', 'empty'])}\")\n",
    "print(f\"pattern 'forward', 'empty', 'feel_front', 'wall' présent : {count_pattern(list_act_out, ['forward', 'empty', 'feel_front', 'wall'])}\")\n",
    "print(f\"pattern 'forward', 'wall', 'feel_front', 'empty' présent : {count_pattern(list_act_out, ['forward', 'wall', 'feel_front', 'empty'])}\")\n",
    "print(f\"pattern 'forward', 'wall', 'feel_front', 'wall' présent : {count_pattern(list_act_out, ['forward', 'wall', 'feel_front', 'wall'])}\")\n",
    "print(f\"pattern 'turn_left', 'empty', 'feel_front', 'empty' présent : {count_pattern(list_act_out, ['turn_left', 'empty', 'feel_front', 'empty'])}\")\n",
    "print(f\"pattern 'turn_left', 'empty', 'feel_front', 'wall' présent : {count_pattern(list_act_out, ['turn_left', 'empty', 'feel_front', 'wall'])}\")\n",
    "print(f\"pattern 'turn_right', 'empty', 'feel_front', 'empty' présent : {count_pattern(list_act_out, ['turn_right', 'empty', 'feel_front', 'empty'])}\")\n",
    "print(f\"pattern 'turn_right', 'empty', 'feel_front', 'wall' présent : {count_pattern(list_act_out, ['turn_right', 'empty', 'feel_front', 'wall'])}\")\n",
    "print(f\"pattern 'feel_front', 'empty', 'feel_front', 'empty' présent : {count_pattern(list_act_out, ['feel_front', 'empty', 'feel_front', 'empty'])}\")\n",
    "print(f\"pattern 'feel_front', 'empty', 'feel_front', 'wall' présent : {count_pattern(list_act_out, ['feel_front', 'empty', 'feel_front', 'wall'])}\")\n",
    "print(f\"pattern 'feel_front', 'wall', 'feel_front', 'empty' présent : {count_pattern(list_act_out, ['feel_front', 'wall', 'feel_front', 'empty'])}\")\n",
    "print(f\"pattern 'feel_front', 'wall', 'feel_front', 'wall' présent : {count_pattern(list_act_out, ['feel_front', 'wall', 'feel_front', 'wall'])}\")\n",
    "\n",
    "print(\"count si on turn_left turn_right\")\n",
    "print(f\"pattern 'turn_left', 'empty', 'turn_left', 'empty' présent : {count_pattern(list_act_out, ['turn_left', 'empty', 'turn_left', 'empty'])}\")\n",
    "print(f\"pattern 'turn_right', 'empty', 'turn_left', 'empty' présent : {count_pattern(list_act_out, ['turn_right', 'empty', 'turn_left', 'empty'])}\")\n",
    "print(f\"pattern 'turn_right', 'empty', 'turn_right', 'empty' présent : {count_pattern(list_act_out, ['turn_right', 'empty', 'turn_right', 'empty'])}\")\n",
    "print(f\"pattern 'turn_left', 'empty', 'turn_right', 'empty' présent : {count_pattern(list_act_out, ['turn_left', 'empty', 'turn_right', 'empty'])}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See decision\n",
    "x = []\n",
    "for i in range(agent_test2._gap_test):\n",
    "    x.append(agent_test2._history_act[-(agent_test2._gap_test -i)])\n",
    "    x.append(agent_test2._history_fb[-(agent_test2._gap_test -i)])\n",
    "    print(-(agent_test2._gap_test -i), i)\n",
    "seq = agent_test2._tokenizer.encode(x)\n",
    "res = agent_test2.recursif_expective_valance(seq=seq, max_depth=3, seuil=0.4)\n",
    "top_5 = sorted(res.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "print(f\"Top 5 of sequences with the best expected valance for {x}\")\n",
    "for top in top_5:\n",
    "    print(f\"Sequence: {top[0]} Expected valance: {top[1]}\")\n",
    "\n",
    "print(f\"Action choisie : {eval(top_5[0][0])[0]}\")\n",
    "\n",
    "print(f'size of history act {len(agent_test2._history_act)}')\n",
    "print(f'size of history fb {len(agent_test2._history_fb)}')\n",
    "print(f'gap {agent_test2._gap_test}')\n",
    "\n",
    "print([i for i in zip(agent_test2._history_act, agent_test2._history_fb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_test2._history_act.append('feel_front')\n",
    "agent_test2._history_fb.append('empty')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Stage (torch)",
   "language": "python",
   "name": "dpt_transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
