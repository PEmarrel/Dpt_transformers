{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24ab00ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset \n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torch.distributions import Categorical\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from model.CustomDataSet import CustomDataSetRNN, SimpleDataSet\n",
    "from model.Tokenizer import SimpleTokenizerV1\n",
    "from model.TokenDrop import TokenDrop, TokenDropOdd, TokenDropEven\n",
    "from model.RNN import LSTM_representation, LSTM_GenText\n",
    "from environnement.gridWorld import gridWorld\n",
    "from outil import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54ba6be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\" if not torch.cuda.is_available() else \"cuda\"\n",
    "# device = \"cpu\" # Pour forcer l'utilisation du CPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999de020",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ac2baef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(env:env, tokenizer:SimpleTokenizerV1, n_episodes:int=1000):\n",
    "    \"\"\"\n",
    "    Generate data from the environment.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    all_action:list = env.get_actions()\n",
    "    for _ in range(n_episodes):\n",
    "        action = np.random.choice(all_action)\n",
    "        feedback = env.outcome(action)\n",
    "        data += tokenizer.encode([action, feedback])\n",
    "    return data\n",
    "\n",
    "def get_data_without(env:env, tokenizer:SimpleTokenizerV1, acts:list[str] , n_episodes:int=1000):\n",
    "    \"\"\"\n",
    "    Generate data from the environment.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    all_action:list = env.get_actions()\n",
    "    all_action = [element for element in all_action if element not in acts]\n",
    "    for _ in range(n_episodes):\n",
    "        action = np.random.choice(all_action)\n",
    "        feedback = env.outcome(action)\n",
    "        data += tokenizer.encode([action, feedback])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d740d3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The robot is in : 0  x: 1 y: 1\n",
      "World : [[1 1 1 1 1 1]\n",
      " [1 0 0 0 1 1]\n",
      " [1 0 1 0 0 1]\n",
      " [1 0 1 1 0 1]\n",
      " [1 0 0 0 0 1]\n",
      " [1 1 1 1 1 1]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env_test = gridWorld(x= 1, y=1, theta=0, world= np.array([\n",
    "                [1, 1, 1, 1, 1, 1],\n",
    "                [1, 0, 0, 0, 1, 1],\n",
    "                [1, 0, 1, 0, 0, 1],\n",
    "                [1, 0, 1, 1, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 1],\n",
    "                [1, 1, 1, 1, 1, 1],\n",
    "            ]))\n",
    "actions, outcomes = [], []\n",
    "env_test.display_world()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61548316",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b8b8b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_vocab = ['<pad>']\n",
    "for act in env_test.get_actions():\n",
    "    list_vocab.append(act)\n",
    "for fb in env_test.get_outcomes():\n",
    "    list_vocab.append(fb)    \n",
    "tmp = create_dico_numerate_word(list_vocab)\n",
    "tokenizer = SimpleTokenizerV1(vocab=tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989150c3",
   "metadata": {},
   "source": [
    "# X and Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9a922d",
   "metadata": {},
   "source": [
    "## Chaque séquence est complètement indépendante\n",
    "### Res :\n",
    "Spoil : au moins a partir de 500, > 95% d'acc (50 epoch) Attention on comptant les \"turn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c164ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_y.shape torch.Size([750, 100])\n"
     ]
    }
   ],
   "source": [
    "data_brut_y=[]\n",
    "for i in range(750):\n",
    "    data_brut_y.append(get_data(env_test, tokenizer, n_episodes=50))\n",
    "\n",
    "data_y = torch.tensor(data_brut_y)\n",
    "print(\"data_y.shape\", data_y.shape)\n",
    "data_loader = DataLoader(data_y, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a2048b",
   "metadata": {},
   "source": [
    "## Une grande séquence découper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03a7b72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 7, 3, 8, 1, 8, 5, 7, 6, 7, 1, 8, 2, 8, 2, 8, 4, 8, 5, 7, 2, 8, 4, 7, 3, 8, 5, 7, 5, 7, 6, 7, 3, 8, 5, 8, 1, 7, 5, 8, 2, 8, 1, 8, 3, 8, 5, 8, 5, 8, 1, 7, 5, 8, 4, 7, 1, 7, 5, 8, 5, 8, 6, 8, 4, 7, 5, 8, 2, 8, 3, 8, 4, 7, 3, 8, 1, 8, 3, 8, 1, 7, 6, 8, 3, 8, 6, 7, 6, 7, 1, 8, 4, 8, 4, 8, 6, 7, 2, 8, 2, 8, 2, 8, 4, 7, 1, 7, 6, 8, 6, 8, 3, 8, 6, 7, 2, 8, 5, 8, 5, 8, 4, 7, 1, 7, 2, 8, 3, 8, 3, 8, 1, 8, 6, 7, 3, 8, 6, 8, 5, 8, 4, 7, 1, 7, 3, 8, 5, 7, 2, 8, 6, 8, 3, 8, 3, 8, 2, 8, 3, 8, 6, 8, 3, 8, 6, 7, 2, 8, 4, 7, 5, 8, 5, 8, 4, 7, 3, 8, 5, 7, 6, 7, 6, 7, 6, 7, 6, 7, 3, 8, 3, 8, 2, 8, 3, 8, 1, 8]\n",
      "[[5, 7, 3, 8, 1, 8, 5, 7, 6, 7, 1, 8, 2, 8, 2, 8, 4, 8, 5, 7, 2, 8, 4, 7, 3, 8, 5, 7, 5, 7], [1, 8, 2, 8, 2, 8, 4, 8, 5, 7, 2, 8, 4, 7, 3, 8, 5, 7, 5, 7, 6, 7, 3, 8, 5, 8, 1, 7, 5, 8], [2, 8, 4, 7, 3, 8, 5, 7, 5, 7, 6, 7, 3, 8, 5, 8, 1, 7, 5, 8, 2, 8, 1, 8, 3, 8, 5, 8, 5, 8], [6, 7, 3, 8, 5, 8, 1, 7, 5, 8, 2, 8, 1, 8, 3, 8, 5, 8, 5, 8, 1, 7, 5, 8, 4, 7, 1, 7, 5, 8], [2, 8, 1, 8, 3, 8, 5, 8, 5, 8, 1, 7, 5, 8, 4, 7, 1, 7, 5, 8, 5, 8, 6, 8, 4, 7, 5, 8, 2, 8], [1, 7, 5, 8, 4, 7, 1, 7, 5, 8, 5, 8, 6, 8, 4, 7, 5, 8, 2, 8, 3, 8, 4, 7, 3, 8, 1, 8, 3, 8], [5, 8, 6, 8, 4, 7, 5, 8, 2, 8, 3, 8, 4, 7, 3, 8, 1, 8, 3, 8, 1, 7, 6, 8, 3, 8, 6, 7, 6, 7], [3, 8, 4, 7, 3, 8, 1, 8, 3, 8, 1, 7, 6, 8, 3, 8, 6, 7, 6, 7, 1, 8, 4, 8, 4, 8, 6, 7, 2, 8], [1, 7, 6, 8, 3, 8, 6, 7, 6, 7, 1, 8, 4, 8, 4, 8, 6, 7, 2, 8, 2, 8, 2, 8, 4, 7, 1, 7, 6, 8], [1, 8, 4, 8, 4, 8, 6, 7, 2, 8, 2, 8, 2, 8, 4, 7, 1, 7, 6, 8, 6, 8, 3, 8, 6, 7, 2, 8, 5, 8], [2, 8, 2, 8, 4, 7, 1, 7, 6, 8, 6, 8, 3, 8, 6, 7, 2, 8, 5, 8, 5, 8, 4, 7, 1, 7, 2, 8, 3, 8], [6, 8, 3, 8, 6, 7, 2, 8, 5, 8, 5, 8, 4, 7, 1, 7, 2, 8, 3, 8, 3, 8, 1, 8, 6, 7, 3, 8, 6, 8], [5, 8, 4, 7, 1, 7, 2, 8, 3, 8, 3, 8, 1, 8, 6, 7, 3, 8, 6, 8, 5, 8, 4, 7, 1, 7, 3, 8, 5, 7], [3, 8, 1, 8, 6, 7, 3, 8, 6, 8, 5, 8, 4, 7, 1, 7, 3, 8, 5, 7, 2, 8, 6, 8, 3, 8, 3, 8, 2, 8], [5, 8, 4, 7, 1, 7, 3, 8, 5, 7, 2, 8, 6, 8, 3, 8, 3, 8, 2, 8, 3, 8, 6, 8, 3, 8, 6, 7, 2, 8], [2, 8, 6, 8, 3, 8, 3, 8, 2, 8, 3, 8, 6, 8, 3, 8, 6, 7, 2, 8, 4, 7, 5, 8, 5, 8, 4, 7, 3, 8], [3, 8, 6, 8, 3, 8, 6, 7, 2, 8, 4, 7, 5, 8, 5, 8, 4, 7, 3, 8, 5, 7, 6, 7, 6, 7, 6, 7, 6, 7], [4, 7, 5, 8, 5, 8, 4, 7, 3, 8, 5, 7, 6, 7, 6, 7, 6, 7, 6, 7, 3, 8, 3, 8, 2, 8, 3, 8, 1, 8]]\n"
     ]
    }
   ],
   "source": [
    "data_brut = get_data(env_test, tokenizer, n_episodes=100)\n",
    "print(data_brut)\n",
    "def decoup_seq(seq:list, size:int, overlap:int=1):\n",
    "    \"\"\"\n",
    "    Decoupe une sequence en sous-sequence de taille size\n",
    "    \"\"\"\n",
    "    return [seq[i:i+size] for i in range(0, len(seq) - size +1, overlap)]\n",
    "\n",
    "data_decoup = decoup_seq(seq=data_brut, size=30, overlap=10)\n",
    "print(data_decoup)\n",
    "data_decoup = torch.tensor(data_decoup)\n",
    "data_loader_decoup = DataLoader(data_decoup, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f694b70d",
   "metadata": {},
   "source": [
    "data_y est alors notre Y. Pour obtenir notre X, nous utiliserons un token Dropen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5223c0cf",
   "metadata": {},
   "source": [
    "Notre x est donc data_x. Maintenant nous voulons que notre model arrive à obvenir un représentation de la séquence pour réussir a compléter les 0.\n",
    "\n",
    "# Multi tasks ?\n",
    "On peut vouloir un encoder qui apprend a encoder pour deviner les actions, et un encoder qui apprends a deviner les observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fbe47b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 7, 6,  ..., 8, 4, 7],\n",
      "        [4, 7, 1,  ..., 7, 5, 8],\n",
      "        [6, 7, 3,  ..., 7, 2, 8],\n",
      "        ...,\n",
      "        [5, 7, 1,  ..., 8, 5, 7],\n",
      "        [2, 8, 6,  ..., 7, 4, 7],\n",
      "        [4, 7, 2,  ..., 8, 5, 7]])\n",
      "len data_set 100\n",
      "data_set 1 tensor([5, 7, 6, 8, 2, 8, 5, 8, 3, 8, 4, 7, 1, 7, 3, 8, 4, 8, 3, 8, 1, 8, 2, 8,\n",
      "        4, 7, 2, 8, 1, 8, 1, 7, 2, 8, 4, 7, 3, 8, 1, 7, 3, 8, 2, 8, 6, 8, 4, 7,\n",
      "        1, 7, 1, 7, 6, 8, 2, 8, 6, 7, 3, 8, 6, 8, 5, 7, 6, 8, 3, 8, 1, 8, 3, 8,\n",
      "        6, 8, 2, 8, 5, 7, 5, 7, 5, 7, 4, 8, 4, 8, 5, 7, 3, 8, 4, 7, 6, 8, 5, 8,\n",
      "        6, 8, 4, 7])\n"
     ]
    }
   ],
   "source": [
    "data_set = SimpleDataSet(data_brut_y)\n",
    "\n",
    "print(\"len data_set\", data_set.__len__())\n",
    "print(\"data_set 1\", data_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1232a8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module, data_loader_train: DataLoader, nb_epoch: int, optimizer, loss_fn, pourcentTokenDrop:float=0.15):\n",
    "    td_act = TokenDropEven(pourcentTokenDrop, pad_token=0, num_special=2).to(device)\n",
    "    td_fb = TokenDropOdd(pourcentTokenDrop, pad_token=0, num_special=2).to(device)\n",
    "\n",
    "    model.train()\n",
    "    acc = 0\n",
    "    total_loss = 0\n",
    "    list_acc = []\n",
    "    list_loss = []\n",
    "    for j in tqdm(range(nb_epoch), desc=f\"Training \", unit=\"epoch\"):\n",
    "        acc_means = [0, 0]\n",
    "        loss_means = [0, 0]\n",
    "        \n",
    "        for i, data in enumerate(data_loader_train):\n",
    "            data = data.to(device)\n",
    "            data_mask_act = td_act(data)\n",
    "            data_mask_fb = td_fb(data)\n",
    "            bs = data.shape[0]\n",
    "            # print(\"batch size \", bs)\n",
    "\n",
    "            # Initialize the memory buffers\n",
    "            hidden = torch.zeros(2 * model.num_layers, bs, model.hidden_size, device=device)\n",
    "            memory = torch.zeros(2 * model.num_layers, bs, model.hidden_size, device=device)\n",
    "            # print(f'shape hidden and memory {hidden.shape} | {memory.shape}')\n",
    "            total_loss = 0  # Accumulate loss over both tasks\n",
    "\n",
    "            for k, tasks in enumerate([data_mask_act, data_mask_fb]):\n",
    "                # Forward pass\n",
    "                tasks = tasks.to(device)\n",
    "                proba, hidden, memory = model(tasks, hidden, memory)\n",
    "                proba = proba.transpose(1, 2)\n",
    "                pred = proba.argmax(dim=1)\n",
    "                pad_mask = (tasks == 0)\n",
    "                correct = (pred == data) & pad_mask\n",
    "                acc = correct.sum().item() / pad_mask.sum().item() if pad_mask.sum().item() > 0 else 0.0\n",
    "                acc_means[k] += acc\n",
    "                \n",
    "                loss = loss_fn(proba, data)\n",
    "                total_loss += loss\n",
    "                loss_means[k] += loss.item()\n",
    "                \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "        acc_means = [acc / len(data_loader_train) for acc in acc_means]\n",
    "        loss_means = [loss / len(data_loader_train) for loss in loss_means]\n",
    "        list_acc.append(acc_means)\n",
    "        list_loss.append(loss_means)\n",
    "        tqdm.write(f\"Epoch {j + 1}/{nb_epoch}, Loss: {loss_means}, Accuracy: {acc_means}\")\n",
    "        \n",
    "    return list_acc, list_loss\n",
    "        \n",
    "def train_fb(model: nn.Module, data_loader_train: DataLoader, nb_epoch: int, optimizer, loss_fn, pourcentTokenDrop:float=0.15):\n",
    "    td_fb = TokenDropOdd(pourcentTokenDrop, pad_token=0, num_special=2).to(device)\n",
    "\n",
    "    model.train()\n",
    "    list_acc = []\n",
    "    list_loss = []\n",
    "    for j in trange(nb_epoch, desc=f\"Training \", unit=\"epoch\"):\n",
    "        acc_means = 0\n",
    "        loss_means = 0\n",
    "        \n",
    "        for i, data in enumerate(data_loader_train):\n",
    "            data = data.to(device)\n",
    "            data_mask_fb = td_fb(data).to(device)\n",
    "            bs = data.shape[0]\n",
    "            # print(\"batch size \", bs)\n",
    "\n",
    "            # Initialize the memory buffers\n",
    "            hidden = torch.zeros(2 * model.num_layers, bs, model.hidden_size, device=device)\n",
    "            memory = torch.zeros(2 * model.num_layers, bs, model.hidden_size, device=device)\n",
    "            # print(f'shape hidden and memory {hidden.shape} | {memory.shape}')\n",
    "                        \n",
    "            proba, hidden, memory = model(data_mask_fb, hidden, memory)\n",
    "            proba = proba.transpose(1, 2)\n",
    "            pred = proba.argmax(dim=1)\n",
    "            pad_mask = (data_mask_fb == 0)\n",
    " \n",
    "            correct = (pred == data) & pad_mask\n",
    "            acc = correct.sum().item() / pad_mask.sum().item() if pad_mask.sum().item() > 0 else 0.0\n",
    "            acc_means += acc\n",
    "        \n",
    "            loss = loss_fn(proba, data) \n",
    "            loss_means += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        acc_means /= len(data_loader_train)\n",
    "        loss_means /= len(data_loader_train)\n",
    "        list_acc.append(acc_means)\n",
    "        list_loss.append(loss_means)\n",
    "        tqdm.write(f\"Epoch {j + 1}/{nb_epoch}, Loss: {loss_means}, Accuracy: {acc_means}\")\n",
    "    return list_acc, list_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4519e2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_fb_decoup = LSTM_representation(\n",
    "#     num_emb=len(list_vocab),\n",
    "#     hidden_size=256,\n",
    "#     emb_size=256,\n",
    "#     num_layers=2,\n",
    "#     dropout=0\n",
    "# ).to(device)\n",
    "\n",
    "# optimizer_fb_decoup = optim.Adam(model_fb_decoup.parameters(), lr=0.001)\n",
    "# loss_fn_fb_decoup = nn.CrossEntropyLoss()\n",
    "\n",
    "# list_loss, list_acc = train_fb(\n",
    "#     model=model_fb_decoup,\n",
    "#     data_loader_train=data_loader_decoup,\n",
    "#     nb_epoch=100,\n",
    "#     optimizer=optimizer_fb_decoup,\n",
    "#     loss_fn=loss_fn_fb_decoup,\n",
    "#     pourcentTokenDrop=0.1\n",
    "# )\n",
    "# # Plot\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(list_loss, label='Loss')\n",
    "# plt.plot(list_acc, label='Accuracy')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Value')\n",
    "# plt.title('Training Loss and Accuracy')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7836b58d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e20ad33f69734365bc5036f502ef756d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training :   0%|          | 0/75 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75, Loss: 1.019886481159545, Accuracy: 0.5721415537041312\n",
      "Epoch 2/75, Loss: 0.05883778615834865, Accuracy: 0.7078127532226981\n",
      "Epoch 3/75, Loss: 0.05594333871564967, Accuracy: 0.7064657046604323\n",
      "Epoch 4/75, Loss: 0.052708440163034075, Accuracy: 0.7334297654150528\n",
      "Epoch 5/75, Loss: 0.0493496558926207, Accuracy: 0.7619321550865948\n",
      "Epoch 6/75, Loss: 0.045580083306165455, Accuracy: 0.7916781565347092\n",
      "Epoch 7/75, Loss: 0.04273708576851703, Accuracy: 0.8133479660413206\n",
      "Epoch 8/75, Loss: 0.03856554726495388, Accuracy: 0.840313496529025\n",
      "Epoch 9/75, Loss: 0.03567686082517847, Accuracy: 0.8468464304388464\n",
      "Epoch 10/75, Loss: 0.0334672776863296, Accuracy: 0.8644159890056416\n",
      "Epoch 11/75, Loss: 0.029568649907695487, Accuracy: 0.8822674862528521\n",
      "Epoch 12/75, Loss: 0.02951660617551905, Accuracy: 0.8879806029426287\n",
      "Epoch 13/75, Loss: 0.02474559492808073, Accuracy: 0.9090861949020284\n",
      "Epoch 14/75, Loss: 0.02253257703194593, Accuracy: 0.9202034042512709\n",
      "Epoch 15/75, Loss: 0.02125826682102807, Accuracy: 0.9215912341432758\n",
      "Epoch 16/75, Loss: 0.019854651011051015, Accuracy: 0.9324677659268541\n",
      "Epoch 17/75, Loss: 0.018775597422760217, Accuracy: 0.9360953795974287\n",
      "Epoch 18/75, Loss: 0.01599664991087419, Accuracy: 0.9483843279142827\n",
      "Epoch 19/75, Loss: 0.015826351772201187, Accuracy: 0.946203474125049\n",
      "Epoch 20/75, Loss: 0.013415098200215305, Accuracy: 0.9555996021918018\n",
      "Epoch 21/75, Loss: 0.01254328806944033, Accuracy: 0.9620978856500872\n",
      "Epoch 22/75, Loss: 0.013046734748368568, Accuracy: 0.9604971780428968\n",
      "Epoch 23/75, Loss: 0.01071494673081535, Accuracy: 0.9677248653570791\n",
      "Epoch 24/75, Loss: 0.011976160416181417, Accuracy: 0.9631176557435451\n",
      "Epoch 25/75, Loss: 0.010617922634837474, Accuracy: 0.9677321721154433\n",
      "Epoch 26/75, Loss: 0.011994988058119061, Accuracy: 0.9625201190795841\n",
      "Epoch 27/75, Loss: 0.009851102097990347, Accuracy: 0.9691446472872929\n",
      "Epoch 28/75, Loss: 0.010729724466998844, Accuracy: 0.9650423832367144\n",
      "Epoch 29/75, Loss: 0.01160521114720626, Accuracy: 0.9623949767774183\n",
      "Epoch 30/75, Loss: 0.00978797113403995, Accuracy: 0.9695309402859655\n",
      "Epoch 31/75, Loss: 0.013005482785879298, Accuracy: 0.9577276901764792\n",
      "Epoch 32/75, Loss: 0.009432633328152465, Accuracy: 0.9711681424096148\n",
      "Epoch 33/75, Loss: 0.009462890661063981, Accuracy: 0.9710063944911084\n",
      "Epoch 34/75, Loss: 0.008921806378527842, Accuracy: 0.9741826918298813\n",
      "Epoch 35/75, Loss: 0.0074372694287647275, Accuracy: 0.9782117700456249\n",
      "Epoch 36/75, Loss: 0.0074247434621359755, Accuracy: 0.9767364832964335\n",
      "Epoch 37/75, Loss: 0.008600436319458359, Accuracy: 0.9726646244510447\n",
      "Epoch 38/75, Loss: 0.007903116673449093, Accuracy: 0.9754770914513524\n",
      "Epoch 39/75, Loss: 0.006971770129661927, Accuracy: 0.9789034940208837\n",
      "Epoch 40/75, Loss: 0.00899364619684267, Accuracy: 0.9739998986640339\n",
      "Epoch 41/75, Loss: 0.008364468362142748, Accuracy: 0.9732474351411444\n",
      "Epoch 42/75, Loss: 0.007606975848172257, Accuracy: 0.9759986113099729\n",
      "Epoch 43/75, Loss: 0.012221015531549905, Accuracy: 0.9621451343204419\n",
      "Epoch 44/75, Loss: 0.009604622060036722, Accuracy: 0.9702227203445212\n",
      "Epoch 45/75, Loss: 0.007665569884108102, Accuracy: 0.9765300690407671\n",
      "Epoch 46/75, Loss: 0.00846639774402881, Accuracy: 0.9764890316286409\n",
      "Epoch 47/75, Loss: 0.008323125318287218, Accuracy: 0.974846541775468\n",
      "Epoch 48/75, Loss: 0.008856222526408098, Accuracy: 0.9728440485940248\n",
      "Epoch 49/75, Loss: 0.0072602383455539, Accuracy: 0.9762514305099369\n",
      "Epoch 50/75, Loss: 0.006622990125175962, Accuracy: 0.9798603842024183\n",
      "Epoch 51/75, Loss: 0.007949948214252102, Accuracy: 0.9769197155302076\n",
      "Epoch 52/75, Loss: 0.014243468107219706, Accuracy: 0.9540369075020677\n",
      "Epoch 53/75, Loss: 0.008356590304484076, Accuracy: 0.9728563958496922\n",
      "Epoch 54/75, Loss: 0.008202297117640363, Accuracy: 0.9751348743733372\n",
      "Epoch 55/75, Loss: 0.0070359221302924, Accuracy: 0.977474109886052\n",
      "Epoch 56/75, Loss: 0.0058792352582268574, Accuracy: 0.9826799079786923\n",
      "Epoch 57/75, Loss: 0.005232654516263172, Accuracy: 0.9840541197939788\n",
      "Epoch 58/75, Loss: 0.005845742124291335, Accuracy: 0.981602915759202\n",
      "Epoch 59/75, Loss: 0.00510258753684924, Accuracy: 0.9832821994251779\n",
      "Epoch 60/75, Loss: 0.00822691184448752, Accuracy: 0.9761749693596936\n",
      "Epoch 61/75, Loss: 0.006119102425377896, Accuracy: 0.9818824283948917\n",
      "Epoch 62/75, Loss: 0.005356611205918833, Accuracy: 0.9833612328125119\n",
      "Epoch 63/75, Loss: 0.006910505341712702, Accuracy: 0.9790002297622717\n",
      "Epoch 64/75, Loss: 0.006513226584115244, Accuracy: 0.9791251123292856\n",
      "Epoch 65/75, Loss: 0.0064234252612879305, Accuracy: 0.9798261731143382\n",
      "Epoch 66/75, Loss: 0.004742954884893558, Accuracy: 0.9858282087030279\n",
      "Epoch 67/75, Loss: 0.008383702350522769, Accuracy: 0.9755200323185003\n",
      "Epoch 68/75, Loss: 0.00741367018286218, Accuracy: 0.9776944697035339\n",
      "Epoch 69/75, Loss: 0.006586805691922757, Accuracy: 0.980848297872386\n",
      "Epoch 70/75, Loss: 0.005620643532428732, Accuracy: 0.9814835583717061\n",
      "Epoch 71/75, Loss: 0.0045942692185177445, Accuracy: 0.9855902254391671\n",
      "Epoch 72/75, Loss: 0.0049313902681534915, Accuracy: 0.9836830550368756\n",
      "Epoch 73/75, Loss: 0.006202972570850336, Accuracy: 0.9811740968701795\n",
      "Epoch 74/75, Loss: 0.0053706967514602745, Accuracy: 0.9821463115440057\n",
      "Epoch 75/75, Loss: 0.00533560643398619, Accuracy: 0.9829940575107994\n"
     ]
    }
   ],
   "source": [
    "num_layers = 4\n",
    "hidden_size = 256\n",
    "model_fb = LSTM_representation(\n",
    "    num_emb=len(list_vocab),\n",
    "    hidden_size=hidden_size,\n",
    "    emb_size=hidden_size,\n",
    "    num_layers=num_layers,\n",
    "    dropout=0\n",
    ").to(device)\n",
    "# 32 = 95 % | plus de 32 = 95 %\n",
    "# 16 < 90 %\n",
    "optimizer_fb = optim.Adam(model_fb.parameters(), lr=0.001)\n",
    "loss_fn_fb = nn.CrossEntropyLoss()\n",
    "\n",
    "list_acc, list_loss = train_fb(\n",
    "    model=model_fb,\n",
    "    data_loader_train=data_loader,\n",
    "    nb_epoch=75,\n",
    "    optimizer=optimizer_fb,\n",
    "    loss_fn=loss_fn_fb,\n",
    "    pourcentTokenDrop=0.25\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7248bc28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(10, 10))\n",
    "# plt.plot(list_loss, label='Loss')\n",
    "plt.plot(list_acc[-20:], label='Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Training Loss and Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319352f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The robot is in : 0  x: 1 y: 1\n",
      "World : [[1 1 1 1 1 1]\n",
      " [1 0 0 0 0 1]\n",
      " [1 0 0 1 0 1]\n",
      " [1 0 1 0 0 1]\n",
      " [1 0 0 0 0 1]\n",
      " [1 1 1 1 1 1]]\n",
      "count_8 empty 10385\n",
      "count_7 wall 9615\n",
      "data_infos {'sequence': [5, 7, 6, 8, 1, 8, 6, 7, 2, 8, 5, 8, 4, 7, 3, 8, 4, 8, 4, 8, 2, 8, 6, 8, 2, 8, 2, 8, 1, 7, 3, 8, 3, 8, 4, 7, 4, 7, 1, 7, 3, 8, 5, 7, 6, 7, 1, 8, 5, 7, 3, 8, 1, 8, 5, 7, 5, 7, 4, 8, 5, 7, 5, 7, 6, 7, 5, 7, 2, 8, 4, 7, 2, 8, 5, 7, 1, 8, 2, 8, 1, 8, 4, 8, 1, 8, 2, 8, 6, 8, 4, 8, 2, 8, 3, 8, 4, 8, 5, 8], 'coo': (2, 1), 'theta': 2, 'last_act': 'feel_left', 'last_feedback': 'empty', 'info_in_sequence': True, 'feel_front': 'empty', 'feel_left': 'empty', 'feel_right': 'empty'}\n",
      "x  [5, 7, 6, 8, 1, 8, 6, 7, 2, 8, 5, 8, 4, 7, 3, 8, 4, 8, 4, 8, 2, 8, 6, 8, 2, 8, 2, 8, 1, 7, 3, 8, 3, 8, 4, 7, 4, 7, 1, 7, 3, 8, 5, 7, 6, 7, 1, 8, 5, 7, 3, 8, 1, 8, 5, 7, 5, 7, 4, 8, 5, 7, 5, 7, 6, 7, 5, 7, 2, 8, 4, 7, 2, 8, 5, 7, 1, 8, 2, 8, 1, 8, 4, 8, 1, 8, 2, 8, 6, 8, 4, 8, 2, 8, 3, 8, 4, 8, 5, 0]\n",
      "y  8\n"
     ]
    }
   ],
   "source": [
    "env_test = gridWorld(x= 1, y=1, theta=0, world= np.array([\n",
    "                [1, 1, 1, 1, 1, 1],\n",
    "                [1, 0, 0, 0, 0, 1],\n",
    "                [1, 0, 0, 1, 0, 1],\n",
    "                [1, 0, 1, 0, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 1],\n",
    "                [1, 1, 1, 1, 1, 1],\n",
    "            ]))\n",
    "\n",
    "data_test_x = []\n",
    "data_test_y = []\n",
    "data_infos = []\n",
    "for i in range(20000):\n",
    "    # range_context = np.random.randint(10, 20)\n",
    "    range_context = 10\n",
    "    last_act = \"turn_left\"\n",
    "    while last_act == \"turn_left\" or last_act == \"turn_right\":\n",
    "        sequence = get_data(env_test, tokenizer, n_episodes=range_context)\n",
    "        last_act = tokenizer.decode(sequence[-2])\n",
    "            \n",
    "    data_test_x.append(sequence[:-1] + [0])    \n",
    "    data_test_y.append(sequence[-1])\n",
    "    \n",
    "    data_infos.append({\n",
    "        \"sequence\": sequence,\n",
    "        \"coo\": env_test.get_coo(),\n",
    "        \"theta\": env_test.get_theta(),\n",
    "        \"last_act\": last_act,\n",
    "        \"last_feedback\": tokenizer.decode(sequence[-1]),\n",
    "        \"info_in_sequence\": bool(info_in_seq(tokenizer.decode(data_test_x[-1]), 6))\n",
    "    })\n",
    "    around = ''\n",
    "    for feel in [\"feel_front\", \"feel_left\", \"feel_right\"]:\n",
    "        state = env_test.outcome(feel)\n",
    "        data_infos[-1][feel] = state\n",
    "        around += f\"{state}|\"\n",
    "    \n",
    "# print(\"data_test_x\", data_test_x)\n",
    "# print(\"data_test_y\", data_test_y)\n",
    "\n",
    "# count 9 and 8 in data_test_y\n",
    "count_7 = 0\n",
    "count_8 = 0\n",
    "\n",
    "for i in data_test_y:\n",
    "    if i == 8:\n",
    "        count_8 += 1\n",
    "    elif i == 7:\n",
    "        count_7 += 1\n",
    "print(f\"count_8 {tokenizer.decode(8)}\", count_8)\n",
    "print(f\"count_7 {tokenizer.decode(7)}\", count_7)\n",
    "\n",
    "print(\"data_infos\", data_infos[0])\n",
    "print(\"x \", data_test_x[0])\n",
    "print(\"y \", data_test_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcab0b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 7, 6, 8, 1, 8, 6, 7, 2, 8, 5, 8, 4, 7, 3, 8, 4, 8, 4, 8, 2, 8, 6, 8,\n",
      "         2, 8, 2, 8, 1, 7, 3, 8, 3, 8, 4, 7, 4, 7, 1, 7, 3, 8, 5, 7, 6, 7, 1, 8,\n",
      "         5, 7, 3, 8, 1, 8, 5, 7, 5, 7, 4, 8, 5, 7, 5, 7, 6, 7, 5, 7, 2, 8, 4, 7,\n",
      "         2, 8, 5, 7, 1, 8, 2, 8, 1, 8, 4, 8, 1, 8, 2, 8, 6, 8, 4, 8, 2, 8, 3, 8,\n",
      "         4, 8, 5, 0]])\n",
      "tensor([8])\n",
      "sequence: [tensor([5]), tensor([7]), tensor([6]), tensor([8]), tensor([1]), tensor([8]), tensor([6]), tensor([7]), tensor([2]), tensor([8]), tensor([5]), tensor([8]), tensor([4]), tensor([7]), tensor([3]), tensor([8]), tensor([4]), tensor([8]), tensor([4]), tensor([8]), tensor([2]), tensor([8]), tensor([6]), tensor([8]), tensor([2]), tensor([8]), tensor([2]), tensor([8]), tensor([1]), tensor([7]), tensor([3]), tensor([8]), tensor([3]), tensor([8]), tensor([4]), tensor([7]), tensor([4]), tensor([7]), tensor([1]), tensor([7]), tensor([3]), tensor([8]), tensor([5]), tensor([7]), tensor([6]), tensor([7]), tensor([1]), tensor([8]), tensor([5]), tensor([7]), tensor([3]), tensor([8]), tensor([1]), tensor([8]), tensor([5]), tensor([7]), tensor([5]), tensor([7]), tensor([4]), tensor([8]), tensor([5]), tensor([7]), tensor([5]), tensor([7]), tensor([6]), tensor([7]), tensor([5]), tensor([7]), tensor([2]), tensor([8]), tensor([4]), tensor([7]), tensor([2]), tensor([8]), tensor([5]), tensor([7]), tensor([1]), tensor([8]), tensor([2]), tensor([8]), tensor([1]), tensor([8]), tensor([4]), tensor([8]), tensor([1]), tensor([8]), tensor([2]), tensor([8]), tensor([6]), tensor([8]), tensor([4]), tensor([8]), tensor([2]), tensor([8]), tensor([3]), tensor([8]), tensor([4]), tensor([8]), tensor([5]), tensor([8])]\n",
      "coo: [tensor([2]), tensor([1])]\n",
      "theta: tensor([2])\n",
      "last_act: ['feel_left']\n",
      "last_feedback: ['empty']\n",
      "info_in_sequence: tensor([True])\n",
      "feel_front: ['empty']\n",
      "feel_left: ['empty']\n",
      "feel_right: ['empty']\n"
     ]
    }
   ],
   "source": [
    "length = max(len(xi) for xi in data_test_x)\n",
    "data_test_x_tensor = torch.zeros((len(data_test_x), length), dtype=torch.long)\n",
    "for i, xi in enumerate(data_test_x):\n",
    "    data_test_x_tensor[i, :len(xi)] = torch.tensor(xi, dtype=torch.long)\n",
    "data_test_y_tensor = torch.tensor(data_test_y, dtype=torch.long)\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data:torch.Tensor, targets:torch.Tensor, data_infos):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.infos = data_infos\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        target = self.targets[idx]\n",
    "        info = self.infos[idx]\n",
    "        return sample, target, info\n",
    "\n",
    "data_loader_test = DataLoader(CustomDataset(data_test_x_tensor, data_test_y_tensor, data_infos), batch_size=1, shuffle=False)\n",
    "\n",
    "for i, (data_x, data_y, info) in enumerate(data_loader_test):\n",
    "    print(data_x)\n",
    "    print(data_y)\n",
    "    for key, value in info.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9df8c814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da76b51ccf30414791c4f3b37f31faa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8818\n"
     ]
    }
   ],
   "source": [
    "model_fb.eval()\n",
    "acc = 0\n",
    "\n",
    "data_frame_seq = pd.DataFrame({\n",
    "    \"seq\": [\"\"] * len(data_loader_test),\n",
    "    \"seq_dec\": [\"\"] * len(data_loader_test),\n",
    "    \"prediction\": [\"\"] * len(data_loader_test),\n",
    "    \"prediction_dec\": [\"\"] * len(data_loader_test),\n",
    "    \"reality\": [\"\"] * len(data_loader_test),\n",
    "    \"reality_dec\": [\"\"] * len(data_loader_test),\n",
    "    \"probability\": [\"\"] * len(data_loader_test),\n",
    "    \"good_prediction\": [False] * len(data_loader_test),\n",
    "    \"info_in_seq\": [False] * len(data_loader_test),\n",
    "    \"info_feel_left\": [False] * len(data_loader_test),\n",
    "    \"info_feel_front\": [False] * len(data_loader_test),\n",
    "    \"info_feel_right\": [False] * len(data_loader_test),\n",
    "    \"coo_xy\": [\"\"] * len(data_loader_test),\n",
    "    \"theta\": [-1] * len(data_loader_test),\n",
    "    \"state_left\": [\"\"] * len(data_loader_test),\n",
    "    \"state_front\": [\"\"] * len(data_loader_test),\n",
    "    \"state_right\": [\"\"] * len(data_loader_test),\n",
    "    \n",
    "})\n",
    "\n",
    "# data_frame_seq = data_frame_seq.astype({\n",
    "#     \"seq\": \"object\",\n",
    "#     \"prediction\": \"U20\",\n",
    "#     \"reality\": \"object\",\n",
    "#     \"probability\": \"object\",\n",
    "#     \"good_prediction\": \"bool\",\n",
    "#     \"info_in_seq\": \"bool\",\n",
    "#     \"info_feel_left\": \"bool\",\n",
    "#     \"info_feel_front\": \"bool\",\n",
    "#     \"info_feel_right\": \"bool\",\n",
    "#     \"coo_xy\": \"object\",\n",
    "#     \"theta\": \"int64\"\n",
    "# })\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (input, target, info) in tqdm(enumerate(data_loader_test)):\n",
    "        input = input.to(device)\n",
    "        target = target.to(device)\n",
    "        h = torch.zeros(model_fb.num_layers * 2, 1, model_fb.hidden_size).to(device)\n",
    "        cell = torch.zeros(model_fb.num_layers * 2, 1, model_fb.hidden_size).to(device)\n",
    "        output, h, cell = model_fb(input, h, cell)\n",
    "        \n",
    "        arrays, x, y, theta = process_sequence(tokenizer.decode(input.tolist()[0]), 6, None)\n",
    "        good_seq = info_in_memory(arrays)\n",
    "        feel_left, feel_front, feel_right = feel_info_end_sequence(tokenizer.decode(input.tolist()[0]), 6, (arrays, x, y, theta))\n",
    "        \n",
    "        proba = F.softmax(output, dim=-1)\n",
    "        output = output.transpose(1, 2)\n",
    "        pred = output.argmax(dim=1)\n",
    "        acc += (pred[-1][-1] == target).item()\n",
    "        state_left = info[\"feel_left\"][0]\n",
    "        state_front = info[\"feel_front\"][0]\n",
    "        state_right = info[\"feel_right\"][0]\n",
    "        coo = (info[\"coo\"][0].item(), info[\"coo\"][1].item())\n",
    "        theta = info[\"theta\"][0].item()\n",
    "\n",
    "        data_frame_seq.loc[i] = [\n",
    "            str(input.tolist()[0]),\n",
    "            str(tokenizer.decode(input.tolist()[0])),\n",
    "            str(pred.tolist()[0][-1]),\n",
    "            str(tokenizer.decode(pred.tolist()[0][-1])),\n",
    "            target.tolist()[0],\n",
    "            tokenizer.decode(target.tolist()[0]),\n",
    "            str(proba.tolist()[-1][-1][-2:]),\n",
    "            (pred[-1][-1] == target).item(),\n",
    "            good_seq,\n",
    "            feel_left,\n",
    "            feel_front,\n",
    "            feel_right,\n",
    "            str(coo),\n",
    "            theta,\n",
    "            state_left,\n",
    "            state_front,\n",
    "            state_right\n",
    "        ]\n",
    "print(f\"Accuracy: {acc / 20000}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "405b2548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52a34203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feel_front', 'wall', 'turn_right', 'empty', 'turn_right', 'empty', 'feel_front', 'empty', 'turn_right', 'empty', 'feel_front', 'wall', 'turn_right', 'empty', 'turn_right', 'empty', 'turn_right', 'empty', 'feel_front', '<pad>']\n",
      "['feel_front', 'wall', 'turn_right', 'empty', 'turn_right', 'empty', 'feel_front', 'empty', 'turn_right', 'empty', 'feel_front', 'wall', 'turn_right', 'empty', 'turn_right', 'empty', 'turn_right', 'empty', 'feel_front', 'empty']\n",
      "proba for last token tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0040, 0.9960],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "['turn_right', 'empty', 'turn_left', 'empty', 'feel_front', 'wall', 'feel_front', 'wall', 'forward', 'wall', 'feel_right', 'empty', 'feel_right', 'empty', 'feel_front', 'wall', 'feel_left', 'wall', 'feel_front', 'wall']\n",
      "proba for last token tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9900, 0.0090],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "['turn_right', 'empty', 'turn_left', 'empty', 'feel_front', 'wall', 'feel_front', 'wall', 'forward', 'wall', 'feel_right', 'empty', 'feel_right', 'empty', 'feel_front', 'wall', 'feel_left', 'wall', 'feel_left', 'wall']\n",
      "proba for last token tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9250, 0.0750],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model_fb.eval()\n",
    "prompt = tokenizer.encode(\n",
    "['feel_front', 'wall', 'turn_right', 'empty', 'turn_right', 'empty', 'feel_front', 'empty', 'turn_right', 'empty', 'feel_front', 'wall', 'turn_right', 'empty', 'turn_right', 'empty', 'turn_right', 'empty', 'feel_front', '<pad>']\n",
    ")\n",
    "\n",
    "hidden = torch.zeros(2 * model_fb.num_layers, 1, model_fb.hidden_size).to(device)\n",
    "memory = torch.zeros(2 * model_fb.num_layers, 1, model_fb.hidden_size).to(device)\n",
    "\n",
    "prompt_tensor = torch.tensor(prompt).to(device)\n",
    "prompt_tensor = prompt_tensor.unsqueeze(0)\n",
    "_proba, hidden, memory = model_fb(prompt_tensor, hidden, memory)\n",
    "proba = _proba.transpose(1, 2)\n",
    "pred = proba.argmax(dim=1)\n",
    "\n",
    "print(tokenizer.decode(prompt_tensor[0].tolist()))\n",
    "print(tokenizer.decode(pred[0].tolist()))\n",
    "print(\"proba for last token\", torch.round(F.softmax(_proba[0, -1, :], dim=0) * 1000) / 1000)\n",
    "prompt = tokenizer.encode(\n",
    "    ['turn_right', 'empty', 'turn_left', 'empty', 'feel_front', 'wall', 'feel_front', 'wall', \n",
    "     'forward', 'wall', 'feel_right', 'empty', 'feel_right', 'empty', 'feel_front', 'wall', \n",
    "     'feel_left', 'wall', 'feel_front', '<pad>'])\n",
    "\n",
    "\n",
    "hidden = torch.zeros(2 * model_fb.num_layers, 1, model_fb.hidden_size).to(device)\n",
    "memory = torch.zeros(2 * model_fb.num_layers, 1, model_fb.hidden_size).to(device)\n",
    "\n",
    "prompt_tensor = torch.tensor(prompt).to(device)\n",
    "prompt_tensor = prompt_tensor.unsqueeze(0)\n",
    "_proba, hidden, memory = model_fb(prompt_tensor, hidden, memory)\n",
    "proba = _proba.transpose(1, 2)\n",
    "pred = proba.argmax(dim=1)\n",
    "\n",
    "print(tokenizer.decode(pred[0].tolist()))\n",
    "print(\"proba for last token\", torch.round(F.softmax(_proba[0, -1, :], dim=0) * 1000) / 1000)\n",
    "\n",
    "prompt = tokenizer.encode(\n",
    "    ['turn_right', 'empty', 'turn_left', 'empty', 'feel_front', 'wall', 'feel_front', 'wall', \n",
    "     'forward', 'wall', 'feel_right', 'empty', 'feel_right', 'empty', 'feel_front', 'wall', \n",
    "     'feel_left', 'wall', 'feel_left', '<pad>'])\n",
    "\n",
    "hidden = torch.zeros(2 * model_fb.num_layers, 1, model_fb.hidden_size).to(device)\n",
    "memory = torch.zeros(2 * model_fb.num_layers, 1, model_fb.hidden_size).to(device)\n",
    "\n",
    "prompt_tensor = torch.tensor(prompt).to(device)\n",
    "prompt_tensor = prompt_tensor.unsqueeze(0)\n",
    "_proba, hidden, memory = model_fb(prompt_tensor, hidden, memory)\n",
    "proba = _proba.transpose(1, 2)\n",
    "pred = proba.argmax(dim=1)\n",
    "\n",
    "print(tokenizer.decode(pred[0].tolist()))\n",
    "print(\"proba for last token\", torch.round(F.softmax(_proba[0, -1, :], dim=0) * 1000) / 1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bb7b709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence: [1, 7, 1, 7, 2, 8, 6, 7, 6, 7, 3, 8, 3, 8, 5, 7, 6, 8, 4, 8, 4, 8, 1, 8, 1, 8, 1, 8, 5, 7, 4, 7, 5, 7, 1, 7, 2, 8, 5, 8, 4, 7, 4, 7, 4, 7, 5, 8, 3, 8, 4, 7, 2, 8, 3, 8, 4, 7, 1, 7, 3, 8, 1, 8, 5, 7, 4, 8, 6, 8, 4, 8, 4, 8, 5, 7, 1, 8, 3, 8, 6, 8, 2, 8, 4, 8, 1, 8, 2, 8, 1, 7, 2, 8, 3, 8, 2, 8, 4, 8]\n",
      "coo: (4, 1)\n",
      "theta: 3\n",
      "last_act: feel_front\n",
      "last_feedback: empty\n",
      "info_in_sequence: True\n",
      "feel_front: empty\n",
      "feel_left: empty\n",
      "feel_right: wall\n"
     ]
    }
   ],
   "source": [
    "for key, value in data_infos[56].items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c744c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only row with good_prediction = True\n",
    "data_frame_seq_success = data_frame_seq.loc[data_frame_seq[\"good_prediction\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42d84e9",
   "metadata": {},
   "source": [
    "# Résultat\n",
    "\n",
    "0.96 % d'accuracy  \n",
    "\n",
    "data test est constituer de 82% sequence dont l'information/feedback demandé a été vue  \n",
    "\n",
    "Sur la partie où l’information n'est pas dans la séquence, l'accuracy tombe à 83%  \n",
    "\n",
    "Sur la partie où l’information est dans la séquence, l'accuracy monte à 99%\n",
    "\n",
    "## Not same environment\n",
    "Quand il n'y a pas le même environment (autre grille) entre le train et le teste, \n",
    "acc = 83%\n",
    "  \n",
    "Si nous prenons que les seq avec infos alors on passe à 97% \n",
    "\n",
    "## Big context\n",
    "0.97 % \n",
    "92% on une séquence avec une infos\n",
    "sinon même stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94734286",
   "metadata": {},
   "source": [
    "# Embeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "796473d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_in torch.Size([8, 1, 256])\n",
      "mem_in torch.Size([8, 1, 256])\n",
      "data_infos_success 17065\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 88.00 MiB. GPU 0 has a total capacity of 5.67 GiB of which 89.12 MiB is free. Including non-PyTorch memory, this process has 5.56 GiB memory in use. Of the allocated memory 5.28 GiB is allocated by PyTorch, and 145.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m all_embedding\u001b[38;5;241m.\u001b[39mappend(model_fb\u001b[38;5;241m.\u001b[39membedding(input_seq))\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# print(\"input_seq\", input_seq.shape)\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m output, (hidden_out, mem_out) \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_fb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_embedding\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m all_hidden\u001b[38;5;241m.\u001b[39mappend(hidden_out[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     26\u001b[0m all_mem\u001b[38;5;241m.\u001b[39mappend(mem_out[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/stage/Dpt_transformers/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/stage/Dpt_transformers/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/stage/Dpt_transformers/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:1124\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1121\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1124\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1128\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1129\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1138\u001b[0m         batch_sizes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[1;32m   1146\u001b[0m     )\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 88.00 MiB. GPU 0 has a total capacity of 5.67 GiB of which 89.12 MiB is free. Including non-PyTorch memory, this process has 5.56 GiB memory in use. Of the allocated memory 5.28 GiB is allocated by PyTorch, and 145.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "model_fb.eval()\n",
    "hidden_in = torch.zeros(model_fb.num_layers * 2, 1, model_fb.hidden_size).to(device)\n",
    "mem_in = torch.zeros(model_fb.num_layers * 2, 1, model_fb.hidden_size).to(device)\n",
    "print(\"hidden_in\", hidden_in.shape)\n",
    "print(\"mem_in\", mem_in.shape)\n",
    "all_hidden = []\n",
    "all_mem = []\n",
    "all_output_1 = []\n",
    "all_output_2 = []\n",
    "all_output_3 = []\n",
    "all_embedding = []\n",
    "\n",
    "data_infos_success = data_frame_seq.loc[\n",
    "    (data_frame_seq[\"info_in_seq\"])\n",
    "]\n",
    "print(\"data_infos_success\", len(data_infos_success))\n",
    "\n",
    "# data_infos_sucess = [d for d in data_infos if all(d[\"feel_left\", \"feel_front\", \"feel_right\"])]\n",
    "for sequence in data_infos_success[\"seq\"]:\n",
    "    sequence = eval(sequence)\n",
    "    input_seq = torch.tensor(sequence).to(device)\n",
    "    all_embedding.append(model_fb.embedding(input_seq))\n",
    "    # print(\"input_seq\", input_seq.shape)\n",
    "    output, (hidden_out, mem_out) = model_fb.lstm(all_embedding[-1])\n",
    "    all_hidden.append(hidden_out[-1])\n",
    "    all_mem.append(mem_out[-1])\n",
    "    all_output_1.append(output[-1])\n",
    "    all_output_2.append(output[-2])\n",
    "    all_output_3.append(output[-3])\n",
    "\n",
    "\n",
    "# print(\"shape output\", all_output_1[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02634e8d",
   "metadata": {},
   "source": [
    "hidden_in torch.Size([8, 1, 256])\n",
    "mem_in torch.Size([8, 1, 256])\n",
    "data_infos_success 13234\n",
    "input_seq torch.Size([20])\n",
    "output torch.Size([20, 512])\n",
    "hidden_out torch.Size([8, 256])\n",
    "mem_out torch.Size([8, 256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03bca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.encode([\"feel_front\", \"feel_left\", \"feel_right\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4d22d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21abe0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsne = TSNE(n_components=2, random_state=42, perplexity=5, max_iter=300)\n",
    "# all_hidden_stack = torch.stack(all_hidden)\n",
    "# all_mem_stack = torch.stack(all_mem)\n",
    "# all_hidden_stack = all_hidden_stack.detach().cpu().numpy()\n",
    "# all_mem_stack = all_mem_stack.detach().cpu().numpy()\n",
    "# all_hidden_emb = tsne.fit_transform(all_hidden_stack)\n",
    "# all_mem_emb = tsne.fit_transform(all_mem_stack)\n",
    "\n",
    "# coo_info = data_infos_success[\"coo_xy\"].tolist()\n",
    "\n",
    "# unique_coo = np.unique(coo_info)\n",
    "# color_map = plt.get_cmap('viridis', len(unique_coo))\n",
    "# coo_colors = [color_map(unique_coo.tolist().index(str(coo))) for coo in coo_info]\n",
    "\n",
    "# theta_info = data_infos_success[\"theta\"].tolist()\n",
    "\n",
    "# unique_theta = np.unique(theta_info)\n",
    "# # Attribuer une former pour chaque valeur unique de theta\n",
    "# markers_list = ['o', 's', 'D', 'v', '^', '<', '>', 'P', 'X', '*']\n",
    "# markers_map = {theta: markers_list[i % len(markers_list)] for i, theta in enumerate(unique_theta)}\n",
    "# theta_markers = [markers_map[theta] for theta in theta_info]\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "\n",
    "# # Plot pour all_hidden_emb\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.scatter(all_hidden_emb[:, 0], all_hidden_emb[:, 1], c=coo_colors, cmap='rocket', alpha=0.6)\n",
    "# plt.title('t-SNE visualization of hidden states')\n",
    "# plt.xlabel('t-SNE component 1')\n",
    "# plt.ylabel('t-SNE component 2')\n",
    "\n",
    "# # Plot pour all_mem_emb\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.scatter(all_mem_emb[:, 0], all_mem_emb[:, 1], c=coo_colors, cmap='rocket', alpha=0.6)\n",
    "# plt.title('t-SNE visualization of memory states')\n",
    "# plt.xlabel('t-SNE component 1')\n",
    "# plt.ylabel('t-SNE component 2')\n",
    "\n",
    "# # Ajouter une légende pour les couleurs\n",
    "# for coo, color in zip(unique_coo, color_map(np.arange(len(unique_coo)))):\n",
    "#     plt.scatter([], [], c=[color], label=f'coo {coo}')\n",
    "# plt.legend(title='coo values')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "# plt.close()\n",
    "\n",
    "# tsne = TSNE(n_components=2, random_state=42, perplexity=2, max_iter=300)\n",
    "\n",
    "# all_output_stack = torch.stack(all_output_1)\n",
    "# all_output_stack = all_output_stack.detach().cpu().numpy()\n",
    "# print(\"all_output_stack\", all_output_stack.shape)\n",
    "# all_output_emb = tsne.fit_transform(all_output_stack)\n",
    "# print(\"all_output_emb\", all_output_emb.shape)\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# for i in range(len(all_output_emb)):\n",
    "#     plt.scatter(all_output_emb[i, 0], all_output_emb[i, 1], c=[coo_colors[i]], marker=theta_markers[i], alpha=0.6)\n",
    "# plt.title('t-SNE visualization of output states')\n",
    "# plt.xlabel('t-SNE component 1')\n",
    "# plt.ylabel('t-SNE component 2')\n",
    "# # Ajouter une légende pour les couleurs\n",
    "# for coo, color in zip(unique_coo, color_map(np.arange(len(unique_coo)))):\n",
    "#     plt.scatter([], [], c=[color], label=f'coo {coo}')\n",
    "# plt.legend(title='coo values')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "# plt.close()\n",
    "\n",
    "# tsne = TSNE(n_components=2, random_state=42, perplexity=2, n_iter=300)\n",
    "\n",
    "# all_output_stack = torch.stack(all_output_2)\n",
    "# all_output_stack = all_output_stack.detach().cpu().numpy()\n",
    "# print(\"all_output_stack\", all_output_stack.shape)\n",
    "# all_output_emb = tsne.fit_transform(all_output_stack)\n",
    "# print(\"all_output_emb\", all_output_emb.shape)\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.scatter(all_output_emb[:, 0], all_output_emb[:, 1], c=coo_colors, cmap='rocket', alpha=0.6)\n",
    "# plt.title('t-SNE visualization of output states')\n",
    "# plt.xlabel('t-SNE component 1')\n",
    "# plt.ylabel('t-SNE component 2')\n",
    "# # Ajouter une légende pour les couleurs\n",
    "# for coo, color in zip(unique_coo, color_map(np.arange(len(unique_coo)))):\n",
    "#     plt.scatter([], [], c=[color], label=f'coo {coo}')\n",
    "# plt.legend(title='coo values')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48bf36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "tsne = TSNE(n_components=3, random_state=42, perplexity=5, max_iter=300)\n",
    "\n",
    "# Stack embeddings and convert to numpy array\n",
    "all_embedding_stack = torch.stack(all_embedding)\n",
    "all_embedding_stack = all_embedding_stack.detach().cpu().numpy()\n",
    "print(\"shape all_embedding_stack\", all_embedding_stack.shape)\n",
    "all_embedding_stack = all_embedding_stack.reshape(all_embedding_stack.shape[0], -1)\n",
    "print(\"reshape in \", all_embedding_stack.shape)\n",
    "\n",
    "# Apply t-SNE to individual embeddings\n",
    "all_embedding_emb = tsne.fit_transform(all_embedding_stack)\n",
    "\n",
    "# Get all tokens\n",
    "all_token = env_test.get_actions() + env_test.get_outcomes() + ['<pad>']\n",
    "unique_tokens = all_token\n",
    "\n",
    "# Create color map\n",
    "n_colors = len(unique_tokens)\n",
    "color_map = plt.get_cmap('tab20', n_colors)\n",
    "token_colors = [color_map(i) for i in range(n_colors)]\n",
    "token_color_map = {tok: f'rgb({int(r*255)}, {int(g*255)}, {int(b*255)})' for tok, (r, g, b, _) in zip(unique_tokens, token_colors)}\n",
    "\n",
    "# Define token markers\n",
    "token_marker_map = {\n",
    "    '<pad>': 'cross',\n",
    "    'empty': 'square-open',\n",
    "    'wall': 'square',\n",
    "    'forward': 'diamond',\n",
    "    'feel_front': 'diamond',\n",
    "    'feel_left': 'diamond',\n",
    "    'feel_right': 'diamond',\n",
    "    'turn_left': 'circle',\n",
    "    'turn_right': 'circle',\n",
    "}\n",
    "\n",
    "# Create 3D scatter plot\n",
    "fig = go.Figure()\n",
    "for tok in unique_tokens:\n",
    "    idxs = [i for i, t in enumerate(all_token) if t == tok]\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=all_embedding_emb[idxs, 0],\n",
    "        y=all_embedding_emb[idxs, 1],\n",
    "        z=all_embedding_emb[idxs, 2],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=5,\n",
    "            color=token_color_map[tok],\n",
    "            line=dict(width=1),\n",
    "            symbol=token_marker_map[tok],\n",
    "            opacity=1\n",
    "        ),\n",
    "        name=tok\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='3D t-SNE visualization of embeddings (token markers)',\n",
    "    scene=dict(\n",
    "        xaxis_title='t-SNE component 1',\n",
    "        yaxis_title='t-SNE component 2',\n",
    "        zaxis_title='t-SNE component 3'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de96e5a1",
   "metadata": {},
   "source": [
    "circle', 'circle-open', 'cross', 'diamond',\n",
    "            'diamond-open', 'square', 'square-open', 'x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135a9f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unique_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eadf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 4\n",
    "tsne = TSNE(n_components=2, random_state=RANDOM_STATE, perplexity=5, max_iter=300)\n",
    "all_hidden_stack = torch.stack(all_hidden)\n",
    "all_mem_stack = torch.stack(all_mem)\n",
    "print(\"all_hidden\", all_hidden_stack.shape)\n",
    "print(\"all_mem\", all_mem_stack.shape)\n",
    "all_hidden_stack = all_hidden_stack.detach().cpu().numpy()\n",
    "all_mem_stack = all_mem_stack.detach().cpu().numpy()\n",
    "print(\"all_hidden\", all_hidden_stack.shape)\n",
    "print(\"all_mem\", all_mem_stack.shape)\n",
    "all_hidden_emb = tsne.fit_transform(all_hidden_stack)\n",
    "all_mem_emb = tsne.fit_transform(all_mem_stack)\n",
    "print(\"all_hidden_emb\", all_hidden_emb.shape)\n",
    "print(\"all_mem_emb\", all_mem_emb.shape)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=RANDOM_STATE, perplexity=2, max_iter=300)\n",
    "\n",
    "all_output_stack_1 = torch.stack(all_output_1)\n",
    "all_output_stack_1 = all_output_stack_1.detach().cpu().numpy()\n",
    "print(\"all_output_stack\", all_output_stack_1.shape)\n",
    "all_output_emb_1 = tsne.fit_transform(all_output_stack_1)\n",
    "print(\"all_output_emb\", all_output_emb_1.shape)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=RANDOM_STATE, perplexity=2, max_iter=300)\n",
    "\n",
    "all_output_stack_2 = torch.stack(all_output_2)\n",
    "all_output_stack_2 = all_output_stack_2.detach().cpu().numpy()\n",
    "print(\"all_output_stack\", all_output_stack_2.shape)\n",
    "all_output_emb_2 = tsne.fit_transform(all_output_stack_2)\n",
    "print(\"all_output_emb\", all_output_stack_2.shape)\n",
    "\n",
    "\n",
    "all_output_stack_3 = torch.stack(all_output_3)\n",
    "all_output_stack_3 = all_output_stack_3.detach().cpu().numpy()\n",
    "print(\"all_output_stack\", all_output_stack_3.shape)\n",
    "all_output_emb_3 = tsne.fit_transform(all_output_stack_3)\n",
    "\n",
    "tsne_3D = TSNE(n_components=3, random_state=RANDOM_STATE, perplexity=5, max_iter=300)\n",
    "all_output_emb_3D = tsne_3D.fit_transform(all_output_stack_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0118265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel_info = [str(info[0][0:2]) + '|' + str(info[1][0:2]) + '|' + str(info[2][0:2]) for info in zip(data_infos_success[\"state_left\"], data_infos_success[\"state_front\"], data_infos_success[\"state_right\"])]\n",
    "feel_info = [str(eval(info[0])[-2]) + '|' + str(info[1][0:2]) for info in zip(data_infos_success[\"seq_dec\"], data_infos_success[\"reality_dec\"], data_infos_success[\"state_right\"])]\n",
    "\n",
    "print(\"feel_info\", feel_info)\n",
    "unique_feel = np.unique(feel_info)\n",
    "print(\"unique_feel\", unique_feel)\n",
    "color_map = plt.get_cmap('viridis', len(unique_feel))\n",
    "feel_colors = [color_map(unique_feel.tolist().index(str(feel))) for feel in feel_info]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "# plt.scatter(all_output_emb[:, 0], all_output_emb[:, 1], c=feel_colors, cmap='viridis', alpha=0.6)\n",
    "# for i in range(len(all_output_emb_1)):\n",
    "plt.scatter(all_output_emb_1[:, 0], all_output_emb_1[:, 1], c=feel_colors, alpha=0.6)\n",
    "plt.title('t-SNE result of LSTM blocks at the last element of the sequence, according to last action and prediction')\n",
    "plt.xlabel('t-SNE component 1')\n",
    "plt.ylabel('t-SNE component 2')\n",
    "# Ajouter une légende pour les couleurs\n",
    "for feel, color in zip(unique_feel, color_map(np.arange(len(unique_feel)))):\n",
    "    plt.scatter([], [], c=[color], label=f'{feel}')\n",
    "plt.legend(title='last action and prediction (act|out)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "outcome_info = [info for info in data_infos_success[\"reality_dec\"]]\n",
    "unique_out = ['empty', 'wall']\n",
    "color_map_out = plt.get_cmap('viridis', len(unique_out))\n",
    "out_colors = [color_map_out(unique_out.index(str(out))) for out in outcome_info]\n",
    "\n",
    "print(\"all_output_emb\", all_output_emb_1.shape)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(all_output_emb_1[:, 0], all_output_emb_1[:, 1], c=out_colors, alpha=0.6)\n",
    "plt.title('t-SNE result of LSTM blocks at the last element of the sequence, according to reality outcome')\n",
    "plt.xlabel('t-SNE component 1')\n",
    "plt.ylabel('t-SNE component 2')\n",
    "# Ajouter une légende pour les couleurs\n",
    "for feel, color in zip(unique_out, color_map_out(np.arange(len(unique_out)))):\n",
    "    plt.scatter([], [], c=[color], label=f'{feel}')\n",
    "plt.legend(title='outcomes values')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "action_info = [str(eval(info)[-2]) for info in data_infos_success[\"seq_dec\"]]\n",
    "unique_act = ['forward', 'feel_front', 'feel_left', 'feel_right']\n",
    "color_map_act = plt.get_cmap('viridis', len(unique_act))\n",
    "act_colors = [color_map_act(unique_act.index(str(act))) for act in action_info]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(all_output_emb_1[:, 0], all_output_emb_1[:, 1], c=act_colors, alpha=0.6)\n",
    "plt.title('t-SNE result of LSTM blocks at the last element of the sequence, according to last action')\n",
    "plt.xlabel('t-SNE component 1')\n",
    "plt.ylabel('t-SNE component 2')\n",
    "# Ajouter une légende pour les couleurs\n",
    "for feel, color in zip(unique_act, color_map_act(np.arange(len(unique_act)))):\n",
    "    plt.scatter([], [], c=[color], label=f'{feel}')\n",
    "plt.legend(title='Actions :')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ================================================= ICI =================================================\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "# plt.scatter(all_output_emb[:, 0], all_output_emb[:, 1], c=feel_colors, cmap='viridis', alpha=0.6)\n",
    "# for i in range(len(all_output_emb_2)):\n",
    "plt.scatter(all_output_emb_2[:, 0], all_output_emb_2[:, 1], c=feel_colors, alpha=0.6)\n",
    "plt.title('t-SNE result of LSTM blocks at the last last action of the sequence, according to last action and prediction')\n",
    "plt.xlabel('t-SNE component 1')\n",
    "plt.ylabel('t-SNE component 2')\n",
    "# Ajouter une légende pour les couleurs\n",
    "for feel, color in zip(unique_feel, color_map(np.arange(len(unique_feel)))):\n",
    "    plt.scatter([], [], c=[color], label=f'{feel}')\n",
    "plt.legend(title='last action and prediction (act|out)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "outcome_info = [info for info in data_infos_success[\"reality_dec\"]]\n",
    "unique_out = ['empty', 'wall']\n",
    "color_map_out = plt.get_cmap('viridis', len(unique_out))\n",
    "out_colors = [color_map_out(unique_out.index(str(out))) for out in outcome_info]\n",
    "\n",
    "print(\"all_output_emb\", all_output_emb_2.shape)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(all_output_emb_2[:, 0], all_output_emb_2[:, 1], c=out_colors, alpha=0.6)\n",
    "plt.title('t-SNE result of LSTM blocks at the last last action of the sequence, according to reality outcome')\n",
    "plt.xlabel('t-SNE component 1')\n",
    "plt.ylabel('t-SNE component 2')\n",
    "# Ajouter une légende pour les couleurs\n",
    "for feel, color in zip(unique_out, color_map_out(np.arange(len(unique_out)))):\n",
    "    plt.scatter([], [], c=[color], label=f'{feel}')\n",
    "plt.legend(title='outcomes values')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "action_info = [str(eval(info)[-2]) for info in data_infos_success[\"seq_dec\"]]\n",
    "unique_act = ['forward', 'feel_front', 'feel_left', 'feel_right']\n",
    "color_map_act = plt.get_cmap('viridis', len(unique_act))\n",
    "act_colors = [color_map_act(unique_act.index(str(act))) for act in action_info]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(all_output_emb_2[:, 0], all_output_emb_2[:, 1], c=act_colors, alpha=0.6)\n",
    "plt.title('t-SNE result of LSTM blocks at the last last action of the sequence, according to last action')\n",
    "plt.xlabel('t-SNE component 1')\n",
    "plt.ylabel('t-SNE component 2')\n",
    "# Ajouter une légende pour les couleurs\n",
    "for feel, color in zip(unique_act, color_map_act(np.arange(len(unique_act)))):\n",
    "    plt.scatter([], [], c=[color], label=f'{feel}')\n",
    "plt.legend(title='Actions :')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ================================================= ICI =================================================\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.scatter(all_output_emb_2[:, 0], all_output_emb_2[:, 1], c=feel_colors, cmap='viridis', alpha=0.6)\n",
    "# plt.title('t-SNE visualization of feels states')\n",
    "# plt.xlabel('t-SNE component 1')\n",
    "# plt.ylabel('t-SNE component 2')\n",
    "# # Ajouter une légende pour les couleurs\n",
    "# for feel, color in zip(unique_feel, color_map(np.arange(len(unique_feel)))):\n",
    "#     plt.scatter([], [], c=[color], label=f'{feel}')\n",
    "# plt.legend(title='feels values (Left Front Right)')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# outcome_info = [str(eval(info)[-3]) for info in data_infos_success[\"seq_dec\"]]\n",
    "\n",
    "# unique_out = ['empty', 'wall']\n",
    "# out_colors = [color_map_out(unique_out.index(str(out))) for out in outcome_info]\n",
    "\n",
    "# print(\"all_output_emb\", all_output_emb_3.shape)\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.scatter(all_output_emb_3[:, 0], all_output_emb_3[:, 1], c=out_colors, cmap='viridis', alpha=0.6)\n",
    "# plt.title('t-SNE visualization of output states')\n",
    "# plt.xlabel('t-SNE component 1')\n",
    "# plt.ylabel('t-SNE component 2')\n",
    "# # Ajouter une légende pour les couleurs\n",
    "# for feel, color in zip(unique_out, color_map_out(np.arange(len(unique_out)))):\n",
    "#     plt.scatter([], [], c=[color], label=f'{feel}')\n",
    "# plt.legend(title='outcomes values')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "feel_info = [str(eval(info[0])[-2]) + '|' + str(info[1][0:2]) for info in zip(data_infos_success[\"seq_dec\"], data_infos_success[\"reality_dec\"], data_infos_success[\"state_right\"])]\n",
    "\n",
    "print(\"feel_info\", feel_info)\n",
    "unique_feel = np.unique(feel_info)\n",
    "print(\"unique_feel\", unique_feel)\n",
    "color_map = plt.get_cmap('viridis', len(unique_feel))\n",
    "feel_colors = [color_map(unique_feel.tolist().index(str(feel))) for feel in feel_info]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "# plt.scatter(all_output_emb[:, 0], all_output_emb[:, 1], c=feel_colors, cmap='viridis', alpha=0.6)\n",
    "# for i in range(len(all_output_emb_1)):\n",
    "plt.scatter(all_hidden_emb[:, 0], all_hidden_emb[:, 1], c=feel_colors, alpha=0.6)\n",
    "plt.title('t-SNE result of LSTM block at last action by last action and prediction')\n",
    "plt.xlabel('t-SNE component 1')\n",
    "plt.ylabel('t-SNE component 2')\n",
    "# Ajouter une légende pour les couleurs\n",
    "for feel, color in zip(unique_feel, color_map(np.arange(len(unique_feel)))):\n",
    "    plt.scatter([], [], c=[color], label=f'{feel}')\n",
    "plt.legend(title='last action and prediction (act|out)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "outcome_info = [info for info in data_infos_success[\"reality_dec\"]]\n",
    "unique_out = ['empty', 'wall']\n",
    "color_map_out = plt.get_cmap('viridis', len(unique_out))\n",
    "out_colors = [color_map_out(unique_out.index(str(out))) for out in outcome_info]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(all_hidden_emb[:, 0], all_hidden_emb[:, 1], c=out_colors, alpha=0.6)\n",
    "plt.title('t-SNE result of LSTM block at last action by last result')\n",
    "plt.xlabel('t-SNE component 1')\n",
    "plt.ylabel('t-SNE component 2')\n",
    "# Ajouter une légende pour les couleurs\n",
    "for feel, color in zip(unique_out, color_map_out(np.arange(len(unique_out)))):\n",
    "    plt.scatter([], [], c=[color], label=f'{feel}')\n",
    "plt.legend(title='outcomes values')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "action_info = [str(eval(info)[-2]) for info in data_infos_success[\"seq_dec\"]]\n",
    "unique_act = ['forward', 'feel_front', 'feel_left', 'feel_right']\n",
    "color_map_act = plt.get_cmap('viridis', len(unique_act))\n",
    "act_colors = [color_map_act(unique_act.index(str(act))) for act in action_info]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(all_hidden_emb[:, 0], all_hidden_emb[:, 1], c=act_colors, alpha=0.6)\n",
    "plt.title('t-SNE result of LSTM block at last action by last action')\n",
    "plt.xlabel('t-SNE component 1')\n",
    "plt.ylabel('t-SNE component 2')\n",
    "# Ajouter une légende pour les couleurs\n",
    "for feel, color in zip(unique_act, color_map_act(np.arange(len(unique_act)))):\n",
    "    plt.scatter([], [], c=[color], label=f'{feel}')\n",
    "plt.legend(title='Actions :')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94189ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_infos_right = data_frame_seq_success.loc[\n",
    "    (data_frame_seq_success[\"info_feel_right\"])\n",
    "]\n",
    "model_fb.eval()\n",
    "hidden_in = torch.zeros(model_fb.num_layers * 2, 1, model_fb.hidden_size).to(device)\n",
    "mem_in = torch.zeros(model_fb.num_layers * 2, 1, model_fb.hidden_size).to(device)\n",
    "print(\"hidden_in\", hidden_in.shape)\n",
    "print(\"mem_in\", mem_in.shape)\n",
    "all_hidden = []\n",
    "all_mem = []\n",
    "all_output_1 = []\n",
    "all_output_2 = []\n",
    "all_output_3 = []\n",
    "all_embedding = []\n",
    "\n",
    "for sequence in data_infos_right[\"seq\"]:\n",
    "    sequence = eval(sequence)\n",
    "    input_seq = torch.tensor(sequence).to(device)\n",
    "    all_embedding.append(model_fb.embedding(input_seq))\n",
    "    # print(\"input_seq\", input_seq.shape)\n",
    "    output, (hidden_out, mem_out) = model_fb.lstm(all_embedding[-1])\n",
    "    all_hidden.append(hidden_out[-1])\n",
    "    all_mem.append(mem_out[-1])\n",
    "    all_output_1.append(output[-1])\n",
    "    all_output_2.append(output[-2])\n",
    "    all_output_3.append(output[-3])\n",
    "    \n",
    "    \n",
    "RANDOM_STATE = 4\n",
    "tsne = TSNE(n_components=2, random_state=RANDOM_STATE, perplexity=5, max_iter=300)\n",
    "all_hidden_stack = torch.stack(all_hidden)\n",
    "all_mem_stack = torch.stack(all_mem)\n",
    "print(\"all_hidden\", all_hidden_stack.shape)\n",
    "print(\"all_mem\", all_mem_stack.shape)\n",
    "all_hidden_stack = all_hidden_stack.detach().cpu().numpy()\n",
    "all_mem_stack = all_mem_stack.detach().cpu().numpy()\n",
    "print(\"all_hidden\", all_hidden_stack.shape)\n",
    "print(\"all_mem\", all_mem_stack.shape)\n",
    "all_hidden_emb = tsne.fit_transform(all_hidden_stack)\n",
    "all_mem_emb = tsne.fit_transform(all_mem_stack)\n",
    "print(\"all_hidden_emb\", all_hidden_emb.shape)\n",
    "print(\"all_mem_emb\", all_mem_emb.shape)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=RANDOM_STATE, perplexity=2, max_iter=300)\n",
    "\n",
    "all_output_stack_1 = torch.stack(all_output_1)\n",
    "all_output_stack_1 = all_output_stack_1.detach().cpu().numpy()\n",
    "print(\"all_output_stack\", all_output_stack_1.shape)\n",
    "all_output_emb_1 = tsne.fit_transform(all_output_stack_1)\n",
    "print(\"all_output_emb\", all_output_emb_1.shape)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=RANDOM_STATE, perplexity=2, max_iter=300)\n",
    "\n",
    "all_output_stack_2 = torch.stack(all_output_2)\n",
    "all_output_stack_2 = all_output_stack_2.detach().cpu().numpy()\n",
    "print(\"all_output_stack\", all_output_stack_2.shape)\n",
    "all_output_emb_2 = tsne.fit_transform(all_output_stack_2)\n",
    "print(\"all_output_emb\", all_output_stack_2.shape)\n",
    "\n",
    "\n",
    "all_output_stack_3 = torch.stack(all_output_3)\n",
    "all_output_stack_3 = all_output_stack_3.detach().cpu().numpy()\n",
    "print(\"all_output_stack\", all_output_stack_3.shape)\n",
    "all_output_emb_3 = tsne.fit_transform(all_output_stack_3)\n",
    "\n",
    "tsne_3D = TSNE(n_components=3, random_state=RANDOM_STATE, perplexity=5, max_iter=300)\n",
    "all_output_emb_3D = tsne_3D.fit_transform(all_output_stack_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09ec27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feel_info = [str(eval(info[0])[-2]) + '|' + str(info[1][0:2]) for info in zip(data_infos_right[\"seq_dec\"], data_infos_success[\"reality_dec\"])]\n",
    "\n",
    "print(\"feel_info\", feel_info)\n",
    "unique_feel = np.unique(feel_info)\n",
    "print(\"unique_feel\", unique_feel)\n",
    "color_map = plt.get_cmap('viridis', len(unique_feel))\n",
    "feel_colors = [color_map(unique_feel.tolist().index(str(feel))) for feel in feel_info]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "# plt.scatter(all_output_emb[:, 0], all_output_emb[:, 1], c=feel_colors, cmap='viridis', alpha=0.6)\n",
    "# for i in range(len(all_output_emb_1)):\n",
    "plt.scatter(all_output_emb_1[:, 0], all_output_emb_1[:, 1], c=feel_colors, alpha=0.6)\n",
    "plt.title('t-SNE result of LSTM blocks at the last element of the sequence, according to last action and prediction')\n",
    "plt.xlabel('t-SNE component 1')\n",
    "plt.ylabel('t-SNE component 2')\n",
    "# Ajouter une légende pour les couleurs\n",
    "for feel, color in zip(unique_feel, color_map(np.arange(len(unique_feel)))):\n",
    "    plt.scatter([], [], c=[color], label=f'{feel}')\n",
    "plt.legend(title='last action and prediction (act|out)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "outcome_info = [info for info in data_infos_right[\"reality_dec\"]]\n",
    "unique_out = ['empty', 'wall']\n",
    "color_map_out = plt.get_cmap('viridis', len(unique_out))\n",
    "out_colors = [color_map_out(unique_out.index(str(out))) for out in outcome_info]\n",
    "\n",
    "print(\"all_output_emb\", all_output_emb_1.shape)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(all_output_emb_1[:, 0], all_output_emb_1[:, 1], c=out_colors, alpha=0.6)\n",
    "plt.title('t-SNE result of LSTM blocks at the last element of the sequence, according to reality outcome')\n",
    "plt.xlabel('t-SNE component 1')\n",
    "plt.ylabel('t-SNE component 2')\n",
    "# Ajouter une légende pour les couleurs\n",
    "for feel, color in zip(unique_out, color_map_out(np.arange(len(unique_out)))):\n",
    "    plt.scatter([], [], c=[color], label=f'{feel}')\n",
    "plt.legend(title='outcomes values')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "action_info = [str(eval(info)[-2]) for info in data_infos_right[\"seq_dec\"]]\n",
    "unique_act = ['forward', 'feel_front', 'feel_left', 'feel_right']\n",
    "color_map_act = plt.get_cmap('viridis', len(unique_act))\n",
    "act_colors = [color_map_act(unique_act.index(str(act))) for act in action_info]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(all_output_emb_1[:, 0], all_output_emb_1[:, 1], c=act_colors, alpha=0.6)\n",
    "plt.title('t-SNE result of LSTM blocks at the last element of the sequence, according to last action')\n",
    "plt.xlabel('t-SNE component 1')\n",
    "plt.ylabel('t-SNE component 2')\n",
    "# Ajouter une légende pour les couleurs\n",
    "for feel, color in zip(unique_act, color_map_act(np.arange(len(unique_act)))):\n",
    "    plt.scatter([], [], c=[color], label=f'{feel}')\n",
    "plt.legend(title='Actions :')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ================================================= ICI =================================================\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "# plt.scatter(all_output_emb[:, 0], all_output_emb[:, 1], c=feel_colors, cmap='viridis', alpha=0.6)\n",
    "# for i in range(len(all_output_emb_2)):\n",
    "plt.scatter(all_output_emb_2[:, 0], all_output_emb_2[:, 1], c=feel_colors, alpha=0.6)\n",
    "plt.title('t-SNE result of LSTM blocks at the last last action of the sequence, according to last action and prediction')\n",
    "plt.xlabel('t-SNE component 1')\n",
    "plt.ylabel('t-SNE component 2')\n",
    "# Ajouter une légende pour les couleurs\n",
    "for feel, color in zip(unique_feel, color_map(np.arange(len(unique_feel)))):\n",
    "    plt.scatter([], [], c=[color], label=f'{feel}')\n",
    "plt.legend(title='last action and prediction (act|out)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "outcome_info = [info for info in data_infos_right[\"reality_dec\"]]\n",
    "unique_out = ['empty', 'wall']\n",
    "color_map_out = plt.get_cmap('viridis', len(unique_out))\n",
    "out_colors = [color_map_out(unique_out.index(str(out))) for out in outcome_info]\n",
    "\n",
    "print(\"all_output_emb\", all_output_emb_2.shape)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(all_output_emb_2[:, 0], all_output_emb_2[:, 1], c=out_colors, alpha=0.6)\n",
    "plt.title('t-SNE result of LSTM blocks at the last last action of the sequence, according to reality outcome')\n",
    "plt.xlabel('t-SNE component 1')\n",
    "plt.ylabel('t-SNE component 2')\n",
    "# Ajouter une légende pour les couleurs\n",
    "for feel, color in zip(unique_out, color_map_out(np.arange(len(unique_out)))):\n",
    "    plt.scatter([], [], c=[color], label=f'{feel}')\n",
    "plt.legend(title='outcomes values')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "action_info = [str(eval(info)[-2]) for info in data_infos_right[\"seq_dec\"]]\n",
    "unique_act = ['forward', 'feel_front', 'feel_left', 'feel_right']\n",
    "color_map_act = plt.get_cmap('viridis', len(unique_act))\n",
    "act_colors = [color_map_act(unique_act.index(str(act))) for act in action_info]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(all_output_emb_2[:, 0], all_output_emb_2[:, 1], c=act_colors, alpha=0.6)\n",
    "plt.title('t-SNE result of LSTM blocks at the last last action of the sequence, according to last action')\n",
    "plt.xlabel('t-SNE component 1')\n",
    "plt.ylabel('t-SNE component 2')\n",
    "# Ajouter une légende pour les couleurs\n",
    "for feel, color in zip(unique_act, color_map_act(np.arange(len(unique_act)))):\n",
    "    plt.scatter([], [], c=[color], label=f'{feel}')\n",
    "plt.legend(title='Actions :')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da753e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import to_hex\n",
    "\n",
    "# 3dimension ploty\n",
    "# add lengend for actions \"forward, feel_front, feel_left, feel_right\"\n",
    "# Prepare a mapping from action to color (as RGB string)\n",
    "\n",
    "# unique_act: ['forward', 'feel_front', 'feel_left', 'feel_right']\n",
    "# act_colors: color for each point, same order as action_info\n",
    "\n",
    "# Build a color map for legend\n",
    "color_map_act = plt.get_cmap('viridis', len(unique_act))\n",
    "act_to_color = {act: to_hex(color_map_act(i)) for i, act in enumerate(unique_act)}\n",
    "\n",
    "# Get the action for each point\n",
    "action_info = [str(eval(seq)[-2]) for seq in data_infos_success[\"seq_dec\"]]\n",
    "\n",
    "color_map_feel = plt.get_cmap('viridis', len(unique_feel))\n",
    "feel_to_color = {feel: to_hex(color_map_feel(i)) for i, feel in enumerate(unique_feel)}\n",
    "\n",
    "feel_info = [str(eval(info[0])[-2]) + '|' + str(info[1][0:2]) for info in zip(data_infos_success[\"seq_dec\"], data_infos_success[\"reality_dec\"])]\n",
    "\n",
    "# Plotly 3D scatter with legend for each action\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "for act in unique_act:\n",
    "    idxs = [i for i, a in enumerate(action_info) if a == act]\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=all_output_emb_3D[idxs, 0],\n",
    "        y=all_output_emb_3D[idxs, 1],\n",
    "        z=all_output_emb_3D[idxs, 2],\n",
    "        mode='markers',\n",
    "        marker=dict(size=5, color=act_to_color[act], opacity=1),\n",
    "        name=act\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='3D t-SNE visualization of output states',\n",
    "    scene=dict(\n",
    "        xaxis_title='t-SNE component 1',\n",
    "        yaxis_title='t-SNE component 2',\n",
    "        zaxis_title='t-SNE component 3'\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2694985",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feel_info)\n",
    "print(unique_feel)\n",
    "print(feel_to_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d787360",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_feel = ['feel_left|em', 'feel_left|wa', 'feel_right|em', 'feel_right|wa', 'feel_front|em', 'feel_front|wa', 'forward|wa', 'forward|em']\n",
    "fig = go.Figure()\n",
    "for feel in unique_feel:\n",
    "    idxs = [i for i, a in enumerate(feel_info) if a == feel]\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=all_output_emb_3D[idxs, 0],\n",
    "        y=all_output_emb_3D[idxs, 1],\n",
    "        z=all_output_emb_3D[idxs, 2],\n",
    "        mode='markers',\n",
    "        marker=dict(size=5, color=feel_to_color[feel], opacity=1),\n",
    "        name=feel\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='3D t-SNE visualization of output states last interaction',\n",
    "    scene=dict(\n",
    "        xaxis_title='t-SNE component 1',\n",
    "        yaxis_title='t-SNE component 2',\n",
    "        zaxis_title='t-SNE component 3'\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115cd2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear memory\n",
    "del all_hidden\n",
    "del all_mem\n",
    "del all_output_1\n",
    "del all_output_2\n",
    "del all_hidden_stack\n",
    "del all_mem_stack\n",
    "del all_output_stack_1\n",
    "del all_output_stack_2\n",
    "del all_hidden_emb\n",
    "del all_mem_emb\n",
    "del all_output_emb_1\n",
    "del all_output_emb_2\n",
    "# del all_output_stack\n",
    "# del all_output_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75046cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hidden = []\n",
    "all_mem = []\n",
    "all_output_1 = []\n",
    "all_output_2 = []\n",
    "all_output_3 = []\n",
    "\n",
    "for sequence in data_frame_seq[\"seq\"]:\n",
    "    sequence = eval(sequence)\n",
    "    input_seq = torch.tensor(sequence).to(device)\n",
    "    output, (hidden_out, mem_out) = model_fb.lstm(model_fb.embedding(input_seq))\n",
    "    all_hidden.append(hidden_out[-1])\n",
    "    all_mem.append(mem_out[-1])\n",
    "    all_output_1.append(output[-1])\n",
    "    all_output_2.append(output[-2])\n",
    "    all_output_3.append(output[-3])    \n",
    "\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=RANDOM_STATE, perplexity=5, max_iter=300)\n",
    "all_hidden_stack = torch.stack(all_hidden)\n",
    "all_mem_stack = torch.stack(all_mem)\n",
    "all_output_stack_1 = torch.stack(all_output_1)\n",
    "all_output_stack_2 = torch.stack(all_output_2)\n",
    "all_output_stack_3 = torch.stack(all_output_3)\n",
    "\n",
    "\n",
    "all_hidden_stack = all_hidden_stack.detach().cpu().numpy()\n",
    "all_mem_stack = all_mem_stack.detach().cpu().numpy()\n",
    "all_output_stack_1 = all_output_stack_1.detach().cpu().numpy()\n",
    "all_output_stack_2 = all_output_stack_2.detach().cpu().numpy()\n",
    "all_output_stack_3 = all_output_stack_3.detach().cpu().numpy()\n",
    "\n",
    "all_hidden_emb = tsne.fit_transform(all_hidden_stack)\n",
    "all_mem_emb = tsne.fit_transform(all_mem_stack)\n",
    "all_output_emb_1 = tsne.fit_transform(all_output_stack_1)\n",
    "all_output_emb_2 = tsne.fit_transform(all_output_stack_2)\n",
    "all_output_emb_3 = tsne.fit_transform(all_output_stack_3)\n",
    "\n",
    "tsne_3D = TSNE(n_components=3, random_state=RANDOM_STATE, perplexity=5, max_iter=300)\n",
    "all_output_stack_3D = torch.stack(all_output_1)\n",
    "all_output_stack_3D = all_output_stack_3D.detach().cpu().numpy()\n",
    "all_output_emb_3D = tsne_3D.fit_transform(all_output_stack_3D)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34750e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# front_info = [str(info) for info in data_infos_success[\"state_front\"]]\n",
    "# left_info = [str(info) for info in data_infos_success[\"state_left\"]]\n",
    "# right_info = [str(info) for info in data_infos_success[\"state_right\"]]\n",
    "\n",
    "# act_pred = [str(eval(to_act)[-2]) + ' | ' +  pred for to_act, pred in zip(data_infos_success[\"seq_dec\"], data_infos_success[\"prediction_dec\"])]\n",
    "# act = [str(eval(to_act)[-2]) for to_act in data_infos_success[\"seq_dec\"]]\n",
    "\n",
    "\n",
    "front_info = [str(info) for info in data_frame_seq[\"state_front\"]]\n",
    "left_info = [str(info) for info in data_frame_seq[\"state_left\"]]\n",
    "right_info = [str(info) for info in data_frame_seq[\"state_right\"]]\n",
    "\n",
    "act_pred = [str(eval(to_act)[-2]) + ' | ' +  pred for to_act, pred in zip(data_frame_seq[\"seq_dec\"], data_frame_seq[\"prediction_dec\"])]\n",
    "act = [str(eval(to_act)[-2]) for to_act in data_frame_seq[\"seq_dec\"]]\n",
    "\n",
    "print(\"act_pred\", act_pred)\n",
    "\n",
    "unique_front = np.unique(front_info)\n",
    "unique_left = np.unique(left_info)\n",
    "unique_right = np.unique(right_info)\n",
    "unique_act_pred = np.unique(act_pred)\n",
    "unique_act = np.unique(act)\n",
    "\n",
    "color_map_front = plt.get_cmap('viridis', len(unique_front))\n",
    "front_colors = [color_map_front(unique_front.tolist().index(str(feel))) for feel in front_info]\n",
    "\n",
    "color_map_left = plt.get_cmap('viridis', len(unique_left))\n",
    "left_colors = [color_map_left(unique_left.tolist().index(str(feel))) for feel in left_info]\n",
    "\n",
    "color_map_right = plt.get_cmap('viridis', len(unique_right))\n",
    "right_colors = [color_map_right(unique_right.tolist().index(str(feel))) for feel in right_info]\n",
    "\n",
    "color_map_act_pred = plt.get_cmap('viridis', len(unique_act_pred))\n",
    "act_pred_colors = [color_map_act_pred(unique_act_pred.tolist().index(_act)) for _act in act_pred]\n",
    "\n",
    "color_map_act = plt.get_cmap('viridis', len(unique_act))\n",
    "act_colors = [color_map_act(unique_act.tolist().index(_act)) for _act in act]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(all_output_emb_1[:, 0], all_output_emb_1[:, 1], c=act_pred_colors, alpha=0.6)\n",
    "plt.title('t-SNE visualization of output states')\n",
    "plt.xlabel('t-SNE component 1')\n",
    "plt.ylabel('t-SNE component 2')\n",
    "# Ajouter une légende pour les couleurs\n",
    "for coo, color in zip(unique_act_pred, color_map_act_pred(np.arange(len(unique_act_pred)))):\n",
    "    plt.scatter([], [], c=[color], label=f'{coo}')\n",
    "plt.legend(title='action, prediction')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(all_output_emb_1[:, 0], all_output_emb_1[:, 1], c=act_colors, cmap='viridis', alpha=0.6)\n",
    "plt.title('t-SNE visualization of output states')\n",
    "plt.xlabel('t-SNE component 1')\n",
    "plt.ylabel('t-SNE component 2')\n",
    "# Ajouter une légende pour les couleurs\n",
    "for coo, color in zip(unique_act, color_map_act(np.arange(len(unique_act)))):\n",
    "    plt.scatter([], [], c=[color], label=f'{coo}')\n",
    "plt.legend(title='action, prediction')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c66e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(act_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f502ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_act is already defined, act_colors is a color list for each point, all_output_emb_3D is your embedding\n",
    "\n",
    "# Map each action to a color\n",
    "color_map_act = plt.get_cmap('viridis', len(unique_act))\n",
    "act_to_color = {act: f'rgb({int(r*255)},{int(g*255)},{int(b*255)})' \n",
    "                for act, (r, g, b, _) in zip(unique_act, color_map_act(np.arange(len(unique_act))))}\n",
    "\n",
    "# Get the action for each point\n",
    "action_info = [str(eval(seq)[-2]) for seq in data_frame_seq[\"seq_dec\"]]\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "for act in unique_act:\n",
    "    idxs = [i for i, a in enumerate(action_info) if a == act]\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=all_output_emb_3D[idxs, 0],\n",
    "        y=all_output_emb_3D[idxs, 1],\n",
    "        z=all_output_emb_3D[idxs, 2],\n",
    "        mode='markers',\n",
    "        marker=dict(size=5, color=act_to_color[act], opacity=1),\n",
    "        name=act\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='3D t-SNE visualization of output states',\n",
    "    scene=dict(\n",
    "        xaxis_title='t-SNE component 1',\n",
    "        yaxis_title='t-SNE component 2',\n",
    "        zaxis_title='t-SNE component 3'\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9897d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import to_hex\n",
    "\n",
    "# 3dimension ploty\n",
    "# add lengend for actions \"forward, feel_front, feel_left, feel_right\"\n",
    "# Prepare a mapping from action to color (as RGB string)\n",
    "\n",
    "# unique_act: ['forward', 'feel_front', 'feel_left', 'feel_right']\n",
    "# act_colors: color for each point, same order as action_info\n",
    "\n",
    "# Build a color map for legend\n",
    "color_map_act = plt.get_cmap('viridis', len(unique_act))\n",
    "act_to_color = {act: to_hex(color_map_act(i)) for i, act in enumerate(unique_act)}\n",
    "\n",
    "# Get the action for each point\n",
    "action_info = [str(eval(seq)[-2]) for seq in data_frame_seq[\"seq_dec\"]]\n",
    "\n",
    "# Plotly 3D scatter with legend for each action\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "for act in unique_act:\n",
    "    idxs = [i for i, a in enumerate(action_info) if a == act]\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=all_output_emb_3D[idxs, 0],\n",
    "        y=all_output_emb_3D[idxs, 1],\n",
    "        z=all_output_emb_3D[idxs, 2],\n",
    "        mode='markers',\n",
    "        marker=dict(size=5, color=act_to_color[act], opacity=1),\n",
    "        name=act\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='3D t-SNE visualization of output states',\n",
    "    scene=dict(\n",
    "        xaxis_title='t-SNE component 1',\n",
    "        yaxis_title='t-SNE component 2',\n",
    "        zaxis_title='t-SNE component 3'\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622d3704",
   "metadata": {},
   "outputs": [],
   "source": [
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c7881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feel_info = [str(eval(info[0])[-2]) + '|' + str(info[1][0:2]) for info in zip(data_frame_seq[\"seq_dec\"], data_frame_seq[\"reality_dec\"], data_frame_seq[\"state_right\"])]\n",
    "\n",
    "print(\"feel_info\", feel_info)\n",
    "unique_feel = np.unique(feel_info)\n",
    "print(\"unique_feel\", unique_feel)\n",
    "color_map = plt.get_cmap('viridis', len(unique_feel))\n",
    "feel_colors = [color_map(unique_feel.tolist().index(str(feel))) for feel in feel_info]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "# plt.scatter(all_output_emb[:, 0], all_output_emb[:, 1], c=feel_colors, cmap='viridis', alpha=0.6)\n",
    "# for i in range(len(all_output_emb_1)):\n",
    "plt.scatter(all_output_emb_1[:, 0], all_output_emb_1[:, 1], c=feel_colors, cmap='viridis', alpha=0.6)\n",
    "plt.title('t-SNE result of LSTM blocks at the last element of the sequence, according to last action and prediction')\n",
    "plt.xlabel('t-SNE component 1')\n",
    "plt.ylabel('t-SNE component 2')\n",
    "# Ajouter une légende pour les couleurs\n",
    "for feel, color in zip(unique_feel, color_map(np.arange(len(unique_feel)))):\n",
    "    plt.scatter([], [], c=[color], label=f'{feel}')\n",
    "plt.legend(title='last action and prediction (act|out)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "outcome_info = [info for info in data_frame_seq[\"reality_dec\"]]\n",
    "unique_out = ['empty', 'wall']\n",
    "color_map_out = plt.get_cmap('viridis', len(unique_out))\n",
    "out_colors = [color_map_out(unique_out.index(str(out))) for out in outcome_info]\n",
    "\n",
    "print(\"all_output_emb\", all_output_emb_1.shape)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(all_output_emb_1[:, 0], all_output_emb_1[:, 1], c=out_colors, cmap='viridis', alpha=0.6)\n",
    "plt.title('t-SNE result of LSTM blocks at the last element of the sequence, according to reality outcome')\n",
    "plt.xlabel('t-SNE component 1')\n",
    "plt.ylabel('t-SNE component 2')\n",
    "# Ajouter une légende pour les couleurs\n",
    "for feel, color in zip(unique_out, color_map_out(np.arange(len(unique_out)))):\n",
    "    plt.scatter([], [], c=[color], label=f'{feel}')\n",
    "plt.legend(title='outcomes values')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "action_info = [str(eval(info)[-2]) for info in data_frame_seq[\"seq_dec\"]]\n",
    "unique_act = ['forward', 'feel_front', 'feel_left', 'feel_right']\n",
    "color_map_act = plt.get_cmap('viridis', len(unique_act))\n",
    "act_colors = [color_map_act(unique_act.index(str(act))) for act in action_info]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(all_output_emb_1[:, 0], all_output_emb_1[:, 1], c=act_colors, cmap='viridis', alpha=0.6)\n",
    "plt.title('t-SNE result of LSTM blocks at the last element of the sequence, according to last action')\n",
    "plt.xlabel('t-SNE component 1')\n",
    "plt.ylabel('t-SNE component 2')\n",
    "# Ajouter une légende pour les couleurs\n",
    "for feel, color in zip(unique_act, color_map_act(np.arange(len(unique_act)))):\n",
    "    plt.scatter([], [], c=[color], label=f'{feel}')\n",
    "plt.legend(title='Actions :')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ================================================= ICI =================================================\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "# plt.scatter(all_output_emb[:, 0], all_output_emb[:, 1], c=feel_colors, cmap='viridis', alpha=0.6)\n",
    "# for i in range(len(all_output_emb_2)):\n",
    "plt.scatter(all_output_emb_2[:, 0], all_output_emb_2[:, 1], c=feel_colors, alpha=0.6)\n",
    "plt.title('t-SNE result of LSTM blocks at the last last action of the sequence, according to last action and prediction')\n",
    "plt.xlabel('t-SNE component 1')\n",
    "plt.ylabel('t-SNE component 2')\n",
    "# Ajouter une légende pour les couleurs\n",
    "for feel, color in zip(unique_feel, color_map(np.arange(len(unique_feel)))):\n",
    "    plt.scatter([], [], c=[color], label=f'{feel}')\n",
    "plt.legend(title='last action and prediction (act|out)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "outcome_info = [info for info in data_frame_seq[\"reality_dec\"]]\n",
    "unique_out = ['empty', 'wall']\n",
    "color_map_out = plt.get_cmap('viridis', len(unique_out))\n",
    "out_colors = [color_map_out(unique_out.index(str(out))) for out in outcome_info]\n",
    "\n",
    "print(\"all_output_emb\", all_output_emb_2.shape)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(all_output_emb_2[:, 0], all_output_emb_2[:, 1], c=out_colors, cmap='viridis', alpha=0.6)\n",
    "plt.title('t-SNE result of LSTM blocks at the last last action of the sequence, according to reality outcome')\n",
    "plt.xlabel('t-SNE component 1')\n",
    "plt.ylabel('t-SNE component 2')\n",
    "# Ajouter une légende pour les couleurs\n",
    "for feel, color in zip(unique_out, color_map_out(np.arange(len(unique_out)))):\n",
    "    plt.scatter([], [], c=[color], label=f'{feel}')\n",
    "plt.legend(title='outcomes values')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "action_info = [str(eval(info)[-2]) for info in data_frame_seq[\"seq_dec\"]]\n",
    "unique_act = ['forward', 'feel_front', 'feel_left', 'feel_right']\n",
    "color_map_act = plt.get_cmap('viridis', len(unique_act))\n",
    "act_colors = [color_map_act(unique_act.index(str(act))) for act in action_info]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(all_output_emb_2[:, 0], all_output_emb_2[:, 1], c=act_colors, cmap='viridis', alpha=0.6)\n",
    "plt.title('t-SNE result of LSTM blocks at the last last action of the sequence, according to last action')\n",
    "plt.xlabel('t-SNE component 1')\n",
    "plt.ylabel('t-SNE component 2')\n",
    "# Ajouter une légende pour les couleurs\n",
    "for feel, color in zip(unique_act, color_map_act(np.arange(len(unique_act)))):\n",
    "    plt.scatter([], [], c=[color], label=f'{feel}')\n",
    "plt.legend(title='Actions :')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298ea6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "\n",
    "# Ajuster TSNE pour générer trois composants\n",
    "tsne = TSNE(n_components=3, random_state=RANDOM_STATE, perplexity=5, n_iter=300)\n",
    "\n",
    "# Transformer les données en embeddings 3D\n",
    "all_hidden_stack = torch.stack(all_hidden)\n",
    "all_mem_stack = torch.stack(all_mem)\n",
    "all_hidden_stack = all_hidden_stack.detach().cpu().numpy()\n",
    "all_mem_stack = all_mem_stack.detach().cpu().numpy()\n",
    "all_hidden_emb = tsne.fit_transform(all_hidden_stack)\n",
    "all_mem_emb = tsne.fit_transform(all_mem_stack)\n",
    "\n",
    "# Extraire les informations \"feel\" de data_infos\n",
    "\n",
    "feel_info = [str(info[0]) + str(info[1]) + str(info[2]) for info in zip(data_infos_success[\"state_left\"], data_infos_success[\"state_front\"], data_infos_success[\"state_right\"])]\n",
    "unique_feel = np.unique(feel_info)\n",
    "color_map = plt.get_cmap('viridis', len(unique_feel))\n",
    "feel_colors = [color_map(unique_feel.tolist().index(str(feel))) for feel in feel_info]\n",
    "\n",
    "# Créer les scatter plots 3D pour les embeddings\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot pour all_hidden_emb\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "sc1 = ax1.scatter(all_hidden_emb[:, 0], all_hidden_emb[:, 1], all_hidden_emb[:, 2], c=feel_colors, cmap='viridis', alpha=0.6)\n",
    "ax1.set_title('t-SNE visualization of hidden states')\n",
    "ax1.set_xlabel('t-SNE component 1')\n",
    "ax1.set_ylabel('t-SNE component 2')\n",
    "ax1.set_zlabel('t-SNE component 3')\n",
    "\n",
    "# Plot pour all_mem_emb\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "sc2 = ax2.scatter(all_mem_emb[:, 0], all_mem_emb[:, 1], all_mem_emb[:, 2], c=feel_colors, cmap='viridis', alpha=0.6)\n",
    "ax2.set_title('t-SNE visualization of memory states')\n",
    "ax2.set_xlabel('t-SNE component 1')\n",
    "ax2.set_ylabel('t-SNE component 2')\n",
    "ax2.set_zlabel('t-SNE component 3')\n",
    "\n",
    "# Ajouter une légende pour les couleurs\n",
    "legend1 = ax1.legend(*sc1.legend_elements(), title=\"feel values\")\n",
    "ax1.add_artist(legend1)\n",
    "legend2 = ax2.legend(*sc2.legend_elements(), title=\"feel values\")\n",
    "ax2.add_artist(legend2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Pour les sorties all_output_1 et all_output_2\n",
    "tsne = TSNE(n_components=3, random_state=RANDOM_STATE, perplexity=2, n_iter=300)\n",
    "\n",
    "all_output_stack_1 = torch.stack(all_output_1)\n",
    "all_output_stack_1 = all_output_stack_1.detach().cpu().numpy()\n",
    "all_output_emb_1 = tsne.fit_transform(all_output_stack_1)\n",
    "\n",
    "all_output_stack_2 = torch.stack(all_output_2)\n",
    "all_output_stack_2 = all_output_stack_2.detach().cpu().numpy()\n",
    "all_output_emb_2 = tsne.fit_transform(all_output_stack_2)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot pour all_output_emb_1\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "sc1 = ax1.scatter(all_output_emb_1[:, 0], all_output_emb_1[:, 1], all_output_emb_1[:, 2], c=feel_colors, cmap='viridis', alpha=0.6)\n",
    "ax1.set_title('t-SNE visualization of output states (all_output_1)')\n",
    "ax1.set_xlabel('t-SNE component 1')\n",
    "ax1.set_ylabel('t-SNE component 2')\n",
    "ax1.set_zlabel('t-SNE component 3')\n",
    "\n",
    "# Plot pour all_output_emb_2\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "sc2 = ax2.scatter(all_output_emb_2[:, 0], all_output_emb_2[:, 1], all_output_emb_2[:, 2], c=feel_colors, cmap='viridis', alpha=0.6)\n",
    "ax2.set_title('t-SNE visualization of output states (all_output_2)')\n",
    "ax2.set_xlabel('t-SNE component 1')\n",
    "ax2.set_ylabel('t-SNE component 2')\n",
    "ax2.set_zlabel('t-SNE component 3')\n",
    "\n",
    "# Ajouter une légende pour les couleurs\n",
    "legend1 = ax1.legend(*sc1.legend_elements(), title=\"feel values\")\n",
    "ax1.add_artist(legend1)\n",
    "legend2 = ax2.legend(*sc2.legend_elements(), title=\"feel values\")\n",
    "ax2.add_artist(legend2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff884fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise \"end\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ceabba",
   "metadata": {},
   "source": [
    "# Not implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749f2def",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq = torch.tensor(tokenizer.encode(\n",
    "    ['forward', 'empty', 'feel_right', 'empty', 'turn_left', 'empty', 'feel_front', 'empty', 'feel_front', 'empty', 'forward', 'empty', 'feel_left', 'empty', 'feel_front', 'wall', 'feel_left', 'empty', 'feel_left', 'empty', 'feel_left', 'empty', 'feel_front', 'wall', 'forward', 'wall', 'turn_right', 'empty', 'turn_right', '<pad>']\n",
    "))\n",
    "\n",
    "# Initialiser les états cachés et de la cellule\n",
    "hidden_in = torch.zeros(model_fb.num_layers * 2, 1, model_fb.hidden_size)\n",
    "mem_in = torch.zeros(model_fb.num_layers * 2, 1, model_fb.hidden_size)\n",
    "\n",
    "# Passer la séquence à travers le LSTM\n",
    "output, (hidden_out, mem_out) = model_fb.lstm(model_fb.embedding(input_seq))\n",
    "\n",
    "# Extraire les états cachés pour chaque pas de temps\n",
    "# Note: output contient les états cachés pour chaque pas de temps\n",
    "hidden_states = output.squeeze(1).detach().numpy()\n",
    "\n",
    "# Appliquer t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=5, n_iter=300)\n",
    "hidden_states_2d = tsne.fit_transform(hidden_states)\n",
    "\n",
    "# Visualiser les résultats\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(hidden_states_2d[:, 0], hidden_states_2d[:, 1], c=np.arange(hidden_states_2d.shape[0]), cmap='viridis')\n",
    "plt.colorbar(label='Time Step')\n",
    "plt.title('t-SNE Visualization of LSTM Hidden States Over Time')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83642a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat 'forward', 'empty', * 5\n",
    "list_seq = ['forward', 'empty'] * 4\n",
    "print(\"list_seq\", list_seq)\n",
    "\n",
    "input_seq = torch.tensor(tokenizer.encode(\n",
    "  list_seq\n",
    "))\n",
    "1000\n",
    "# Initialiser les états cachés et de la cellule\n",
    "hidden_in = torch.zeros(model_fb.num_layers * 2, 1, model_fb.hidden_size)\n",
    "mem_in = torch.zeros(model_fb.num_layers * 2, 1, model_fb.hidden_size)\n",
    "\n",
    "# Passer la séquence à travers le LSTM\n",
    "output, (hidden_out, mem_out) = model_fb.lstm(model_fb.embedding(input_seq))\n",
    "\n",
    "# Extraire les états cachés pour chaque pas de temps\n",
    "# Note: output contient les états cachés pour chaque pas de temps\n",
    "hidden_states = output.squeeze(1).detach().numpy()\n",
    "\n",
    "# Appliquer t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=5, n_iter=300)\n",
    "hidden_states_2d = tsne.fit_transform(hidden_states)\n",
    "\n",
    "# Visualiser les résultats\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(hidden_states_2d[:, 0], hidden_states_2d[:, 1], c=np.arange(hidden_states_2d.shape[0]), cmap='viridis')\n",
    "plt.colorbar(label='Time Step')\n",
    "plt.title('t-SNE Visualization of LSTM Hidden States Over Time')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a361052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat 'forward', 'empty', * 5\n",
    "list_seq[-1] = 'wall'\n",
    "print(\"list_seq\", list_seq)\n",
    "\n",
    "input_seq = torch.tensor(tokenizer.encode(\n",
    "  list_seq\n",
    "))\n",
    "\n",
    "# Initialiser les états cachés et de la cellule\n",
    "hidden_in = torch.zeros(model_fb.num_layers * 2, 1, model_fb.hidden_size)\n",
    "mem_in = torch.zeros(model_fb.num_layers * 2, 1, model_fb.hidden_size)\n",
    "\n",
    "# Passer la séquence à travers le LSTM\n",
    "output, (hidden_out, mem_out) = model_fb.lstm(model_fb.embedding(input_seq))\n",
    "\n",
    "# Extraire les états cachés pour chaque pas de temps\n",
    "# Note: output contient les états cachés pour chaque pas de temps\n",
    "hidden_states = output.squeeze(1).detach().numpy()\n",
    "\n",
    "# Appliquer t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=5, n_iter=300)\n",
    "hidden_states_2d = tsne.fit_transform(hidden_states)\n",
    "\n",
    "# Visualiser les résultats\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(hidden_states_2d[:, 0], hidden_states_2d[:, 1], c=np.arange(hidden_states_2d.shape[0]), cmap='viridis')\n",
    "plt.colorbar(label='Time Step')\n",
    "plt.title('t-SNE Visualization of LSTM Hidden States Over Time')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7302c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat 'forward', 'empty', * 5\n",
    "list_seq[-2] = 'feel_front'\n",
    "list_seq[-1] = 'wall'\n",
    "print(\"list_seq\", list_seq)\n",
    "\n",
    "input_seq = torch.tensor(tokenizer.encode(\n",
    "  list_seq\n",
    "))\n",
    "\n",
    "# Initialiser les états cachés et de la cellule\n",
    "hidden_in = torch.zeros(model_fb.num_layers * 2, 1, model_fb.hidden_size)\n",
    "mem_in = torch.zeros(model_fb.num_layers * 2, 1, model_fb.hidden_size)\n",
    "\n",
    "# Passer la séquence à travers le LSTM\n",
    "output, (hidden_out, mem_out) = model_fb.lstm(model_fb.embedding(input_seq))\n",
    "\n",
    "# Extraire les états cachés pour chaque pas de temps\n",
    "# Note: output contient les états cachés pour chaque pas de temps\n",
    "hidden_states = output.squeeze(1).detach().numpy()\n",
    "\n",
    "# Appliquer t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=5, n_iter=300)\n",
    "hidden_states_2d = tsne.fit_transform(hidden_states)\n",
    "\n",
    "# Visualiser les résultats\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(hidden_states_2d[:, 0], hidden_states_2d[:, 1], c=np.arange(hidden_states_2d.shape[0]), cmap='viridis')\n",
    "plt.colorbar(label='Time Step')\n",
    "plt.title('t-SNE Visualization of LSTM Hidden States Over Time')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa29a303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat 'forward', 'empty', * 5\n",
    "list_seq = ['feel_left', 'wall', 'turn_right', 'empty', 'turn_right', 'empty', 'turn_right', 'empty', 'feel_front', 'empty']\n",
    "print(\"list_seq\", list_seq)\n",
    "\n",
    "input_seq = torch.tensor(tokenizer.encode(\n",
    "  list_seq\n",
    "))\n",
    "\n",
    "# Initialiser les états cachés et de la cellule\n",
    "hidden_in = torch.zeros(model_fb.num_layers * 2, 1, model_fb.hidden_size)\n",
    "mem_in = torch.zeros(model_fb.num_layers * 2, 1, model_fb.hidden_size)\n",
    "\n",
    "# Passer la séquence à travers le LSTM\n",
    "output, (hidden_out, mem_out) = model_fb.lstm(model_fb.embedding(input_seq))\n",
    "\n",
    "# Extraire les états cachés pour chaque pas de temps\n",
    "# Note: output contient les états cachés pour chaque pas de temps\n",
    "hidden_states = output.squeeze(1).detach().numpy()\n",
    "\n",
    "# Appliquer t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=5, n_iter=300)\n",
    "hidden_states_2d = tsne.fit_transform(hidden_states)\n",
    "\n",
    "# Visualiser les résultats\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(hidden_states_2d[:, 0], hidden_states_2d[:, 1], c=np.arange(hidden_states_2d.shape[0]), cmap='viridis')\n",
    "plt.colorbar(label='Time Step')\n",
    "plt.title('t-SNE Visualization of LSTM Hidden States Over Time')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764fb5f3",
   "metadata": {},
   "source": [
    "# Avec interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e098eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_interaction = gridWorld(x= 1, y=1, theta=0, world= np.array([\n",
    "                [1, 1, 1, 1, 1, 1],\n",
    "                [1, 0, 0, 0, 0, 1],\n",
    "                [1, 0, 0, 1, 0, 1],\n",
    "                [1, 0, 1, 0, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 1],\n",
    "                [1, 1, 1, 1, 1, 1],\n",
    "            ]))\n",
    "env_interaction.display_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59beab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_vocab = ['<pad>', '<mask>']\n",
    "for act in env_interaction.get_actions():\n",
    "    for fb in env_interaction.get_outcomes():\n",
    "        list_vocab.append((act, fb))\n",
    "for act in env_interaction.get_actions():\n",
    "    list_vocab.append(act)\n",
    "for fb in env_interaction.get_outcomes():\n",
    "        list_vocab.append(fb)\n",
    "tmp = create_dico_numerate_word(list_vocab)\n",
    "tokenizer_interaction = SimpleTokenizerV1(vocab=tmp)\n",
    "for key, value in tokenizer_interaction.str_to_int.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c683310e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_interaction(env:env, tokenizer:SimpleTokenizerV1, n_episodes:int=1000):\n",
    "    \"\"\"\n",
    "    Generate data from the environment.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for _ in range(n_episodes):\n",
    "        action = np.random.choice(env.get_actions())\n",
    "        feedback = env.outcome(action)\n",
    "        data.append(tokenizer.encode((action, feedback)))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b3c137",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_inter = []\n",
    "for i in range(10):\n",
    "    data_train_inter.append(get_data_interaction(env_interaction, tokenizer_interaction, n_episodes=5))\n",
    "print(\"data_train_inter\", data_train_inter)\n",
    "for seq in data_train_inter:\n",
    "    print(tokenizer_interaction.decode(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eb73f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenDropInteraction(nn.Module):\n",
    "    \"\"\"For a batch of tokens indices, randomly replace a interaction token with action associated to it.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tokenizer, prob=0.1, num_special=4):\n",
    "        self.prob = prob\n",
    "        self.num_special = num_special\n",
    "        self.dic_remplacement = {}\n",
    "        for key, value in tokenizer.str_to_int.items():\n",
    "            if type(key) == tuple:\n",
    "                self.dic_remplacement[value] = tokenizer.encode(key[0])\n",
    "                \n",
    "    def __call__(self, sample):\n",
    "        mask = torch.bernoulli(self.prob * torch.ones_like(sample)).long()\n",
    "        \n",
    "        can_drop = (sample >= self.num_special).long()\n",
    "        mask = mask * can_drop\n",
    "        \n",
    "        for interaction, replacement in self.dic_remplacement.items():\n",
    "            interaction_mask = (sample == interaction) & (mask == 1)\n",
    "            sample = torch.where(interaction_mask, replacement, sample)\n",
    "        \n",
    "        return sample, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4a28de",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = TokenDropInteraction(tokenizer=tokenizer_interaction, prob=0.5, num_special=2)\n",
    "\n",
    "data_train_inter[0][-1] = 0\n",
    "data_target_inter, mask = td(torch.tensor(data_train_inter))\n",
    "for seq in data_train_inter:\n",
    "    print(tokenizer_interaction.decode(seq))\n",
    "    \n",
    "print(\"version masker\")\n",
    "for seq in data_target_inter.tolist():\n",
    "    print(tokenizer_interaction.decode(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80934ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_interaction = SimpleDataSet(data_train_inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef553a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_inter(model, data_loader, tokenizer):\n",
    "    acc = 0\n",
    "    data_frame_seq_inter = pd.DataFrame({\n",
    "        \"seq\": [\"\"] * len(data_loader),\n",
    "        \"seq_dec\": [\"\"] * len(data_loader),\n",
    "        \"prediction\": [\"\"] * len(data_loader),\n",
    "        \"prediction_dec\": [\"\"] * len(data_loader),\n",
    "        \"reality\": [\"\"] * len(data_loader),\n",
    "        \"reality_dec\": [\"\"] * len(data_loader),\n",
    "        \"probability\": [\"\"] * len(data_loader),\n",
    "        \"good_prediction\": [False] * len(data_loader),\n",
    "        \"info_in_seq\": [False] * len(data_loader),\n",
    "        \"info_feel_left\": [False] * len(data_loader),\n",
    "        \"info_feel_front\": [False] * len(data_loader),\n",
    "        \"info_feel_right\": [False] * len(data_loader),\n",
    "        \"coo_xy\": [\"\"] * len(data_loader),\n",
    "        \"theta\": [-1] * len(data_loader),\n",
    "        \"state_left\": [\"\"] * len(data_loader),\n",
    "        \"state_front\": [\"\"] * len(data_loader),\n",
    "        \"state_right\": [\"\"] * len(data_loader)\n",
    "    })\n",
    "\n",
    "    with torch.no_grad():\n",
    "        h = torch.zeros(model.num_layers * 2, 1, model.hidden_size).to(device)\n",
    "        cell = torch.zeros(model.num_layers * 2, 1, model.hidden_size).to(device)\n",
    "        for i, (input, target, info) in tqdm(enumerate(data_loader)):\n",
    "            input = input.to(device)\n",
    "            target = target.to(device)\n",
    "            \n",
    "            output, _, _ = model(input, h, cell)\n",
    "            \n",
    "            arrays, x, y, theta = process_sequence_inter(tokenizer.decode(input.tolist()[0]), 6, None)\n",
    "            good_seq = info_in_memory(arrays)\n",
    "            feel_left, feel_front, feel_right = feel_info_end_sequence(tokenizer.decode(input.tolist()[0]), 6, (arrays, x, y, theta))\n",
    "            \n",
    "            proba = F.softmax(output, dim=-1)\n",
    "            output = output.transpose(1, 2)\n",
    "            pred = output.argmax(dim=1)\n",
    "            acc += (pred[-1][-1] == target).item()\n",
    "            state_left = info[\"feel_left\"][0]\n",
    "            state_front = info[\"feel_front\"][0]\n",
    "            state_right = info[\"feel_right\"][0]\n",
    "            coo = (info[\"coo\"][0].item(), info[\"coo\"][1].item())\n",
    "            theta = info[\"theta\"][0].item()\n",
    "\n",
    "            data_frame_seq_inter.loc[i] = [\n",
    "                str(input.tolist()[0]),\n",
    "                str(tokenizer.decode(input.tolist()[0])),\n",
    "                str(pred.tolist()[0][-1]),\n",
    "                str(tokenizer.decode(pred.tolist()[0][-1])),\n",
    "                str(target.tolist()[0]),\n",
    "                str(tokenizer.decode(target.tolist()[0])),\n",
    "                str(proba.tolist()[-1][-1][-2:]),\n",
    "                (pred[-1][-1] == target).item(),\n",
    "                good_seq,\n",
    "                feel_left,\n",
    "                feel_front,\n",
    "                feel_right,\n",
    "                str(coo),\n",
    "                theta,\n",
    "                state_left,\n",
    "                state_front,\n",
    "                state_right\n",
    "            ]\n",
    "    \n",
    "    return acc, data_frame_seq_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9414da67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_inter(model: nn.Module, \n",
    "            data_loader_train: DataLoader, data_loader_validation: DataLoader,\n",
    "            nb_epoch: int, tokenizer:SimpleTokenizerV1,\n",
    "            optimizer, loss_fn, pourcentTokenDrop:float=0.15):\n",
    "    td = TokenDropInteraction(\n",
    "        prob=pourcentTokenDrop,\n",
    "        tokenizer=tokenizer,\n",
    "        num_special=2)\n",
    "\n",
    "    model.train()\n",
    "    list_acc = []\n",
    "    list_validation = []\n",
    "    list_loss = []\n",
    "    for epoch in tqdm(range(nb_epoch), desc=f\"Training \", unit=\"epoch\"):\n",
    "        acc_means = 0\n",
    "        loss_means = 0\n",
    "        model.train()\n",
    "        for i, data in enumerate(data_loader_train):\n",
    "            data_mask, mask = td(data)\n",
    "            # print(\"data_mask\", data_mask)\n",
    "            # for seq in data_mask.tolist():\n",
    "            #     print(tokenizer_interaction.decode(seq))\n",
    "            bs = data.shape[0]\n",
    "\n",
    "            hidden = torch.zeros(2 * model.num_layers, bs, model.hidden_size).to(device)\n",
    "            memory = torch.zeros(2 * model.num_layers, bs, model.hidden_size).to(device)\n",
    "            \n",
    "            data_mask = data_mask.to(device)\n",
    "            data = data.to(device)\n",
    "                        \n",
    "            proba, hidden, memory = model(data_mask, hidden, memory)\n",
    "            proba = proba.transpose(1, 2)\n",
    "            pred = proba.argmax(dim=1)\n",
    "            pad_mask = (mask == 0)\n",
    "            \n",
    "            pad_mask = pad_mask.to(device)\n",
    "            pred = pred.to(device)\n",
    "            mask = mask.to(device)\n",
    "            # pred_in_seq = pred * pad_mask + 0 * mask\n",
    "            \n",
    "            # Mettre <pad> pour les tokens non masqués\n",
    "            # pred_in_seq = pred_in_seq.masked_fill(pad_mask, tokenizer.encode(\"<pad>\"))\n",
    "            # print(\"proba\", proba.shape)\n",
    "            # print(\"pad_mask\", pad_mask.shape)\n",
    "            # pad_mask pass shape [bs, context_size] to [bs, num_emb ,context_size]\n",
    "            # pad_mask = pad_mask.unsqueeze(1).expand(-1, proba.shape[1], -1)\n",
    "            # print(\"pad_mask\", pad_mask.shape)\n",
    "            # prob_without_mask = proba.masked_fill(pad_mask, tokenizer.encode(\"<pad>\"))\n",
    "            # print(\"prob_without_mask\", prob_without_mask)\n",
    "            \n",
    "            correct = (pred == data)\n",
    "            # print(\"pred\", pred)\n",
    "            # for seq in pred.tolist():\n",
    "            #     print(tokenizer_interaction.decode(seq))\n",
    "            # print(\"data\", data)\n",
    "            # for seq in data.tolist():\n",
    "            #     print(tokenizer_interaction.decode(seq))\n",
    "\n",
    "            \n",
    "            acc = correct.sum() / (correct.shape[0] * correct.shape[1])\n",
    "            # acc2 = correct.sum() / (correct.shape[0] * correct.shape[1])\n",
    "            # acc = correct.sum().item() / pad_mask.sum().item() if pad_mask.sum().item() > 0 else 0.0\n",
    "            acc_means += acc\n",
    "        \n",
    "            loss = loss_fn(proba, data) \n",
    "            loss_means += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if data_loader_validation is not None:\n",
    "            model.eval()\n",
    "            acc_val, _ = eval_inter(model, data_loader_validation, tokenizer)\n",
    "            acc_val = acc_val / len(data_loader_validation)\n",
    "            list_validation.append(acc_val)\n",
    "        acc_means /= len(data_loader_train)\n",
    "        loss_means /= len(data_loader_train)\n",
    "        list_acc.append(acc_means)\n",
    "        list_loss.append(loss_means)\n",
    "        tqdm.write(f\"Epoch {epoch + 1}/{nb_epoch}, Loss: {loss_means}, Accuracy: {acc_means}\")\n",
    "        \n",
    "    return list_acc, list_loss, list_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001d3184",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_interaction = gridWorld(x= 1, y=1, theta=0, world= np.array([\n",
    "                [1, 1, 1, 1, 1, 1],\n",
    "                [1, 0, 0, 0, 0, 1],\n",
    "                [1, 0, 0, 1, 0, 1],\n",
    "                [1, 0, 1, 0, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 1],\n",
    "                [1, 1, 1, 1, 1, 1],\n",
    "            ]))\n",
    "\n",
    "list_vocab = ['<pad>', '<mask>']\n",
    "for act in env_interaction.get_actions():\n",
    "    for fb in env_interaction.get_outcomes():\n",
    "        list_vocab.append((act, fb))\n",
    "for act in env_interaction.get_actions():\n",
    "    list_vocab.append(act)\n",
    "for fb in env_interaction.get_outcomes():\n",
    "        list_vocab.append(fb)\n",
    "tmp = create_dico_numerate_word(list_vocab)\n",
    "tokenizer_interaction = SimpleTokenizerV1(vocab=tmp)\n",
    "\n",
    "dic_remplacement = {}\n",
    "for key, value in tokenizer_interaction.str_to_int.items():\n",
    "    if type(key) == tuple:\n",
    "        dic_remplacement[value] = tokenizer_interaction.encode(key[0])\n",
    "\n",
    "data_train_inter = []\n",
    "for i in range(10000):\n",
    "    data_train_inter.append(get_data_interaction(env_interaction, tokenizer_interaction, n_episodes=50))\n",
    "data_set_interaction = SimpleDataSet(data_train_inter)\n",
    "data_loader_interaction = DataLoader(data_set_interaction, batch_size=16, shuffle=True)\n",
    "\n",
    "hidden_size = 1024\n",
    "num_layers = 1\n",
    "model_inter = LSTM_representation(\n",
    "    num_emb=len(list_vocab),\n",
    "    hidden_size=hidden_size,\n",
    "    emb_size=hidden_size,\n",
    "    num_layers=num_layers,\n",
    "    dropout=0.15\n",
    ")\n",
    "\n",
    "model_inter.to(device)\n",
    "\n",
    "optimizer_inter = optim.Adam(model_inter.parameters(), lr=0.001)\n",
    "loss_fn_inter = nn.CrossEntropyLoss(ignore_index=tokenizer_interaction.encode(\"<pad>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4230d6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_acc, list_loss, list_val = train_inter(\n",
    "    model=model_inter,\n",
    "    data_loader_train=data_loader_interaction, # data_loader_validation=data_loader_test_inter,\n",
    "    nb_epoch=50,\n",
    "    tokenizer=tokenizer_interaction,\n",
    "    optimizer=optimizer_inter,\n",
    "    loss_fn=loss_fn_inter,\n",
    "    pourcentTokenDrop=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec25817",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "# plt.plot(list_loss, label='Loss')\n",
    "list_acc = torch.tensor(list_acc).cpu()\n",
    "plt.plot(list_acc, label='Accuracy')\n",
    "\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Training Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Value')\n",
    "plt.plot(list_loss, label='Accuracy')\n",
    "plt.title('Training loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "# plt.plot(list_loss, label='Loss')\n",
    "plt.plot(list_val, label='Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Value')\n",
    "plt.title('validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b8241e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_test_inter = gridWorld(x= 1, y=1, theta=0, world= np.array([\n",
    "                [1, 1, 1, 1, 1, 1],\n",
    "                [1, 0, 0, 0, 0, 1],\n",
    "                [1, 0, 0, 1, 0, 1],\n",
    "                [1, 0, 1, 0, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 1],\n",
    "                [1, 1, 1, 1, 1, 1],\n",
    "            ]))\n",
    "\n",
    "data_test_x_inter = []\n",
    "data_test_y_inter = []\n",
    "data_infos_inter = []\n",
    "for i in range(1000):\n",
    "    # range_context = np.random.randint(10, 20)\n",
    "    range_context = 20\n",
    "    last_inter =  ('turn_right', 'empty')\n",
    "    while last_inter ==  ('turn_right', 'empty') or last_inter ==  ('turn_left', 'empty'):\n",
    "        sequence = get_data_interaction(env_test_inter, tokenizer_interaction, n_episodes=range_context)\n",
    "        last_inter = tokenizer_interaction.decode(sequence[-1])\n",
    "        \n",
    "    # print(\"last_inter\", last_inter)\n",
    "    # print(\"sequence\", tokenizer_interaction.decode(sequence))\n",
    "    \n",
    "           \n",
    "    data_test_y_inter.append(sequence[-1])\n",
    "    data_test_x_inter.append(sequence[:-1] + [dic_remplacement[sequence[-1]]])\n",
    "    \n",
    "    # print(\"data_test_x\", data_test_x_inter)\n",
    "    # print(\"data_test_x\", tokenizer_interaction.decode(data_test_x_inter[-1]))\n",
    "\n",
    "    \n",
    "    data_infos_inter.append({\n",
    "        \"sequence\": sequence,\n",
    "        \"coo\": env_test_inter.get_coo(),\n",
    "        \"theta\": env_test_inter.get_theta(),\n",
    "        \"last_inter\": last_inter,\n",
    "        \"info_in_sequence\": bool(info_in_seq(tokenizer_interaction.decode(data_test_x_inter[-1]), 6))\n",
    "    })\n",
    "    around = ''\n",
    "    for feel in [\"feel_front\", \"feel_left\", \"feel_right\"]:\n",
    "        state = env_test_inter.outcome(feel)\n",
    "        data_infos_inter[-1][feel] = state\n",
    "        around += f\"{state}|\"\n",
    "    \n",
    "# print(\"data_test_x\", data_test_x)\n",
    "# print(\"data_test_y\", data_test_y)\n",
    "\n",
    "# count 9 and 8 in data_test_y\n",
    "count_7 = 0\n",
    "count_8 = 0\n",
    "\n",
    "for i in data_test_y_inter:\n",
    "    if i == 8:\n",
    "        count_8 += 1\n",
    "    elif i == 9:\n",
    "        count_7 += 1\n",
    "print(f\"count_8 {tokenizer_interaction.decode(8)}\", count_8)\n",
    "print(f\"count_7 {tokenizer_interaction.decode(9)}\", count_7)\n",
    "\n",
    "print(\"data_infos\", data_infos_inter[0])\n",
    "print(\"x \", data_test_x_inter[0])\n",
    "print(\"y \", data_test_y_inter[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420aef5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataSetInfo(Dataset):\n",
    "    def __init__(self, data:torch.Tensor, targets:torch.Tensor, data_infos):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.infos = data_infos\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        target = self.targets[idx]\n",
    "        info = self.infos[idx]\n",
    "        return sample, target, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5ac615",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = max(len(xi) for xi in data_test_x_inter)\n",
    "data_test_x_tensor_inter = torch.zeros((len(data_test_x_inter), length), dtype=torch.long)\n",
    "for i, xi in enumerate(data_test_x_inter):\n",
    "    data_test_x_tensor_inter[i, :len(xi)] = torch.tensor(xi, dtype=torch.long)\n",
    "data_test_y_tensor_inter = torch.tensor(data_test_y_inter, dtype=torch.long)\n",
    "\n",
    "data_loader_test_inter = DataLoader(CustomDataSetInfo(data_test_x_tensor_inter, data_test_y_tensor_inter, data_infos_inter), batch_size=1, shuffle=False)\n",
    "\n",
    "for i, (data_x, data_y, info) in enumerate(data_loader_test_inter):\n",
    "    print(data_x)\n",
    "    print(data_y)\n",
    "    for key, value in info.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8f7da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, data_frame_seq_inter = eval_inter(model_inter, data_loader_test_inter, tokenizer_interaction)\n",
    "print(f\"Accuracy: {acc / 1000}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8383f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Stage (torch)",
   "language": "python",
   "name": "dpt_transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
