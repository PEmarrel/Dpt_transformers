{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./.venv/lib/python3.11/site-packages (2.6.0+cu126)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.11/site-packages (2.1.2)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.11/site-packages (3.10.0)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.11/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in ./.venv/lib/python3.11/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in ./.venv/lib/python3.11/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in ./.venv/lib/python3.11/site-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in ./.venv/lib/python3.11/site-packages (from torch) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in ./.venv/lib/python3.11/site-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in ./.venv/lib/python3.11/site-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in ./.venv/lib/python3.11/site-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in ./.venv/lib/python3.11/site-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in ./.venv/lib/python3.11/site-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in ./.venv/lib/python3.11/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.venv/lib/python3.11/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in ./.venv/lib/python3.11/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in ./.venv/lib/python3.11/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: triton==3.2.0 in ./.venv/lib/python3.11/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.11/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.11/site-packages (from matplotlib) (4.55.8)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.11/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.11/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.11/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "# Package utilisé\n",
    "# pytorch : https://pytorch.org/\n",
    "# numpy : https://numpy.org/\n",
    "# matplotlib : https://matplotlib.org/\n",
    "# pandas : https://pandas.pydata.org/\n",
    "# scikit-learn : https://scikit-learn.org/stable/\n",
    "! pip install torch numpy matplotlib pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from importlib.metadata import version\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "# import math\n",
    "# from dataclasses import dataclass\n",
    "# from matplotlib import pyplot as plt\n",
    "# import time\n",
    "# import os\n",
    "\n",
    "# Pour torch si vous avez un GPU\n",
    "# device = \"cpu\" if not torch.cuda.is_available() else \"cuda\"\n",
    "device = \"cpu\" # Pour forcer l'utilisation du CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environement potentielement testé\n",
    "from environnement.environnement import Environnement as env # mother class\n",
    "from environnement.environnement1 import Environnement1 as env1\n",
    "from environnement.environnement2Str import Environnement2 as env2Str\n",
    "from environnement.environnement3Str import Environnement3 as env3Str\n",
    "from environnement.environnement6Str import Environnement6 as env6Str\n",
    "from environnement.small_loop import small_loop\n",
    "\n",
    "# model machine learning\n",
    "from model.DeepNN import *\n",
    "from model.Tokenizer import *\n",
    "from outil import *\n",
    "from inter.interactions import Interaction\n",
    "from inter.simpleInteraction import simpleInteraction as inter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L'agent qui choisit son destin\n",
    "Dans se notebook nous reprennons la méthode de prédiciton de l'agent 1, mais cette fois l'action ne sera plus pris au hasard. Une fois que notre modèle est entrainé et arrive a correctement prédire le prochain feedback, l'agent poura prendre la meilleure action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent 2\n",
    "Nous reprenons l'agent 1 et nous allons lui ajouter une fonction 'decide', qui permet de choisir la bonne action a faire en suivant une valence et les prédictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent2:\n",
    "    def __init__(self, model, all_outcomes, all_actions, valance, tokenizer, optimizer=None, loss_func=None):\n",
    "        \"\"\" \n",
    "        Création de l'agent.\n",
    "        \n",
    "        - self._action : action précédente\n",
    "        - self._predicted_outcome : prédiction de l'outcome précédent\n",
    "        \"\"\"\n",
    "        self._action = None\n",
    "        self._predicted_outcome = None\n",
    "        self._model = model\n",
    "        self._otimizer = optimizer\n",
    "        self._loss_func = loss_func\n",
    "        self._tokenizer:SimpleTokenizerV1 = tokenizer\n",
    "        self._all_outcomes = all_outcomes\n",
    "        self._all_actions = all_actions\n",
    "        self._history_act = []\n",
    "        self._history_fb = []\n",
    "        self._valance=valance\n",
    "\n",
    "    def fit(self, actions:list, outcomes:list, validate_loader=None):\n",
    "        \"\"\"\n",
    "        Fonction d'entrainement de l'agent\n",
    "\n",
    "        :param: **actions** liste des actions effectuées dans le passé\n",
    "        :param: **outcomes** liste des outcomes en réponse aux actions effectuées\n",
    "        :param: **validate_loader** OPTIONEL validate_loader pour valider le modèle \n",
    "        \"\"\"\n",
    "        actions = [[self._tokenizer.encode(act)] for act in actions]\n",
    "        outcomes = self._tokenizer.encode(outcomes)\n",
    "        if isinstance(self._model, torch.nn.Module):\n",
    "            self._model.train()\n",
    "            actions = torch.tensor(actions, dtype=torch.float).to(device)\n",
    "            outcomes = torch.tensor(outcomes, dtype=torch.long).to(device)\n",
    "            outcomes = torch.nn.functional.one_hot(outcomes, \n",
    "                num_classes=len(self._all_outcomes)\n",
    "                ).to(torch.float)\n",
    "            \n",
    "            data_loader = torch.utils.data.DataLoader(\n",
    "                torch.utils.data.TensorDataset(actions, outcomes),\n",
    "                batch_size=32, shuffle=True\n",
    "            )\n",
    "\n",
    "            train_with_batch(model=self._model, \n",
    "                    train_loader=data_loader,\n",
    "                    optimizer=self._otimizer,\n",
    "                    loss_func=self._loss_func,\n",
    "                    nb_epochs=10,\n",
    "                    validate_loader=validate_loader,\n",
    "                    print_=True)\n",
    "        else: # Si le model n'est pas un model pytorch\n",
    "            raise Exception('Not implemented')\n",
    "            self._model.fit(action, outcome)\n",
    "            pass\n",
    "    \n",
    "    # Ajout par raport a l'agent 1 bonus\n",
    "    def decide(self):\n",
    "        \"\"\"\n",
    "        Fonction qui va choisir la meilleur action a faire, dépandament des prédictions du modèles entrainné.\n",
    "        \"\"\"\n",
    "        best_act = self._all_actions[0] # On initialise avec la première action\n",
    "        best_expected_val = -np.inf # On initialise avec une valeur très basse\n",
    "        for act in self._all_actions: # On parcours toutes les actions\n",
    "            predi = self.predict(act) # On prédit l'outcome de l'action\n",
    "            expected_val = self._valance[inter(act, predi)] # On récupère la valance de l'action\n",
    "            if expected_val > best_expected_val: # Si la valance est meilleure que la meilleure valance actuelle\n",
    "                best_act = act # On garde l'action\n",
    "                best_expected_val = expected_val # On met a jour la meilleure valance trouvée\n",
    "        self._action = best_act # On choit l'action à faire\n",
    "        return best_act\n",
    "\n",
    "    def predict(self, action):\n",
    "        \"\"\"\n",
    "        Funciton de prédiction\n",
    "        \"\"\"\n",
    "        action = self._tokenizer.encode(action)\n",
    "        if isinstance(self._model, torch.nn.Module):\n",
    "            self._model.eval() \n",
    "            action = torch.tensor([action], dtype=torch.float).to(device)\n",
    "            x = self._model(action)\n",
    "            x = torch.argmax(x, dim=0).item()\n",
    "\n",
    "        else:\n",
    "            raise Exception('Not implemented')\n",
    "            x=self._model.predict(action)\n",
    "        \n",
    "        return self._tokenizer.decode(x)\n",
    "\n",
    "    # Modification par rapport à l'agent 1\n",
    "    def action(self, outcome, fit=True, validate_loader=None):\n",
    "        \"\"\" \n",
    "        Fonction qui choisit l'action a faire en fonction de la dernière \\\n",
    "        intéraction avec l'environnement. \\n\n",
    "        C'est ici que nous allons implémenter un mécanisme de ML \\\n",
    "        pour choisir la prochaine action.\n",
    "\n",
    "        :param: **outcome** feedback de la dernière intéraction avec l'environnement\n",
    "\n",
    "        :return: **action** action à effectuer\n",
    "        \"\"\"\n",
    "        if self._action is not None:\n",
    "            self._history_fb.append(outcome)\n",
    "            print(f\"Action: {self._action}, Prediction: {self._predicted_outcome}, Outcome: {outcome}, \" \n",
    "                  f\"\\033[0;31m Satisfaction: {self._predicted_outcome == outcome} \\033[0m\")\n",
    "            if self._predicted_outcome != outcome:\n",
    "                self.fit(self._history_act, self._history_fb, validate_loader)\n",
    "            # Maintenant nous choisissons la prochaine action en fonction de la valance\n",
    "            self._action = self.decide()\n",
    "            self._history_act.append(self._action)\n",
    "            self._predicted_outcome = self.predict(self._action)\n",
    "        else:\n",
    "            self._action = self._all_actions[0]\n",
    "            self._history_act.append(self._action)\n",
    "            self._predicted_outcome = self.predict(self._action)\n",
    "            print(f\"Action de base : {self._action} Prediction: {self._predicted_outcome}\")\n",
    "        \n",
    "        return self._action, self._predicted_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liste hidden init [10, 5]\n",
      "=======================\u001b[0;32m iteration 0 \u001b[0m=======================\n",
      "Action de base : a Prediction: y\n",
      "action a predi y outcome x\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 1 \u001b[0m=======================\n",
      "Action: a, Prediction: y, Outcome: x, \u001b[0;31m Satisfaction: False \u001b[0m\n",
      "Epoch 1/10, Loss: 0.8512\n",
      "Epoch 2/10, Loss: 0.7447\n",
      "Epoch 3/10, Loss: 0.6398\n",
      "Epoch 4/10, Loss: 0.5403\n",
      "Epoch 5/10, Loss: 0.4132\n",
      "Epoch 6/10, Loss: 0.2838\n",
      "Epoch 7/10, Loss: 0.1525\n",
      "Epoch 8/10, Loss: 0.0547\n",
      "Epoch 9/10, Loss: 0.0119\n",
      "Epoch 10/10, Loss: 0.0017\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 2 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 3 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 4 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 5 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 6 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 7 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 8 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 9 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m90 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 10 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 11 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 12 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 13 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 14 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 15 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 16 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 17 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 18 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 19 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env_test2 = env1()\n",
    "\n",
    "model_ML = DeepNetwork(hidden_size=[10, 5], input_size=1, output_size=2)\n",
    "optimizer = torch.optim.Adam(model_ML.parameters(), lr=1e-1, weight_decay=1e-2)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "tokenizer = SimpleTokenizerV1(create_dico_numerate_word(env_test2.get_outcomes() + env_test2.get_actions()))\n",
    "\n",
    "valence = {\n",
    "    inter('a', 'x') : -1,\n",
    "    inter('a', 'y') : 1,\n",
    "    inter('b', 'x') : -1,\n",
    "    inter('b', 'y') : 1\n",
    "}\n",
    "agent_test2 = Agent2(\n",
    "    model=model_ML,\n",
    "    all_outcomes= env_test2.get_outcomes(),\n",
    "    all_actions= env_test2.get_actions(),\n",
    "    valance=valence,\n",
    "    tokenizer=tokenizer,\n",
    "    optimizer=optimizer,\n",
    "    loss_func=loss_func)\n",
    "\n",
    "history_good = []\n",
    "pourcent_by_10 = []\n",
    "outcome = None\n",
    "for i in range(20):\n",
    "    print(f\"=======================\\033[0;32m iteration {i} \\033[0m=======================\")\n",
    "    action, predi = agent_test2.action(outcome, False)\n",
    "    outcome = env_test2.outcome(action)\n",
    "    history_good.append(outcome == predi)\n",
    "    pourcent_by_10.append(sum(history_good[-10:]) * 10 if len(history_good) >= 10 else 0)\n",
    "    print(f'action {action} predi {predi} outcome {outcome}')\n",
    "    print(f\"Action choisie : {action} \\033[0;34m{pourcent_by_10[-1]} \\033[0m\")\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Résultats\n",
    "Au début le modèl peut avoir de la chance et correctement prédire une action sur deux corectement. Dans ce cas nous risquons de ne pas tester toutes les actions possible. Si l'agent ne teste pas toutes les actions possible alors il risque de se contenté d'une seul action même si elle ne maximise pas la valence.\n",
    "\n",
    "## Exemple :\n",
    "Si le modèl prédit initialement (c'est à dire sans entrainement), a => x et b => x. Et que la valance est celle ci :\n",
    "\n",
    "```py\n",
    "valence = {\n",
    "    inter('a', 'x') : -1,\n",
    "    inter('a', 'y') : 1,\n",
    "    inter('b', 'x') : -10,\n",
    "    inter('b', 'y') : 10\n",
    "}\n",
    "```\n",
    "\n",
    "Alors le modèl va préférer l'action 'a' indépendament du vrai résultat de de l'action b.\n",
    "\n",
    "Si l'environement renvois :\n",
    "\n",
    "- 'a' : 'x'\n",
    "- 'b' : 'y'\n",
    "\n",
    "Nous préférions que l'agent chocise l'action 'b'.\n",
    "\n",
    "## Solution\n",
    "Nous avons plusieurs solutions possible a ce problème.\n",
    "\n",
    "### Tester toutes les actions possible\n",
    "Nous pouvons tester toutes les actions possible pour pouvoir prédire correctement.\n",
    "\n",
    "### Mécanisme d'ennui\n",
    "Nous pouvons imaginer que notre agent a 'envie' d'explorer son environement pour s'assurer que ses prédictions sont correct. Nous pouvons mettre en place un cycle qui tout les X temps choisit une autre actions. Nous pouvons pousser ce mécanisme en choisisant les actions les moins 'sûr'.\n",
    "\n",
    "### Probabilités\n",
    "Nous pouvons regarder les probablités pour chaques actions. Si pour une action le modèl n'est pas sûr, alors l'agent peut vouloir s'entrainner sur ces actions. \n",
    "\n",
    "Nous pouvons imaginer une formule qui nous permet de savoir si une probablilé est sûr ou non :\n",
    "\n",
    "$p(A) < \\frac{1}{n} \\times \\lambda + \\frac{1}{n}$\n",
    "- p(A) : La probabilité maximal donné par le modèle\n",
    "- n : Le nombre d'outcomes possibles\n",
    "- $\\lambda$ : Un réel compris entre 0 et 1, à détermnier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution, probabilités\n",
    "\n",
    "Implémentation de l'agent avec cette notion de probabilité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent2Prob:\n",
    "    def __init__(self, model, all_outcomes, all_actions, valance, tokenizer, optimizer=None, loss_func=None):\n",
    "        \"\"\" \n",
    "        Création de l'agent.\n",
    "        \n",
    "        - self._action : action précédente\n",
    "        - self._predicted_outcome : prédiction de l'outcome précédent\n",
    "        \"\"\"\n",
    "        self._action = None\n",
    "        self._predicted_outcome = None\n",
    "        self._model = model\n",
    "        self._otimizer = optimizer\n",
    "        self._loss_func = loss_func\n",
    "        self._tokenizer:SimpleTokenizerV1 = tokenizer\n",
    "        self._all_outcomes = all_outcomes\n",
    "        self._all_actions = all_actions\n",
    "        self._history_act = []\n",
    "        self._history_fb = []\n",
    "        self._valance=valance\n",
    "\n",
    "    def fit(self, actions:list, outcomes:list,nb_epoch:int= 5, validate_loader=None):\n",
    "        \"\"\"\n",
    "        Fonction d'entrainement de l'agent\n",
    "        \"\"\"\n",
    "        actions = [[self._tokenizer.encode(act)] for act in actions]\n",
    "        outcomes = self._tokenizer.encode(outcomes)\n",
    "        if isinstance(self._model, torch.nn.Module):\n",
    "            self._model.train()\n",
    "            actions = torch.tensor(actions, dtype=torch.float).to(device)\n",
    "            outcomes = torch.tensor(outcomes, dtype=torch.long).to(device)\n",
    "            outcomes = torch.nn.functional.one_hot(outcomes, \n",
    "                num_classes=len(self._all_outcomes) # On précise le nombre d'ouctomes possible \n",
    "                ).to(torch.float)\n",
    "            \n",
    "            data_loader = torch.utils.data.DataLoader(\n",
    "                torch.utils.data.TensorDataset(actions, outcomes),\n",
    "                batch_size=32, shuffle=True\n",
    "            )\n",
    "\n",
    "            train_with_batch(model=self._model, \n",
    "                    train_loader=data_loader,\n",
    "                    optimizer=self._otimizer,\n",
    "                    loss_func=self._loss_func,\n",
    "                    nb_epochs=nb_epoch,\n",
    "                    validate_loader=validate_loader,\n",
    "                    print_=True)\n",
    "        else: # Si le model n'est pas un model pytorch\n",
    "            raise Exception('Not implemented')\n",
    "            self._model.fit(action, outcome)\n",
    "            pass\n",
    "\n",
    "    def get_prediction(self, action):\n",
    "        action = self._tokenizer.encode(action)\n",
    "        if isinstance(self._model, torch.nn.Module):\n",
    "            self._model.eval() \n",
    "            action = torch.tensor([action], dtype=torch.float).to(device)\n",
    "            x = self._model(action)\n",
    "            x = torch.nn.functional.softmax(x, dim=0)\n",
    "        else:\n",
    "            raise Exception('Not implemented')\n",
    "            x=self._model.predict(action)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def decide(self):\n",
    "        \"\"\"\n",
    "        Fonction qui choisit l'action a faire en fonction des prédictions \\\n",
    "        du modèles entrainné. Nous renforçons choisisons les actions que \\\n",
    "        ou le modèle n'est pas sûr.\n",
    "        \"\"\"\n",
    "        best_act = self._all_actions[0]\n",
    "        best_expected_val = -np.inf\n",
    "        # Vérifie si le modèles est sur de sa prédiction\n",
    "        for act in self._all_actions:\n",
    "            probs:torch.Tensor = self.get_prediction(act)\n",
    "            max_prob = torch.max(probs).item()\n",
    "            # Formule utilisé $p(A) < \\frac{1}{n} \\times \\lambda + \\frac{1}{n}$\n",
    "            # Avec \\lambda = 0.5\n",
    "            print(f'for action {act} probs {probs} max_prob {max_prob}')\n",
    "            if max_prob < (1/probs.size(dim=0)) + 0.5 * (1/probs.size(dim=0)):\n",
    "                return act\n",
    "            # Si le modèle as une prédiction sur, on regarde sa valance\n",
    "            predi = self._tokenizer.decode(torch.argmax(probs, dim=0).item())\n",
    "            expected_val = self._valance[inter(act, predi)]\n",
    "            if expected_val > best_expected_val:\n",
    "                best_act = act\n",
    "                best_expected_val = expected_val\n",
    "        self._action = best_act\n",
    "        return best_act\n",
    "\n",
    "    def predict(self, action):\n",
    "        \"\"\"\n",
    "        Funciton de prédiction\n",
    "        \"\"\"\n",
    "        action = self._tokenizer.encode(action)\n",
    "        if isinstance(self._model, torch.nn.Module):\n",
    "            self._model.eval() \n",
    "            action = torch.tensor([action], dtype=torch.float).to(device)\n",
    "            x = self._model(action)\n",
    "            x = torch.argmax(x, dim=0).item()\n",
    "\n",
    "        else:\n",
    "            raise Exception('Not implemented')\n",
    "            x=self._model.predict(action)\n",
    "        \n",
    "        return self._tokenizer.decode(x)\n",
    "\n",
    "    def action(self, outcome, fit=True, validate_loader=None):\n",
    "        \"\"\" \n",
    "        Fonction qui choisit l'action a faire en fonction de la dernière \\\n",
    "        intéraction avec l'environnement. \\n\n",
    "        C'est ici que nous allons implémenter un mécanisme de ML \\\n",
    "        pour choisir la prochaine action.\n",
    "\n",
    "        :param: **outcome** feedback de la dernière intéraction avec l'environnement\n",
    "\n",
    "        :return: **action** action à effectuer\n",
    "        \"\"\"\n",
    "        if self._action is not None:\n",
    "            self._history_fb.append(outcome)\n",
    "            print(f\"Action: {self._action}, Prediction: {self._predicted_outcome}, Outcome: {outcome}, \" \n",
    "                  f\"\\033[0;31m Satisfaction: {self._predicted_outcome == outcome} \\033[0m\")\n",
    "            if self._predicted_outcome != outcome:\n",
    "                self.fit(self._history_act, self._history_fb, validate_loader=validate_loader)\n",
    "            # Maintenant nous choisissons la prochaine action en fonction de la valance\n",
    "            self._action = self.decide()\n",
    "            self._history_act.append(self._action)\n",
    "            self._predicted_outcome = self.predict(self._action)\n",
    "        else:\n",
    "            self._action = self._all_actions[0]\n",
    "            self._history_act.append(self._action)\n",
    "            self._predicted_outcome = self.predict(self._action)\n",
    "            print(f\"Action de base : {self._action} Prediction: {self._predicted_outcome}\")\n",
    "        \n",
    "        return self._action, self._predicted_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liste hidden init [10, 5]\n",
      "=======================\u001b[0;32m iteration 0 \u001b[0m=======================\n",
      "Action de base : a Prediction: y\n",
      "action a predi y outcome x\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 1 \u001b[0m=======================\n",
      "Action: a, Prediction: y, Outcome: x, \u001b[0;31m Satisfaction: False \u001b[0m\n",
      "Epoch 1/5, Loss: 0.8872\n",
      "Epoch 2/5, Loss: 0.6906\n",
      "Epoch 3/5, Loss: 0.4980\n",
      "Epoch 4/5, Loss: 0.2793\n",
      "Epoch 5/5, Loss: 0.1039\n",
      "for action a probs tensor([0.9790, 0.0210], grad_fn=<SoftmaxBackward0>) max_prob 0.9790276885032654\n",
      "for action b probs tensor([0.9950, 0.0050], grad_fn=<SoftmaxBackward0>) max_prob 0.9949656128883362\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 2 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.9790, 0.0210], grad_fn=<SoftmaxBackward0>) max_prob 0.9790276885032654\n",
      "for action b probs tensor([0.9950, 0.0050], grad_fn=<SoftmaxBackward0>) max_prob 0.9949656128883362\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 3 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.9790, 0.0210], grad_fn=<SoftmaxBackward0>) max_prob 0.9790276885032654\n",
      "for action b probs tensor([0.9950, 0.0050], grad_fn=<SoftmaxBackward0>) max_prob 0.9949656128883362\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 4 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.9790, 0.0210], grad_fn=<SoftmaxBackward0>) max_prob 0.9790276885032654\n",
      "for action b probs tensor([0.9950, 0.0050], grad_fn=<SoftmaxBackward0>) max_prob 0.9949656128883362\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 5 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.9790, 0.0210], grad_fn=<SoftmaxBackward0>) max_prob 0.9790276885032654\n",
      "for action b probs tensor([0.9950, 0.0050], grad_fn=<SoftmaxBackward0>) max_prob 0.9949656128883362\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 6 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.9790, 0.0210], grad_fn=<SoftmaxBackward0>) max_prob 0.9790276885032654\n",
      "for action b probs tensor([0.9950, 0.0050], grad_fn=<SoftmaxBackward0>) max_prob 0.9949656128883362\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 7 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.9790, 0.0210], grad_fn=<SoftmaxBackward0>) max_prob 0.9790276885032654\n",
      "for action b probs tensor([0.9950, 0.0050], grad_fn=<SoftmaxBackward0>) max_prob 0.9949656128883362\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 8 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.9790, 0.0210], grad_fn=<SoftmaxBackward0>) max_prob 0.9790276885032654\n",
      "for action b probs tensor([0.9950, 0.0050], grad_fn=<SoftmaxBackward0>) max_prob 0.9949656128883362\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 9 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.9790, 0.0210], grad_fn=<SoftmaxBackward0>) max_prob 0.9790276885032654\n",
      "for action b probs tensor([0.9950, 0.0050], grad_fn=<SoftmaxBackward0>) max_prob 0.9949656128883362\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m90 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 10 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.9790, 0.0210], grad_fn=<SoftmaxBackward0>) max_prob 0.9790276885032654\n",
      "for action b probs tensor([0.9950, 0.0050], grad_fn=<SoftmaxBackward0>) max_prob 0.9949656128883362\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 11 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.9790, 0.0210], grad_fn=<SoftmaxBackward0>) max_prob 0.9790276885032654\n",
      "for action b probs tensor([0.9950, 0.0050], grad_fn=<SoftmaxBackward0>) max_prob 0.9949656128883362\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 12 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.9790, 0.0210], grad_fn=<SoftmaxBackward0>) max_prob 0.9790276885032654\n",
      "for action b probs tensor([0.9950, 0.0050], grad_fn=<SoftmaxBackward0>) max_prob 0.9949656128883362\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 13 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.9790, 0.0210], grad_fn=<SoftmaxBackward0>) max_prob 0.9790276885032654\n",
      "for action b probs tensor([0.9950, 0.0050], grad_fn=<SoftmaxBackward0>) max_prob 0.9949656128883362\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 14 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.9790, 0.0210], grad_fn=<SoftmaxBackward0>) max_prob 0.9790276885032654\n",
      "for action b probs tensor([0.9950, 0.0050], grad_fn=<SoftmaxBackward0>) max_prob 0.9949656128883362\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 15 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.9790, 0.0210], grad_fn=<SoftmaxBackward0>) max_prob 0.9790276885032654\n",
      "for action b probs tensor([0.9950, 0.0050], grad_fn=<SoftmaxBackward0>) max_prob 0.9949656128883362\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 16 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.9790, 0.0210], grad_fn=<SoftmaxBackward0>) max_prob 0.9790276885032654\n",
      "for action b probs tensor([0.9950, 0.0050], grad_fn=<SoftmaxBackward0>) max_prob 0.9949656128883362\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 17 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.9790, 0.0210], grad_fn=<SoftmaxBackward0>) max_prob 0.9790276885032654\n",
      "for action b probs tensor([0.9950, 0.0050], grad_fn=<SoftmaxBackward0>) max_prob 0.9949656128883362\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 18 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.9790, 0.0210], grad_fn=<SoftmaxBackward0>) max_prob 0.9790276885032654\n",
      "for action b probs tensor([0.9950, 0.0050], grad_fn=<SoftmaxBackward0>) max_prob 0.9949656128883362\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 19 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.9790, 0.0210], grad_fn=<SoftmaxBackward0>) max_prob 0.9790276885032654\n",
      "for action b probs tensor([0.9950, 0.0050], grad_fn=<SoftmaxBackward0>) max_prob 0.9949656128883362\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env_test2 = env1()\n",
    "\n",
    "model_ML = DeepNetwork(hidden_size=[10, 5], input_size=1, output_size=2)\n",
    "optimizer = torch.optim.Adam(model_ML.parameters(), lr=1e-1, weight_decay=1e-2)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "tokenizer = SimpleTokenizerV1(create_dico_numerate_word(env_test2.get_outcomes() + env_test2.get_actions()))\n",
    "\n",
    "valence = {\n",
    "    inter('a', 'x') : -1,\n",
    "    inter('a', 'y') : 1,\n",
    "    inter('b', 'x') : -1,\n",
    "    inter('b', 'y') : 1\n",
    "}\n",
    "agent_test2 = Agent2Prob(\n",
    "    model=model_ML,\n",
    "    all_outcomes= env_test2.get_outcomes(),\n",
    "    all_actions= env_test2.get_actions(),\n",
    "    valance=valence,\n",
    "    tokenizer=tokenizer,\n",
    "    optimizer=optimizer,\n",
    "    loss_func=loss_func)\n",
    "\n",
    "history_good = []\n",
    "pourcent_by_10 = []\n",
    "outcome = None\n",
    "for i in range(20):\n",
    "    print(f\"=======================\\033[0;32m iteration {i} \\033[0m=======================\")\n",
    "    action, predi = agent_test2.action(outcome, False)\n",
    "    outcome = env_test2.outcome(action)\n",
    "    history_good.append(outcome == predi)\n",
    "    pourcent_by_10.append(sum(history_good[-10:]) * 10 if len(history_good) >= 10 else 0)\n",
    "    print(f'action {action} predi {predi} outcome {outcome}')\n",
    "    print(f\"Action choisie : {action} \\033[0;34m{pourcent_by_10[-1]} \\033[0m\")\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Résultat :\n",
    "L'agent renforce ca connaicance sur 'a', mais renforce aussi sa __mauvaisse__ connaissance sur 'b'. Il est sûr que 'b' donne 'x' sans avoir tester l'action. Pour palier a ce problème, nous pouvons obliger l'agent a tenter toutes les actions possible.\n",
    "\n",
    "# Nouvelle agent\n",
    "Nous allons implémenter deux solutions, celle des probabilité et celle de tester toutes les actions possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent2ProbAllTest:\n",
    "    def __init__(self, model, all_outcomes, all_actions, valance, tokenizer, optimizer=None, loss_func=None):\n",
    "        \"\"\" \n",
    "        Création de l'agent.\n",
    "        \n",
    "        - self._action : action précédente\n",
    "        - self._predicted_outcome : prédiction de l'outcome précédent\n",
    "        \"\"\"\n",
    "        self._action = None\n",
    "        self._predicted_outcome = None\n",
    "        self._model = model\n",
    "        self._otimizer = optimizer\n",
    "        self._loss_func = loss_func\n",
    "        self._tokenizer:SimpleTokenizerV1 = tokenizer\n",
    "        self._all_outcomes = all_outcomes\n",
    "        self._all_actions = all_actions\n",
    "        self._history_act = []\n",
    "        self._history_fb = []\n",
    "        self._valance=valance\n",
    "\n",
    "    def fit(self, actions:list, outcomes:list,nb_epoch:int= 5, validate_loader=None):\n",
    "        \"\"\"\n",
    "        Fonction d'entrainement de l'agent\n",
    "        \"\"\"\n",
    "        print(f\"je fit sur {actions} et {outcomes}\")\n",
    "        actions = [[self._tokenizer.encode(act)] for act in actions]\n",
    "        outcomes = self._tokenizer.encode(outcomes)\n",
    "        if isinstance(self._model, torch.nn.Module):\n",
    "            self._model.train()\n",
    "            actions = torch.tensor(actions, dtype=torch.float).to(device)\n",
    "            outcomes = torch.tensor(outcomes, dtype=torch.long).to(device)\n",
    "            outcomes = torch.nn.functional.one_hot(outcomes, \n",
    "                num_classes=len(self._all_outcomes)\n",
    "                ).to(torch.float)\n",
    "            \n",
    "            data_loader = torch.utils.data.DataLoader(\n",
    "                torch.utils.data.TensorDataset(actions, outcomes),\n",
    "                batch_size=32, shuffle=True\n",
    "            )\n",
    "\n",
    "            train_with_batch(model=self._model, \n",
    "                    train_loader=data_loader,\n",
    "                    optimizer=self._otimizer,\n",
    "                    loss_func=self._loss_func,\n",
    "                    nb_epochs=nb_epoch,\n",
    "                    validate_loader=validate_loader,\n",
    "                    print_=True)\n",
    "        else:\n",
    "            raise Exception('Not implemented')\n",
    "            self._model.fit(action, outcome)\n",
    "            pass\n",
    "\n",
    "    def get_prediction(self, action):\n",
    "        action = self._tokenizer.encode(action)\n",
    "        if isinstance(self._model, torch.nn.Module):\n",
    "            self._model.eval() \n",
    "            action = torch.tensor([action], dtype=torch.float).to(device)\n",
    "            x = self._model(action)\n",
    "            x = torch.nn.functional.softmax(x, dim=0)\n",
    "        else:\n",
    "            raise Exception('Not implemented')\n",
    "            x=self._model.predict(action)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    # Nouvelle fonction qui renvois None si le modèle a tester toutes les actions\n",
    "    # Sinon une action à découvrir\n",
    "    def check_all_actions(self):\n",
    "        \"\"\"\n",
    "        Fonction qui vérifie si le modèle a tester toutes les actions\n",
    "        \"\"\"\n",
    "        act_to_test = None\n",
    "        for act in self._all_actions:\n",
    "            if act not in self._history_act:\n",
    "                act_to_test = act\n",
    "                break\n",
    "        return act_to_test\n",
    "    \n",
    "    def decide(self):\n",
    "        \"\"\"\n",
    "        Fonction qui choisit l'action a faire en fonction des prédictions \\\n",
    "        du modèles entrainné. Nous renforçons choisisons les actions que \\\n",
    "        ou le modèle n'est pas sûr.\n",
    "        \"\"\"\n",
    "        # Vérifie si le modèle a tester toutes les actions\n",
    "        act_test = self.check_all_actions()\n",
    "        if act_test:\n",
    "            print(\"i don't know\", act_test)\n",
    "            self._action = act_test\n",
    "            return act_test\n",
    "\n",
    "        best_act = self._all_actions[0]\n",
    "        best_expected_val = -np.inf\n",
    "        # Vérifie si le modèles est sur de sa prédiction\n",
    "        for act in self._all_actions:\n",
    "            probs:torch.Tensor = self.get_prediction(act)\n",
    "            max_prob = torch.max(probs).item()\n",
    "            # Formule utiliser : 1 / n + 0.5 / n\n",
    "            print(f'for action {act} probs {probs} max_prob {max_prob}')\n",
    "            if max_prob < (1/probs.size(dim=0)) + 0.5 * (1/probs.size(dim=0)):\n",
    "                print(\"je ne suis pas sur de \", act) # On se réentraine au cas ou les actions passé sont déjà suffisante\n",
    "                self.fit(self._history_act, self._history_fb, validate_loader=None, nb_epoch=10)\n",
    "\n",
    "                probs:torch.Tensor = self.get_prediction(act)\n",
    "                max_prob = torch.max(probs).item()\n",
    "                if max_prob < (1/probs.size(dim=0)) + 0.5 * (1/probs.size(dim=0)):\n",
    "                    print(\"je n'arrive pas à être sur de \", act) # Le modèl n'arrive pas à être sur\n",
    "                    return act # On demande a l'agent de refaire l'action\n",
    "            \n",
    "            # Si le modèle as une prédiction sur, on regarde sa valance\n",
    "            predi = self._tokenizer.decode(torch.argmax(probs, dim=0).item())\n",
    "            expected_val = self._valance[inter(act, predi)]\n",
    "            if expected_val > best_expected_val:\n",
    "                best_act = act\n",
    "                best_expected_val = expected_val\n",
    "        self._action = best_act\n",
    "        return best_act\n",
    "\n",
    "    def predict(self, action):\n",
    "        \"\"\"\n",
    "        Funciton de prédiction\n",
    "        \"\"\"\n",
    "        action = self._tokenizer.encode(action)\n",
    "        if isinstance(self._model, torch.nn.Module):\n",
    "            self._model.eval() \n",
    "            action = torch.tensor([action], dtype=torch.float).to(device)\n",
    "            x = self._model(action)\n",
    "            x = torch.argmax(x, dim=0).item()\n",
    "\n",
    "        else:\n",
    "            raise Exception('Not implemented')\n",
    "            x=self._model.predict(action)\n",
    "        \n",
    "        return self._tokenizer.decode(x)\n",
    "\n",
    "    def action(self, outcome, fit=True, validate_loader=None):\n",
    "        \"\"\" \n",
    "        Fonction qui choisit l'action a faire en fonction de la dernière \\\n",
    "        intéraction avec l'environnement. \\n\n",
    "        C'est ici que nous allons implémenter un mécanisme de ML \\\n",
    "        pour choisir la prochaine action.\n",
    "\n",
    "        :param: **outcome** feedback de la dernière intéraction avec l'environnement\n",
    "\n",
    "        :return: **action** action à effectuer\n",
    "        \"\"\"\n",
    "        if self._action is not None:\n",
    "            self._history_fb.append(outcome)\n",
    "            print(f\"Action: {self._action}, Prediction: {self._predicted_outcome}, Outcome: {outcome}, \" \n",
    "                  f\"\\033[0;31m Satisfaction: {self._predicted_outcome == outcome} \\033[0m\")\n",
    "            if self._predicted_outcome != outcome:\n",
    "                self.fit(self._history_act, self._history_fb, validate_loader=validate_loader, nb_epoch=10)\n",
    "            self._action = self.decide()\n",
    "            self._history_act.append(self._action)\n",
    "            self._predicted_outcome = self.predict(self._action)\n",
    "        else:\n",
    "            self._action = self._all_actions[0]\n",
    "            self._history_act.append(self._action)\n",
    "            self._predicted_outcome = self.predict(self._action)\n",
    "            print(f\"Action de base : {self._action} Prediction: {self._predicted_outcome}\")\n",
    "        \n",
    "        return self._action, self._predicted_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liste hidden init [10, 5]\n",
      "=======================\u001b[0;32m iteration 0 \u001b[0m=======================\n",
      "Action de base : a Prediction: x\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 1 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "i don't know b\n",
      "action b predi x outcome y\n",
      "Action choisie : b \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 2 \u001b[0m=======================\n",
      "Action: b, Prediction: x, Outcome: y, \u001b[0;31m Satisfaction: False \u001b[0m\n",
      "je fit sur ['a', 'b'] et ['x', 'y']\n",
      "Epoch 1/10, Loss: 0.7217\n",
      "Epoch 2/10, Loss: 0.6920\n",
      "Epoch 3/10, Loss: 0.6673\n",
      "Epoch 4/10, Loss: 0.6478\n",
      "Epoch 5/10, Loss: 0.6334\n",
      "Epoch 6/10, Loss: 0.6237\n",
      "Epoch 7/10, Loss: 0.6181\n",
      "Epoch 8/10, Loss: 0.6152\n",
      "Epoch 9/10, Loss: 0.6139\n",
      "Epoch 10/10, Loss: 0.6133\n",
      "for action a probs tensor([0.4313, 0.5687], grad_fn=<SoftmaxBackward0>) max_prob 0.5687147378921509\n",
      "je ne suis pas sur de  a\n",
      "je fit sur ['a', 'b'] et ['x', 'y']\n",
      "Epoch 1/10, Loss: 0.6123\n",
      "Epoch 2/10, Loss: 0.6103\n",
      "Epoch 3/10, Loss: 0.6069\n",
      "Epoch 4/10, Loss: 0.6021\n",
      "Epoch 5/10, Loss: 0.5961\n",
      "Epoch 6/10, Loss: 0.5891\n",
      "Epoch 7/10, Loss: 0.5825\n",
      "Epoch 8/10, Loss: 0.5766\n",
      "Epoch 9/10, Loss: 0.5711\n",
      "Epoch 10/10, Loss: 0.5659\n",
      "je n'arrive pas à être sur de  a\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 3 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.5038, 0.4962], grad_fn=<SoftmaxBackward0>) max_prob 0.5038331151008606\n",
      "je ne suis pas sur de  a\n",
      "je fit sur ['a', 'b', 'a'] et ['x', 'y', 'x']\n",
      "Epoch 1/10, Loss: 0.6026\n",
      "Epoch 2/10, Loss: 0.5888\n",
      "Epoch 3/10, Loss: 0.5746\n",
      "Epoch 4/10, Loss: 0.5613\n",
      "Epoch 5/10, Loss: 0.5499\n",
      "Epoch 6/10, Loss: 0.5407\n",
      "Epoch 7/10, Loss: 0.5337\n",
      "Epoch 8/10, Loss: 0.5288\n",
      "Epoch 9/10, Loss: 0.5253\n",
      "Epoch 10/10, Loss: 0.5227\n",
      "je n'arrive pas à être sur de  a\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 4 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.7033, 0.2967], grad_fn=<SoftmaxBackward0>) max_prob 0.7032670378684998\n",
      "je ne suis pas sur de  a\n",
      "je fit sur ['a', 'b', 'a', 'a'] et ['x', 'y', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.4781\n",
      "Epoch 2/10, Loss: 0.4718\n",
      "Epoch 3/10, Loss: 0.4661\n",
      "Epoch 4/10, Loss: 0.4609\n",
      "Epoch 5/10, Loss: 0.4559\n",
      "Epoch 6/10, Loss: 0.4509\n",
      "Epoch 7/10, Loss: 0.4455\n",
      "Epoch 8/10, Loss: 0.4395\n",
      "Epoch 9/10, Loss: 0.4327\n",
      "Epoch 10/10, Loss: 0.4251\n",
      "for action b probs tensor([0.6054, 0.3946], grad_fn=<SoftmaxBackward0>) max_prob 0.6054377555847168\n",
      "je ne suis pas sur de  b\n",
      "je fit sur ['a', 'b', 'a', 'a'] et ['x', 'y', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.4167\n",
      "Epoch 2/10, Loss: 0.4078\n",
      "Epoch 3/10, Loss: 0.3984\n",
      "Epoch 4/10, Loss: 0.3890\n",
      "Epoch 5/10, Loss: 0.3797\n",
      "Epoch 6/10, Loss: 0.3708\n",
      "Epoch 7/10, Loss: 0.3620\n",
      "Epoch 8/10, Loss: 0.3532\n",
      "Epoch 9/10, Loss: 0.3445\n",
      "Epoch 10/10, Loss: 0.3339\n",
      "je n'arrive pas à être sur de  b\n",
      "action b predi y outcome y\n",
      "Action choisie : b \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 5 \u001b[0m=======================\n",
      "Action: b, Prediction: y, Outcome: y, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.7790, 0.2210], grad_fn=<SoftmaxBackward0>) max_prob 0.779048502445221\n",
      "for action b probs tensor([0.4198, 0.5802], grad_fn=<SoftmaxBackward0>) max_prob 0.580195426940918\n",
      "je ne suis pas sur de  b\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b'] et ['x', 'y', 'x', 'x', 'y']\n",
      "Epoch 1/10, Loss: 0.3676\n",
      "Epoch 2/10, Loss: 0.3539\n",
      "Epoch 3/10, Loss: 0.3405\n",
      "Epoch 4/10, Loss: 0.3269\n",
      "Epoch 5/10, Loss: 0.3117\n",
      "Epoch 6/10, Loss: 0.2963\n",
      "Epoch 7/10, Loss: 0.2838\n",
      "Epoch 8/10, Loss: 0.2716\n",
      "Epoch 9/10, Loss: 0.2603\n",
      "Epoch 10/10, Loss: 0.2497\n",
      "action b predi y outcome y\n",
      "Action choisie : b \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 6 \u001b[0m=======================\n",
      "Action: b, Prediction: y, Outcome: y, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.7746, 0.2254], grad_fn=<SoftmaxBackward0>) max_prob 0.7745595574378967\n",
      "for action b probs tensor([0.1932, 0.8068], grad_fn=<SoftmaxBackward0>) max_prob 0.806794285774231\n",
      "action b predi y outcome y\n",
      "Action choisie : b \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 7 \u001b[0m=======================\n",
      "Action: b, Prediction: y, Outcome: y, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.7746, 0.2254], grad_fn=<SoftmaxBackward0>) max_prob 0.7745595574378967\n",
      "for action b probs tensor([0.1932, 0.8068], grad_fn=<SoftmaxBackward0>) max_prob 0.806794285774231\n",
      "action b predi y outcome y\n",
      "Action choisie : b \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 8 \u001b[0m=======================\n",
      "Action: b, Prediction: y, Outcome: y, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.7746, 0.2254], grad_fn=<SoftmaxBackward0>) max_prob 0.7745595574378967\n",
      "for action b probs tensor([0.1932, 0.8068], grad_fn=<SoftmaxBackward0>) max_prob 0.806794285774231\n",
      "action b predi y outcome y\n",
      "Action choisie : b \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 9 \u001b[0m=======================\n",
      "Action: b, Prediction: y, Outcome: y, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.7746, 0.2254], grad_fn=<SoftmaxBackward0>) max_prob 0.7745595574378967\n",
      "for action b probs tensor([0.1932, 0.8068], grad_fn=<SoftmaxBackward0>) max_prob 0.806794285774231\n",
      "action b predi y outcome y\n",
      "Action choisie : b \u001b[0;34m90 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 10 \u001b[0m=======================\n",
      "Action: b, Prediction: y, Outcome: y, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.7746, 0.2254], grad_fn=<SoftmaxBackward0>) max_prob 0.7745595574378967\n",
      "for action b probs tensor([0.1932, 0.8068], grad_fn=<SoftmaxBackward0>) max_prob 0.806794285774231\n",
      "action b predi y outcome y\n",
      "Action choisie : b \u001b[0;34m90 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 11 \u001b[0m=======================\n",
      "Action: b, Prediction: y, Outcome: y, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.7746, 0.2254], grad_fn=<SoftmaxBackward0>) max_prob 0.7745595574378967\n",
      "for action b probs tensor([0.1932, 0.8068], grad_fn=<SoftmaxBackward0>) max_prob 0.806794285774231\n",
      "action b predi y outcome y\n",
      "Action choisie : b \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 12 \u001b[0m=======================\n",
      "Action: b, Prediction: y, Outcome: y, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.7746, 0.2254], grad_fn=<SoftmaxBackward0>) max_prob 0.7745595574378967\n",
      "for action b probs tensor([0.1932, 0.8068], grad_fn=<SoftmaxBackward0>) max_prob 0.806794285774231\n",
      "action b predi y outcome y\n",
      "Action choisie : b \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 13 \u001b[0m=======================\n",
      "Action: b, Prediction: y, Outcome: y, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.7746, 0.2254], grad_fn=<SoftmaxBackward0>) max_prob 0.7745595574378967\n",
      "for action b probs tensor([0.1932, 0.8068], grad_fn=<SoftmaxBackward0>) max_prob 0.806794285774231\n",
      "action b predi y outcome y\n",
      "Action choisie : b \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 14 \u001b[0m=======================\n",
      "Action: b, Prediction: y, Outcome: y, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.7746, 0.2254], grad_fn=<SoftmaxBackward0>) max_prob 0.7745595574378967\n",
      "for action b probs tensor([0.1932, 0.8068], grad_fn=<SoftmaxBackward0>) max_prob 0.806794285774231\n",
      "action b predi y outcome y\n",
      "Action choisie : b \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 15 \u001b[0m=======================\n",
      "Action: b, Prediction: y, Outcome: y, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.7746, 0.2254], grad_fn=<SoftmaxBackward0>) max_prob 0.7745595574378967\n",
      "for action b probs tensor([0.1932, 0.8068], grad_fn=<SoftmaxBackward0>) max_prob 0.806794285774231\n",
      "action b predi y outcome y\n",
      "Action choisie : b \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 16 \u001b[0m=======================\n",
      "Action: b, Prediction: y, Outcome: y, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.7746, 0.2254], grad_fn=<SoftmaxBackward0>) max_prob 0.7745595574378967\n",
      "for action b probs tensor([0.1932, 0.8068], grad_fn=<SoftmaxBackward0>) max_prob 0.806794285774231\n",
      "action b predi y outcome y\n",
      "Action choisie : b \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 17 \u001b[0m=======================\n",
      "Action: b, Prediction: y, Outcome: y, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.7746, 0.2254], grad_fn=<SoftmaxBackward0>) max_prob 0.7745595574378967\n",
      "for action b probs tensor([0.1932, 0.8068], grad_fn=<SoftmaxBackward0>) max_prob 0.806794285774231\n",
      "action b predi y outcome y\n",
      "Action choisie : b \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 18 \u001b[0m=======================\n",
      "Action: b, Prediction: y, Outcome: y, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.7746, 0.2254], grad_fn=<SoftmaxBackward0>) max_prob 0.7745595574378967\n",
      "for action b probs tensor([0.1932, 0.8068], grad_fn=<SoftmaxBackward0>) max_prob 0.806794285774231\n",
      "action b predi y outcome y\n",
      "Action choisie : b \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 19 \u001b[0m=======================\n",
      "Action: b, Prediction: y, Outcome: y, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.7746, 0.2254], grad_fn=<SoftmaxBackward0>) max_prob 0.7745595574378967\n",
      "for action b probs tensor([0.1932, 0.8068], grad_fn=<SoftmaxBackward0>) max_prob 0.806794285774231\n",
      "action b predi y outcome y\n",
      "Action choisie : b \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env_test2 = env1()\n",
    "\n",
    "model_ML = DeepNetwork(hidden_size=[10, 5], input_size=1, output_size=2)\n",
    "optimizer = torch.optim.Adam(model_ML.parameters(), lr=1e-2, weight_decay=1e-4)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "tokenizer = SimpleTokenizerV1(create_dico_numerate_word(env_test2.get_outcomes() + env_test2.get_actions()))\n",
    "\n",
    "valence = {\n",
    "    inter('a', 'x') : -1,\n",
    "    inter('a', 'y') : 1,\n",
    "    inter('b', 'x') : -1,\n",
    "    inter('b', 'y') : 1\n",
    "}\n",
    "agent_test2 = Agent2ProbAllTest(\n",
    "    model=model_ML,\n",
    "    all_outcomes= env_test2.get_outcomes(),\n",
    "    all_actions= env_test2.get_actions(),\n",
    "    valance=valence,\n",
    "    tokenizer=tokenizer,\n",
    "    optimizer=optimizer,\n",
    "    loss_func=loss_func)\n",
    "\n",
    "history_good = []\n",
    "pourcent_by_10 = []\n",
    "outcome = None\n",
    "for i in range(20):\n",
    "    print(f\"=======================\\033[0;32m iteration {i} \\033[0m=======================\")\n",
    "    action, predi = agent_test2.action(outcome, False)\n",
    "    outcome = env_test2.outcome(action)\n",
    "    history_good.append(outcome == predi)\n",
    "    pourcent_by_10.append(sum(history_good[-10:]) * 10 if len(history_good) >= 10 else 0)\n",
    "    print(f'action {action} predi {predi} outcome {outcome}')\n",
    "    print(f\"Action choisie : {action} \\033[0;34m{pourcent_by_10[-1]} \\033[0m\")\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Résultat\n",
    "L'agent arrive a tester toutes les actions et renforce ses connaissances sur les actions dont il n'est sûr. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liste hidden init [10, 5]\n",
      "=======================\u001b[0;32m iteration 0 \u001b[0m=======================\n",
      "Action de base : a Prediction: y\n",
      "action a predi y outcome x\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 1 \u001b[0m=======================\n",
      "Action: a, Prediction: y, Outcome: x, \u001b[0;31m Satisfaction: False \u001b[0m\n",
      "je fit sur ['a'] et ['x']\n",
      "Epoch 1/10, Loss: 0.7598\n",
      "Epoch 2/10, Loss: 0.5073\n",
      "Epoch 3/10, Loss: 0.2437\n",
      "Epoch 4/10, Loss: 0.0658\n",
      "Epoch 5/10, Loss: 0.0083\n",
      "Epoch 6/10, Loss: 0.0006\n",
      "Epoch 7/10, Loss: 0.0000\n",
      "Epoch 8/10, Loss: 0.0000\n",
      "Epoch 9/10, Loss: 0.0000\n",
      "Epoch 10/10, Loss: 0.0000\n",
      "i don't know b\n",
      "action b predi x outcome y\n",
      "Action choisie : b \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 2 \u001b[0m=======================\n",
      "Action: b, Prediction: x, Outcome: y, \u001b[0;31m Satisfaction: False \u001b[0m\n",
      "je fit sur ['a', 'b'] et ['x', 'y']\n",
      "Epoch 1/10, Loss: 12.3014\n",
      "Epoch 2/10, Loss: 10.0630\n",
      "Epoch 3/10, Loss: 7.3981\n",
      "Epoch 4/10, Loss: 4.7797\n",
      "Epoch 5/10, Loss: 2.4850\n",
      "Epoch 6/10, Loss: 0.8407\n",
      "Epoch 7/10, Loss: 0.7409\n",
      "Epoch 8/10, Loss: 0.7228\n",
      "Epoch 9/10, Loss: 0.7093\n",
      "Epoch 10/10, Loss: 0.7001\n",
      "for action a probs tensor([0.5296, 0.4704], grad_fn=<SoftmaxBackward0>) max_prob 0.5295801162719727\n",
      "je ne suis pas sur de  a\n",
      "je fit sur ['a', 'b'] et ['x', 'y']\n",
      "Epoch 1/10, Loss: 0.6949\n",
      "Epoch 2/10, Loss: 0.6932\n",
      "Epoch 3/10, Loss: 0.6942\n",
      "Epoch 4/10, Loss: 0.6971\n",
      "Epoch 5/10, Loss: 0.7013\n",
      "Epoch 6/10, Loss: 0.7060\n",
      "Epoch 7/10, Loss: 0.7105\n",
      "Epoch 8/10, Loss: 0.7145\n",
      "Epoch 9/10, Loss: 0.7175\n",
      "Epoch 10/10, Loss: 0.7193\n",
      "je n'arrive pas à être sur de  a\n",
      "action a predi y outcome y\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 3 \u001b[0m=======================\n",
      "Action: a, Prediction: y, Outcome: y, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.3857, 0.6143], grad_fn=<SoftmaxBackward0>) max_prob 0.6143046617507935\n",
      "je ne suis pas sur de  a\n",
      "je fit sur ['a', 'b', 'a'] et ['x', 'y', 'y']\n",
      "Epoch 1/10, Loss: 0.6424\n",
      "Epoch 2/10, Loss: 0.6419\n",
      "Epoch 3/10, Loss: 0.6413\n",
      "Epoch 4/10, Loss: 0.6406\n",
      "Epoch 5/10, Loss: 0.6399\n",
      "Epoch 6/10, Loss: 0.6392\n",
      "Epoch 7/10, Loss: 0.6385\n",
      "Epoch 8/10, Loss: 0.6379\n",
      "Epoch 9/10, Loss: 0.6375\n",
      "Epoch 10/10, Loss: 0.6370\n",
      "je n'arrive pas à être sur de  a\n",
      "action a predi y outcome x\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 4 \u001b[0m=======================\n",
      "Action: a, Prediction: y, Outcome: x, \u001b[0;31m Satisfaction: False \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a'] et ['x', 'y', 'y', 'x']\n",
      "Epoch 1/10, Loss: 0.7467\n",
      "Epoch 2/10, Loss: 0.7342\n",
      "Epoch 3/10, Loss: 0.7166\n",
      "Epoch 4/10, Loss: 0.7487\n",
      "Epoch 5/10, Loss: 0.7161\n",
      "Epoch 6/10, Loss: 0.7241\n",
      "Epoch 7/10, Loss: 0.7319\n",
      "Epoch 8/10, Loss: 0.7290\n",
      "Epoch 9/10, Loss: 0.7211\n",
      "Epoch 10/10, Loss: 0.7128\n",
      "for action a probs tensor([0.4436, 0.5564], grad_fn=<SoftmaxBackward0>) max_prob 0.5563703179359436\n",
      "je ne suis pas sur de  a\n",
      "je fit sur ['a', 'b', 'a', 'a'] et ['x', 'y', 'y', 'x']\n",
      "Epoch 1/10, Loss: 0.7062\n",
      "Epoch 2/10, Loss: 0.7050\n",
      "Epoch 3/10, Loss: 0.7074\n",
      "Epoch 4/10, Loss: 0.7043\n",
      "Epoch 5/10, Loss: 0.6995\n",
      "Epoch 6/10, Loss: 0.6991\n",
      "Epoch 7/10, Loss: 0.6998\n",
      "Epoch 8/10, Loss: 0.6977\n",
      "Epoch 9/10, Loss: 0.6944\n",
      "Epoch 10/10, Loss: 0.6928\n",
      "je n'arrive pas à être sur de  a\n",
      "action a predi y outcome x\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 5 \u001b[0m=======================\n",
      "Action: a, Prediction: y, Outcome: x, \u001b[0;31m Satisfaction: False \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.6936\n",
      "Epoch 2/10, Loss: 0.6840\n",
      "Epoch 3/10, Loss: 0.6796\n",
      "Epoch 4/10, Loss: 0.6804\n",
      "Epoch 5/10, Loss: 0.6803\n",
      "Epoch 6/10, Loss: 0.6759\n",
      "Epoch 7/10, Loss: 0.6706\n",
      "Epoch 8/10, Loss: 0.6741\n",
      "Epoch 9/10, Loss: 0.6735\n",
      "Epoch 10/10, Loss: 0.6731\n",
      "for action a probs tensor([0.5997, 0.4003], grad_fn=<SoftmaxBackward0>) max_prob 0.5996564030647278\n",
      "je ne suis pas sur de  a\n",
      "je fit sur ['a', 'b', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.6730\n",
      "Epoch 2/10, Loss: 0.6731\n",
      "Epoch 3/10, Loss: 0.6733\n",
      "Epoch 4/10, Loss: 0.6735\n",
      "Epoch 5/10, Loss: 0.6738\n",
      "Epoch 6/10, Loss: 0.6740\n",
      "Epoch 7/10, Loss: 0.6742\n",
      "Epoch 8/10, Loss: 0.6742\n",
      "Epoch 9/10, Loss: 0.6742\n",
      "Epoch 10/10, Loss: 0.6741\n",
      "je n'arrive pas à être sur de  a\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 6 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.6215, 0.3785], grad_fn=<SoftmaxBackward0>) max_prob 0.6214936375617981\n",
      "je ne suis pas sur de  a\n",
      "je fit sur ['a', 'b', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.6409\n",
      "Epoch 2/10, Loss: 0.6410\n",
      "Epoch 3/10, Loss: 0.6407\n",
      "Epoch 4/10, Loss: 0.6403\n",
      "Epoch 5/10, Loss: 0.6398\n",
      "Epoch 6/10, Loss: 0.6391\n",
      "Epoch 7/10, Loss: 0.6385\n",
      "Epoch 8/10, Loss: 0.6379\n",
      "Epoch 9/10, Loss: 0.6374\n",
      "Epoch 10/10, Loss: 0.6370\n",
      "je n'arrive pas à être sur de  a\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 7 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.6565, 0.3435], grad_fn=<SoftmaxBackward0>) max_prob 0.6565293669700623\n",
      "je ne suis pas sur de  a\n",
      "je fit sur ['a', 'b', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.6059\n",
      "Epoch 2/10, Loss: 0.6044\n",
      "Epoch 3/10, Loss: 0.6029\n",
      "Epoch 4/10, Loss: 0.6016\n",
      "Epoch 5/10, Loss: 0.6004\n",
      "Epoch 6/10, Loss: 0.5995\n",
      "Epoch 7/10, Loss: 0.5988\n",
      "Epoch 8/10, Loss: 0.5984\n",
      "Epoch 9/10, Loss: 0.5983\n",
      "Epoch 10/10, Loss: 0.5983\n",
      "je n'arrive pas à être sur de  a\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 8 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.7221, 0.2779], grad_fn=<SoftmaxBackward0>) max_prob 0.7220856547355652\n",
      "je ne suis pas sur de  a\n",
      "je fit sur ['a', 'b', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.5643\n",
      "Epoch 2/10, Loss: 0.5637\n",
      "Epoch 3/10, Loss: 0.5632\n",
      "Epoch 4/10, Loss: 0.5628\n",
      "Epoch 5/10, Loss: 0.5626\n",
      "Epoch 6/10, Loss: 0.5624\n",
      "Epoch 7/10, Loss: 0.5623\n",
      "Epoch 8/10, Loss: 0.5623\n",
      "Epoch 9/10, Loss: 0.5624\n",
      "Epoch 10/10, Loss: 0.5624\n",
      "for action b probs tensor([0.7579, 0.2421], grad_fn=<SoftmaxBackward0>) max_prob 0.7579125761985779\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 9 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.7579, 0.2421], grad_fn=<SoftmaxBackward0>) max_prob 0.7579125761985779\n",
      "for action b probs tensor([0.7579, 0.2421], grad_fn=<SoftmaxBackward0>) max_prob 0.7579125761985779\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m60 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 10 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.7579, 0.2421], grad_fn=<SoftmaxBackward0>) max_prob 0.7579125761985779\n",
      "for action b probs tensor([0.7579, 0.2421], grad_fn=<SoftmaxBackward0>) max_prob 0.7579125761985779\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m70 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 11 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.7579, 0.2421], grad_fn=<SoftmaxBackward0>) max_prob 0.7579125761985779\n",
      "for action b probs tensor([0.7579, 0.2421], grad_fn=<SoftmaxBackward0>) max_prob 0.7579125761985779\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m80 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 12 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.7579, 0.2421], grad_fn=<SoftmaxBackward0>) max_prob 0.7579125761985779\n",
      "for action b probs tensor([0.7579, 0.2421], grad_fn=<SoftmaxBackward0>) max_prob 0.7579125761985779\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m80 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 13 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.7579, 0.2421], grad_fn=<SoftmaxBackward0>) max_prob 0.7579125761985779\n",
      "for action b probs tensor([0.7579, 0.2421], grad_fn=<SoftmaxBackward0>) max_prob 0.7579125761985779\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m90 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 14 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.7579, 0.2421], grad_fn=<SoftmaxBackward0>) max_prob 0.7579125761985779\n",
      "for action b probs tensor([0.7579, 0.2421], grad_fn=<SoftmaxBackward0>) max_prob 0.7579125761985779\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 15 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.7579, 0.2421], grad_fn=<SoftmaxBackward0>) max_prob 0.7579125761985779\n",
      "for action b probs tensor([0.7579, 0.2421], grad_fn=<SoftmaxBackward0>) max_prob 0.7579125761985779\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 16 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.7579, 0.2421], grad_fn=<SoftmaxBackward0>) max_prob 0.7579125761985779\n",
      "for action b probs tensor([0.7579, 0.2421], grad_fn=<SoftmaxBackward0>) max_prob 0.7579125761985779\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 17 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.7579, 0.2421], grad_fn=<SoftmaxBackward0>) max_prob 0.7579125761985779\n",
      "for action b probs tensor([0.7579, 0.2421], grad_fn=<SoftmaxBackward0>) max_prob 0.7579125761985779\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 18 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.7579, 0.2421], grad_fn=<SoftmaxBackward0>) max_prob 0.7579125761985779\n",
      "for action b probs tensor([0.7579, 0.2421], grad_fn=<SoftmaxBackward0>) max_prob 0.7579125761985779\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 19 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.7579, 0.2421], grad_fn=<SoftmaxBackward0>) max_prob 0.7579125761985779\n",
      "for action b probs tensor([0.7579, 0.2421], grad_fn=<SoftmaxBackward0>) max_prob 0.7579125761985779\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env_test2 = env3Str()\n",
    "\n",
    "model_ML = DeepNetwork(hidden_size=[10, 5], input_size=1, output_size=2)\n",
    "optimizer = torch.optim.Adam(model_ML.parameters(), lr=1e-1, weight_decay=1e-2)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "tokenizer = SimpleTokenizerV1(create_dico_numerate_word(env_test2.get_outcomes() + env_test2.get_actions()))\n",
    "\n",
    "valence = {\n",
    "    inter('a', 'x') : -1,\n",
    "    inter('a', 'y') : 1,\n",
    "    inter('b', 'x') : -1,\n",
    "    inter('b', 'y') : 1\n",
    "}\n",
    "agent_test2 = Agent2ProbAllTest(\n",
    "    model=model_ML,\n",
    "    all_outcomes= env_test2.get_outcomes(),\n",
    "    all_actions= env_test2.get_actions(),\n",
    "    valance=valence,\n",
    "    tokenizer=tokenizer,\n",
    "    optimizer=optimizer,\n",
    "    loss_func=loss_func)\n",
    "\n",
    "history_good = []\n",
    "pourcent_by_10 = []\n",
    "outcome = None\n",
    "for i in range(20):\n",
    "    print(f\"=======================\\033[0;32m iteration {i} \\033[0m=======================\")\n",
    "    action, predi = agent_test2.action(outcome, False)\n",
    "    outcome = env_test2.outcome(action)\n",
    "    history_good.append(outcome == predi)\n",
    "    pourcent_by_10.append(sum(history_good[-10:]) * 10 if len(history_good) >= 10 else 0)\n",
    "    print(f'action {action} predi {predi} outcome {outcome}')\n",
    "    print(f\"Action choisie : {action} \\033[0;34m{pourcent_by_10[-1]} \\033[0m\")\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environement \"plus complexe\"\n",
    "Si nous voulons obtenir le comportement optimal en fonction des probabilités que le modèle renvois, nous voulons utiliser une formule qui prend en compte chaque probabilité. Comme celle ci :\n",
    "\n",
    "$\\displaystyle \\mathbb{E}(V_a) = \\sum_{s \\in S} \\sum_{j=1}^{n_s} v_{sj} \\cdot \\prod_{k=1}^{j} p_{sk} $\n",
    "\n",
    "dans laquelle $n_s$ est la longueur de $s$, c'est-à-dire le nombre d'interactions primitives de $s$, et $p_{sk}$ est la probabilité de réaliser avec succès la $k^{ième}$ interaction primitive de $s$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent2DecideWithProb:\n",
    "    def __init__(self, model, all_outcomes, all_actions, valance, tokenizer, optimizer=None, loss_func=None):\n",
    "        \"\"\" \n",
    "        Création de l'agent.\n",
    "        \n",
    "        - self._action : action précédente\n",
    "        - self._predicted_outcome : prédiction de l'outcome précédent\n",
    "        \"\"\"\n",
    "        self._action = None\n",
    "        self._predicted_outcome = None\n",
    "        self._model = model\n",
    "        self._otimizer = optimizer\n",
    "        self._loss_func = loss_func\n",
    "        self._tokenizer:SimpleTokenizerV1 = tokenizer\n",
    "        self._all_outcomes = all_outcomes\n",
    "        self._all_actions = all_actions\n",
    "        self._history_act = []\n",
    "        self._history_fb = []\n",
    "        self._valance=valance\n",
    "\n",
    "    def fit(self, actions:list, outcomes:list,nb_epoch:int= 5, validate_loader=None):\n",
    "        \"\"\"\n",
    "        Fonction d'entrainement de l'agent\n",
    "        \"\"\"\n",
    "        print(f\"je fit sur {actions} et {outcomes}\")\n",
    "        actions = [[self._tokenizer.encode(act)] for act in actions]\n",
    "        outcomes = self._tokenizer.encode(outcomes)\n",
    "        if isinstance(self._model, torch.nn.Module):\n",
    "            self._model.train()\n",
    "            actions = torch.tensor(actions, dtype=torch.float).to(device)\n",
    "            outcomes = torch.tensor(outcomes, dtype=torch.long).to(device)\n",
    "            outcomes = torch.nn.functional.one_hot(outcomes, \n",
    "                num_classes=len(self._all_outcomes)\n",
    "                ).to(torch.float)\n",
    "            \n",
    "            data_loader = torch.utils.data.DataLoader(\n",
    "                torch.utils.data.TensorDataset(actions, outcomes),\n",
    "                batch_size=32, shuffle=True\n",
    "            )\n",
    "\n",
    "            train_with_batch(model=self._model, \n",
    "                    train_loader=data_loader,\n",
    "                    optimizer=self._otimizer,\n",
    "                    loss_func=self._loss_func,\n",
    "                    nb_epochs=nb_epoch,\n",
    "                    validate_loader=validate_loader,\n",
    "                    print_=True)\n",
    "        else:\n",
    "            raise Exception('Not implemented')\n",
    "            self._model.fit(action, outcome)\n",
    "            pass\n",
    "\n",
    "    def get_prediction(self, action):\n",
    "        action = self._tokenizer.encode(action)\n",
    "        if isinstance(self._model, torch.nn.Module):\n",
    "            self._model.eval() \n",
    "            action = torch.tensor([action], dtype=torch.float).to(device)\n",
    "            x = self._model(action)\n",
    "            x = torch.nn.functional.softmax(x, dim=0)\n",
    "        else:\n",
    "            raise Exception('Not implemented')\n",
    "            x=self._model.predict(action)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    # Nouvelle fonction qui renvois None si le modèle a tester toutes les actions\n",
    "    # Sinon une action à découvrir\n",
    "    def check_all_actions(self):\n",
    "        \"\"\"\n",
    "        Fonction qui vérifie si le modèle a tester toutes les actions\n",
    "        \"\"\"\n",
    "        act_to_test = None\n",
    "        for act in self._all_actions:\n",
    "            if act not in self._history_act:\n",
    "                act_to_test = act\n",
    "                break\n",
    "        return act_to_test\n",
    "    \n",
    "    def decide(self):\n",
    "        \"\"\"\n",
    "        Fonction qui choisit l'action a faire en fonction des prédictions \\\n",
    "        du modèles entrainné. Nous renforçons choisisons les actions que \\\n",
    "        ou le modèle n'est pas sûr.\n",
    "        \"\"\"\n",
    "        # On laisse le mécanisme d'exploration pour le moment\n",
    "        act_test = self.check_all_actions()\n",
    "        if act_test:\n",
    "            print(\"i don't know\", act_test)\n",
    "            self._action = act_test\n",
    "            return act_test\n",
    "\n",
    "        best_act = self._all_actions[0]\n",
    "        best_expected_val = -np.inf\n",
    "        # Vérifie si le modèles est sur de sa prédiction\n",
    "        for act in self._all_actions:\n",
    "            probs:torch.Tensor = self.get_prediction(act)\n",
    "            max_prob = torch.max(probs).item()\n",
    "            # Formule utiliser : 1 / n + 0.5 / n\n",
    "            print(f'for action {act} probs {probs} max_prob {max_prob}')\n",
    "            expected_val = 0\n",
    "            for i, prob in enumerate(probs):\n",
    "                print(f'action {act} probabilité {prob.item()} valance {self._valance[inter(act, self._tokenizer.decode(i))]} outcome {self._tokenizer.decode(i)}')\n",
    "                expected_val += prob.item() * self._valance[inter(act, self._tokenizer.decode(i))]\n",
    "            \n",
    "            if expected_val > best_expected_val:\n",
    "                best_act = act\n",
    "                best_expected_val = expected_val\n",
    "        self._action = best_act\n",
    "        return best_act\n",
    "\n",
    "    def predict(self, action):\n",
    "        \"\"\"\n",
    "        Funciton de prédiction\n",
    "        \"\"\"\n",
    "        action = self._tokenizer.encode(action)\n",
    "        if isinstance(self._model, torch.nn.Module):\n",
    "            self._model.eval() \n",
    "            action = torch.tensor([action], dtype=torch.float).to(device)\n",
    "            x = self._model(action)\n",
    "            x = torch.argmax(x, dim=0).item()\n",
    "\n",
    "        else:\n",
    "            raise Exception('Not implemented')\n",
    "            x=self._model.predict(action)\n",
    "        \n",
    "        return self._tokenizer.decode(x)\n",
    "\n",
    "    def action(self, outcome, fit=True, validate_loader=None):\n",
    "        \"\"\" \n",
    "        Fonction qui choisit l'action a faire en fonction de la dernière \\\n",
    "        intéraction avec l'environnement. \\n\n",
    "        C'est ici que nous allons implémenter un mécanisme de ML \\\n",
    "        pour choisir la prochaine action.\n",
    "\n",
    "        :param: **outcome** feedback de la dernière intéraction avec l'environnement\n",
    "\n",
    "        :return: **action** action à effectuer\n",
    "        \"\"\"\n",
    "        if self._action is not None:\n",
    "            self._history_fb.append(outcome)\n",
    "            print(f\"Action: {self._action}, Prediction: {self._predicted_outcome}, Outcome: {outcome}, \" \n",
    "                  f\"\\033[0;31m Satisfaction: {self._predicted_outcome == outcome} \\033[0m\")\n",
    "            if self._predicted_outcome != outcome:\n",
    "                self.fit(self._history_act, self._history_fb, validate_loader=validate_loader, nb_epoch=10)\n",
    "            self._action = self.decide()\n",
    "            self._history_act.append(self._action)\n",
    "            self._predicted_outcome = self.predict(self._action)\n",
    "        else:\n",
    "            self._action = self._all_actions[0]\n",
    "            self._history_act.append(self._action)\n",
    "            self._predicted_outcome = self.predict(self._action)\n",
    "            print(f\"Action de base : {self._action} Prediction: {self._predicted_outcome}\")\n",
    "        \n",
    "        return self._action, self._predicted_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liste hidden init [10, 5]\n",
      "=======================\u001b[0;32m iteration 0 \u001b[0m=======================\n",
      "Action de base : a Prediction: x\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 1 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "i don't know b\n",
      "action b predi x outcome y\n",
      "Action choisie : b \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 2 \u001b[0m=======================\n",
      "Action: b, Prediction: x, Outcome: y, \u001b[0;31m Satisfaction: False \u001b[0m\n",
      "je fit sur ['a', 'b'] et ['x', 'y']\n",
      "Epoch 1/10, Loss: 0.7326\n",
      "Epoch 2/10, Loss: 0.7183\n",
      "Epoch 3/10, Loss: 0.7061\n",
      "Epoch 4/10, Loss: 0.6954\n",
      "Epoch 5/10, Loss: 0.6859\n",
      "Epoch 6/10, Loss: 0.6769\n",
      "Epoch 7/10, Loss: 0.6695\n",
      "Epoch 8/10, Loss: 0.6643\n",
      "Epoch 9/10, Loss: 0.6600\n",
      "Epoch 10/10, Loss: 0.6568\n",
      "for action a probs tensor([0.4534, 0.5466], grad_fn=<SoftmaxBackward0>) max_prob 0.546560525894165\n",
      "action a probabilité 0.45343947410583496 valance -1 outcome x\n",
      "action a probabilité 0.546560525894165 valance 1 outcome y\n",
      "for action b probs tensor([0.4045, 0.5955], grad_fn=<SoftmaxBackward0>) max_prob 0.5955348610877991\n",
      "action b probabilité 0.4044651687145233 valance -1 outcome x\n",
      "action b probabilité 0.5955348610877991 valance 1 outcome y\n",
      "action b predi y outcome y\n",
      "Action choisie : b \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 3 \u001b[0m=======================\n",
      "Action: b, Prediction: y, Outcome: y, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.4534, 0.5466], grad_fn=<SoftmaxBackward0>) max_prob 0.546560525894165\n",
      "action a probabilité 0.45343947410583496 valance -1 outcome x\n",
      "action a probabilité 0.546560525894165 valance 1 outcome y\n",
      "for action b probs tensor([0.4045, 0.5955], grad_fn=<SoftmaxBackward0>) max_prob 0.5955348610877991\n",
      "action b probabilité 0.4044651687145233 valance -1 outcome x\n",
      "action b probabilité 0.5955348610877991 valance 1 outcome y\n",
      "action b predi y outcome y\n",
      "Action choisie : b \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 4 \u001b[0m=======================\n",
      "Action: b, Prediction: y, Outcome: y, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.4534, 0.5466], grad_fn=<SoftmaxBackward0>) max_prob 0.546560525894165\n",
      "action a probabilité 0.45343947410583496 valance -1 outcome x\n",
      "action a probabilité 0.546560525894165 valance 1 outcome y\n",
      "for action b probs tensor([0.4045, 0.5955], grad_fn=<SoftmaxBackward0>) max_prob 0.5955348610877991\n",
      "action b probabilité 0.4044651687145233 valance -1 outcome x\n",
      "action b probabilité 0.5955348610877991 valance 1 outcome y\n",
      "action b predi y outcome y\n",
      "Action choisie : b \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 5 \u001b[0m=======================\n",
      "Action: b, Prediction: y, Outcome: y, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.4534, 0.5466], grad_fn=<SoftmaxBackward0>) max_prob 0.546560525894165\n",
      "action a probabilité 0.45343947410583496 valance -1 outcome x\n",
      "action a probabilité 0.546560525894165 valance 1 outcome y\n",
      "for action b probs tensor([0.4045, 0.5955], grad_fn=<SoftmaxBackward0>) max_prob 0.5955348610877991\n",
      "action b probabilité 0.4044651687145233 valance -1 outcome x\n",
      "action b probabilité 0.5955348610877991 valance 1 outcome y\n",
      "action b predi y outcome y\n",
      "Action choisie : b \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 6 \u001b[0m=======================\n",
      "Action: b, Prediction: y, Outcome: y, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.4534, 0.5466], grad_fn=<SoftmaxBackward0>) max_prob 0.546560525894165\n",
      "action a probabilité 0.45343947410583496 valance -1 outcome x\n",
      "action a probabilité 0.546560525894165 valance 1 outcome y\n",
      "for action b probs tensor([0.4045, 0.5955], grad_fn=<SoftmaxBackward0>) max_prob 0.5955348610877991\n",
      "action b probabilité 0.4044651687145233 valance -1 outcome x\n",
      "action b probabilité 0.5955348610877991 valance 1 outcome y\n",
      "action b predi y outcome y\n",
      "Action choisie : b \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 7 \u001b[0m=======================\n",
      "Action: b, Prediction: y, Outcome: y, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.4534, 0.5466], grad_fn=<SoftmaxBackward0>) max_prob 0.546560525894165\n",
      "action a probabilité 0.45343947410583496 valance -1 outcome x\n",
      "action a probabilité 0.546560525894165 valance 1 outcome y\n",
      "for action b probs tensor([0.4045, 0.5955], grad_fn=<SoftmaxBackward0>) max_prob 0.5955348610877991\n",
      "action b probabilité 0.4044651687145233 valance -1 outcome x\n",
      "action b probabilité 0.5955348610877991 valance 1 outcome y\n",
      "action b predi y outcome y\n",
      "Action choisie : b \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 8 \u001b[0m=======================\n",
      "Action: b, Prediction: y, Outcome: y, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.4534, 0.5466], grad_fn=<SoftmaxBackward0>) max_prob 0.546560525894165\n",
      "action a probabilité 0.45343947410583496 valance -1 outcome x\n",
      "action a probabilité 0.546560525894165 valance 1 outcome y\n",
      "for action b probs tensor([0.4045, 0.5955], grad_fn=<SoftmaxBackward0>) max_prob 0.5955348610877991\n",
      "action b probabilité 0.4044651687145233 valance -1 outcome x\n",
      "action b probabilité 0.5955348610877991 valance 1 outcome y\n",
      "action b predi y outcome y\n",
      "Action choisie : b \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 9 \u001b[0m=======================\n",
      "Action: b, Prediction: y, Outcome: y, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.4534, 0.5466], grad_fn=<SoftmaxBackward0>) max_prob 0.546560525894165\n",
      "action a probabilité 0.45343947410583496 valance -1 outcome x\n",
      "action a probabilité 0.546560525894165 valance 1 outcome y\n",
      "for action b probs tensor([0.4045, 0.5955], grad_fn=<SoftmaxBackward0>) max_prob 0.5955348610877991\n",
      "action b probabilité 0.4044651687145233 valance -1 outcome x\n",
      "action b probabilité 0.5955348610877991 valance 1 outcome y\n",
      "action b predi y outcome y\n",
      "Action choisie : b \u001b[0;34m90 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 10 \u001b[0m=======================\n",
      "Action: b, Prediction: y, Outcome: y, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.4534, 0.5466], grad_fn=<SoftmaxBackward0>) max_prob 0.546560525894165\n",
      "action a probabilité 0.45343947410583496 valance -1 outcome x\n",
      "action a probabilité 0.546560525894165 valance 1 outcome y\n",
      "for action b probs tensor([0.4045, 0.5955], grad_fn=<SoftmaxBackward0>) max_prob 0.5955348610877991\n",
      "action b probabilité 0.4044651687145233 valance -1 outcome x\n",
      "action b probabilité 0.5955348610877991 valance 1 outcome y\n",
      "action b predi y outcome y\n",
      "Action choisie : b \u001b[0;34m90 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 11 \u001b[0m=======================\n",
      "Action: b, Prediction: y, Outcome: y, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.4534, 0.5466], grad_fn=<SoftmaxBackward0>) max_prob 0.546560525894165\n",
      "action a probabilité 0.45343947410583496 valance -1 outcome x\n",
      "action a probabilité 0.546560525894165 valance 1 outcome y\n",
      "for action b probs tensor([0.4045, 0.5955], grad_fn=<SoftmaxBackward0>) max_prob 0.5955348610877991\n",
      "action b probabilité 0.4044651687145233 valance -1 outcome x\n",
      "action b probabilité 0.5955348610877991 valance 1 outcome y\n",
      "action b predi y outcome y\n",
      "Action choisie : b \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 12 \u001b[0m=======================\n",
      "Action: b, Prediction: y, Outcome: y, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.4534, 0.5466], grad_fn=<SoftmaxBackward0>) max_prob 0.546560525894165\n",
      "action a probabilité 0.45343947410583496 valance -1 outcome x\n",
      "action a probabilité 0.546560525894165 valance 1 outcome y\n",
      "for action b probs tensor([0.4045, 0.5955], grad_fn=<SoftmaxBackward0>) max_prob 0.5955348610877991\n",
      "action b probabilité 0.4044651687145233 valance -1 outcome x\n",
      "action b probabilité 0.5955348610877991 valance 1 outcome y\n",
      "action b predi y outcome y\n",
      "Action choisie : b \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 13 \u001b[0m=======================\n",
      "Action: b, Prediction: y, Outcome: y, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.4534, 0.5466], grad_fn=<SoftmaxBackward0>) max_prob 0.546560525894165\n",
      "action a probabilité 0.45343947410583496 valance -1 outcome x\n",
      "action a probabilité 0.546560525894165 valance 1 outcome y\n",
      "for action b probs tensor([0.4045, 0.5955], grad_fn=<SoftmaxBackward0>) max_prob 0.5955348610877991\n",
      "action b probabilité 0.4044651687145233 valance -1 outcome x\n",
      "action b probabilité 0.5955348610877991 valance 1 outcome y\n",
      "action b predi y outcome y\n",
      "Action choisie : b \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 14 \u001b[0m=======================\n",
      "Action: b, Prediction: y, Outcome: y, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.4534, 0.5466], grad_fn=<SoftmaxBackward0>) max_prob 0.546560525894165\n",
      "action a probabilité 0.45343947410583496 valance -1 outcome x\n",
      "action a probabilité 0.546560525894165 valance 1 outcome y\n",
      "for action b probs tensor([0.4045, 0.5955], grad_fn=<SoftmaxBackward0>) max_prob 0.5955348610877991\n",
      "action b probabilité 0.4044651687145233 valance -1 outcome x\n",
      "action b probabilité 0.5955348610877991 valance 1 outcome y\n",
      "action b predi y outcome y\n",
      "Action choisie : b \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 15 \u001b[0m=======================\n",
      "Action: b, Prediction: y, Outcome: y, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.4534, 0.5466], grad_fn=<SoftmaxBackward0>) max_prob 0.546560525894165\n",
      "action a probabilité 0.45343947410583496 valance -1 outcome x\n",
      "action a probabilité 0.546560525894165 valance 1 outcome y\n",
      "for action b probs tensor([0.4045, 0.5955], grad_fn=<SoftmaxBackward0>) max_prob 0.5955348610877991\n",
      "action b probabilité 0.4044651687145233 valance -1 outcome x\n",
      "action b probabilité 0.5955348610877991 valance 1 outcome y\n",
      "action b predi y outcome y\n",
      "Action choisie : b \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 16 \u001b[0m=======================\n",
      "Action: b, Prediction: y, Outcome: y, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.4534, 0.5466], grad_fn=<SoftmaxBackward0>) max_prob 0.546560525894165\n",
      "action a probabilité 0.45343947410583496 valance -1 outcome x\n",
      "action a probabilité 0.546560525894165 valance 1 outcome y\n",
      "for action b probs tensor([0.4045, 0.5955], grad_fn=<SoftmaxBackward0>) max_prob 0.5955348610877991\n",
      "action b probabilité 0.4044651687145233 valance -1 outcome x\n",
      "action b probabilité 0.5955348610877991 valance 1 outcome y\n",
      "action b predi y outcome y\n",
      "Action choisie : b \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 17 \u001b[0m=======================\n",
      "Action: b, Prediction: y, Outcome: y, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.4534, 0.5466], grad_fn=<SoftmaxBackward0>) max_prob 0.546560525894165\n",
      "action a probabilité 0.45343947410583496 valance -1 outcome x\n",
      "action a probabilité 0.546560525894165 valance 1 outcome y\n",
      "for action b probs tensor([0.4045, 0.5955], grad_fn=<SoftmaxBackward0>) max_prob 0.5955348610877991\n",
      "action b probabilité 0.4044651687145233 valance -1 outcome x\n",
      "action b probabilité 0.5955348610877991 valance 1 outcome y\n",
      "action b predi y outcome y\n",
      "Action choisie : b \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 18 \u001b[0m=======================\n",
      "Action: b, Prediction: y, Outcome: y, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.4534, 0.5466], grad_fn=<SoftmaxBackward0>) max_prob 0.546560525894165\n",
      "action a probabilité 0.45343947410583496 valance -1 outcome x\n",
      "action a probabilité 0.546560525894165 valance 1 outcome y\n",
      "for action b probs tensor([0.4045, 0.5955], grad_fn=<SoftmaxBackward0>) max_prob 0.5955348610877991\n",
      "action b probabilité 0.4044651687145233 valance -1 outcome x\n",
      "action b probabilité 0.5955348610877991 valance 1 outcome y\n",
      "action b predi y outcome y\n",
      "Action choisie : b \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 19 \u001b[0m=======================\n",
      "Action: b, Prediction: y, Outcome: y, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.4534, 0.5466], grad_fn=<SoftmaxBackward0>) max_prob 0.546560525894165\n",
      "action a probabilité 0.45343947410583496 valance -1 outcome x\n",
      "action a probabilité 0.546560525894165 valance 1 outcome y\n",
      "for action b probs tensor([0.4045, 0.5955], grad_fn=<SoftmaxBackward0>) max_prob 0.5955348610877991\n",
      "action b probabilité 0.4044651687145233 valance -1 outcome x\n",
      "action b probabilité 0.5955348610877991 valance 1 outcome y\n",
      "action b predi y outcome y\n",
      "Action choisie : b \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env_test2 = env1()\n",
    "\n",
    "model_ML = DeepNetwork(hidden_size=[10, 5], input_size=1, output_size=2)\n",
    "optimizer = torch.optim.Adam(model_ML.parameters(), lr=1e-2, weight_decay=1e-4)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "tokenizer = SimpleTokenizerV1(create_dico_numerate_word(env_test2.get_outcomes() + env_test2.get_actions()))\n",
    "\n",
    "valence = {\n",
    "    inter('a', 'x') : -1,\n",
    "    inter('a', 'y') : 1,\n",
    "    inter('b', 'x') : -1,\n",
    "    inter('b', 'y') : 1\n",
    "}\n",
    "agent_test2 = Agent2DecideWithProb(\n",
    "    model=model_ML,\n",
    "    all_outcomes= env_test2.get_outcomes(),\n",
    "    all_actions= env_test2.get_actions(),\n",
    "    valance=valence,\n",
    "    tokenizer=tokenizer,\n",
    "    optimizer=optimizer,\n",
    "    loss_func=loss_func)\n",
    "\n",
    "history_good = []\n",
    "pourcent_by_10 = []\n",
    "outcome = None\n",
    "for i in range(20):\n",
    "    print(f\"=======================\\033[0;32m iteration {i} \\033[0m=======================\")\n",
    "    action, predi = agent_test2.action(outcome, False)\n",
    "    outcome = env_test2.outcome(action)\n",
    "    history_good.append(outcome == predi)\n",
    "    pourcent_by_10.append(sum(history_good[-10:]) * 10 if len(history_good) >= 10 else 0)\n",
    "    print(f'action {action} predi {predi} outcome {outcome}')\n",
    "    print(f\"Action choisie : {action} \\033[0;34m{pourcent_by_10[-1]} \\033[0m\")\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liste hidden init [10, 5]\n",
      "=======================\u001b[0;32m iteration 0 \u001b[0m=======================\n",
      "Action de base : a Prediction: x\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 1 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "i don't know b\n",
      "action b predi x outcome y\n",
      "Action choisie : b \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 2 \u001b[0m=======================\n",
      "Action: b, Prediction: x, Outcome: y, \u001b[0;31m Satisfaction: False \u001b[0m\n",
      "je fit sur ['a', 'b'] et ['x', 'y']\n",
      "Epoch 1/10, Loss: 0.7460\n",
      "Epoch 2/10, Loss: 0.7287\n",
      "Epoch 3/10, Loss: 0.7144\n",
      "Epoch 4/10, Loss: 0.7028\n",
      "Epoch 5/10, Loss: 0.6940\n",
      "Epoch 6/10, Loss: 0.6979\n",
      "Epoch 7/10, Loss: 0.6982\n",
      "Epoch 8/10, Loss: 0.6974\n",
      "Epoch 9/10, Loss: 0.6967\n",
      "Epoch 10/10, Loss: 0.6960\n",
      "for action a probs tensor([0.5338, 0.4662], grad_fn=<SoftmaxBackward0>) max_prob 0.5338100790977478\n",
      "action a probabilité 0.5338100790977478 valance -1 outcome x\n",
      "action a probabilité 0.4661898612976074 valance 1 outcome y\n",
      "for action b probs tensor([0.5338, 0.4662], grad_fn=<SoftmaxBackward0>) max_prob 0.5338100790977478\n",
      "action b probabilité 0.5338100790977478 valance -1 outcome x\n",
      "action b probabilité 0.4661898612976074 valance 1 outcome y\n",
      "action a predi x outcome y\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 3 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: y, \u001b[0;31m Satisfaction: False \u001b[0m\n",
      "je fit sur ['a', 'b', 'a'] et ['x', 'y', 'y']\n",
      "Epoch 1/10, Loss: 0.7180\n",
      "Epoch 2/10, Loss: 0.7146\n",
      "Epoch 3/10, Loss: 0.7111\n",
      "Epoch 4/10, Loss: 0.7075\n",
      "Epoch 5/10, Loss: 0.7039\n",
      "Epoch 6/10, Loss: 0.7003\n",
      "Epoch 7/10, Loss: 0.6967\n",
      "Epoch 8/10, Loss: 0.6932\n",
      "Epoch 9/10, Loss: 0.6898\n",
      "Epoch 10/10, Loss: 0.6865\n",
      "for action a probs tensor([0.4844, 0.5156], grad_fn=<SoftmaxBackward0>) max_prob 0.5155810713768005\n",
      "action a probabilité 0.48441892862319946 valance -1 outcome x\n",
      "action a probabilité 0.5155810713768005 valance 1 outcome y\n",
      "for action b probs tensor([0.4844, 0.5156], grad_fn=<SoftmaxBackward0>) max_prob 0.5155810713768005\n",
      "action b probabilité 0.48441892862319946 valance -1 outcome x\n",
      "action b probabilité 0.5155810713768005 valance 1 outcome y\n",
      "action a predi y outcome x\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 4 \u001b[0m=======================\n",
      "Action: a, Prediction: y, Outcome: x, \u001b[0;31m Satisfaction: False \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a'] et ['x', 'y', 'y', 'x']\n",
      "Epoch 1/10, Loss: 0.6936\n",
      "Epoch 2/10, Loss: 0.6940\n",
      "Epoch 3/10, Loss: 0.6943\n",
      "Epoch 4/10, Loss: 0.6947\n",
      "Epoch 5/10, Loss: 0.6951\n",
      "Epoch 6/10, Loss: 0.6955\n",
      "Epoch 7/10, Loss: 0.6958\n",
      "Epoch 8/10, Loss: 0.6961\n",
      "Epoch 9/10, Loss: 0.6964\n",
      "Epoch 10/10, Loss: 0.6966\n",
      "for action a probs tensor([0.4573, 0.5427], grad_fn=<SoftmaxBackward0>) max_prob 0.542729914188385\n",
      "action a probabilité 0.4572700560092926 valance -1 outcome x\n",
      "action a probabilité 0.542729914188385 valance 1 outcome y\n",
      "for action b probs tensor([0.4568, 0.5432], grad_fn=<SoftmaxBackward0>) max_prob 0.5431548357009888\n",
      "action b probabilité 0.4568451941013336 valance -1 outcome x\n",
      "action b probabilité 0.5431548357009888 valance 1 outcome y\n",
      "action b predi y outcome y\n",
      "Action choisie : b \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 5 \u001b[0m=======================\n",
      "Action: b, Prediction: y, Outcome: y, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.4573, 0.5427], grad_fn=<SoftmaxBackward0>) max_prob 0.542729914188385\n",
      "action a probabilité 0.4572700560092926 valance -1 outcome x\n",
      "action a probabilité 0.542729914188385 valance 1 outcome y\n",
      "for action b probs tensor([0.4568, 0.5432], grad_fn=<SoftmaxBackward0>) max_prob 0.5431548357009888\n",
      "action b probabilité 0.4568451941013336 valance -1 outcome x\n",
      "action b probabilité 0.5431548357009888 valance 1 outcome y\n",
      "action b predi y outcome x\n",
      "Action choisie : b \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 6 \u001b[0m=======================\n",
      "Action: b, Prediction: y, Outcome: x, \u001b[0;31m Satisfaction: False \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'b'] et ['x', 'y', 'y', 'x', 'y', 'x']\n",
      "Epoch 1/10, Loss: 0.6967\n",
      "Epoch 2/10, Loss: 0.6969\n",
      "Epoch 3/10, Loss: 0.6971\n",
      "Epoch 4/10, Loss: 0.6971\n",
      "Epoch 5/10, Loss: 0.6970\n",
      "Epoch 6/10, Loss: 0.6968\n",
      "Epoch 7/10, Loss: 0.6965\n",
      "Epoch 8/10, Loss: 0.6968\n",
      "Epoch 9/10, Loss: 0.6967\n",
      "Epoch 10/10, Loss: 0.6965\n",
      "for action a probs tensor([0.4599, 0.5401], grad_fn=<SoftmaxBackward0>) max_prob 0.5400693416595459\n",
      "action a probabilité 0.4599306583404541 valance -1 outcome x\n",
      "action a probabilité 0.5400693416595459 valance 1 outcome y\n",
      "for action b probs tensor([0.4599, 0.5401], grad_fn=<SoftmaxBackward0>) max_prob 0.5400693416595459\n",
      "action b probabilité 0.4599306583404541 valance -1 outcome x\n",
      "action b probabilité 0.5400693416595459 valance 1 outcome y\n",
      "action a predi y outcome y\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 7 \u001b[0m=======================\n",
      "Action: a, Prediction: y, Outcome: y, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.4599, 0.5401], grad_fn=<SoftmaxBackward0>) max_prob 0.5400693416595459\n",
      "action a probabilité 0.4599306583404541 valance -1 outcome x\n",
      "action a probabilité 0.5400693416595459 valance 1 outcome y\n",
      "for action b probs tensor([0.4599, 0.5401], grad_fn=<SoftmaxBackward0>) max_prob 0.5400693416595459\n",
      "action b probabilité 0.4599306583404541 valance -1 outcome x\n",
      "action b probabilité 0.5400693416595459 valance 1 outcome y\n",
      "action a predi y outcome x\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 8 \u001b[0m=======================\n",
      "Action: a, Prediction: y, Outcome: x, \u001b[0;31m Satisfaction: False \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'b', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'x', 'y', 'x']\n",
      "Epoch 1/10, Loss: 0.6964\n",
      "Epoch 2/10, Loss: 0.6962\n",
      "Epoch 3/10, Loss: 0.6960\n",
      "Epoch 4/10, Loss: 0.6958\n",
      "Epoch 5/10, Loss: 0.6956\n",
      "Epoch 6/10, Loss: 0.6954\n",
      "Epoch 7/10, Loss: 0.6952\n",
      "Epoch 8/10, Loss: 0.6950\n",
      "Epoch 9/10, Loss: 0.6948\n",
      "Epoch 10/10, Loss: 0.6947\n",
      "for action a probs tensor([0.4740, 0.5260], grad_fn=<SoftmaxBackward0>) max_prob 0.5259724855422974\n",
      "action a probabilité 0.474027544260025 valance -1 outcome x\n",
      "action a probabilité 0.5259724855422974 valance 1 outcome y\n",
      "for action b probs tensor([0.4740, 0.5260], grad_fn=<SoftmaxBackward0>) max_prob 0.5259724855422974\n",
      "action b probabilité 0.474027544260025 valance -1 outcome x\n",
      "action b probabilité 0.5259724855422974 valance 1 outcome y\n",
      "action a predi y outcome x\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 9 \u001b[0m=======================\n",
      "Action: a, Prediction: y, Outcome: x, \u001b[0;31m Satisfaction: False \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'b', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'x', 'y', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.7003\n",
      "Epoch 2/10, Loss: 0.6997\n",
      "Epoch 3/10, Loss: 0.6990\n",
      "Epoch 4/10, Loss: 0.6983\n",
      "Epoch 5/10, Loss: 0.6976\n",
      "Epoch 6/10, Loss: 0.6968\n",
      "Epoch 7/10, Loss: 0.6960\n",
      "Epoch 8/10, Loss: 0.6953\n",
      "Epoch 9/10, Loss: 0.6945\n",
      "Epoch 10/10, Loss: 0.6938\n",
      "for action a probs tensor([0.5002, 0.4998], grad_fn=<SoftmaxBackward0>) max_prob 0.5002484321594238\n",
      "action a probabilité 0.5002484321594238 valance -1 outcome x\n",
      "action a probabilité 0.49975159764289856 valance 1 outcome y\n",
      "for action b probs tensor([0.5002, 0.4998], grad_fn=<SoftmaxBackward0>) max_prob 0.5002484321594238\n",
      "action b probabilité 0.5002484321594238 valance -1 outcome x\n",
      "action b probabilité 0.49975159764289856 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m40 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 10 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.5002, 0.4998], grad_fn=<SoftmaxBackward0>) max_prob 0.5002484321594238\n",
      "action a probabilité 0.5002484321594238 valance -1 outcome x\n",
      "action a probabilité 0.49975159764289856 valance 1 outcome y\n",
      "for action b probs tensor([0.5002, 0.4998], grad_fn=<SoftmaxBackward0>) max_prob 0.5002484321594238\n",
      "action b probabilité 0.5002484321594238 valance -1 outcome x\n",
      "action b probabilité 0.49975159764289856 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m40 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 11 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.5002, 0.4998], grad_fn=<SoftmaxBackward0>) max_prob 0.5002484321594238\n",
      "action a probabilité 0.5002484321594238 valance -1 outcome x\n",
      "action a probabilité 0.49975159764289856 valance 1 outcome y\n",
      "for action b probs tensor([0.5002, 0.4998], grad_fn=<SoftmaxBackward0>) max_prob 0.5002484321594238\n",
      "action b probabilité 0.5002484321594238 valance -1 outcome x\n",
      "action b probabilité 0.49975159764289856 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m50 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 12 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.5002, 0.4998], grad_fn=<SoftmaxBackward0>) max_prob 0.5002484321594238\n",
      "action a probabilité 0.5002484321594238 valance -1 outcome x\n",
      "action a probabilité 0.49975159764289856 valance 1 outcome y\n",
      "for action b probs tensor([0.5002, 0.4998], grad_fn=<SoftmaxBackward0>) max_prob 0.5002484321594238\n",
      "action b probabilité 0.5002484321594238 valance -1 outcome x\n",
      "action b probabilité 0.49975159764289856 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m60 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 13 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.5002, 0.4998], grad_fn=<SoftmaxBackward0>) max_prob 0.5002484321594238\n",
      "action a probabilité 0.5002484321594238 valance -1 outcome x\n",
      "action a probabilité 0.49975159764289856 valance 1 outcome y\n",
      "for action b probs tensor([0.5002, 0.4998], grad_fn=<SoftmaxBackward0>) max_prob 0.5002484321594238\n",
      "action b probabilité 0.5002484321594238 valance -1 outcome x\n",
      "action b probabilité 0.49975159764289856 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m70 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 14 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.5002, 0.4998], grad_fn=<SoftmaxBackward0>) max_prob 0.5002484321594238\n",
      "action a probabilité 0.5002484321594238 valance -1 outcome x\n",
      "action a probabilité 0.49975159764289856 valance 1 outcome y\n",
      "for action b probs tensor([0.5002, 0.4998], grad_fn=<SoftmaxBackward0>) max_prob 0.5002484321594238\n",
      "action b probabilité 0.5002484321594238 valance -1 outcome x\n",
      "action b probabilité 0.49975159764289856 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m70 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 15 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.5002, 0.4998], grad_fn=<SoftmaxBackward0>) max_prob 0.5002484321594238\n",
      "action a probabilité 0.5002484321594238 valance -1 outcome x\n",
      "action a probabilité 0.49975159764289856 valance 1 outcome y\n",
      "for action b probs tensor([0.5002, 0.4998], grad_fn=<SoftmaxBackward0>) max_prob 0.5002484321594238\n",
      "action b probabilité 0.5002484321594238 valance -1 outcome x\n",
      "action b probabilité 0.49975159764289856 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m80 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 16 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.5002, 0.4998], grad_fn=<SoftmaxBackward0>) max_prob 0.5002484321594238\n",
      "action a probabilité 0.5002484321594238 valance -1 outcome x\n",
      "action a probabilité 0.49975159764289856 valance 1 outcome y\n",
      "for action b probs tensor([0.5002, 0.4998], grad_fn=<SoftmaxBackward0>) max_prob 0.5002484321594238\n",
      "action b probabilité 0.5002484321594238 valance -1 outcome x\n",
      "action b probabilité 0.49975159764289856 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m80 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 17 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.5002, 0.4998], grad_fn=<SoftmaxBackward0>) max_prob 0.5002484321594238\n",
      "action a probabilité 0.5002484321594238 valance -1 outcome x\n",
      "action a probabilité 0.49975159764289856 valance 1 outcome y\n",
      "for action b probs tensor([0.5002, 0.4998], grad_fn=<SoftmaxBackward0>) max_prob 0.5002484321594238\n",
      "action b probabilité 0.5002484321594238 valance -1 outcome x\n",
      "action b probabilité 0.49975159764289856 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m90 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 18 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.5002, 0.4998], grad_fn=<SoftmaxBackward0>) max_prob 0.5002484321594238\n",
      "action a probabilité 0.5002484321594238 valance -1 outcome x\n",
      "action a probabilité 0.49975159764289856 valance 1 outcome y\n",
      "for action b probs tensor([0.5002, 0.4998], grad_fn=<SoftmaxBackward0>) max_prob 0.5002484321594238\n",
      "action b probabilité 0.5002484321594238 valance -1 outcome x\n",
      "action b probabilité 0.49975159764289856 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 19 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "for action a probs tensor([0.5002, 0.4998], grad_fn=<SoftmaxBackward0>) max_prob 0.5002484321594238\n",
      "action a probabilité 0.5002484321594238 valance -1 outcome x\n",
      "action a probabilité 0.49975159764289856 valance 1 outcome y\n",
      "for action b probs tensor([0.5002, 0.4998], grad_fn=<SoftmaxBackward0>) max_prob 0.5002484321594238\n",
      "action b probabilité 0.5002484321594238 valance -1 outcome x\n",
      "action b probabilité 0.49975159764289856 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env_test2 = env3Str()\n",
    "\n",
    "model_ML = DeepNetwork(hidden_size=[10, 5], input_size=1, output_size=2)\n",
    "optimizer = torch.optim.Adam(model_ML.parameters(), lr=1e-2, weight_decay=1e-4)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "tokenizer = SimpleTokenizerV1(create_dico_numerate_word(env_test2.get_outcomes() + env_test2.get_actions()))\n",
    "\n",
    "valence = {\n",
    "    inter('a', 'x') : -1,\n",
    "    inter('a', 'y') : 1,\n",
    "    inter('b', 'x') : -1,\n",
    "    inter('b', 'y') : 1\n",
    "}\n",
    "agent_test2 = Agent2DecideWithProb(\n",
    "    model=model_ML,\n",
    "    all_outcomes= env_test2.get_outcomes(),\n",
    "    all_actions= env_test2.get_actions(),\n",
    "    valance=valence,\n",
    "    tokenizer=tokenizer,\n",
    "    optimizer=optimizer,\n",
    "    loss_func=loss_func)\n",
    "\n",
    "history_good = []\n",
    "pourcent_by_10 = []\n",
    "outcome = None\n",
    "for i in range(20):\n",
    "    print(f\"=======================\\033[0;32m iteration {i} \\033[0m=======================\")\n",
    "    action, predi = agent_test2.action(outcome, False)\n",
    "    outcome = env_test2.outcome(action)\n",
    "    history_good.append(outcome == predi)\n",
    "    pourcent_by_10.append(sum(history_good[-10:]) * 10 if len(history_good) >= 10 else 0)\n",
    "    print(f'action {action} predi {predi} outcome {outcome}')\n",
    "    print(f\"Action choisie : {action} \\033[0;34m{pourcent_by_10[-1]} \\033[0m\")\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Résultat\n",
    "On voit que l'agent n'a pas compris comment obtenir y, donc il ne va jamais faire le comportement optimal. Il faut de nouveau entrainer le modèle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent2DecideWithProbFit:\n",
    "    def __init__(self, model, all_outcomes, all_actions, valance, tokenizer, optimizer=None, loss_func=None):\n",
    "        \"\"\" \n",
    "        Création de l'agent.\n",
    "        \n",
    "        - self._action : action précédente\n",
    "        - self._predicted_outcome : prédiction de l'outcome précédent\n",
    "        \"\"\"\n",
    "        self._action = None\n",
    "        self._predicted_outcome = None\n",
    "        self._model = model\n",
    "        self._otimizer = optimizer\n",
    "        self._loss_func = loss_func\n",
    "        self._tokenizer:SimpleTokenizerV1 = tokenizer\n",
    "        self._all_outcomes = all_outcomes\n",
    "        self._all_actions = all_actions\n",
    "        self._history_act = []\n",
    "        self._history_fb = []\n",
    "        self._valance=valance\n",
    "\n",
    "    def fit(self, actions:list, outcomes:list,nb_epoch:int= 5, validate_loader=None):\n",
    "        \"\"\"\n",
    "        Fonction d'entrainement de l'agent\n",
    "        \"\"\"\n",
    "        print(f\"je fit sur {actions} et {outcomes}\")\n",
    "        actions = [[self._tokenizer.encode(act)] for act in actions]\n",
    "        outcomes = self._tokenizer.encode(outcomes)\n",
    "        if isinstance(self._model, torch.nn.Module):\n",
    "            self._model.train()\n",
    "            actions = torch.tensor(actions, dtype=torch.float).to(device)\n",
    "            outcomes = torch.tensor(outcomes, dtype=torch.long).to(device)\n",
    "            outcomes = torch.nn.functional.one_hot(outcomes, \n",
    "                num_classes=len(self._all_outcomes)\n",
    "                ).to(torch.float)\n",
    "            \n",
    "            data_loader = torch.utils.data.DataLoader(\n",
    "                torch.utils.data.TensorDataset(actions, outcomes),\n",
    "                batch_size=32, shuffle=True\n",
    "            )\n",
    "\n",
    "            train_with_batch(model=self._model, \n",
    "                    train_loader=data_loader,\n",
    "                    optimizer=self._otimizer,\n",
    "                    loss_func=self._loss_func,\n",
    "                    nb_epochs=nb_epoch,\n",
    "                    validate_loader=validate_loader,\n",
    "                    print_=True)\n",
    "        else:\n",
    "            raise Exception('Not implemented')\n",
    "            self._model.fit(action, outcome)\n",
    "            pass\n",
    "\n",
    "    def get_prediction(self, action):\n",
    "        action = self._tokenizer.encode(action)\n",
    "        if isinstance(self._model, torch.nn.Module):\n",
    "            self._model.eval() \n",
    "            action = torch.tensor([action], dtype=torch.float).to(device)\n",
    "            x = self._model(action)\n",
    "            x = torch.nn.functional.softmax(x, dim=0)\n",
    "        else:\n",
    "            raise Exception('Not implemented')\n",
    "            x=self._model.predict(action)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    # Nouvelle fonction qui renvois None si le modèle a tester toutes les actions\n",
    "    # Sinon une action à découvrir\n",
    "    def check_all_actions(self):\n",
    "        \"\"\"\n",
    "        Fonction qui vérifie si le modèle a tester toutes les actions\n",
    "        \"\"\"\n",
    "        act_to_test = None\n",
    "        for act in self._all_actions:\n",
    "            if act not in self._history_act:\n",
    "                act_to_test = act\n",
    "                break\n",
    "        return act_to_test\n",
    "    \n",
    "    def decide(self):\n",
    "        \"\"\"\n",
    "        Fonction qui choisit l'action a faire en fonction des prédictions \\\n",
    "        du modèles entrainné. Nous renforçons choisisons les actions que \\\n",
    "        ou le modèle n'est pas sûr.\n",
    "        \"\"\"\n",
    "        # On laisse le mécanisme d'exploration pour le moment\n",
    "        act_test = self.check_all_actions()\n",
    "        if act_test:\n",
    "            print(\"i don't know\", act_test)\n",
    "            self._action = act_test\n",
    "            return act_test\n",
    "\n",
    "        best_act = self._all_actions[0]\n",
    "        best_expected_val = -np.inf\n",
    "        for act in self._all_actions:\n",
    "            probs:torch.Tensor = self.get_prediction(act)\n",
    "            max_prob = torch.max(probs).item()\n",
    "            print(f'for action {act} probs {probs} max_prob {max_prob}')\n",
    "            expected_val = 0\n",
    "            for i, prob in enumerate(probs):\n",
    "                print(f'action {act} probabilité {prob.item()} valance {self._valance[inter(act, self._tokenizer.decode(i))]} outcome {self._tokenizer.decode(i)}')\n",
    "                expected_val += prob.item() * self._valance[inter(act, self._tokenizer.decode(i))]\n",
    "            \n",
    "            if expected_val > best_expected_val:\n",
    "                best_act = act\n",
    "                best_expected_val = expected_val\n",
    "        self._action = best_act\n",
    "        return best_act\n",
    "\n",
    "    def predict(self, action):\n",
    "        \"\"\"\n",
    "        Funciton de prédiction\n",
    "        \"\"\"\n",
    "        action = self._tokenizer.encode(action)\n",
    "        if isinstance(self._model, torch.nn.Module):\n",
    "            self._model.eval() \n",
    "            action = torch.tensor([action], dtype=torch.float).to(device)\n",
    "            x = self._model(action)\n",
    "            x = torch.argmax(x, dim=0).item()\n",
    "\n",
    "        else:\n",
    "            raise Exception('Not implemented')\n",
    "            x=self._model.predict(action)\n",
    "        \n",
    "        return self._tokenizer.decode(x)\n",
    "\n",
    "    def action(self, outcome, fit=True, validate_loader=None):\n",
    "        \"\"\" \n",
    "        Fonction qui choisit l'action a faire en fonction de la dernière \\\n",
    "        intéraction avec l'environnement. \\n\n",
    "        C'est ici que nous allons implémenter un mécanisme de ML \\\n",
    "        pour choisir la prochaine action.\n",
    "\n",
    "        :param: **outcome** feedback de la dernière intéraction avec l'environnement\n",
    "\n",
    "        :return: **action** action à effectuer\n",
    "        \"\"\"\n",
    "        if self._action is not None:\n",
    "            self._history_fb.append(outcome)\n",
    "            print(f\"Action: {self._action}, Prediction: {self._predicted_outcome}, Outcome: {outcome}, \" \n",
    "                  f\"\\033[0;31m Satisfaction: {self._predicted_outcome == outcome} \\033[0m\")\n",
    "            # if self._predicted_outcome != outcome: on retire se if pour tout le temps fit\n",
    "            self.fit(self._history_act, self._history_fb, validate_loader=validate_loader, nb_epoch=10)\n",
    "            self._action = self.decide()\n",
    "            self._history_act.append(self._action)\n",
    "            self._predicted_outcome = self.predict(self._action)\n",
    "        else:\n",
    "            self._action = self._all_actions[0]\n",
    "            self._history_act.append(self._action)\n",
    "            self._predicted_outcome = self.predict(self._action)\n",
    "            print(f\"Action de base : {self._action} Prediction: {self._predicted_outcome}\")\n",
    "        \n",
    "        return self._action, self._predicted_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liste hidden init [10, 5]\n",
      "=======================\u001b[0;32m iteration 0 \u001b[0m=======================\n",
      "Action de base : a Prediction: y\n",
      "action a predi y outcome x\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 1 \u001b[0m=======================\n",
      "Action: a, Prediction: y, Outcome: x, \u001b[0;31m Satisfaction: False \u001b[0m\n",
      "je fit sur ['a'] et ['x']\n",
      "Epoch 1/10, Loss: 0.7824\n",
      "Epoch 2/10, Loss: 0.6940\n",
      "Epoch 3/10, Loss: 0.6109\n",
      "Epoch 4/10, Loss: 0.5330\n",
      "Epoch 5/10, Loss: 0.4603\n",
      "Epoch 6/10, Loss: 0.3929\n",
      "Epoch 7/10, Loss: 0.3323\n",
      "Epoch 8/10, Loss: 0.2850\n",
      "Epoch 9/10, Loss: 0.2408\n",
      "Epoch 10/10, Loss: 0.2003\n",
      "i don't know b\n",
      "action b predi x outcome y\n",
      "Action choisie : b \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 2 \u001b[0m=======================\n",
      "Action: b, Prediction: x, Outcome: y, \u001b[0;31m Satisfaction: False \u001b[0m\n",
      "je fit sur ['a', 'b'] et ['x', 'y']\n",
      "Epoch 1/10, Loss: 1.2843\n",
      "Epoch 2/10, Loss: 1.3271\n",
      "Epoch 3/10, Loss: 1.3254\n",
      "Epoch 4/10, Loss: 1.2949\n",
      "Epoch 5/10, Loss: 1.2465\n",
      "Epoch 6/10, Loss: 1.1880\n",
      "Epoch 7/10, Loss: 1.1253\n",
      "Epoch 8/10, Loss: 1.0627\n",
      "Epoch 9/10, Loss: 1.0032\n",
      "Epoch 10/10, Loss: 0.9488\n",
      "for action a probs tensor([0.7185, 0.2815], grad_fn=<SoftmaxBackward0>) max_prob 0.7184754014015198\n",
      "action a probabilité 0.7184754014015198 valance -1 outcome x\n",
      "action a probabilité 0.28152456879615784 valance 1 outcome y\n",
      "for action b probs tensor([0.7702, 0.2298], grad_fn=<SoftmaxBackward0>) max_prob 0.7702181339263916\n",
      "action b probabilité 0.7702181339263916 valance -1 outcome x\n",
      "action b probabilité 0.2297818958759308 valance 1 outcome y\n",
      "action a predi x outcome y\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 3 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: y, \u001b[0;31m Satisfaction: False \u001b[0m\n",
      "je fit sur ['a', 'b', 'a'] et ['x', 'y', 'y']\n",
      "Epoch 1/10, Loss: 1.0229\n",
      "Epoch 2/10, Loss: 0.9671\n",
      "Epoch 3/10, Loss: 0.9177\n",
      "Epoch 4/10, Loss: 0.8749\n",
      "Epoch 5/10, Loss: 0.8383\n",
      "Epoch 6/10, Loss: 0.8073\n",
      "Epoch 7/10, Loss: 0.7822\n",
      "Epoch 8/10, Loss: 0.7618\n",
      "Epoch 9/10, Loss: 0.7445\n",
      "Epoch 10/10, Loss: 0.7299\n",
      "for action a probs tensor([0.5295, 0.4705], grad_fn=<SoftmaxBackward0>) max_prob 0.5294762253761292\n",
      "action a probabilité 0.5294762253761292 valance -1 outcome x\n",
      "action a probabilité 0.47052380442619324 valance 1 outcome y\n",
      "for action b probs tensor([0.5336, 0.4664], grad_fn=<SoftmaxBackward0>) max_prob 0.5335602164268494\n",
      "action b probabilité 0.5335602164268494 valance -1 outcome x\n",
      "action b probabilité 0.46643978357315063 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 4 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a'] et ['x', 'y', 'y', 'x']\n",
      "Epoch 1/10, Loss: 0.6971\n",
      "Epoch 2/10, Loss: 0.6955\n",
      "Epoch 3/10, Loss: 0.6947\n",
      "Epoch 4/10, Loss: 0.6941\n",
      "Epoch 5/10, Loss: 0.6937\n",
      "Epoch 6/10, Loss: 0.6934\n",
      "Epoch 7/10, Loss: 0.6933\n",
      "Epoch 8/10, Loss: 0.6932\n",
      "Epoch 9/10, Loss: 0.6932\n",
      "Epoch 10/10, Loss: 0.6932\n",
      "for action a probs tensor([0.4873, 0.5127], grad_fn=<SoftmaxBackward0>) max_prob 0.5127202272415161\n",
      "action a probabilité 0.48727983236312866 valance -1 outcome x\n",
      "action a probabilité 0.5127202272415161 valance 1 outcome y\n",
      "for action b probs tensor([0.4867, 0.5133], grad_fn=<SoftmaxBackward0>) max_prob 0.5132678151130676\n",
      "action b probabilité 0.4867321848869324 valance -1 outcome x\n",
      "action b probabilité 0.5132678151130676 valance 1 outcome y\n",
      "action b predi y outcome y\n",
      "Action choisie : b \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 5 \u001b[0m=======================\n",
      "Action: b, Prediction: y, Outcome: y, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b'] et ['x', 'y', 'y', 'x', 'y']\n",
      "Epoch 1/10, Loss: 0.6880\n",
      "Epoch 2/10, Loss: 0.6873\n",
      "Epoch 3/10, Loss: 0.6866\n",
      "Epoch 4/10, Loss: 0.6863\n",
      "Epoch 5/10, Loss: 0.6859\n",
      "Epoch 6/10, Loss: 0.6855\n",
      "Epoch 7/10, Loss: 0.6850\n",
      "Epoch 8/10, Loss: 0.6846\n",
      "Epoch 9/10, Loss: 0.6841\n",
      "Epoch 10/10, Loss: 0.6837\n",
      "for action a probs tensor([0.4711, 0.5289], grad_fn=<SoftmaxBackward0>) max_prob 0.528899610042572\n",
      "action a probabilité 0.471100389957428 valance -1 outcome x\n",
      "action a probabilité 0.528899610042572 valance 1 outcome y\n",
      "for action b probs tensor([0.4711, 0.5289], grad_fn=<SoftmaxBackward0>) max_prob 0.528899610042572\n",
      "action b probabilité 0.471100389957428 valance -1 outcome x\n",
      "action b probabilité 0.528899610042572 valance 1 outcome y\n",
      "action a predi y outcome y\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 6 \u001b[0m=======================\n",
      "Action: a, Prediction: y, Outcome: y, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y']\n",
      "Epoch 1/10, Loss: 0.6755\n",
      "Epoch 2/10, Loss: 0.6746\n",
      "Epoch 3/10, Loss: 0.6737\n",
      "Epoch 4/10, Loss: 0.6727\n",
      "Epoch 5/10, Loss: 0.6717\n",
      "Epoch 6/10, Loss: 0.6707\n",
      "Epoch 7/10, Loss: 0.6697\n",
      "Epoch 8/10, Loss: 0.6686\n",
      "Epoch 9/10, Loss: 0.6675\n",
      "Epoch 10/10, Loss: 0.6665\n",
      "for action a probs tensor([0.4514, 0.5486], grad_fn=<SoftmaxBackward0>) max_prob 0.5485783815383911\n",
      "action a probabilité 0.4514216482639313 valance -1 outcome x\n",
      "action a probabilité 0.5485783815383911 valance 1 outcome y\n",
      "for action b probs tensor([0.4514, 0.5486], grad_fn=<SoftmaxBackward0>) max_prob 0.5485783815383911\n",
      "action b probabilité 0.4514216482639313 valance -1 outcome x\n",
      "action b probabilité 0.5485783815383911 valance 1 outcome y\n",
      "action a predi y outcome x\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 7 \u001b[0m=======================\n",
      "Action: a, Prediction: y, Outcome: x, \u001b[0;31m Satisfaction: False \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x']\n",
      "Epoch 1/10, Loss: 0.6840\n",
      "Epoch 2/10, Loss: 0.6838\n",
      "Epoch 3/10, Loss: 0.6836\n",
      "Epoch 4/10, Loss: 0.6835\n",
      "Epoch 5/10, Loss: 0.6834\n",
      "Epoch 6/10, Loss: 0.6833\n",
      "Epoch 7/10, Loss: 0.6832\n",
      "Epoch 8/10, Loss: 0.6832\n",
      "Epoch 9/10, Loss: 0.6831\n",
      "Epoch 10/10, Loss: 0.6831\n",
      "for action a probs tensor([0.4365, 0.5635], grad_fn=<SoftmaxBackward0>) max_prob 0.5634645223617554\n",
      "action a probabilité 0.43653547763824463 valance -1 outcome x\n",
      "action a probabilité 0.5634645223617554 valance 1 outcome y\n",
      "for action b probs tensor([0.4365, 0.5635], grad_fn=<SoftmaxBackward0>) max_prob 0.5634645223617554\n",
      "action b probabilité 0.43653547763824463 valance -1 outcome x\n",
      "action b probabilité 0.5634645223617554 valance 1 outcome y\n",
      "action a predi y outcome x\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 8 \u001b[0m=======================\n",
      "Action: a, Prediction: y, Outcome: x, \u001b[0;31m Satisfaction: False \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.7013\n",
      "Epoch 2/10, Loss: 0.7015\n",
      "Epoch 3/10, Loss: 0.7016\n",
      "Epoch 4/10, Loss: 0.7017\n",
      "Epoch 5/10, Loss: 0.7018\n",
      "Epoch 6/10, Loss: 0.7018\n",
      "Epoch 7/10, Loss: 0.7018\n",
      "Epoch 8/10, Loss: 0.7017\n",
      "Epoch 9/10, Loss: 0.7016\n",
      "Epoch 10/10, Loss: 0.7015\n",
      "for action a probs tensor([0.4363, 0.5637], grad_fn=<SoftmaxBackward0>) max_prob 0.5636512041091919\n",
      "action a probabilité 0.4363488256931305 valance -1 outcome x\n",
      "action a probabilité 0.5636512041091919 valance 1 outcome y\n",
      "for action b probs tensor([0.4363, 0.5637], grad_fn=<SoftmaxBackward0>) max_prob 0.5636512041091919\n",
      "action b probabilité 0.4363488256931305 valance -1 outcome x\n",
      "action b probabilité 0.5636512041091919 valance 1 outcome y\n",
      "action a predi y outcome x\n",
      "Action choisie : a \u001b[0;34m0 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 9 \u001b[0m=======================\n",
      "Action: a, Prediction: y, Outcome: x, \u001b[0;31m Satisfaction: False \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.7155\n",
      "Epoch 2/10, Loss: 0.7152\n",
      "Epoch 3/10, Loss: 0.7147\n",
      "Epoch 4/10, Loss: 0.7141\n",
      "Epoch 5/10, Loss: 0.7135\n",
      "Epoch 6/10, Loss: 0.7128\n",
      "Epoch 7/10, Loss: 0.7121\n",
      "Epoch 8/10, Loss: 0.7113\n",
      "Epoch 9/10, Loss: 0.7105\n",
      "Epoch 10/10, Loss: 0.7097\n",
      "for action a probs tensor([0.4511, 0.5489], grad_fn=<SoftmaxBackward0>) max_prob 0.5489040613174438\n",
      "action a probabilité 0.45109596848487854 valance -1 outcome x\n",
      "action a probabilité 0.5489040613174438 valance 1 outcome y\n",
      "for action b probs tensor([0.4511, 0.5489], grad_fn=<SoftmaxBackward0>) max_prob 0.5489040613174438\n",
      "action b probabilité 0.45109596848487854 valance -1 outcome x\n",
      "action b probabilité 0.5489040613174438 valance 1 outcome y\n",
      "action a predi y outcome x\n",
      "Action choisie : a \u001b[0;34m30 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 10 \u001b[0m=======================\n",
      "Action: a, Prediction: y, Outcome: x, \u001b[0;31m Satisfaction: False \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.7176\n",
      "Epoch 2/10, Loss: 0.7163\n",
      "Epoch 3/10, Loss: 0.7150\n",
      "Epoch 4/10, Loss: 0.7136\n",
      "Epoch 5/10, Loss: 0.7121\n",
      "Epoch 6/10, Loss: 0.7107\n",
      "Epoch 7/10, Loss: 0.7092\n",
      "Epoch 8/10, Loss: 0.7077\n",
      "Epoch 9/10, Loss: 0.7063\n",
      "Epoch 10/10, Loss: 0.7048\n",
      "for action a probs tensor([0.4772, 0.5228], grad_fn=<SoftmaxBackward0>) max_prob 0.5228411555290222\n",
      "action a probabilité 0.4771588146686554 valance -1 outcome x\n",
      "action a probabilité 0.5228411555290222 valance 1 outcome y\n",
      "for action b probs tensor([0.4772, 0.5228], grad_fn=<SoftmaxBackward0>) max_prob 0.5228411555290222\n",
      "action b probabilité 0.4771588146686554 valance -1 outcome x\n",
      "action b probabilité 0.5228411555290222 valance 1 outcome y\n",
      "action a predi y outcome x\n",
      "Action choisie : a \u001b[0;34m30 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 11 \u001b[0m=======================\n",
      "Action: a, Prediction: y, Outcome: x, \u001b[0;31m Satisfaction: False \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.7067\n",
      "Epoch 2/10, Loss: 0.7047\n",
      "Epoch 3/10, Loss: 0.7028\n",
      "Epoch 4/10, Loss: 0.7009\n",
      "Epoch 5/10, Loss: 0.6989\n",
      "Epoch 6/10, Loss: 0.6970\n",
      "Epoch 7/10, Loss: 0.6951\n",
      "Epoch 8/10, Loss: 0.6933\n",
      "Epoch 9/10, Loss: 0.6914\n",
      "Epoch 10/10, Loss: 0.6896\n",
      "for action a probs tensor([0.5100, 0.4900], grad_fn=<SoftmaxBackward0>) max_prob 0.5099829435348511\n",
      "action a probabilité 0.5099829435348511 valance -1 outcome x\n",
      "action a probabilité 0.4900171458721161 valance 1 outcome y\n",
      "for action b probs tensor([0.5100, 0.4900], grad_fn=<SoftmaxBackward0>) max_prob 0.5099829435348511\n",
      "action b probabilité 0.5099829435348511 valance -1 outcome x\n",
      "action b probabilité 0.4900171458721161 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m40 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 12 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.6867\n",
      "Epoch 2/10, Loss: 0.6845\n",
      "Epoch 3/10, Loss: 0.6824\n",
      "Epoch 4/10, Loss: 0.6803\n",
      "Epoch 5/10, Loss: 0.6782\n",
      "Epoch 6/10, Loss: 0.6762\n",
      "Epoch 7/10, Loss: 0.6742\n",
      "Epoch 8/10, Loss: 0.6723\n",
      "Epoch 9/10, Loss: 0.6704\n",
      "Epoch 10/10, Loss: 0.6686\n",
      "for action a probs tensor([0.5455, 0.4545], grad_fn=<SoftmaxBackward0>) max_prob 0.5454996228218079\n",
      "action a probabilité 0.5454996228218079 valance -1 outcome x\n",
      "action a probabilité 0.45450034737586975 valance 1 outcome y\n",
      "for action b probs tensor([0.5455, 0.4545], grad_fn=<SoftmaxBackward0>) max_prob 0.5454996228218079\n",
      "action b probabilité 0.5454996228218079 valance -1 outcome x\n",
      "action b probabilité 0.45450034737586975 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m50 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 13 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.6622\n",
      "Epoch 2/10, Loss: 0.6601\n",
      "Epoch 3/10, Loss: 0.6581\n",
      "Epoch 4/10, Loss: 0.6561\n",
      "Epoch 5/10, Loss: 0.6541\n",
      "Epoch 6/10, Loss: 0.6523\n",
      "Epoch 7/10, Loss: 0.6504\n",
      "Epoch 8/10, Loss: 0.6487\n",
      "Epoch 9/10, Loss: 0.6469\n",
      "Epoch 10/10, Loss: 0.6453\n",
      "for action a probs tensor([0.5807, 0.4193], grad_fn=<SoftmaxBackward0>) max_prob 0.5807047486305237\n",
      "action a probabilité 0.5807047486305237 valance -1 outcome x\n",
      "action a probabilité 0.4192952811717987 valance 1 outcome y\n",
      "for action b probs tensor([0.5807, 0.4193], grad_fn=<SoftmaxBackward0>) max_prob 0.5807047486305237\n",
      "action b probabilité 0.5807047486305237 valance -1 outcome x\n",
      "action b probabilité 0.4192952811717987 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m50 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 14 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.6366\n",
      "Epoch 2/10, Loss: 0.6347\n",
      "Epoch 3/10, Loss: 0.6329\n",
      "Epoch 4/10, Loss: 0.6312\n",
      "Epoch 5/10, Loss: 0.6295\n",
      "Epoch 6/10, Loss: 0.6278\n",
      "Epoch 7/10, Loss: 0.6262\n",
      "Epoch 8/10, Loss: 0.6247\n",
      "Epoch 9/10, Loss: 0.6232\n",
      "Epoch 10/10, Loss: 0.6218\n",
      "for action a probs tensor([0.6137, 0.3863], grad_fn=<SoftmaxBackward0>) max_prob 0.6137397885322571\n",
      "action a probabilité 0.6137397885322571 valance -1 outcome x\n",
      "action a probabilité 0.3862602412700653 valance 1 outcome y\n",
      "for action b probs tensor([0.6137, 0.3863], grad_fn=<SoftmaxBackward0>) max_prob 0.6137397885322571\n",
      "action b probabilité 0.6137397885322571 valance -1 outcome x\n",
      "action b probabilité 0.3862602412700653 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m50 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 15 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.6117\n",
      "Epoch 2/10, Loss: 0.6101\n",
      "Epoch 3/10, Loss: 0.6086\n",
      "Epoch 4/10, Loss: 0.6071\n",
      "Epoch 5/10, Loss: 0.6057\n",
      "Epoch 6/10, Loss: 0.6043\n",
      "Epoch 7/10, Loss: 0.6030\n",
      "Epoch 8/10, Loss: 0.6017\n",
      "Epoch 9/10, Loss: 0.6005\n",
      "Epoch 10/10, Loss: 0.5994\n",
      "for action a probs tensor([0.6437, 0.3563], grad_fn=<SoftmaxBackward0>) max_prob 0.6436989903450012\n",
      "action a probabilité 0.6436989903450012 valance -1 outcome x\n",
      "action a probabilité 0.3563010096549988 valance 1 outcome y\n",
      "for action b probs tensor([0.6437, 0.3563], grad_fn=<SoftmaxBackward0>) max_prob 0.6436989903450012\n",
      "action b probabilité 0.6436989903450012 valance -1 outcome x\n",
      "action b probabilité 0.3563010096549988 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m50 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 16 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.5884\n",
      "Epoch 2/10, Loss: 0.5871\n",
      "Epoch 3/10, Loss: 0.5859\n",
      "Epoch 4/10, Loss: 0.5847\n",
      "Epoch 5/10, Loss: 0.5835\n",
      "Epoch 6/10, Loss: 0.5824\n",
      "Epoch 7/10, Loss: 0.5813\n",
      "Epoch 8/10, Loss: 0.5803\n",
      "Epoch 9/10, Loss: 0.5793\n",
      "Epoch 10/10, Loss: 0.5783\n",
      "for action a probs tensor([0.6703, 0.3297], grad_fn=<SoftmaxBackward0>) max_prob 0.6703360676765442\n",
      "action a probabilité 0.6703360676765442 valance -1 outcome x\n",
      "action a probabilité 0.3296639323234558 valance 1 outcome y\n",
      "for action b probs tensor([0.6703, 0.3297], grad_fn=<SoftmaxBackward0>) max_prob 0.6703360676765442\n",
      "action b probabilité 0.6703360676765442 valance -1 outcome x\n",
      "action b probabilité 0.3296639323234558 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m60 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 17 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.5670\n",
      "Epoch 2/10, Loss: 0.5659\n",
      "Epoch 3/10, Loss: 0.5649\n",
      "Epoch 4/10, Loss: 0.5639\n",
      "Epoch 5/10, Loss: 0.5630\n",
      "Epoch 6/10, Loss: 0.5621\n",
      "Epoch 7/10, Loss: 0.5612\n",
      "Epoch 8/10, Loss: 0.5604\n",
      "Epoch 9/10, Loss: 0.5595\n",
      "Epoch 10/10, Loss: 0.5588\n",
      "for action a probs tensor([0.6938, 0.3062], grad_fn=<SoftmaxBackward0>) max_prob 0.6937892436981201\n",
      "action a probabilité 0.6937892436981201 valance -1 outcome x\n",
      "action a probabilité 0.3062107563018799 valance 1 outcome y\n",
      "for action b probs tensor([0.6938, 0.3062], grad_fn=<SoftmaxBackward0>) max_prob 0.6937892436981201\n",
      "action b probabilité 0.6937892436981201 valance -1 outcome x\n",
      "action b probabilité 0.3062107563018799 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m70 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 18 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.5473\n",
      "Epoch 2/10, Loss: 0.5465\n",
      "Epoch 3/10, Loss: 0.5457\n",
      "Epoch 4/10, Loss: 0.5449\n",
      "Epoch 5/10, Loss: 0.5441\n",
      "Epoch 6/10, Loss: 0.5434\n",
      "Epoch 7/10, Loss: 0.5426\n",
      "Epoch 8/10, Loss: 0.5420\n",
      "Epoch 9/10, Loss: 0.5413\n",
      "Epoch 10/10, Loss: 0.5407\n",
      "for action a probs tensor([0.7144, 0.2856], grad_fn=<SoftmaxBackward0>) max_prob 0.7143787145614624\n",
      "action a probabilité 0.7143787145614624 valance -1 outcome x\n",
      "action a probabilité 0.2856212854385376 valance 1 outcome y\n",
      "for action b probs tensor([0.7144, 0.2856], grad_fn=<SoftmaxBackward0>) max_prob 0.7143787145614624\n",
      "action b probabilité 0.7143787145614624 valance -1 outcome x\n",
      "action b probabilité 0.2856212854385376 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m80 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 19 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.5293\n",
      "Epoch 2/10, Loss: 0.5286\n",
      "Epoch 3/10, Loss: 0.5280\n",
      "Epoch 4/10, Loss: 0.5273\n",
      "Epoch 5/10, Loss: 0.5267\n",
      "Epoch 6/10, Loss: 0.5261\n",
      "Epoch 7/10, Loss: 0.5255\n",
      "Epoch 8/10, Loss: 0.5249\n",
      "Epoch 9/10, Loss: 0.5244\n",
      "Epoch 10/10, Loss: 0.5239\n",
      "for action a probs tensor([0.7325, 0.2675], grad_fn=<SoftmaxBackward0>) max_prob 0.732480525970459\n",
      "action a probabilité 0.732480525970459 valance -1 outcome x\n",
      "action a probabilité 0.267519474029541 valance 1 outcome y\n",
      "for action b probs tensor([0.7325, 0.2675], grad_fn=<SoftmaxBackward0>) max_prob 0.732480525970459\n",
      "action b probabilité 0.732480525970459 valance -1 outcome x\n",
      "action b probabilité 0.267519474029541 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m90 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 20 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.5128\n",
      "Epoch 2/10, Loss: 0.5122\n",
      "Epoch 3/10, Loss: 0.5116\n",
      "Epoch 4/10, Loss: 0.5111\n",
      "Epoch 5/10, Loss: 0.5106\n",
      "Epoch 6/10, Loss: 0.5101\n",
      "Epoch 7/10, Loss: 0.5096\n",
      "Epoch 8/10, Loss: 0.5091\n",
      "Epoch 9/10, Loss: 0.5087\n",
      "Epoch 10/10, Loss: 0.5082\n",
      "for action a probs tensor([0.7485, 0.2515], grad_fn=<SoftmaxBackward0>) max_prob 0.74845951795578\n",
      "action a probabilité 0.74845951795578 valance -1 outcome x\n",
      "action a probabilité 0.2515404522418976 valance 1 outcome y\n",
      "for action b probs tensor([0.7485, 0.2515], grad_fn=<SoftmaxBackward0>) max_prob 0.74845951795578\n",
      "action b probabilité 0.74845951795578 valance -1 outcome x\n",
      "action b probabilité 0.2515404522418976 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 21 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.4974\n",
      "Epoch 2/10, Loss: 0.4970\n",
      "Epoch 3/10, Loss: 0.4965\n",
      "Epoch 4/10, Loss: 0.4960\n",
      "Epoch 5/10, Loss: 0.4956\n",
      "Epoch 6/10, Loss: 0.4952\n",
      "Epoch 7/10, Loss: 0.4948\n",
      "Epoch 8/10, Loss: 0.4944\n",
      "Epoch 9/10, Loss: 0.4940\n",
      "Epoch 10/10, Loss: 0.4936\n",
      "for action a probs tensor([0.7626, 0.2374], grad_fn=<SoftmaxBackward0>) max_prob 0.7626402378082275\n",
      "action a probabilité 0.7626402378082275 valance -1 outcome x\n",
      "action a probabilité 0.23735970258712769 valance 1 outcome y\n",
      "for action b probs tensor([0.7626, 0.2374], grad_fn=<SoftmaxBackward0>) max_prob 0.7626402378082275\n",
      "action b probabilité 0.7626402378082275 valance -1 outcome x\n",
      "action b probabilité 0.23735970258712769 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 22 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.4832\n",
      "Epoch 2/10, Loss: 0.4828\n",
      "Epoch 3/10, Loss: 0.4824\n",
      "Epoch 4/10, Loss: 0.4820\n",
      "Epoch 5/10, Loss: 0.4816\n",
      "Epoch 6/10, Loss: 0.4813\n",
      "Epoch 7/10, Loss: 0.4809\n",
      "Epoch 8/10, Loss: 0.4806\n",
      "Epoch 9/10, Loss: 0.4803\n",
      "Epoch 10/10, Loss: 0.4800\n",
      "for action a probs tensor([0.7753, 0.2247], grad_fn=<SoftmaxBackward0>) max_prob 0.7752987146377563\n",
      "action a probabilité 0.7752987146377563 valance -1 outcome x\n",
      "action a probabilité 0.22470131516456604 valance 1 outcome y\n",
      "for action b probs tensor([0.7753, 0.2247], grad_fn=<SoftmaxBackward0>) max_prob 0.7752987146377563\n",
      "action b probabilité 0.7752987146377563 valance -1 outcome x\n",
      "action b probabilité 0.22470131516456604 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 23 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.4699\n",
      "Epoch 2/10, Loss: 0.4696\n",
      "Epoch 3/10, Loss: 0.4692\n",
      "Epoch 4/10, Loss: 0.4689\n",
      "Epoch 5/10, Loss: 0.4686\n",
      "Epoch 6/10, Loss: 0.4683\n",
      "Epoch 7/10, Loss: 0.4680\n",
      "Epoch 8/10, Loss: 0.4677\n",
      "Epoch 9/10, Loss: 0.4674\n",
      "Epoch 10/10, Loss: 0.4672\n",
      "for action a probs tensor([0.7867, 0.2133], grad_fn=<SoftmaxBackward0>) max_prob 0.7866641879081726\n",
      "action a probabilité 0.7866641879081726 valance -1 outcome x\n",
      "action a probabilité 0.2133358269929886 valance 1 outcome y\n",
      "for action b probs tensor([0.7867, 0.2133], grad_fn=<SoftmaxBackward0>) max_prob 0.7866641879081726\n",
      "action b probabilité 0.7866641879081726 valance -1 outcome x\n",
      "action b probabilité 0.2133358269929886 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 24 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.4574\n",
      "Epoch 2/10, Loss: 0.4571\n",
      "Epoch 3/10, Loss: 0.4569\n",
      "Epoch 4/10, Loss: 0.4566\n",
      "Epoch 5/10, Loss: 0.4563\n",
      "Epoch 6/10, Loss: 0.4560\n",
      "Epoch 7/10, Loss: 0.4558\n",
      "Epoch 8/10, Loss: 0.4555\n",
      "Epoch 9/10, Loss: 0.4553\n",
      "Epoch 10/10, Loss: 0.4551\n",
      "for action a probs tensor([0.7969, 0.2031], grad_fn=<SoftmaxBackward0>) max_prob 0.7969255447387695\n",
      "action a probabilité 0.7969255447387695 valance -1 outcome x\n",
      "action a probabilité 0.20307445526123047 valance 1 outcome y\n",
      "for action b probs tensor([0.7969, 0.2031], grad_fn=<SoftmaxBackward0>) max_prob 0.7969255447387695\n",
      "action b probabilité 0.7969255447387695 valance -1 outcome x\n",
      "action b probabilité 0.20307445526123047 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 25 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.4457\n",
      "Epoch 2/10, Loss: 0.4455\n",
      "Epoch 3/10, Loss: 0.4452\n",
      "Epoch 4/10, Loss: 0.4450\n",
      "Epoch 5/10, Loss: 0.4448\n",
      "Epoch 6/10, Loss: 0.4445\n",
      "Epoch 7/10, Loss: 0.4443\n",
      "Epoch 8/10, Loss: 0.4441\n",
      "Epoch 9/10, Loss: 0.4439\n",
      "Epoch 10/10, Loss: 0.4437\n",
      "for action a probs tensor([0.8062, 0.1938], grad_fn=<SoftmaxBackward0>) max_prob 0.8062379360198975\n",
      "action a probabilité 0.8062379360198975 valance -1 outcome x\n",
      "action a probabilité 0.19376210868358612 valance 1 outcome y\n",
      "for action b probs tensor([0.8062, 0.1938], grad_fn=<SoftmaxBackward0>) max_prob 0.8062379360198975\n",
      "action b probabilité 0.8062379360198975 valance -1 outcome x\n",
      "action b probabilité 0.19376210868358612 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 26 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.4347\n",
      "Epoch 2/10, Loss: 0.4345\n",
      "Epoch 3/10, Loss: 0.4343\n",
      "Epoch 4/10, Loss: 0.4341\n",
      "Epoch 5/10, Loss: 0.4339\n",
      "Epoch 6/10, Loss: 0.4337\n",
      "Epoch 7/10, Loss: 0.4335\n",
      "Epoch 8/10, Loss: 0.4333\n",
      "Epoch 9/10, Loss: 0.4331\n",
      "Epoch 10/10, Loss: 0.4329\n",
      "for action a probs tensor([0.8147, 0.1853], grad_fn=<SoftmaxBackward0>) max_prob 0.8147290349006653\n",
      "action a probabilité 0.8147290349006653 valance -1 outcome x\n",
      "action a probabilité 0.1852709949016571 valance 1 outcome y\n",
      "for action b probs tensor([0.8147, 0.1853], grad_fn=<SoftmaxBackward0>) max_prob 0.8147290349006653\n",
      "action b probabilité 0.8147290349006653 valance -1 outcome x\n",
      "action b probabilité 0.1852709949016571 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 27 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.4243\n",
      "Epoch 2/10, Loss: 0.4241\n",
      "Epoch 3/10, Loss: 0.4239\n",
      "Epoch 4/10, Loss: 0.4237\n",
      "Epoch 5/10, Loss: 0.4236\n",
      "Epoch 6/10, Loss: 0.4234\n",
      "Epoch 7/10, Loss: 0.4232\n",
      "Epoch 8/10, Loss: 0.4230\n",
      "Epoch 9/10, Loss: 0.4229\n",
      "Epoch 10/10, Loss: 0.4227\n",
      "for action a probs tensor([0.8225, 0.1775], grad_fn=<SoftmaxBackward0>) max_prob 0.8225046396255493\n",
      "action a probabilité 0.8225046396255493 valance -1 outcome x\n",
      "action a probabilité 0.17749537527561188 valance 1 outcome y\n",
      "for action b probs tensor([0.8225, 0.1775], grad_fn=<SoftmaxBackward0>) max_prob 0.8225046396255493\n",
      "action b probabilité 0.8225046396255493 valance -1 outcome x\n",
      "action b probabilité 0.17749537527561188 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 28 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.4145\n",
      "Epoch 2/10, Loss: 0.4143\n",
      "Epoch 3/10, Loss: 0.4141\n",
      "Epoch 4/10, Loss: 0.4140\n",
      "Epoch 5/10, Loss: 0.4138\n",
      "Epoch 6/10, Loss: 0.4136\n",
      "Epoch 7/10, Loss: 0.4135\n",
      "Epoch 8/10, Loss: 0.4133\n",
      "Epoch 9/10, Loss: 0.4132\n",
      "Epoch 10/10, Loss: 0.4130\n",
      "for action a probs tensor([0.8297, 0.1703], grad_fn=<SoftmaxBackward0>) max_prob 0.8296530842781067\n",
      "action a probabilité 0.8296530842781067 valance -1 outcome x\n",
      "action a probabilité 0.1703469455242157 valance 1 outcome y\n",
      "for action b probs tensor([0.8297, 0.1703], grad_fn=<SoftmaxBackward0>) max_prob 0.8296530842781067\n",
      "action b probabilité 0.8296530842781067 valance -1 outcome x\n",
      "action b probabilité 0.1703469455242157 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 29 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.4051\n",
      "Epoch 2/10, Loss: 0.4050\n",
      "Epoch 3/10, Loss: 0.4048\n",
      "Epoch 4/10, Loss: 0.4047\n",
      "Epoch 5/10, Loss: 0.4045\n",
      "Epoch 6/10, Loss: 0.4044\n",
      "Epoch 7/10, Loss: 0.4042\n",
      "Epoch 8/10, Loss: 0.4041\n",
      "Epoch 9/10, Loss: 0.4040\n",
      "Epoch 10/10, Loss: 0.4039\n",
      "for action a probs tensor([0.8362, 0.1638], grad_fn=<SoftmaxBackward0>) max_prob 0.8362482786178589\n",
      "action a probabilité 0.8362482786178589 valance -1 outcome x\n",
      "action a probabilité 0.16375170648097992 valance 1 outcome y\n",
      "for action b probs tensor([0.8362, 0.1638], grad_fn=<SoftmaxBackward0>) max_prob 0.8362482786178589\n",
      "action b probabilité 0.8362482786178589 valance -1 outcome x\n",
      "action b probabilité 0.16375170648097992 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 30 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.3962\n",
      "Epoch 2/10, Loss: 0.3961\n",
      "Epoch 3/10, Loss: 0.3960\n",
      "Epoch 4/10, Loss: 0.3958\n",
      "Epoch 5/10, Loss: 0.3957\n",
      "Epoch 6/10, Loss: 0.3956\n",
      "Epoch 7/10, Loss: 0.3955\n",
      "Epoch 8/10, Loss: 0.3953\n",
      "Epoch 9/10, Loss: 0.3952\n",
      "Epoch 10/10, Loss: 0.3951\n",
      "for action a probs tensor([0.8424, 0.1576], grad_fn=<SoftmaxBackward0>) max_prob 0.8423530459403992\n",
      "action a probabilité 0.8423530459403992 valance -1 outcome x\n",
      "action a probabilité 0.1576469987630844 valance 1 outcome y\n",
      "for action b probs tensor([0.8424, 0.1576], grad_fn=<SoftmaxBackward0>) max_prob 0.8423530459403992\n",
      "action b probabilité 0.8423530459403992 valance -1 outcome x\n",
      "action b probabilité 0.1576469987630844 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 31 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.3878\n",
      "Epoch 2/10, Loss: 0.3877\n",
      "Epoch 3/10, Loss: 0.3875\n",
      "Epoch 4/10, Loss: 0.3874\n",
      "Epoch 5/10, Loss: 0.3873\n",
      "Epoch 6/10, Loss: 0.3872\n",
      "Epoch 7/10, Loss: 0.3871\n",
      "Epoch 8/10, Loss: 0.3870\n",
      "Epoch 9/10, Loss: 0.3869\n",
      "Epoch 10/10, Loss: 0.3868\n",
      "for action a probs tensor([0.8480, 0.1520], grad_fn=<SoftmaxBackward0>) max_prob 0.848020613193512\n",
      "action a probabilité 0.848020613193512 valance -1 outcome x\n",
      "action a probabilité 0.15197934210300446 valance 1 outcome y\n",
      "for action b probs tensor([0.8480, 0.1520], grad_fn=<SoftmaxBackward0>) max_prob 0.848020613193512\n",
      "action b probabilité 0.848020613193512 valance -1 outcome x\n",
      "action b probabilité 0.15197934210300446 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 32 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.3797\n",
      "Epoch 2/10, Loss: 0.3796\n",
      "Epoch 3/10, Loss: 0.3795\n",
      "Epoch 4/10, Loss: 0.3794\n",
      "Epoch 5/10, Loss: 0.3793\n",
      "Epoch 6/10, Loss: 0.3792\n",
      "Epoch 7/10, Loss: 0.3791\n",
      "Epoch 8/10, Loss: 0.3790\n",
      "Epoch 9/10, Loss: 0.3789\n",
      "Epoch 10/10, Loss: 0.3788\n",
      "for action a probs tensor([0.8533, 0.1467], grad_fn=<SoftmaxBackward0>) max_prob 0.8532969355583191\n",
      "action a probabilité 0.8532969355583191 valance -1 outcome x\n",
      "action a probabilité 0.1467030644416809 valance 1 outcome y\n",
      "for action b probs tensor([0.8533, 0.1467], grad_fn=<SoftmaxBackward0>) max_prob 0.8532969355583191\n",
      "action b probabilité 0.8532969355583191 valance -1 outcome x\n",
      "action b probabilité 0.1467030644416809 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 33 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.1581\n",
      "Epoch 2/10, Loss: 0.1564\n",
      "Epoch 3/10, Loss: 0.1543\n",
      "Epoch 4/10, Loss: 0.1519\n",
      "Epoch 5/10, Loss: 0.1493\n",
      "Epoch 6/10, Loss: 0.1466\n",
      "Epoch 7/10, Loss: 2.0104\n",
      "Epoch 8/10, Loss: 0.1449\n",
      "Epoch 9/10, Loss: 2.0013\n",
      "Epoch 10/10, Loss: 0.1485\n",
      "for action a probs tensor([0.8610, 0.1390], grad_fn=<SoftmaxBackward0>) max_prob 0.8609864115715027\n",
      "action a probabilité 0.8609864115715027 valance -1 outcome x\n",
      "action a probabilité 0.13901351392269135 valance 1 outcome y\n",
      "for action b probs tensor([0.8610, 0.1390], grad_fn=<SoftmaxBackward0>) max_prob 0.8609864115715027\n",
      "action b probabilité 0.8609864115715027 valance -1 outcome x\n",
      "action b probabilité 0.13901351392269135 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 34 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 1.0590\n",
      "Epoch 2/10, Loss: 0.1536\n",
      "Epoch 3/10, Loss: 0.1554\n",
      "Epoch 4/10, Loss: 0.1563\n",
      "Epoch 5/10, Loss: 1.0447\n",
      "Epoch 6/10, Loss: 0.1575\n",
      "Epoch 7/10, Loss: 1.0409\n",
      "Epoch 8/10, Loss: 0.1593\n",
      "Epoch 9/10, Loss: 0.1599\n",
      "Epoch 10/10, Loss: 0.1596\n",
      "for action a probs tensor([0.8528, 0.1472], grad_fn=<SoftmaxBackward0>) max_prob 0.8528043031692505\n",
      "action a probabilité 0.8528043031692505 valance -1 outcome x\n",
      "action a probabilité 0.14719568192958832 valance 1 outcome y\n",
      "for action b probs tensor([0.8528, 0.1472], grad_fn=<SoftmaxBackward0>) max_prob 0.8528043031692505\n",
      "action b probabilité 0.8528043031692505 valance -1 outcome x\n",
      "action b probabilité 0.14719568192958832 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 35 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.7454\n",
      "Epoch 2/10, Loss: 0.1586\n",
      "Epoch 3/10, Loss: 0.1578\n",
      "Epoch 4/10, Loss: 0.1565\n",
      "Epoch 5/10, Loss: 0.1549\n",
      "Epoch 6/10, Loss: 0.1529\n",
      "Epoch 7/10, Loss: 0.1508\n",
      "Epoch 8/10, Loss: 0.7593\n",
      "Epoch 9/10, Loss: 0.1471\n",
      "Epoch 10/10, Loss: 0.1455\n",
      "for action a probs tensor([0.8654, 0.1346], grad_fn=<SoftmaxBackward0>) max_prob 0.8653597831726074\n",
      "action a probabilité 0.8653597831726074 valance -1 outcome x\n",
      "action a probabilité 0.13464021682739258 valance 1 outcome y\n",
      "for action b probs tensor([0.8654, 0.1346], grad_fn=<SoftmaxBackward0>) max_prob 0.8653597831726074\n",
      "action b probabilité 0.8653597831726074 valance -1 outcome x\n",
      "action b probabilité 0.13464021682739258 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 36 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.1438\n",
      "Epoch 2/10, Loss: 0.1418\n",
      "Epoch 3/10, Loss: 0.6141\n",
      "Epoch 4/10, Loss: 0.6154\n",
      "Epoch 5/10, Loss: 0.1375\n",
      "Epoch 6/10, Loss: 0.6172\n",
      "Epoch 7/10, Loss: 0.1358\n",
      "Epoch 8/10, Loss: 0.1349\n",
      "Epoch 9/10, Loss: 0.6198\n",
      "Epoch 10/10, Loss: 0.6205\n",
      "for action a probs tensor([0.8755, 0.1245], grad_fn=<SoftmaxBackward0>) max_prob 0.8754770755767822\n",
      "action a probabilité 0.8754770755767822 valance -1 outcome x\n",
      "action a probabilité 0.12452291697263718 valance 1 outcome y\n",
      "for action b probs tensor([0.8755, 0.1245], grad_fn=<SoftmaxBackward0>) max_prob 0.8754770755767822\n",
      "action b probabilité 0.8754770755767822 valance -1 outcome x\n",
      "action b probabilité 0.12452291697263718 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 37 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.9135\n",
      "Epoch 2/10, Loss: 0.1334\n",
      "Epoch 3/10, Loss: 0.5228\n",
      "Epoch 4/10, Loss: 0.5227\n",
      "Epoch 5/10, Loss: 0.5225\n",
      "Epoch 6/10, Loss: 0.5222\n",
      "Epoch 7/10, Loss: 0.1348\n",
      "Epoch 8/10, Loss: 0.1348\n",
      "Epoch 9/10, Loss: 0.9103\n",
      "Epoch 10/10, Loss: 0.5221\n",
      "for action a probs tensor([0.8739, 0.1261], grad_fn=<SoftmaxBackward0>) max_prob 0.8738778829574585\n",
      "action a probabilité 0.8738778829574585 valance -1 outcome x\n",
      "action a probabilité 0.1261221319437027 valance 1 outcome y\n",
      "for action b probs tensor([0.8739, 0.1261], grad_fn=<SoftmaxBackward0>) max_prob 0.8738778829574585\n",
      "action b probabilité 0.8738778829574585 valance -1 outcome x\n",
      "action b probabilité 0.1261221319437027 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 38 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.4574\n",
      "Epoch 2/10, Loss: 0.1354\n",
      "Epoch 3/10, Loss: 0.1353\n",
      "Epoch 4/10, Loss: 0.7803\n",
      "Epoch 5/10, Loss: 0.1347\n",
      "Epoch 6/10, Loss: 0.1344\n",
      "Epoch 7/10, Loss: 0.4578\n",
      "Epoch 8/10, Loss: 0.4580\n",
      "Epoch 9/10, Loss: 0.1326\n",
      "Epoch 10/10, Loss: 0.4585\n",
      "for action a probs tensor([0.8768, 0.1232], grad_fn=<SoftmaxBackward0>) max_prob 0.8768085241317749\n",
      "action a probabilité 0.8768085241317749 valance -1 outcome x\n",
      "action a probabilité 0.12319144606590271 valance 1 outcome y\n",
      "for action b probs tensor([0.8768, 0.1232], grad_fn=<SoftmaxBackward0>) max_prob 0.8768085241317749\n",
      "action b probabilité 0.8768085241317749 valance -1 outcome x\n",
      "action b probabilité 0.12319144606590271 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 39 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.4119\n",
      "Epoch 2/10, Loss: 0.4120\n",
      "Epoch 3/10, Loss: 0.4120\n",
      "Epoch 4/10, Loss: 0.1299\n",
      "Epoch 5/10, Loss: 0.1292\n",
      "Epoch 6/10, Loss: 0.1282\n",
      "Epoch 7/10, Loss: 0.4126\n",
      "Epoch 8/10, Loss: 0.4128\n",
      "Epoch 9/10, Loss: 0.1253\n",
      "Epoch 10/10, Loss: 0.1243\n",
      "for action a probs tensor([0.8837, 0.1163], grad_fn=<SoftmaxBackward0>) max_prob 0.8836507797241211\n",
      "action a probabilité 0.8836507797241211 valance -1 outcome x\n",
      "action a probabilité 0.11634927242994308 valance 1 outcome y\n",
      "for action b probs tensor([0.8837, 0.1163], grad_fn=<SoftmaxBackward0>) max_prob 0.8836507797241211\n",
      "action b probabilité 0.8836507797241211 valance -1 outcome x\n",
      "action b probabilité 0.11634927242994308 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 40 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.3772\n",
      "Epoch 2/10, Loss: 0.3773\n",
      "Epoch 3/10, Loss: 0.6335\n",
      "Epoch 4/10, Loss: 0.1208\n",
      "Epoch 5/10, Loss: 0.1202\n",
      "Epoch 6/10, Loss: 0.3775\n",
      "Epoch 7/10, Loss: 0.1187\n",
      "Epoch 8/10, Loss: 0.1178\n",
      "Epoch 9/10, Loss: 0.1168\n",
      "Epoch 10/10, Loss: 0.3780\n",
      "for action a probs tensor([0.8913, 0.1087], grad_fn=<SoftmaxBackward0>) max_prob 0.8912527561187744\n",
      "action a probabilité 0.8912527561187744 valance -1 outcome x\n",
      "action a probabilité 0.10874724388122559 valance 1 outcome y\n",
      "for action b probs tensor([0.8913, 0.1087], grad_fn=<SoftmaxBackward0>) max_prob 0.8912527561187744\n",
      "action b probabilité 0.8912527561187744 valance -1 outcome x\n",
      "action b probabilité 0.10874724388122559 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 41 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.3489\n",
      "Epoch 2/10, Loss: 0.3489\n",
      "Epoch 3/10, Loss: 0.5847\n",
      "Epoch 4/10, Loss: 0.5851\n",
      "Epoch 5/10, Loss: 0.3489\n",
      "Epoch 6/10, Loss: 0.5852\n",
      "Epoch 7/10, Loss: 0.3489\n",
      "Epoch 8/10, Loss: 0.3489\n",
      "Epoch 9/10, Loss: 0.1132\n",
      "Epoch 10/10, Loss: 0.1130\n",
      "for action a probs tensor([0.8934, 0.1066], grad_fn=<SoftmaxBackward0>) max_prob 0.8933798670768738\n",
      "action a probabilité 0.8933798670768738 valance -1 outcome x\n",
      "action a probabilité 0.10662012547254562 valance 1 outcome y\n",
      "for action b probs tensor([0.8934, 0.1066], grad_fn=<SoftmaxBackward0>) max_prob 0.8933798670768738\n",
      "action b probabilité 0.8933798670768738 valance -1 outcome x\n",
      "action b probabilité 0.10662012547254562 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 42 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.5381\n",
      "Epoch 2/10, Loss: 0.3253\n",
      "Epoch 3/10, Loss: 0.1121\n",
      "Epoch 4/10, Loss: 0.3253\n",
      "Epoch 5/10, Loss: 0.5394\n",
      "Epoch 6/10, Loss: 0.5396\n",
      "Epoch 7/10, Loss: 0.3252\n",
      "Epoch 8/10, Loss: 0.3252\n",
      "Epoch 9/10, Loss: 0.3252\n",
      "Epoch 10/10, Loss: 0.5398\n",
      "for action a probs tensor([0.8952, 0.1048], grad_fn=<SoftmaxBackward0>) max_prob 0.8952072858810425\n",
      "action a probabilité 0.8952072858810425 valance -1 outcome x\n",
      "action a probabilité 0.10479266196489334 valance 1 outcome y\n",
      "for action b probs tensor([0.8952, 0.1048], grad_fn=<SoftmaxBackward0>) max_prob 0.8952072858810425\n",
      "action b probabilité 0.8952072858810425 valance -1 outcome x\n",
      "action b probabilité 0.10479266196489334 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 43 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.3057\n",
      "Epoch 2/10, Loss: 0.1108\n",
      "Epoch 3/10, Loss: 0.1106\n",
      "Epoch 4/10, Loss: 0.3056\n",
      "Epoch 5/10, Loss: 0.6977\n",
      "Epoch 6/10, Loss: 0.5017\n",
      "Epoch 7/10, Loss: 0.1095\n",
      "Epoch 8/10, Loss: 0.3055\n",
      "Epoch 9/10, Loss: 0.6986\n",
      "Epoch 10/10, Loss: 0.1091\n",
      "for action a probs tensor([0.8967, 0.1033], grad_fn=<SoftmaxBackward0>) max_prob 0.8967196345329285\n",
      "action a probabilité 0.8967196345329285 valance -1 outcome x\n",
      "action a probabilité 0.10328032821416855 valance 1 outcome y\n",
      "for action b probs tensor([0.8967, 0.1033], grad_fn=<SoftmaxBackward0>) max_prob 0.8967196345329285\n",
      "action b probabilité 0.8967196345329285 valance -1 outcome x\n",
      "action b probabilité 0.10328032821416855 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 44 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.4693\n",
      "Epoch 2/10, Loss: 0.4694\n",
      "Epoch 3/10, Loss: 0.2891\n",
      "Epoch 4/10, Loss: 0.4694\n",
      "Epoch 5/10, Loss: 0.2891\n",
      "Epoch 6/10, Loss: 0.2891\n",
      "Epoch 7/10, Loss: 0.4695\n",
      "Epoch 8/10, Loss: 0.1085\n",
      "Epoch 9/10, Loss: 0.2890\n",
      "Epoch 10/10, Loss: 0.4699\n",
      "for action a probs tensor([0.8978, 0.1022], grad_fn=<SoftmaxBackward0>) max_prob 0.8978355526924133\n",
      "action a probabilité 0.8978355526924133 valance -1 outcome x\n",
      "action a probabilité 0.10216443985700607 valance 1 outcome y\n",
      "for action b probs tensor([0.8978, 0.1022], grad_fn=<SoftmaxBackward0>) max_prob 0.8978355526924133\n",
      "action b probabilité 0.8978355526924133 valance -1 outcome x\n",
      "action b probabilité 0.10216443985700607 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 45 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.6096\n",
      "Epoch 2/10, Loss: 0.6096\n",
      "Epoch 3/10, Loss: 0.4422\n",
      "Epoch 4/10, Loss: 0.2750\n",
      "Epoch 5/10, Loss: 0.4420\n",
      "Epoch 6/10, Loss: 0.4420\n",
      "Epoch 7/10, Loss: 0.1083\n",
      "Epoch 8/10, Loss: 0.4419\n",
      "Epoch 9/10, Loss: 0.2750\n",
      "Epoch 10/10, Loss: 0.2750\n",
      "for action a probs tensor([0.8978, 0.1022], grad_fn=<SoftmaxBackward0>) max_prob 0.8978230953216553\n",
      "action a probabilité 0.8978230953216553 valance -1 outcome x\n",
      "action a probabilité 0.1021769568324089 valance 1 outcome y\n",
      "for action b probs tensor([0.8978, 0.1022], grad_fn=<SoftmaxBackward0>) max_prob 0.8978230953216553\n",
      "action b probabilité 0.8978230953216553 valance -1 outcome x\n",
      "action b probabilité 0.1021769568324089 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 46 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.5737\n",
      "Epoch 2/10, Loss: 0.1076\n",
      "Epoch 3/10, Loss: 0.4185\n",
      "Epoch 4/10, Loss: 0.1070\n",
      "Epoch 5/10, Loss: 0.2627\n",
      "Epoch 6/10, Loss: 0.4190\n",
      "Epoch 7/10, Loss: 0.2624\n",
      "Epoch 8/10, Loss: 0.2623\n",
      "Epoch 9/10, Loss: 0.2621\n",
      "Epoch 10/10, Loss: 0.2620\n",
      "for action a probs tensor([0.9011, 0.0989], grad_fn=<SoftmaxBackward0>) max_prob 0.9011470079421997\n",
      "action a probabilité 0.9011470079421997 valance -1 outcome x\n",
      "action a probabilité 0.0988529846072197 valance 1 outcome y\n",
      "for action b probs tensor([0.9011, 0.0989], grad_fn=<SoftmaxBackward0>) max_prob 0.9011470079421997\n",
      "action b probabilité 0.9011470079421997 valance -1 outcome x\n",
      "action b probabilité 0.0988529846072197 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 47 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.5464\n",
      "Epoch 2/10, Loss: 0.3990\n",
      "Epoch 3/10, Loss: 0.2511\n",
      "Epoch 4/10, Loss: 0.2511\n",
      "Epoch 5/10, Loss: 0.3993\n",
      "Epoch 6/10, Loss: 0.2508\n",
      "Epoch 7/10, Loss: 0.1020\n",
      "Epoch 8/10, Loss: 0.2506\n",
      "Epoch 9/10, Loss: 0.1011\n",
      "Epoch 10/10, Loss: 0.2503\n",
      "for action a probs tensor([0.9047, 0.0953], grad_fn=<SoftmaxBackward0>) max_prob 0.9047094583511353\n",
      "action a probabilité 0.9047094583511353 valance -1 outcome x\n",
      "action a probabilité 0.09529051929712296 valance 1 outcome y\n",
      "for action b probs tensor([0.9047, 0.0953], grad_fn=<SoftmaxBackward0>) max_prob 0.9047094583511353\n",
      "action b probabilité 0.9047094583511353 valance -1 outcome x\n",
      "action b probabilité 0.09529051929712296 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 48 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.2407\n",
      "Epoch 2/10, Loss: 0.3818\n",
      "Epoch 3/10, Loss: 0.5236\n",
      "Epoch 4/10, Loss: 0.3821\n",
      "Epoch 5/10, Loss: 0.5243\n",
      "Epoch 6/10, Loss: 0.3822\n",
      "Epoch 7/10, Loss: 0.3822\n",
      "Epoch 8/10, Loss: 0.2400\n",
      "Epoch 9/10, Loss: 0.2400\n",
      "Epoch 10/10, Loss: 0.2399\n",
      "for action a probs tensor([0.9072, 0.0928], grad_fn=<SoftmaxBackward0>) max_prob 0.907158374786377\n",
      "action a probabilité 0.907158374786377 valance -1 outcome x\n",
      "action a probabilité 0.09284155070781708 valance 1 outcome y\n",
      "for action b probs tensor([0.9072, 0.0928], grad_fn=<SoftmaxBackward0>) max_prob 0.907158374786377\n",
      "action b probabilité 0.907158374786377 valance -1 outcome x\n",
      "action b probabilité 0.09284155070781708 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 49 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.0974\n",
      "Epoch 2/10, Loss: 0.2314\n",
      "Epoch 3/10, Loss: 0.2312\n",
      "Epoch 4/10, Loss: 0.0962\n",
      "Epoch 5/10, Loss: 0.2309\n",
      "Epoch 6/10, Loss: 0.0952\n",
      "Epoch 7/10, Loss: 0.2305\n",
      "Epoch 8/10, Loss: 0.2303\n",
      "Epoch 9/10, Loss: 0.3668\n",
      "Epoch 10/10, Loss: 0.3670\n",
      "for action a probs tensor([0.9115, 0.0885], grad_fn=<SoftmaxBackward0>) max_prob 0.9114555716514587\n",
      "action a probabilité 0.9114555716514587 valance -1 outcome x\n",
      "action a probabilité 0.08854444324970245 valance 1 outcome y\n",
      "for action b probs tensor([0.9115, 0.0885], grad_fn=<SoftmaxBackward0>) max_prob 0.9114555716514587\n",
      "action b probabilité 0.9114555716514587 valance -1 outcome x\n",
      "action b probabilité 0.08854444324970245 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 50 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.4815\n",
      "Epoch 2/10, Loss: 0.2221\n",
      "Epoch 3/10, Loss: 0.2220\n",
      "Epoch 4/10, Loss: 0.3520\n",
      "Epoch 5/10, Loss: 0.3521\n",
      "Epoch 6/10, Loss: 0.2217\n",
      "Epoch 7/10, Loss: 0.2217\n",
      "Epoch 8/10, Loss: 0.3523\n",
      "Epoch 9/10, Loss: 0.3523\n",
      "Epoch 10/10, Loss: 0.3524\n",
      "for action a probs tensor([0.9136, 0.0864], grad_fn=<SoftmaxBackward0>) max_prob 0.913635790348053\n",
      "action a probabilité 0.913635790348053 valance -1 outcome x\n",
      "action a probabilité 0.0863642543554306 valance 1 outcome y\n",
      "for action b probs tensor([0.9136, 0.0864], grad_fn=<SoftmaxBackward0>) max_prob 0.913635790348053\n",
      "action b probabilité 0.913635790348053 valance -1 outcome x\n",
      "action b probabilité 0.0863642543554306 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 51 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.2145\n",
      "Epoch 2/10, Loss: 0.0902\n",
      "Epoch 3/10, Loss: 0.3387\n",
      "Epoch 4/10, Loss: 0.2142\n",
      "Epoch 5/10, Loss: 0.3389\n",
      "Epoch 6/10, Loss: 0.3389\n",
      "Epoch 7/10, Loss: 0.3390\n",
      "Epoch 8/10, Loss: 0.4643\n",
      "Epoch 9/10, Loss: 0.2138\n",
      "Epoch 10/10, Loss: 0.3391\n",
      "for action a probs tensor([0.9154, 0.0846], grad_fn=<SoftmaxBackward0>) max_prob 0.9154344201087952\n",
      "action a probabilité 0.9154344201087952 valance -1 outcome x\n",
      "action a probabilité 0.08456555753946304 valance 1 outcome y\n",
      "for action b probs tensor([0.9154, 0.0846], grad_fn=<SoftmaxBackward0>) max_prob 0.9154344201087952\n",
      "action b probabilité 0.9154344201087952 valance -1 outcome x\n",
      "action b probabilité 0.08456555753946304 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 52 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.4457\n",
      "Epoch 2/10, Loss: 0.3266\n",
      "Epoch 3/10, Loss: 0.0882\n",
      "Epoch 4/10, Loss: 0.2073\n",
      "Epoch 5/10, Loss: 0.2073\n",
      "Epoch 6/10, Loss: 0.0877\n",
      "Epoch 7/10, Loss: 0.2070\n",
      "Epoch 8/10, Loss: 0.2069\n",
      "Epoch 9/10, Loss: 0.3269\n",
      "Epoch 10/10, Loss: 0.2066\n",
      "for action a probs tensor([0.9174, 0.0826], grad_fn=<SoftmaxBackward0>) max_prob 0.917407214641571\n",
      "action a probabilité 0.917407214641571 valance -1 outcome x\n",
      "action a probabilité 0.08259279280900955 valance 1 outcome y\n",
      "for action b probs tensor([0.9174, 0.0826], grad_fn=<SoftmaxBackward0>) max_prob 0.917407214641571\n",
      "action b probabilité 0.917407214641571 valance -1 outcome x\n",
      "action b probabilité 0.08259279280900955 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 53 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.3155\n",
      "Epoch 2/10, Loss: 0.3156\n",
      "Epoch 3/10, Loss: 0.2006\n",
      "Epoch 4/10, Loss: 0.5462\n",
      "Epoch 5/10, Loss: 0.3157\n",
      "Epoch 6/10, Loss: 0.2003\n",
      "Epoch 7/10, Loss: 0.0849\n",
      "Epoch 8/10, Loss: 0.3158\n",
      "Epoch 9/10, Loss: 0.2001\n",
      "Epoch 10/10, Loss: 0.2000\n",
      "for action a probs tensor([0.9194, 0.0806], grad_fn=<SoftmaxBackward0>) max_prob 0.9193554520606995\n",
      "action a probabilité 0.9193554520606995 valance -1 outcome x\n",
      "action a probabilité 0.08064456284046173 valance 1 outcome y\n",
      "for action b probs tensor([0.9194, 0.0806], grad_fn=<SoftmaxBackward0>) max_prob 0.9193554520606995\n",
      "action b probabilité 0.9193554520606995 valance -1 outcome x\n",
      "action b probabilité 0.08064456284046173 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 54 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.0840\n",
      "Epoch 2/10, Loss: 0.1945\n",
      "Epoch 3/10, Loss: 0.3054\n",
      "Epoch 4/10, Loss: 0.3055\n",
      "Epoch 5/10, Loss: 0.4169\n",
      "Epoch 6/10, Loss: 0.1941\n",
      "Epoch 7/10, Loss: 0.1940\n",
      "Epoch 8/10, Loss: 0.3056\n",
      "Epoch 9/10, Loss: 0.1938\n",
      "Epoch 10/10, Loss: 0.1938\n",
      "for action a probs tensor([0.9215, 0.0785], grad_fn=<SoftmaxBackward0>) max_prob 0.9214790463447571\n",
      "action a probabilité 0.9214790463447571 valance -1 outcome x\n",
      "action a probabilité 0.07852095365524292 valance 1 outcome y\n",
      "for action b probs tensor([0.9215, 0.0785], grad_fn=<SoftmaxBackward0>) max_prob 0.9214790463447571\n",
      "action b probabilité 0.9214790463447571 valance -1 outcome x\n",
      "action b probabilité 0.07852095365524292 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 55 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.1888\n",
      "Epoch 2/10, Loss: 0.1887\n",
      "Epoch 3/10, Loss: 0.4034\n",
      "Epoch 4/10, Loss: 0.1885\n",
      "Epoch 5/10, Loss: 0.1884\n",
      "Epoch 6/10, Loss: 0.2961\n",
      "Epoch 7/10, Loss: 0.0805\n",
      "Epoch 8/10, Loss: 0.5122\n",
      "Epoch 9/10, Loss: 0.1881\n",
      "Epoch 10/10, Loss: 0.4044\n",
      "for action a probs tensor([0.9234, 0.0766], grad_fn=<SoftmaxBackward0>) max_prob 0.9233790636062622\n",
      "action a probabilité 0.9233790636062622 valance -1 outcome x\n",
      "action a probabilité 0.07662095874547958 valance 1 outcome y\n",
      "for action b probs tensor([0.9234, 0.0766], grad_fn=<SoftmaxBackward0>) max_prob 0.9233790636062622\n",
      "action b probabilité 0.9233790636062622 valance -1 outcome x\n",
      "action b probabilité 0.07662095874547958 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 56 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.1834\n",
      "Epoch 2/10, Loss: 0.2872\n",
      "Epoch 3/10, Loss: 0.1833\n",
      "Epoch 4/10, Loss: 0.1833\n",
      "Epoch 5/10, Loss: 0.0792\n",
      "Epoch 6/10, Loss: 0.1831\n",
      "Epoch 7/10, Loss: 0.3915\n",
      "Epoch 8/10, Loss: 0.1829\n",
      "Epoch 9/10, Loss: 0.3918\n",
      "Epoch 10/10, Loss: 0.2873\n",
      "for action a probs tensor([0.9249, 0.0751], grad_fn=<SoftmaxBackward0>) max_prob 0.9248668551445007\n",
      "action a probabilité 0.9248668551445007 valance -1 outcome x\n",
      "action a probabilité 0.07513315230607986 valance 1 outcome y\n",
      "for action b probs tensor([0.9249, 0.0751], grad_fn=<SoftmaxBackward0>) max_prob 0.9248668551445007\n",
      "action b probabilité 0.9248668551445007 valance -1 outcome x\n",
      "action b probabilité 0.07513315230607986 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 57 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.3794\n",
      "Epoch 2/10, Loss: 0.1784\n",
      "Epoch 3/10, Loss: 0.1784\n",
      "Epoch 4/10, Loss: 0.2790\n",
      "Epoch 5/10, Loss: 0.3797\n",
      "Epoch 6/10, Loss: 0.2790\n",
      "Epoch 7/10, Loss: 0.1782\n",
      "Epoch 8/10, Loss: 0.2790\n",
      "Epoch 9/10, Loss: 0.1781\n",
      "Epoch 10/10, Loss: 0.3801\n",
      "for action a probs tensor([0.9260, 0.0740], grad_fn=<SoftmaxBackward0>) max_prob 0.926005482673645\n",
      "action a probabilité 0.926005482673645 valance -1 outcome x\n",
      "action a probabilité 0.07399442791938782 valance 1 outcome y\n",
      "for action b probs tensor([0.9260, 0.0740], grad_fn=<SoftmaxBackward0>) max_prob 0.926005482673645\n",
      "action b probabilité 0.926005482673645 valance -1 outcome x\n",
      "action b probabilité 0.07399442791938782 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 58 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.3685\n",
      "Epoch 2/10, Loss: 0.1740\n",
      "Epoch 3/10, Loss: 0.3686\n",
      "Epoch 4/10, Loss: 0.2713\n",
      "Epoch 5/10, Loss: 0.1739\n",
      "Epoch 6/10, Loss: 0.2713\n",
      "Epoch 7/10, Loss: 0.3689\n",
      "Epoch 8/10, Loss: 0.1737\n",
      "Epoch 9/10, Loss: 0.3690\n",
      "Epoch 10/10, Loss: 0.3691\n",
      "for action a probs tensor([0.9270, 0.0730], grad_fn=<SoftmaxBackward0>) max_prob 0.9270457625389099\n",
      "action a probabilité 0.9270457625389099 valance -1 outcome x\n",
      "action a probabilité 0.07295427471399307 valance 1 outcome y\n",
      "for action b probs tensor([0.9270, 0.0730], grad_fn=<SoftmaxBackward0>) max_prob 0.9270457625389099\n",
      "action b probabilité 0.9270457625389099 valance -1 outcome x\n",
      "action b probabilité 0.07295427471399307 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 59 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.4525\n",
      "Epoch 2/10, Loss: 0.2641\n",
      "Epoch 3/10, Loss: 0.2641\n",
      "Epoch 4/10, Loss: 0.2641\n",
      "Epoch 5/10, Loss: 0.1698\n",
      "Epoch 6/10, Loss: 0.1697\n",
      "Epoch 7/10, Loss: 0.3585\n",
      "Epoch 8/10, Loss: 0.3586\n",
      "Epoch 9/10, Loss: 0.2641\n",
      "Epoch 10/10, Loss: 0.1695\n",
      "for action a probs tensor([0.9279, 0.0721], grad_fn=<SoftmaxBackward0>) max_prob 0.9278786778450012\n",
      "action a probabilité 0.9278786778450012 valance -1 outcome x\n",
      "action a probabilité 0.07212133705615997 valance 1 outcome y\n",
      "for action b probs tensor([0.9279, 0.0721], grad_fn=<SoftmaxBackward0>) max_prob 0.9278786778450012\n",
      "action b probabilité 0.9278786778450012 valance -1 outcome x\n",
      "action b probabilité 0.07212133705615997 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 60 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.2573\n",
      "Epoch 2/10, Loss: 0.1660\n",
      "Epoch 3/10, Loss: 0.2573\n",
      "Epoch 4/10, Loss: 0.1659\n",
      "Epoch 5/10, Loss: 0.0744\n",
      "Epoch 6/10, Loss: 0.2573\n",
      "Epoch 7/10, Loss: 0.1657\n",
      "Epoch 8/10, Loss: 0.2573\n",
      "Epoch 9/10, Loss: 0.2573\n",
      "Epoch 10/10, Loss: 0.1654\n",
      "for action a probs tensor([0.9292, 0.0708], grad_fn=<SoftmaxBackward0>) max_prob 0.92924964427948\n",
      "action a probabilité 0.92924964427948 valance -1 outcome x\n",
      "action a probabilité 0.07075030356645584 valance 1 outcome y\n",
      "for action b probs tensor([0.9292, 0.0708], grad_fn=<SoftmaxBackward0>) max_prob 0.92924964427948\n",
      "action b probabilité 0.92924964427948 valance -1 outcome x\n",
      "action b probabilité 0.07075030356645584 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 61 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.3398\n",
      "Epoch 2/10, Loss: 0.1620\n",
      "Epoch 3/10, Loss: 0.2510\n",
      "Epoch 4/10, Loss: 0.1619\n",
      "Epoch 5/10, Loss: 0.2510\n",
      "Epoch 6/10, Loss: 0.3402\n",
      "Epoch 7/10, Loss: 0.2510\n",
      "Epoch 8/10, Loss: 0.1616\n",
      "Epoch 9/10, Loss: 0.2510\n",
      "Epoch 10/10, Loss: 0.1614\n",
      "for action a probs tensor([0.9307, 0.0693], grad_fn=<SoftmaxBackward0>) max_prob 0.9306638836860657\n",
      "action a probabilité 0.9306638836860657 valance -1 outcome x\n",
      "action a probabilité 0.06933607161045074 valance 1 outcome y\n",
      "for action b probs tensor([0.9307, 0.0693], grad_fn=<SoftmaxBackward0>) max_prob 0.9306638836860657\n",
      "action b probabilité 0.9306638836860657 valance -1 outcome x\n",
      "action b probabilité 0.06933607161045074 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 62 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.0719\n",
      "Epoch 2/10, Loss: 0.2450\n",
      "Epoch 3/10, Loss: 0.3317\n",
      "Epoch 4/10, Loss: 0.1582\n",
      "Epoch 5/10, Loss: 0.1581\n",
      "Epoch 6/10, Loss: 0.3319\n",
      "Epoch 7/10, Loss: 0.2450\n",
      "Epoch 8/10, Loss: 0.1579\n",
      "Epoch 9/10, Loss: 0.1578\n",
      "Epoch 10/10, Loss: 0.1578\n",
      "for action a probs tensor([0.9319, 0.0681], grad_fn=<SoftmaxBackward0>) max_prob 0.9319266080856323\n",
      "action a probabilité 0.9319266080856323 valance -1 outcome x\n",
      "action a probabilité 0.0680733472108841 valance 1 outcome y\n",
      "for action b probs tensor([0.9319, 0.0681], grad_fn=<SoftmaxBackward0>) max_prob 0.9319266080856323\n",
      "action b probabilité 0.9319266080856323 valance -1 outcome x\n",
      "action b probabilité 0.0680733472108841 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 63 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.3238\n",
      "Epoch 2/10, Loss: 0.1548\n",
      "Epoch 3/10, Loss: 0.3239\n",
      "Epoch 4/10, Loss: 0.2393\n",
      "Epoch 5/10, Loss: 0.2393\n",
      "Epoch 6/10, Loss: 0.2393\n",
      "Epoch 7/10, Loss: 0.3242\n",
      "Epoch 8/10, Loss: 0.1544\n",
      "Epoch 9/10, Loss: 0.1543\n",
      "Epoch 10/10, Loss: 0.1543\n",
      "for action a probs tensor([0.9331, 0.0669], grad_fn=<SoftmaxBackward0>) max_prob 0.9331250190734863\n",
      "action a probabilité 0.9331250190734863 valance -1 outcome x\n",
      "action a probabilité 0.06687502562999725 valance 1 outcome y\n",
      "for action b probs tensor([0.9331, 0.0669], grad_fn=<SoftmaxBackward0>) max_prob 0.9331250190734863\n",
      "action b probabilité 0.9331250190734863 valance -1 outcome x\n",
      "action b probabilité 0.06687502562999725 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 64 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.3164\n",
      "Epoch 2/10, Loss: 0.1515\n",
      "Epoch 3/10, Loss: 0.2339\n",
      "Epoch 4/10, Loss: 0.3165\n",
      "Epoch 5/10, Loss: 0.3166\n",
      "Epoch 6/10, Loss: 0.2339\n",
      "Epoch 7/10, Loss: 0.2339\n",
      "Epoch 8/10, Loss: 0.1511\n",
      "Epoch 9/10, Loss: 0.0682\n",
      "Epoch 10/10, Loss: 0.3168\n",
      "for action a probs tensor([0.9343, 0.0657], grad_fn=<SoftmaxBackward0>) max_prob 0.9342530965805054\n",
      "action a probabilité 0.9342530965805054 valance -1 outcome x\n",
      "action a probabilité 0.06574689596891403 valance 1 outcome y\n",
      "for action b probs tensor([0.9343, 0.0657], grad_fn=<SoftmaxBackward0>) max_prob 0.9342530965805054\n",
      "action b probabilité 0.9342530965805054 valance -1 outcome x\n",
      "action b probabilité 0.06574689596891403 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 65 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.0679\n",
      "Epoch 2/10, Loss: 0.0674\n",
      "Epoch 3/10, Loss: 0.0669\n",
      "Epoch 4/10, Loss: 2.7490\n",
      "Epoch 5/10, Loss: 0.0691\n",
      "Epoch 6/10, Loss: 0.0711\n",
      "Epoch 7/10, Loss: 0.0722\n",
      "Epoch 8/10, Loss: 0.0727\n",
      "Epoch 9/10, Loss: 2.6575\n",
      "Epoch 10/10, Loss: 0.0761\n",
      "for action a probs tensor([0.9259, 0.0741], grad_fn=<SoftmaxBackward0>) max_prob 0.925934910774231\n",
      "action a probabilité 0.925934910774231 valance -1 outcome x\n",
      "action a probabilité 0.07406511157751083 valance 1 outcome y\n",
      "for action b probs tensor([0.9259, 0.0741], grad_fn=<SoftmaxBackward0>) max_prob 0.925934910774231\n",
      "action b probabilité 0.925934910774231 valance -1 outcome x\n",
      "action b probabilité 0.07406511157751083 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 66 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.0783\n",
      "Epoch 2/10, Loss: 0.0796\n",
      "Epoch 3/10, Loss: 0.0800\n",
      "Epoch 4/10, Loss: 1.3235\n",
      "Epoch 5/10, Loss: 0.0814\n",
      "Epoch 6/10, Loss: 0.0820\n",
      "Epoch 7/10, Loss: 0.0820\n",
      "Epoch 8/10, Loss: 0.0815\n",
      "Epoch 9/10, Loss: 0.0806\n",
      "Epoch 10/10, Loss: 0.0795\n",
      "for action a probs tensor([0.9239, 0.0761], grad_fn=<SoftmaxBackward0>) max_prob 0.9239110350608826\n",
      "action a probabilité 0.9239110350608826 valance -1 outcome x\n",
      "action a probabilité 0.07608898729085922 valance 1 outcome y\n",
      "for action b probs tensor([0.9239, 0.0761], grad_fn=<SoftmaxBackward0>) max_prob 0.9239110350608826\n",
      "action b probabilité 0.9239110350608826 valance -1 outcome x\n",
      "action b probabilité 0.07608898729085922 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 67 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.0783\n",
      "Epoch 2/10, Loss: 0.0771\n",
      "Epoch 3/10, Loss: 0.0758\n",
      "Epoch 4/10, Loss: 0.0745\n",
      "Epoch 5/10, Loss: 0.0732\n",
      "Epoch 6/10, Loss: 0.9373\n",
      "Epoch 7/10, Loss: 0.0718\n",
      "Epoch 8/10, Loss: 0.0715\n",
      "Epoch 9/10, Loss: 0.0709\n",
      "Epoch 10/10, Loss: 0.0702\n",
      "for action a probs tensor([0.9325, 0.0675], grad_fn=<SoftmaxBackward0>) max_prob 0.9324735999107361\n",
      "action a probabilité 0.9324735999107361 valance -1 outcome x\n",
      "action a probabilité 0.0675264522433281 valance 1 outcome y\n",
      "for action b probs tensor([0.9325, 0.0675], grad_fn=<SoftmaxBackward0>) max_prob 0.9324735999107361\n",
      "action b probabilité 0.9324735999107361 valance -1 outcome x\n",
      "action b probabilité 0.0675264522433281 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 68 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.0694\n",
      "Epoch 2/10, Loss: 0.0686\n",
      "Epoch 3/10, Loss: 0.0677\n",
      "Epoch 4/10, Loss: 0.0668\n",
      "Epoch 5/10, Loss: 0.0659\n",
      "Epoch 6/10, Loss: 0.0650\n",
      "Epoch 7/10, Loss: 0.0641\n",
      "Epoch 8/10, Loss: 0.0634\n",
      "Epoch 9/10, Loss: 0.0626\n",
      "Epoch 10/10, Loss: 0.0618\n",
      "for action a probs tensor([0.9403, 0.0597], grad_fn=<SoftmaxBackward0>) max_prob 0.9403072595596313\n",
      "action a probabilité 0.9403072595596313 valance -1 outcome x\n",
      "action a probabilité 0.05969269201159477 valance 1 outcome y\n",
      "for action b probs tensor([0.9403, 0.0597], grad_fn=<SoftmaxBackward0>) max_prob 0.9403072595596313\n",
      "action b probabilité 0.9403072595596313 valance -1 outcome x\n",
      "action b probabilité 0.05969269201159477 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 69 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.0611\n",
      "Epoch 2/10, Loss: 0.0604\n",
      "Epoch 3/10, Loss: 0.0598\n",
      "Epoch 4/10, Loss: 0.0591\n",
      "Epoch 5/10, Loss: 0.0585\n",
      "Epoch 6/10, Loss: 0.6220\n",
      "Epoch 7/10, Loss: 0.0578\n",
      "Epoch 8/10, Loss: 0.0576\n",
      "Epoch 9/10, Loss: 0.0574\n",
      "Epoch 10/10, Loss: 0.0570\n",
      "for action a probs tensor([0.9447, 0.0553], grad_fn=<SoftmaxBackward0>) max_prob 0.9447128772735596\n",
      "action a probabilité 0.9447128772735596 valance -1 outcome x\n",
      "action a probabilité 0.05528709664940834 valance 1 outcome y\n",
      "for action b probs tensor([0.9447, 0.0553], grad_fn=<SoftmaxBackward0>) max_prob 0.9447128772735596\n",
      "action b probabilité 0.9447128772735596 valance -1 outcome x\n",
      "action b probabilité 0.05528709664940834 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 70 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.5305\n",
      "Epoch 2/10, Loss: 0.0567\n",
      "Epoch 3/10, Loss: 0.0566\n",
      "Epoch 4/10, Loss: 0.0565\n",
      "Epoch 5/10, Loss: 0.5314\n",
      "Epoch 6/10, Loss: 0.0563\n",
      "Epoch 7/10, Loss: 0.5313\n",
      "Epoch 8/10, Loss: 0.0565\n",
      "Epoch 9/10, Loss: 0.0566\n",
      "Epoch 10/10, Loss: 0.0565\n",
      "for action a probs tensor([0.9451, 0.0549], grad_fn=<SoftmaxBackward0>) max_prob 0.9450889825820923\n",
      "action a probabilité 0.9450889825820923 valance -1 outcome x\n",
      "action a probabilité 0.05491095036268234 valance 1 outcome y\n",
      "for action b probs tensor([0.9451, 0.0549], grad_fn=<SoftmaxBackward0>) max_prob 0.9450889825820923\n",
      "action b probabilité 0.9450889825820923 valance -1 outcome x\n",
      "action b probabilité 0.05491095036268234 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 71 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.0564\n",
      "Epoch 2/10, Loss: 0.0561\n",
      "Epoch 3/10, Loss: 0.4641\n",
      "Epoch 4/10, Loss: 0.0558\n",
      "Epoch 5/10, Loss: 0.4644\n",
      "Epoch 6/10, Loss: 0.0558\n",
      "Epoch 7/10, Loss: 0.4641\n",
      "Epoch 8/10, Loss: 0.0561\n",
      "Epoch 9/10, Loss: 0.0562\n",
      "Epoch 10/10, Loss: 0.4637\n",
      "for action a probs tensor([0.9455, 0.0545], grad_fn=<SoftmaxBackward0>) max_prob 0.9454771280288696\n",
      "action a probabilité 0.9454771280288696 valance -1 outcome x\n",
      "action a probabilité 0.0545228011906147 valance 1 outcome y\n",
      "for action b probs tensor([0.9455, 0.0545], grad_fn=<SoftmaxBackward0>) max_prob 0.9454771280288696\n",
      "action b probabilité 0.9454771280288696 valance -1 outcome x\n",
      "action b probabilité 0.0545228011906147 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 72 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.0561\n",
      "Epoch 2/10, Loss: 0.0562\n",
      "Epoch 3/10, Loss: 0.0561\n",
      "Epoch 4/10, Loss: 0.0558\n",
      "Epoch 5/10, Loss: 0.0555\n",
      "Epoch 6/10, Loss: 0.0552\n",
      "Epoch 7/10, Loss: 0.4143\n",
      "Epoch 8/10, Loss: 0.0548\n",
      "Epoch 9/10, Loss: 0.0547\n",
      "Epoch 10/10, Loss: 0.4149\n",
      "for action a probs tensor([0.9470, 0.0530], grad_fn=<SoftmaxBackward0>) max_prob 0.9470202922821045\n",
      "action a probabilité 0.9470202922821045 valance -1 outcome x\n",
      "action a probabilité 0.0529797300696373 valance 1 outcome y\n",
      "for action b probs tensor([0.9470, 0.0530], grad_fn=<SoftmaxBackward0>) max_prob 0.9470202922821045\n",
      "action b probabilité 0.9470202922821045 valance -1 outcome x\n",
      "action b probabilité 0.0529797300696373 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 73 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.3748\n",
      "Epoch 2/10, Loss: 0.0547\n",
      "Epoch 3/10, Loss: 0.0547\n",
      "Epoch 4/10, Loss: 0.0546\n",
      "Epoch 5/10, Loss: 0.3749\n",
      "Epoch 6/10, Loss: 0.0544\n",
      "Epoch 7/10, Loss: 0.0543\n",
      "Epoch 8/10, Loss: 0.3751\n",
      "Epoch 9/10, Loss: 0.0541\n",
      "Epoch 10/10, Loss: 0.3753\n",
      "for action a probs tensor([0.9474, 0.0526], grad_fn=<SoftmaxBackward0>) max_prob 0.9473870396614075\n",
      "action a probabilité 0.9473870396614075 valance -1 outcome x\n",
      "action a probabilité 0.0526130385696888 valance 1 outcome y\n",
      "for action b probs tensor([0.9474, 0.0526], grad_fn=<SoftmaxBackward0>) max_prob 0.9473870396614075\n",
      "action b probabilité 0.9473870396614075 valance -1 outcome x\n",
      "action b probabilité 0.0526130385696888 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 74 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.3431\n",
      "Epoch 2/10, Loss: 0.6317\n",
      "Epoch 3/10, Loss: 0.0548\n",
      "Epoch 4/10, Loss: 0.0550\n",
      "Epoch 5/10, Loss: 0.3422\n",
      "Epoch 6/10, Loss: 0.0552\n",
      "Epoch 7/10, Loss: 0.3421\n",
      "Epoch 8/10, Loss: 0.0553\n",
      "Epoch 9/10, Loss: 0.3421\n",
      "Epoch 10/10, Loss: 0.3420\n",
      "for action a probs tensor([0.9461, 0.0539], grad_fn=<SoftmaxBackward0>) max_prob 0.9461283683776855\n",
      "action a probabilité 0.9461283683776855 valance -1 outcome x\n",
      "action a probabilité 0.05387156084179878 valance 1 outcome y\n",
      "for action b probs tensor([0.9461, 0.0539], grad_fn=<SoftmaxBackward0>) max_prob 0.9461283683776855\n",
      "action b probabilité 0.9461283683776855 valance -1 outcome x\n",
      "action b probabilité 0.05387156084179878 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 75 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.3158\n",
      "Epoch 2/10, Loss: 0.3157\n",
      "Epoch 3/10, Loss: 0.0559\n",
      "Epoch 4/10, Loss: 0.0559\n",
      "Epoch 5/10, Loss: 0.3156\n",
      "Epoch 6/10, Loss: 0.0559\n",
      "Epoch 7/10, Loss: 0.0558\n",
      "Epoch 8/10, Loss: 0.5761\n",
      "Epoch 9/10, Loss: 0.0557\n",
      "Epoch 10/10, Loss: 0.3158\n",
      "for action a probs tensor([0.9459, 0.0541], grad_fn=<SoftmaxBackward0>) max_prob 0.945935070514679\n",
      "action a probabilité 0.945935070514679 valance -1 outcome x\n",
      "action a probabilité 0.05406493693590164 valance 1 outcome y\n",
      "for action b probs tensor([0.9459, 0.0541], grad_fn=<SoftmaxBackward0>) max_prob 0.945935070514679\n",
      "action b probabilité 0.945935070514679 valance -1 outcome x\n",
      "action b probabilité 0.05406493693590164 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 76 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.2941\n",
      "Epoch 2/10, Loss: 0.2940\n",
      "Epoch 3/10, Loss: 0.0559\n",
      "Epoch 4/10, Loss: 0.5321\n",
      "Epoch 5/10, Loss: 0.0561\n",
      "Epoch 6/10, Loss: 0.2938\n",
      "Epoch 7/10, Loss: 0.5317\n",
      "Epoch 8/10, Loss: 0.5313\n",
      "Epoch 9/10, Loss: 0.2935\n",
      "Epoch 10/10, Loss: 0.5298\n",
      "for action a probs tensor([0.9444, 0.0556], grad_fn=<SoftmaxBackward0>) max_prob 0.944446861743927\n",
      "action a probabilité 0.944446861743927 valance -1 outcome x\n",
      "action a probabilité 0.05555318295955658 valance 1 outcome y\n",
      "for action b probs tensor([0.9444, 0.0556], grad_fn=<SoftmaxBackward0>) max_prob 0.944446861743927\n",
      "action b probabilité 0.944446861743927 valance -1 outcome x\n",
      "action b probabilité 0.05555318295955658 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 77 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.2750\n",
      "Epoch 2/10, Loss: 0.0579\n",
      "Epoch 3/10, Loss: 0.0581\n",
      "Epoch 4/10, Loss: 0.0581\n",
      "Epoch 5/10, Loss: 0.2748\n",
      "Epoch 6/10, Loss: 0.4921\n",
      "Epoch 7/10, Loss: 0.0578\n",
      "Epoch 8/10, Loss: 0.2749\n",
      "Epoch 9/10, Loss: 0.0577\n",
      "Epoch 10/10, Loss: 0.0575\n",
      "for action a probs tensor([0.9443, 0.0557], grad_fn=<SoftmaxBackward0>) max_prob 0.9442500472068787\n",
      "action a probabilité 0.9442500472068787 valance -1 outcome x\n",
      "action a probabilité 0.05574992299079895 valance 1 outcome y\n",
      "for action b probs tensor([0.9443, 0.0557], grad_fn=<SoftmaxBackward0>) max_prob 0.9442500472068787\n",
      "action b probabilité 0.9442500472068787 valance -1 outcome x\n",
      "action b probabilité 0.05574992299079895 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 78 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.2595\n",
      "Epoch 2/10, Loss: 0.0569\n",
      "Epoch 3/10, Loss: 0.0565\n",
      "Epoch 4/10, Loss: 0.0562\n",
      "Epoch 5/10, Loss: 0.2599\n",
      "Epoch 6/10, Loss: 0.0555\n",
      "Epoch 7/10, Loss: 0.0552\n",
      "Epoch 8/10, Loss: 0.0549\n",
      "Epoch 9/10, Loss: 0.2604\n",
      "Epoch 10/10, Loss: 0.4668\n",
      "for action a probs tensor([0.9473, 0.0527], grad_fn=<SoftmaxBackward0>) max_prob 0.947252631187439\n",
      "action a probabilité 0.947252631187439 valance -1 outcome x\n",
      "action a probabilité 0.05274737998843193 valance 1 outcome y\n",
      "for action b probs tensor([0.9473, 0.0527], grad_fn=<SoftmaxBackward0>) max_prob 0.947252631187439\n",
      "action b probabilité 0.947252631187439 valance -1 outcome x\n",
      "action b probabilité 0.05274737998843193 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 79 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.0542\n",
      "Epoch 2/10, Loss: 0.2468\n",
      "Epoch 3/10, Loss: 0.0539\n",
      "Epoch 4/10, Loss: 0.2468\n",
      "Epoch 5/10, Loss: 0.0536\n",
      "Epoch 6/10, Loss: 0.0535\n",
      "Epoch 7/10, Loss: 0.2470\n",
      "Epoch 8/10, Loss: 0.2471\n",
      "Epoch 9/10, Loss: 0.0530\n",
      "Epoch 10/10, Loss: 0.2471\n",
      "for action a probs tensor([0.9486, 0.0514], grad_fn=<SoftmaxBackward0>) max_prob 0.9485831260681152\n",
      "action a probabilité 0.9485831260681152 valance -1 outcome x\n",
      "action a probabilité 0.05141688138246536 valance 1 outcome y\n",
      "for action b probs tensor([0.9486, 0.0514], grad_fn=<SoftmaxBackward0>) max_prob 0.9485831260681152\n",
      "action b probabilité 0.9485831260681152 valance -1 outcome x\n",
      "action b probabilité 0.05141688138246536 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 80 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.0527\n",
      "Epoch 2/10, Loss: 0.2350\n",
      "Epoch 3/10, Loss: 0.0525\n",
      "Epoch 4/10, Loss: 0.2351\n",
      "Epoch 5/10, Loss: 0.0521\n",
      "Epoch 6/10, Loss: 0.2352\n",
      "Epoch 7/10, Loss: 0.4187\n",
      "Epoch 8/10, Loss: 0.2352\n",
      "Epoch 9/10, Loss: 0.4187\n",
      "Epoch 10/10, Loss: 0.2352\n",
      "for action a probs tensor([0.9493, 0.0507], grad_fn=<SoftmaxBackward0>) max_prob 0.9492919445037842\n",
      "action a probabilité 0.9492919445037842 valance -1 outcome x\n",
      "action a probabilité 0.0507081001996994 valance 1 outcome y\n",
      "for action b probs tensor([0.9493, 0.0507], grad_fn=<SoftmaxBackward0>) max_prob 0.9492919445037842\n",
      "action b probabilité 0.9492919445037842 valance -1 outcome x\n",
      "action b probabilité 0.0507081001996994 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 81 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.2244\n",
      "Epoch 2/10, Loss: 0.0523\n",
      "Epoch 3/10, Loss: 0.2243\n",
      "Epoch 4/10, Loss: 0.0523\n",
      "Epoch 5/10, Loss: 0.2243\n",
      "Epoch 6/10, Loss: 0.2244\n",
      "Epoch 7/10, Loss: 0.2244\n",
      "Epoch 8/10, Loss: 0.0520\n",
      "Epoch 9/10, Loss: 0.2244\n",
      "Epoch 10/10, Loss: 0.0519\n",
      "for action a probs tensor([0.9495, 0.0505], grad_fn=<SoftmaxBackward0>) max_prob 0.9495302438735962\n",
      "action a probabilité 0.9495302438735962 valance -1 outcome x\n",
      "action a probabilité 0.05046970397233963 valance 1 outcome y\n",
      "for action b probs tensor([0.9495, 0.0505], grad_fn=<SoftmaxBackward0>) max_prob 0.9495302438735962\n",
      "action b probabilité 0.9495302438735962 valance -1 outcome x\n",
      "action b probabilité 0.05046970397233963 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 82 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.2148\n",
      "Epoch 2/10, Loss: 0.3782\n",
      "Epoch 3/10, Loss: 0.3783\n",
      "Epoch 4/10, Loss: 0.2148\n",
      "Epoch 5/10, Loss: 0.2148\n",
      "Epoch 6/10, Loss: 0.0517\n",
      "Epoch 7/10, Loss: 0.0516\n",
      "Epoch 8/10, Loss: 0.2148\n",
      "Epoch 9/10, Loss: 0.2149\n",
      "Epoch 10/10, Loss: 0.3785\n",
      "for action a probs tensor([0.9500, 0.0500], grad_fn=<SoftmaxBackward0>) max_prob 0.9500234127044678\n",
      "action a probabilité 0.9500234127044678 valance -1 outcome x\n",
      "action a probabilité 0.049976564943790436 valance 1 outcome y\n",
      "for action b probs tensor([0.9500, 0.0500], grad_fn=<SoftmaxBackward0>) max_prob 0.9500234127044678\n",
      "action b probabilité 0.9500234127044678 valance -1 outcome x\n",
      "action b probabilité 0.049976564943790436 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 83 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.2063\n",
      "Epoch 2/10, Loss: 0.3613\n",
      "Epoch 3/10, Loss: 0.2063\n",
      "Epoch 4/10, Loss: 0.0514\n",
      "Epoch 5/10, Loss: 0.0514\n",
      "Epoch 6/10, Loss: 0.0514\n",
      "Epoch 7/10, Loss: 0.0512\n",
      "Epoch 8/10, Loss: 0.0509\n",
      "Epoch 9/10, Loss: 0.2063\n",
      "Epoch 10/10, Loss: 0.0505\n",
      "for action a probs tensor([0.9508, 0.0492], grad_fn=<SoftmaxBackward0>) max_prob 0.9508321285247803\n",
      "action a probabilité 0.9508321285247803 valance -1 outcome x\n",
      "action a probabilité 0.04916787147521973 valance 1 outcome y\n",
      "for action b probs tensor([0.9508, 0.0492], grad_fn=<SoftmaxBackward0>) max_prob 0.9508321285247803\n",
      "action b probabilité 0.9508321285247803 valance -1 outcome x\n",
      "action b probabilité 0.04916787147521973 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 84 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.3468\n",
      "Epoch 2/10, Loss: 0.1985\n",
      "Epoch 3/10, Loss: 0.1985\n",
      "Epoch 4/10, Loss: 0.1985\n",
      "Epoch 5/10, Loss: 0.1985\n",
      "Epoch 6/10, Loss: 0.1985\n",
      "Epoch 7/10, Loss: 0.0498\n",
      "Epoch 8/10, Loss: 0.1985\n",
      "Epoch 9/10, Loss: 0.3475\n",
      "Epoch 10/10, Loss: 0.1985\n",
      "for action a probs tensor([0.9516, 0.0484], grad_fn=<SoftmaxBackward0>) max_prob 0.9516410231590271\n",
      "action a probabilité 0.9516410231590271 valance -1 outcome x\n",
      "action a probabilité 0.04835903272032738 valance 1 outcome y\n",
      "for action b probs tensor([0.9516, 0.0484], grad_fn=<SoftmaxBackward0>) max_prob 0.9516410231590271\n",
      "action b probabilité 0.9516410231590271 valance -1 outcome x\n",
      "action b probabilité 0.04835903272032738 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 85 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.0496\n",
      "Epoch 2/10, Loss: 0.1914\n",
      "Epoch 3/10, Loss: 0.1914\n",
      "Epoch 4/10, Loss: 0.3335\n",
      "Epoch 5/10, Loss: 0.1914\n",
      "Epoch 6/10, Loss: 0.1914\n",
      "Epoch 7/10, Loss: 0.0495\n",
      "Epoch 8/10, Loss: 0.1914\n",
      "Epoch 9/10, Loss: 0.1914\n",
      "Epoch 10/10, Loss: 0.3337\n",
      "for action a probs tensor([0.9520, 0.0480], grad_fn=<SoftmaxBackward0>) max_prob 0.9519891142845154\n",
      "action a probabilité 0.9519891142845154 valance -1 outcome x\n",
      "action a probabilité 0.04801090806722641 valance 1 outcome y\n",
      "for action b probs tensor([0.9520, 0.0480], grad_fn=<SoftmaxBackward0>) max_prob 0.9519891142845154\n",
      "action b probabilité 0.9519891142845154 valance -1 outcome x\n",
      "action b probabilité 0.04801090806722641 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 86 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.0492\n",
      "Epoch 2/10, Loss: 0.1850\n",
      "Epoch 3/10, Loss: 0.1850\n",
      "Epoch 4/10, Loss: 0.0491\n",
      "Epoch 5/10, Loss: 0.0490\n",
      "Epoch 6/10, Loss: 0.1850\n",
      "Epoch 7/10, Loss: 0.3212\n",
      "Epoch 8/10, Loss: 0.3213\n",
      "Epoch 9/10, Loss: 0.1850\n",
      "Epoch 10/10, Loss: 0.1850\n",
      "for action a probs tensor([0.9525, 0.0475], grad_fn=<SoftmaxBackward0>) max_prob 0.9525294899940491\n",
      "action a probabilité 0.9525294899940491 valance -1 outcome x\n",
      "action a probabilité 0.047470573335886 valance 1 outcome y\n",
      "for action b probs tensor([0.9525, 0.0475], grad_fn=<SoftmaxBackward0>) max_prob 0.9525294899940491\n",
      "action b probabilité 0.9525294899940491 valance -1 outcome x\n",
      "action b probabilité 0.047470573335886 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 87 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.0487\n",
      "Epoch 2/10, Loss: 0.3095\n",
      "Epoch 3/10, Loss: 0.1790\n",
      "Epoch 4/10, Loss: 0.0485\n",
      "Epoch 5/10, Loss: 0.1790\n",
      "Epoch 6/10, Loss: 0.0484\n",
      "Epoch 7/10, Loss: 0.1790\n",
      "Epoch 8/10, Loss: 0.3098\n",
      "Epoch 9/10, Loss: 0.0481\n",
      "Epoch 10/10, Loss: 0.1790\n",
      "for action a probs tensor([0.9532, 0.0468], grad_fn=<SoftmaxBackward0>) max_prob 0.9531584978103638\n",
      "action a probabilité 0.9531584978103638 valance -1 outcome x\n",
      "action a probabilité 0.046841464936733246 valance 1 outcome y\n",
      "for action b probs tensor([0.9532, 0.0468], grad_fn=<SoftmaxBackward0>) max_prob 0.9531584978103638\n",
      "action b probabilité 0.9531584978103638 valance -1 outcome x\n",
      "action b probabilité 0.046841464936733246 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 88 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.1735\n",
      "Epoch 2/10, Loss: 0.0480\n",
      "Epoch 3/10, Loss: 0.1735\n",
      "Epoch 4/10, Loss: 0.2993\n",
      "Epoch 5/10, Loss: 0.1735\n",
      "Epoch 6/10, Loss: 0.2994\n",
      "Epoch 7/10, Loss: 0.2994\n",
      "Epoch 8/10, Loss: 0.1735\n",
      "Epoch 9/10, Loss: 0.0476\n",
      "Epoch 10/10, Loss: 0.2994\n",
      "for action a probs tensor([0.9536, 0.0464], grad_fn=<SoftmaxBackward0>) max_prob 0.9536166191101074\n",
      "action a probabilité 0.9536166191101074 valance -1 outcome x\n",
      "action a probabilité 0.046383343636989594 valance 1 outcome y\n",
      "for action b probs tensor([0.9536, 0.0464], grad_fn=<SoftmaxBackward0>) max_prob 0.9536166191101074\n",
      "action b probabilité 0.9536166191101074 valance -1 outcome x\n",
      "action b probabilité 0.046383343636989594 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 89 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.0476\n",
      "Epoch 2/10, Loss: 0.0476\n",
      "Epoch 3/10, Loss: 0.4105\n",
      "Epoch 4/10, Loss: 0.1684\n",
      "Epoch 5/10, Loss: 0.1684\n",
      "Epoch 6/10, Loss: 0.2896\n",
      "Epoch 7/10, Loss: 0.2896\n",
      "Epoch 8/10, Loss: 0.2896\n",
      "Epoch 9/10, Loss: 0.0474\n",
      "Epoch 10/10, Loss: 0.2895\n",
      "for action a probs tensor([0.9538, 0.0462], grad_fn=<SoftmaxBackward0>) max_prob 0.9538480639457703\n",
      "action a probabilité 0.9538480639457703 valance -1 outcome x\n",
      "action a probabilité 0.046151939779520035 valance 1 outcome y\n",
      "for action b probs tensor([0.9538, 0.0462], grad_fn=<SoftmaxBackward0>) max_prob 0.9538480639457703\n",
      "action b probabilité 0.9538480639457703 valance -1 outcome x\n",
      "action b probabilité 0.046151939779520035 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 90 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.1637\n",
      "Epoch 2/10, Loss: 0.1637\n",
      "Epoch 3/10, Loss: 0.1637\n",
      "Epoch 4/10, Loss: 0.1637\n",
      "Epoch 5/10, Loss: 0.2803\n",
      "Epoch 6/10, Loss: 0.1637\n",
      "Epoch 7/10, Loss: 0.1637\n",
      "Epoch 8/10, Loss: 0.0470\n",
      "Epoch 9/10, Loss: 0.2805\n",
      "Epoch 10/10, Loss: 0.2805\n",
      "for action a probs tensor([0.9543, 0.0457], grad_fn=<SoftmaxBackward0>) max_prob 0.954271674156189\n",
      "action a probabilité 0.954271674156189 valance -1 outcome x\n",
      "action a probabilité 0.045728329569101334 valance 1 outcome y\n",
      "for action b probs tensor([0.9543, 0.0457], grad_fn=<SoftmaxBackward0>) max_prob 0.954271674156189\n",
      "action b probabilité 0.954271674156189 valance -1 outcome x\n",
      "action b probabilité 0.045728329569101334 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 91 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.0469\n",
      "Epoch 2/10, Loss: 0.1593\n",
      "Epoch 3/10, Loss: 0.0468\n",
      "Epoch 4/10, Loss: 0.0467\n",
      "Epoch 5/10, Loss: 0.0467\n",
      "Epoch 6/10, Loss: 0.1593\n",
      "Epoch 7/10, Loss: 0.0465\n",
      "Epoch 8/10, Loss: 0.1592\n",
      "Epoch 9/10, Loss: 0.1592\n",
      "Epoch 10/10, Loss: 0.0461\n",
      "for action a probs tensor([0.9550, 0.0450], grad_fn=<SoftmaxBackward0>) max_prob 0.9549652934074402\n",
      "action a probabilité 0.9549652934074402 valance -1 outcome x\n",
      "action a probabilité 0.04503469169139862 valance 1 outcome y\n",
      "for action b probs tensor([0.9550, 0.0450], grad_fn=<SoftmaxBackward0>) max_prob 0.9549652934074402\n",
      "action b probabilité 0.9549652934074402 valance -1 outcome x\n",
      "action b probabilité 0.04503469169139862 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 92 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.2643\n",
      "Epoch 2/10, Loss: 0.0460\n",
      "Epoch 3/10, Loss: 0.0459\n",
      "Epoch 4/10, Loss: 0.0458\n",
      "Epoch 5/10, Loss: 0.0457\n",
      "Epoch 6/10, Loss: 0.2646\n",
      "Epoch 7/10, Loss: 0.0455\n",
      "Epoch 8/10, Loss: 0.1550\n",
      "Epoch 9/10, Loss: 0.1550\n",
      "Epoch 10/10, Loss: 0.1550\n",
      "for action a probs tensor([0.9559, 0.0441], grad_fn=<SoftmaxBackward0>) max_prob 0.9558596611022949\n",
      "action a probabilité 0.9558596611022949 valance -1 outcome x\n",
      "action a probabilité 0.04414039105176926 valance 1 outcome y\n",
      "for action b probs tensor([0.9559, 0.0441], grad_fn=<SoftmaxBackward0>) max_prob 0.9558596611022949\n",
      "action b probabilité 0.9558596611022949 valance -1 outcome x\n",
      "action b probabilité 0.04414039105176926 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 93 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.2573\n",
      "Epoch 2/10, Loss: 0.2573\n",
      "Epoch 3/10, Loss: 0.1512\n",
      "Epoch 4/10, Loss: 0.0450\n",
      "Epoch 5/10, Loss: 0.1511\n",
      "Epoch 6/10, Loss: 0.1511\n",
      "Epoch 7/10, Loss: 0.1511\n",
      "Epoch 8/10, Loss: 0.2575\n",
      "Epoch 9/10, Loss: 0.1511\n",
      "Epoch 10/10, Loss: 0.1511\n",
      "for action a probs tensor([0.9562, 0.0438], grad_fn=<SoftmaxBackward0>) max_prob 0.9562075734138489\n",
      "action a probabilité 0.9562075734138489 valance -1 outcome x\n",
      "action a probabilité 0.04379250481724739 valance 1 outcome y\n",
      "for action b probs tensor([0.9562, 0.0438], grad_fn=<SoftmaxBackward0>) max_prob 0.9562075734138489\n",
      "action b probabilité 0.9562075734138489 valance -1 outcome x\n",
      "action b probabilité 0.04379250481724739 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 94 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.1476\n",
      "Epoch 2/10, Loss: 0.0448\n",
      "Epoch 3/10, Loss: 0.2504\n",
      "Epoch 4/10, Loss: 0.2505\n",
      "Epoch 5/10, Loss: 0.2505\n",
      "Epoch 6/10, Loss: 0.3537\n",
      "Epoch 7/10, Loss: 0.1475\n",
      "Epoch 8/10, Loss: 0.2506\n",
      "Epoch 9/10, Loss: 0.2506\n",
      "Epoch 10/10, Loss: 0.2506\n",
      "for action a probs tensor([0.9567, 0.0433], grad_fn=<SoftmaxBackward0>) max_prob 0.9566757082939148\n",
      "action a probabilité 0.9566757082939148 valance -1 outcome x\n",
      "action a probabilité 0.04332427680492401 valance 1 outcome y\n",
      "for action b probs tensor([0.9567, 0.0433], grad_fn=<SoftmaxBackward0>) max_prob 0.9566757082939148\n",
      "action b probabilité 0.9566757082939148 valance -1 outcome x\n",
      "action b probabilité 0.04332427680492401 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 95 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.3439\n",
      "Epoch 2/10, Loss: 0.0443\n",
      "Epoch 3/10, Loss: 0.1441\n",
      "Epoch 4/10, Loss: 0.0443\n",
      "Epoch 5/10, Loss: 0.2440\n",
      "Epoch 6/10, Loss: 0.0443\n",
      "Epoch 7/10, Loss: 0.4441\n",
      "Epoch 8/10, Loss: 0.1441\n",
      "Epoch 9/10, Loss: 0.0441\n",
      "Epoch 10/10, Loss: 0.2441\n",
      "for action a probs tensor([0.9569, 0.0431], grad_fn=<SoftmaxBackward0>) max_prob 0.9569246172904968\n",
      "action a probabilité 0.9569246172904968 valance -1 outcome x\n",
      "action a probabilité 0.043075356632471085 valance 1 outcome y\n",
      "for action b probs tensor([0.9569, 0.0431], grad_fn=<SoftmaxBackward0>) max_prob 0.9569246172904968\n",
      "action b probabilité 0.9569246172904968 valance -1 outcome x\n",
      "action b probabilité 0.043075356632471085 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 96 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.3349\n",
      "Epoch 2/10, Loss: 0.1409\n",
      "Epoch 3/10, Loss: 0.2379\n",
      "Epoch 4/10, Loss: 0.0439\n",
      "Epoch 5/10, Loss: 0.1409\n",
      "Epoch 6/10, Loss: 0.1409\n",
      "Epoch 7/10, Loss: 0.2379\n",
      "Epoch 8/10, Loss: 0.2380\n",
      "Epoch 9/10, Loss: 0.3353\n",
      "Epoch 10/10, Loss: 0.1408\n",
      "for action a probs tensor([0.9574, 0.0426], grad_fn=<SoftmaxBackward0>) max_prob 0.9573728442192078\n",
      "action a probabilité 0.9573728442192078 valance -1 outcome x\n",
      "action a probabilité 0.042627111077308655 valance 1 outcome y\n",
      "for action b probs tensor([0.9574, 0.0426], grad_fn=<SoftmaxBackward0>) max_prob 0.9573728442192078\n",
      "action b probabilité 0.9573728442192078 valance -1 outcome x\n",
      "action b probabilité 0.042627111077308655 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 97 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.0434\n",
      "Epoch 2/10, Loss: 0.0432\n",
      "Epoch 3/10, Loss: 0.0429\n",
      "Epoch 4/10, Loss: 0.0425\n",
      "Epoch 5/10, Loss: 0.0420\n",
      "Epoch 6/10, Loss: 0.0415\n",
      "Epoch 7/10, Loss: 0.0412\n",
      "Epoch 8/10, Loss: 0.0407\n",
      "Epoch 9/10, Loss: 0.0404\n",
      "Epoch 10/10, Loss: 0.0399\n",
      "for action a probs tensor([0.9611, 0.0389], grad_fn=<SoftmaxBackward0>) max_prob 0.9610557556152344\n",
      "action a probabilité 0.9610557556152344 valance -1 outcome x\n",
      "action a probabilité 0.03894418105483055 valance 1 outcome y\n",
      "for action b probs tensor([0.9611, 0.0389], grad_fn=<SoftmaxBackward0>) max_prob 0.9610557556152344\n",
      "action b probabilité 0.9610557556152344 valance -1 outcome x\n",
      "action b probabilité 0.03894418105483055 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 98 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.0395\n",
      "Epoch 2/10, Loss: 0.0391\n",
      "Epoch 3/10, Loss: 0.0388\n",
      "Epoch 4/10, Loss: 0.0383\n",
      "Epoch 5/10, Loss: 0.0380\n",
      "Epoch 6/10, Loss: 0.0377\n",
      "Epoch 7/10, Loss: 0.0375\n",
      "Epoch 8/10, Loss: 0.0372\n",
      "Epoch 9/10, Loss: 0.0369\n",
      "Epoch 10/10, Loss: 0.0365\n",
      "for action a probs tensor([0.9642, 0.0358], grad_fn=<SoftmaxBackward0>) max_prob 0.9641927480697632\n",
      "action a probabilité 0.9641927480697632 valance -1 outcome x\n",
      "action a probabilité 0.0358072929084301 valance 1 outcome y\n",
      "for action b probs tensor([0.9642, 0.0358], grad_fn=<SoftmaxBackward0>) max_prob 0.9641927480697632\n",
      "action b probabilité 0.9641927480697632 valance -1 outcome x\n",
      "action b probabilité 0.0358072929084301 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n",
      "=======================\u001b[0;32m iteration 99 \u001b[0m=======================\n",
      "Action: a, Prediction: x, Outcome: x, \u001b[0;31m Satisfaction: True \u001b[0m\n",
      "je fit sur ['a', 'b', 'a', 'a', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a'] et ['x', 'y', 'y', 'x', 'y', 'y', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']\n",
      "Epoch 1/10, Loss: 0.0363\n",
      "Epoch 2/10, Loss: 0.0361\n",
      "Epoch 3/10, Loss: 0.0358\n",
      "Epoch 4/10, Loss: 0.0356\n",
      "Epoch 5/10, Loss: 0.0355\n",
      "Epoch 6/10, Loss: 1.1442\n",
      "Epoch 7/10, Loss: 1.1363\n",
      "Epoch 8/10, Loss: 0.0381\n",
      "Epoch 9/10, Loss: 0.0393\n",
      "Epoch 10/10, Loss: 0.0400\n",
      "for action a probs tensor([0.9607, 0.0393], grad_fn=<SoftmaxBackward0>) max_prob 0.9607062339782715\n",
      "action a probabilité 0.9607062339782715 valance -1 outcome x\n",
      "action a probabilité 0.03929377719759941 valance 1 outcome y\n",
      "for action b probs tensor([0.9607, 0.0393], grad_fn=<SoftmaxBackward0>) max_prob 0.9607062339782715\n",
      "action b probabilité 0.9607062339782715 valance -1 outcome x\n",
      "action b probabilité 0.03929377719759941 valance 1 outcome y\n",
      "action a predi x outcome x\n",
      "Action choisie : a \u001b[0;34m100 \u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env_test2 = env3Str()\n",
    "\n",
    "model_ML = DeepNetwork(hidden_size=[10, 5], input_size=1, output_size=2)\n",
    "optimizer = torch.optim.Adam(model_ML.parameters(), lr=1e-2, weight_decay=1e-4)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "tokenizer = SimpleTokenizerV1(create_dico_numerate_word(env_test2.get_outcomes() + env_test2.get_actions()))\n",
    "\n",
    "valence = {\n",
    "    inter('a', 'x') : -1,\n",
    "    inter('a', 'y') : 1,\n",
    "    inter('b', 'x') : -1,\n",
    "    inter('b', 'y') : 1\n",
    "}\n",
    "agent_test2 = Agent2DecideWithProbFit(\n",
    "    model=model_ML,\n",
    "    all_outcomes= env_test2.get_outcomes(),\n",
    "    all_actions= env_test2.get_actions(),\n",
    "    valance=valence,\n",
    "    tokenizer=tokenizer,\n",
    "    optimizer=optimizer,\n",
    "    loss_func=loss_func)\n",
    "\n",
    "history_good = []\n",
    "pourcent_by_10 = []\n",
    "outcome = None\n",
    "for i in range(100):\n",
    "    print(f\"=======================\\033[0;32m iteration {i} \\033[0m=======================\")\n",
    "    action, predi = agent_test2.action(outcome, False)\n",
    "    outcome = env_test2.outcome(action)\n",
    "    history_good.append(outcome == predi)\n",
    "    pourcent_by_10.append(sum(history_good[-10:]) * 10 if len(history_good) >= 10 else 0)\n",
    "    print(f'action {action} predi {predi} outcome {outcome}')\n",
    "    print(f\"Action choisie : {action} \\033[0;34m{pourcent_by_10[-1]} \\033[0m\")\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Stage (torch)",
   "language": "python",
   "name": "dpt_transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
