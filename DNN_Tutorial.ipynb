{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83329c47-b6b8-4720-a992-b1fd3eb7013f",
   "metadata": {},
   "source": [
    "# On crée le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f69bfbe4-f786-493b-862a-1eaed8541971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liste hidden init [10, 5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeepNetwork(\n",
       "  (fc1): Linear(in_features=1, out_features=10, bias=True)\n",
       "  (hidden_layers): ModuleList(\n",
       "    (0): Linear(in_features=10, out_features=5, bias=True)\n",
       "  )\n",
       "  (fc4): Linear(in_features=5, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importe le modèle préparé par PE\n",
    "from model.deepNN import DeepNetwork\n",
    "\n",
    "# Première couche cachée: 10 neurones \n",
    "# Deuxième couche cachée: 5 neurones\n",
    "# Entrée: 1 action \n",
    "# Sortie: 2 probabilités de chaque outcome\n",
    "model_ML = DeepNetwork(hidden_size=[10, 5], input_size=1, output_size=2)\n",
    "model_ML.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c707067c-d678-4ecf-b48b-5f6133ef065c",
   "metadata": {},
   "source": [
    "# On tokenize le vocabulaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "da92a5d3-7726-434f-8b16-620f547b83d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulaire: {'x': 0, 'y': 1, 'a': 2, 'b': 3}\n",
      "Test encode a: 2\n",
      "Test decode l: y\n"
     ]
    }
   ],
   "source": [
    "# Import le tokenizer préparé par PE\n",
    "from model.Tokenizer import SimpleTokenizerV1\n",
    "from outil import create_dico_numerate_word\n",
    "\n",
    "# Notre vocabulaire:\n",
    "all_word = create_dico_numerate_word(['x', 'y', 'a', 'b'])\n",
    "# Voici all_word : {'x': 0, 'y': 1, 'a': 2, 'b': 3}\n",
    "print(\"Vocabulaire:\", all_word)\n",
    "# Nous n'avons pas besoin d'un tokenzier complexe, \n",
    "# il va avoir le même rôle qu'un dictionnaire\n",
    "tokenizer = SimpleTokenizerV1(all_word)\n",
    "# Maintenant pour encoder une action ou un outcome nous pouvons faire :\n",
    "print('Test encode a:', tokenizer.encode('a'))\n",
    "# et pour decoder :\n",
    "print('Test decode l:', tokenizer.decode(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd17452c-926e-4fc3-ab41-5d34e043a9df",
   "metadata": {},
   "source": [
    "# On définit les paramètres du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37701691-d582-4240-835f-8b60e6330e21",
   "metadata": {},
   "source": [
    "Le `lr` et le `weight_decay` sont des paramètres très importants qui vont permettre de corriger plus ou moins vite le modèle. Une correction rapide est moins précise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1940305a-0382-474b-9bca-91a25c59855a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-1\n",
    "weight_decay = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "58900391-266c-48bb-9fb3-16a33f4af1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe les outils fournis par torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Le modèle a besoin d'un optimizer pour corriger les poids.\n",
    "optimizer = torch.optim.Adam(model_ML.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "# Nous avons aussi besoin d'une fonction de loss, par exemple la CrossEntropy\n",
    "# Au vue de la simplicité de prédiction le type de loss importe peu\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53930b3d-0811-414f-a4e0-c77cd94d3e06",
   "metadata": {},
   "source": [
    "# On crée un dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724ccdb2-be1e-4519-aa02-e0359b3d6c64",
   "metadata": {},
   "source": [
    "l'action `a` renvoie l'outcome `x`. L'action `b` renvoie l'outcome `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f7e5cda3-76f4-4d4c-a872-fc32ed2e2a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (tokenized actions):\n",
      " tensor([[2.],\n",
      "        [3.]])\n",
      "y (tokenized outcomes):\n",
      " tensor([0, 1])\n"
     ]
    }
   ],
   "source": [
    "tokenized_actions = [[tokenizer.encode('a')], [tokenizer.encode('b')]]\n",
    "tokenized_outomes = [tokenizer.encode('x'), tokenizer.encode('y')]\n",
    "\n",
    "# Convertit en tensors pour torch\n",
    "x = torch.tensor(tokenized_actions, dtype=torch.float).to(\"cpu\")\n",
    "y = torch.tensor(tokenized_outomes, dtype=torch.long).to(\"cpu\")\n",
    "\n",
    "# Notre dataset de test :\n",
    "print(\"x (tokenized actions):\\n\", x)\n",
    "print(\"y (tokenized outcomes):\\n\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467e9ffd-762d-4bb3-aae5-268ca31d8591",
   "metadata": {},
   "source": [
    "On crée un loader pour charger le dataset dans le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7ac5d80-dbe0-427a-ac34-aa210db003bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous utilisons un dataLoader de pytorch\n",
    "# Le batch_size n'a pas d'importance de même que le shuffle\n",
    "validate_loader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(x, y),\n",
    "    batch_size=32, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d85910-fff9-4116-8599-ad4618a25e76",
   "metadata": {},
   "source": [
    "# La fonction fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "131e5434-95e4-4573-a5a2-3c914400589e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(action, outcome):\n",
    "    action = tokenizer.encode(action)\n",
    "    action = torch.tensor([action], dtype=torch.float).to(\"cpu\")\n",
    "    outcome = tokenizer.encode(outcome)\n",
    "    outcome = torch.tensor(outcome, dtype=torch.long).to(\"cpu\")\n",
    "    outcome = torch.nn.functional.one_hot(outcome, num_classes=2).to(torch.float)\n",
    "    # Qu'est ce que ca fait ?\n",
    "    model_ML.train()\n",
    "\n",
    "    train(model=model_ML, \n",
    "          train_data=[(action, outcome)],\n",
    "          optimizer=optimizer,\n",
    "          loss_func=loss_func,\n",
    "          nb_epochs=1,\n",
    "          validate_loader=validate_loader,\n",
    "          print_=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "bb2b1cba-e7df-4f26-9505-dd2557745d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1,\u001b[0;34m 0.5 \u001b[0m, Loss: 0.6984\n",
      "Epoch 1/1,\u001b[0;34m 0.5 \u001b[0m, Loss: 0.6932\n"
     ]
    }
   ],
   "source": [
    "fit('a', 'x')\n",
    "fit('b', 'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd572606-93cc-4884-873c-2a2e30c0ac23",
   "metadata": {},
   "source": [
    "# La fonction predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d6ed6716-ca40-4b83-b228-7ce22ede7b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(action):\n",
    "    action = tokenizer.encode(action)\n",
    "    action = torch.tensor([action], dtype=torch.float).to(\"cpu\")\n",
    "    model_ML.eval() # On peut le passer en mode evaluation\n",
    "    x = model_ML(action)\n",
    "    print(x)\n",
    "    x = torch.argmax(x, dim=0).item()\n",
    "    return tokenizer.decode(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "4f74ccc7-8e87-4006-b574-ff633f8125ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2534, 0.2635], grad_fn=<ViewBackward0>)\n",
      "Predication pour a: y\n",
      "tensor([0.2534, 0.2635], grad_fn=<ViewBackward0>)\n",
      "Predication pour b: y\n"
     ]
    }
   ],
   "source": [
    "predicted_outcome = predict('a')\n",
    "print(\"Predication pour a:\", predicted_outcome)\n",
    "predicted_outcome = predict('b')\n",
    "print(\"Predication pour b:\", predicted_outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b52228-6bb1-44dd-8094-ca0dcebf8f03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
