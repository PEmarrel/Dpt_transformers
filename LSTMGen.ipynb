{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torch.distributions import Categorical\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from model.CustomDataSet import CustomDataSetRNN\n",
    "from model.Tokenizer import SimpleTokenizerV1\n",
    "from environnement.environnement1Str import Environnement1\n",
    "from environnement.environnement3Str import Environnement3\n",
    "from environnement.environnement6Str import Environnement6\n",
    "from environnement.small_loop import small_loop\n",
    "from environnement.gridWorld import gridWorld\n",
    "from model.RNN import LSTM_GenText\n",
    "from inter.simpleInteraction import simpleInteraction as inter\n",
    "\n",
    "from outil import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environement\n",
    "Nous prennons un environnement pour obtenir les tokens que nous voulons générer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_test = gridWorld(x= 1, y=1, theta=0, world= np.array([\n",
    "                [1, 1, 1, 1, 1, 1],\n",
    "                [1, 0, 0, 0, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 1],\n",
    "                [1, 1, 1, 1, 1, 1],\n",
    "            ]))\n",
    "actions, outcomes = [], []\n",
    "env_test.display_world()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Liste vocab\n",
    "Nous pouvons maintenant définir notre liste de vocabulaire et notre tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_vocab = ['<pad>']\n",
    "# Nous notons toutes les interactions techniquement possible\n",
    "for act in env_test.get_actions():\n",
    "    for fb in env_test.get_outcomes():\n",
    "        list_vocab.append((act, fb))\n",
    "\n",
    "# Nous pouvons suprimer des interactions qui ne sont en réalité pas possible.\n",
    "list_vocab.remove(('turn_left', 'wall'))\n",
    "list_vocab.remove(('turn_right', 'wall'))\n",
    "for element in list_vocab:\n",
    "    print(element)\n",
    "    \n",
    "tmp = create_dico_numerate_word(list_vocab)\n",
    "print(tmp)\n",
    "tokenizer = SimpleTokenizerV1(vocab=tmp)\n",
    "# Test tokenizer\n",
    "# print(tokenizer.encode((\"forward\", \"empty\")))\n",
    "# print(tokenizer.encode(\"<pad>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Génération de texte\n",
    "## Entrainement ?\n",
    "\n",
    "Dans notre cas nous n'avons pas de données au début, l'agent n'a pas encore intéragit avec son environement. Donc nous n'avons pas de train possible.\n",
    "\n",
    "## Prompt\n",
    "Mais pour que le LSTM génére du texte il nous faut un prompt. Pour se faire nous avons plusieurs possiblité, soit nous appliquons une action de base (Ce qui est fait pour les agents précédent) soit nous lui donnons le token \\<pad\\>. Vue que le modèl n'est pas entrainner cela n'a pas d'importence. \n",
    "\n",
    "\n",
    "A noter que si plus tard nous lui donnons un entrainement qui utilise \\<pad\\> Alors il n'est plus pertinent d'utiliser cette balise comme cela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mots que l'on veut prompt (ca doit être une liste)\n",
    "input_tokens = tokenizer.encode([\"<pad>\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "Nous pouvons maintenant definir le modèl, nous prennons une configuration de base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "torch.manual_seed(1)\n",
    "num_layers = 2\n",
    "hidden_size = 128\n",
    "temp = 1.0\n",
    "lstm_generator = LSTM_GenText(\n",
    "    num_emb=len(list_vocab),\n",
    "    hidden_size=hidden_size,\n",
    "    emb_size=hidden_size,\n",
    "    num_layers=num_layers,\n",
    "    dropout=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Génération\n",
    "## Première génération\n",
    "Nous passons au modèle le prompt et nous voulons qu'il génere une phrase. Notre objectif est d'atteindre l'interaction ('forward', 'Empty'). Dans ce cas il suffit d'arreter la phrase à ce moment.\n",
    "\n",
    "## FONCTION DE GÉNERATION 1ER VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(lstm_generator:nn.Module, input_tokens, tokenizer:SimpleTokenizerV1, temp:int=1.0, max_len:int=50, end_token:int|None=2):\n",
    "    lstm_generator.eval()\n",
    "    log_tokens = []\n",
    "    \n",
    "    interactions = []\n",
    "    probability = {}\n",
    "    for i in range(tokenizer.size_vocab):\n",
    "        probability[tokenizer.decode(i)] = []\n",
    "    \n",
    "    # Disable gradient calculation\n",
    "    with torch.no_grad():\n",
    "        # Initialize hidden and memory states\n",
    "        hidden = torch.zeros(lstm_generator.num_layers, 1, lstm_generator.hidden_size)\n",
    "        memory = torch.zeros(lstm_generator.num_layers, 1, lstm_generator.hidden_size)\n",
    "\n",
    "        # Generate text\n",
    "        for i in range(max_len): # On met une limite de 100 tokens\n",
    "            # Forward pass through LSTM generator\n",
    "            data_pred, hidden, memory = lstm_generator(input_tokens, hidden, memory)\n",
    "\n",
    "            # Sample from the distribution of probabilities (with temperature)\n",
    "            dist = Categorical(logits=data_pred[:, -1] / temp)\n",
    "            input_tokens = dist.sample().reshape(1, 1)\n",
    "\n",
    "            # Append generated token to log_tokens\n",
    "            log_tokens.append(input_tokens.cpu())\n",
    "            \n",
    "            interactions.append(tokenizer.decode(input_tokens.item()))            \n",
    "            proba_tmp = F.softmax(data_pred/temp, -1).cpu().numpy().flatten()\n",
    "            for i in range(tokenizer.size_vocab):\n",
    "                probability[tokenizer.decode(i)].append(round(float(proba_tmp[i]), 3))\n",
    "\n",
    "            # Check for end-of-sentence token\n",
    "            if input_tokens.item() == end_token: # Si le token est ('forward', 'empty') on s'arrête\n",
    "                break\n",
    "    tmp = probability\n",
    "    tmp.update({'interactions choisies': interactions})\n",
    "    df_interactions = pd.DataFrame(tmp)\n",
    "    return log_tokens, data_pred, df_interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "# Nous devons reshape input_tokens pour qu'il soit de la forme (1, -1)\n",
    "# Pour résumer nous ajoutons une dimension pour le batch\n",
    "input_tokens = tokenizer.encode([\"<pad>\"])\n",
    "input_tokens = torch.tensor(input_tokens).reshape(1, -1)\n",
    "print(\"\\033[0;32m le tensor input : \\033[0m\")\n",
    "print(input_tokens)\n",
    "\n",
    "log_tokens, data_pred, df = generate_sentence(lstm_generator, input_tokens, tokenizer=tokenizer)\n",
    "print()\n",
    "print(\"\\033[0;32m les tensor d'output :\\033[0m\")\n",
    "for i in log_tokens:\n",
    "    print(tokenizer.decode(i.item()))\n",
    "print(log_tokens)\n",
    "\n",
    "# La distribution de probabilité\n",
    "# ce qui correspond à la prédiction du modèle pour le prochain token\n",
    "# Cette distribution est calculée avec la fonction softmax et dépand de la température\n",
    "plt.xticks(range(len(list_vocab)), list_vocab, fontsize=8, rotation=60, ha='right')\n",
    "plt.plot(F.softmax(data_pred/temp, -1).cpu().numpy().flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n",
    "Ce que le modèl sort est très variable si nous ne fixons pas la seed. Le modèl propose une distribution corespondant à l'initialisation de ses poids (aléatoirement).\n",
    "## Appliquation de la génération\n",
    "Avec notre premier output nous pouvons demander à notre \"agent\" d'appliquer les actions des tokens pour vérifier si les prédictions sont bonne ou non. \n",
    "De manière évidente en début les prédictions ont que très peu de chance d'être bonne. Ce qui est normal l'agent doit découvrir son environement.\n",
    "## Fonction RUN TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_token(tokens:torch.Tensor, env_to_run:env, path:str|None=None):\n",
    "    \"\"\"Applique toutes les actions des tokens\n",
    "\n",
    "    Args:\n",
    "        token (torch.Tensor): La sortie brut du modèle de prédiction\n",
    "        env (env): L'environnement dans lequel on veut appliquer les actions\n",
    "\n",
    "    Returns:\n",
    "        list: La liste des actions\n",
    "        list: La liste des outcomes\n",
    "    \"\"\"\n",
    "    actions = []\n",
    "    outcomes = []\n",
    "    for tok in tokens:\n",
    "        interaction:tuple|str = tokenizer.decode(tok.item())\n",
    "        if interaction in [\"<pad>\"]: # Liste des tokens qui ne correspondent à aucune action\n",
    "            continue\n",
    "        actions.append(interaction[0]) # On ajoute l'action à la liste\n",
    "        outcomes.append(env_to_run.outcome(actions[-1])) # On récupère l'outcome de l'action\n",
    "        if path is not None:\n",
    "            env_to_run.save_world(path=path)\n",
    "    return actions, outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = log_tokens\n",
    "actions, outcomes = run_token(tokens, env_test)\n",
    "print(\"Les actions tirées de la génération du modèle\")\n",
    "print(actions)\n",
    "print(\"Les outcomes réel de l'environnement\")\n",
    "print(outcomes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "## Jeu de données\n",
    "Pour entrainer le modèle, il nous faut des données. Nous pouvons récupérer les interactions que \"l'agent\" à fait.\n",
    "### Traitement des interactions\n",
    "Nous avons les actions et outcomes, nous devons les transformers en token. Il nous faut une taille de contexte pour que l'entrainement soit fixe (cela améliore les performances). Nous pouvons prendre une grande taille que nous comblerons par des \\<pad\\>\n",
    "\n",
    "#### Transformation en token\n",
    "\n",
    "## Fonction ACTION OUT to TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_outcome_to_token(actions, outcomes):\n",
    "    token = []\n",
    "    for i in range(len(actions)):\n",
    "        token.append(tokenizer.encode((actions[i], outcomes[i])))\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\033[0;32mLes actions\\033[0m {actions} \\n\\033[0;32met outcomes\\033[0m {outcomes}\")\n",
    "seq_token = action_outcome_to_token(actions, outcomes)\n",
    "print(f\"\\033[0;32mLes tokens déduit\\033[0m {seq_token}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Création du data set\n",
    "Pour avoir le plus possible de phrase avec peu d'interaction, nous découpons le plus possible la séquence d'interaction faites par l'agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du data set :\n",
    "def create_data(tokens, context_lenght, padding, min = 1):\n",
    "    \"\"\"\n",
    "    Create the data\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    for range_cut in range(min, context_lenght + 1):\n",
    "        for i in range(0, len(tokens) - range_cut, 1):\n",
    "            sentences.append(tokens[i:i + range_cut])\n",
    "            sentences[-1] = sentences[-1] + [padding] * (context_lenght - len(sentences[-1]))\n",
    "    return sentences\n",
    "\n",
    "data_set = create_data(seq_token, 10, tokenizer.encode(\"<pad>\"), min = 1)\n",
    "print(f\"\\033[0;32mLe data set\\033[0m\")\n",
    "for i in data_set:\n",
    "    print(i)\n",
    "    # print(tokenizer.decode(i))\n",
    "    # print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Token de fin dans les phrases\n",
    "Actuelement notre data set fini par des \\<pad\\>, si nous laissons notre data set comme ceci, le modèle peut générer beaucoup de balise \\<pad\\> sans chercher à finir par ('forward', 'empty'). Hors nous voulons que le modèls trouve un moyen d'arriver a cette interaction.  \n",
    "Nous devons donc ne garder que les phrases qui contiennent ('forward', 'empty')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data set finnissant par un token de fin\n",
    "def create_data(tokens, context_lenght, padding, min = 1):\n",
    "    \"\"\"\n",
    "    Create the data\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    for range_cut in range(min, context_lenght + 1):\n",
    "        for i in range(0, len(tokens) - range_cut + 1, 1):\n",
    "            sequence = tokens[i:i + range_cut]\n",
    "            if tokenizer.encode(('forward', 'empty')) in sequence:\n",
    "                sentences.append(tokens[i:i + range_cut] + \\\n",
    "                                 [padding] * (context_lenght - len(tokens[i:i + range_cut])))\n",
    "    return sentences\n",
    "\n",
    "data_set = create_data(seq_token, 10, tokenizer.encode(\"<pad>\"), min = 1)\n",
    "print(f\"\\033[0;32mLe data set\\033[0m\")\n",
    "for i in data_set:\n",
    "    print(i)\n",
    "\n",
    "print(f\"\\033[0;32mLa séquence \\033[0m\")\n",
    "print(tokenizer.decode(seq_token))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plus d'interactions\n",
    "Il se peut que pour la première génération du modèles n'arrive pas à faire réellement l'interactation ('forward', 'empty'). Pour arriver a cette intéraction au moins une fois, nous ne pouvons pas demander au modèl de nous générer en boucle des interactions a appliqué, car le modèl donneras toujours le même output. L'éxecusion seepder donne :  \n",
    "`('feel_left', 'wall'), ('turn_right', 'empty'), ('feel_front', 'empty'), ('turn_left', 'empty'), ('forward', 'wall')`  \n",
    "Hors répeter ses actions en boucle sur l'environement, ne permet d'arriver à l'interaction souhaiter.\n",
    "\n",
    "##### Exploration aléatoire\n",
    "En considérant que le robot n'a aucune connnaissance sur l'environement, nous pouvons lancé des actions aléatoirement jusqu'à obtenir l'interaction : `('forward', 'empty')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while seq_token[-1] != tokenizer.encode(('forward', 'empty')):\n",
    "    action_random = np.random.choice(env_test.get_actions())\n",
    "    outcome_random = env_test.outcome(action_random)\n",
    "    seq_token.append(tokenizer.encode((action_random, outcome_random)))\n",
    "    env_test.save_world(path=\"imgToGif2\")\n",
    "    \n",
    "print(f\"\\033[0;32mLa séquence \\033[0m\")\n",
    "print(tokenizer.decode(seq_token))\n",
    "print(f\"Nombre de token : {len(seq_token)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data set avec forward empty\n",
    "Nous sommes maintenant sùr que notre modèle peut apprendre des \"phrases\" avec l'interaction souhaité, voici le data set :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = create_data(seq_token, 10, tokenizer.encode(\"<pad>\"), min = 1)\n",
    "print(f\"\\033[0;32mLe data set\\033[0m\")\n",
    "for i in data_set:\n",
    "    print(i)\n",
    "\n",
    "print(f\"\\033[0;32mLa séquence \\033[0m\")\n",
    "print(tokenizer.decode(seq_token))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set\n",
    "Maintenant que le data set est créer nous pouvons utiliser pytorch pour gérer notre data train. (Nous mettons aussi les données sous forme de tensor)\n",
    "\n",
    "## Class CustomDataSetTextGenByToken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataSetTextGenByToken(Dataset):\n",
    "    def __init__(self, token, context_lenght:int, id_pad:int=0, min:int = 1):\n",
    "        \"\"\"\n",
    "        Creates a custom dataset\n",
    "        \"\"\"\n",
    "        # assert context_lenght % 2 != 0, \"context_lenght must be odd\"\n",
    "        # assert len(actions) == len(outcomes), \"actions and outcomes must have the same length\"\n",
    "        assert context_lenght > 0, \"context_lenght can't be negative or zero\"\n",
    "\n",
    "        self.context_lenght = context_lenght\n",
    "        self.tokenizer = tokenizer\n",
    "        self.dim_out = tokenizer.size_vocab\n",
    "        self.token = token\n",
    "        self.padding = id_pad\n",
    "        self.min = min\n",
    "        self.data = self.create_data()\n",
    "\n",
    "    # Fonction vue précédament\n",
    "    def create_data(self):\n",
    "        \"\"\"\n",
    "        Create the data\n",
    "        \"\"\"\n",
    "        sentences = []\n",
    "        for range_cut in range(self.min, self.context_lenght +1):\n",
    "            for i in range(0, len(self.token) + 1 - range_cut, 1):\n",
    "                sequence = self.token[i:i + range_cut]\n",
    "                if self.tokenizer.encode(('forward', 'empty')) in sequence:\n",
    "                    sentences.append(self.token[i:i + range_cut] + \\\n",
    "                                    [self.padding] * (self.context_lenght - len(self.token[i:i + range_cut])))\n",
    "        \n",
    "        return sentences\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Get the length of the dataset\n",
    "        :return: length\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get the item at the index idx\n",
    "\n",
    "        :param idx: index\n",
    "        :return: x\n",
    "        \"\"\"\n",
    "        return torch.tensor(self.data[idx])\n",
    "    \n",
    "class CustomDataSetTextGenByTokenV2(Dataset):\n",
    "    def __init__(self, token, context_lenght:int, id_pad:int=0, min:int = 1):\n",
    "        \"\"\"\n",
    "        Creates a custom dataset\n",
    "        \"\"\"\n",
    "        # assert context_lenght % 2 != 0, \"context_lenght must be odd\"\n",
    "        # assert len(actions) == len(outcomes), \"actions and outcomes must have the same length\"\n",
    "        assert context_lenght > 0, \"context_lenght can't be negative or zero\"\n",
    "\n",
    "        self.context_lenght = context_lenght\n",
    "        self.tokenizer = tokenizer\n",
    "        self.dim_out = tokenizer.size_vocab\n",
    "        self.token = token\n",
    "        self.padding = id_pad\n",
    "        self.min = min\n",
    "        self.data = self.create_data()\n",
    "\n",
    "    # Fonction vue précédament\n",
    "    def create_data(self):\n",
    "        \"\"\"\n",
    "        Create the data\n",
    "        \"\"\"\n",
    "        sentences = []\n",
    "        for range_cut in range(self.min, self.context_lenght +1):\n",
    "            for i in range(0, len(self.token) + 1 - range_cut, 1):\n",
    "                sequence = self.token[i:i + range_cut]\n",
    "                sentences.append(\n",
    "                    sequence + [self.padding] * (self.context_lenght - len(self.token[i:i + range_cut]))\n",
    "                )\n",
    "        \n",
    "        return sentences\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Get the length of the dataset\n",
    "        :return: length\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get the item at the index idx\n",
    "\n",
    "        :param idx: index\n",
    "        :return: x\n",
    "        \"\"\"\n",
    "        return torch.tensor(self.data[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(seq_token)\n",
    "data_set = CustomDataSetTextGenByToken(\n",
    "    token=seq_token,\n",
    "    id_pad=tokenizer.encode(\"<pad>\"),\n",
    "    context_lenght=10,\n",
    "    min=1)\n",
    "print(f\"\\033[0;32mLe data set\\033[0m\")\n",
    "for i in data_set:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loader\n",
    "Nous faisons appel a pytorch pour créer un data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_train = DataLoader(\n",
    "    data_set, # C'est le data set que nous avons créé\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss et opti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = optim.Adam(lstm_generator.parameters(), lr=0.001)\n",
    "loss_fct = nn.CrossEntropyLoss(ignore_index=tokenizer.encode(\"<pad>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token Drop ?\n",
    "Le fais de cacher certain mots dans l'apprantissage du modèle (token drop) permet d'éviter le surapprentissage et permet de résister a des variations dans les phrases. Le modèle apprends a tiré l'information de certain mots important et pas de tous.\n",
    "\n",
    "<!-- Je ne suis pas encore sûr mais le token drop améliore les performances avec des tailles variable lors de l'entrainement -->\n",
    "\n",
    "La question d'utiliser un token drop dans notre cas n'est pas facil. Il faut tester sur un jeu de données suffisant. Mais il est possible que les résultat dépende trop de l'environement. Un environement simple ou il est facil \"d'overfit\" pour être bon, n'aura certainement pas beson de token drop. Mais pour des environement complexe, il se peut que le token drop améliore les performence.\n",
    "\n",
    "## CLASS TOKEN DROP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenDrop(nn.Module):\n",
    "    \"\"\"For a batch of tokens indices, randomly replace a non-specical token with <pad>.\n",
    "    \n",
    "    Args:\n",
    "        prob (float): probability of dropping a token\n",
    "        pad_token (int): index for the <pad> token\n",
    "        num_special (int): Number of special tokens, assumed to be at the start of the vocab\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, prob=0.1, pad_token=0, num_special=4):\n",
    "        self.prob = prob\n",
    "        self.num_special = num_special\n",
    "        self.pad_token = pad_token\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        mask = torch.bernoulli(self.prob * torch.ones_like(sample)).long()\n",
    "        \n",
    "        can_drop = (sample >= self.num_special).long()\n",
    "        mask = mask * can_drop\n",
    "        \n",
    "        replace_with = (self.pad_token * torch.ones_like(sample)).long()\n",
    "        \n",
    "        sample_out = (1 - mask) * sample + mask * replace_with\n",
    "        \n",
    "        return sample_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "L'entrainement du modèle suit la logique de n'importe quels réseaux de neurone. Il y a quelque variations comme pour la target. Le data loader ne donne pas de target, c'est à nous de le créer. Pour se faire nous prennons chaque phrase, sur ces phrases nous prennons chaque mots et le modèle doit deviner le mots d'après. Exemple :  \n",
    "Avec la phrase `(feel_front, wall), (turn_right, empty), (feel_front, empty), (forward, empty)`\n",
    "Ce qui est passer au modèl est `(feel_front, wall), (turn_right, empty), (feel_front, empty)` et nous voulons qu'a chaque cellule avoir `(turn_right, empty), (feel_front, empty), (forward, empty)`\n",
    "\n",
    "## FONCTION TRAIN 1ER VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(lstm_generator:nn.Module, data_loader_train:DataLoader, nb_epoch:int, optimizer, loss_fn, td:TokenDrop|None=None):\n",
    "    # Monitor training loss and entropy\n",
    "    training_loss_logger = []\n",
    "    entropy_logger = []\n",
    "\n",
    "    for _ in tqdm(range(nb_epoch)):\n",
    "        # Set LSTM generator model to training mode\n",
    "        lstm_generator.train()\n",
    "        # Iterate over batches in training data loader\n",
    "        for text in tqdm(data_loader_train, desc=\"Training\", leave=False):\n",
    "            # Transform text tokens using training transform and move to device\n",
    "            bs = text.shape[0]\n",
    "            \n",
    "            # Randomly drop input tokens\n",
    "            if td is not None:\n",
    "                input_text = td(text[:, 0:-1])\n",
    "            else:\n",
    "                input_text = text[:, 0:-1]\n",
    "            output_text = text[:, 1:]\n",
    "            \n",
    "            # Or not drop tokens\n",
    "            # input_text = text[:, 0:-1]\n",
    "            # output_text = text[:, 1:]\n",
    "            \n",
    "            # Initialize the memory buffers\n",
    "            hidden = torch.zeros(lstm_generator.num_layers, bs, lstm_generator.hidden_size)\n",
    "            memory = torch.zeros(lstm_generator.num_layers, bs, lstm_generator.hidden_size)\n",
    "            \n",
    "            # Forward pass through the LSTM generator\n",
    "            pred, hidden, memory = lstm_generator(input_text, hidden, memory)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = loss_fn(pred.transpose(1, 2), output_text)\n",
    "            \n",
    "            # Zero gradients, perform backward pass, and update weights\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Log training loss\n",
    "            training_loss_logger.append(loss.item())\n",
    "            \n",
    "            # Log entropy during training (for monitoring)\n",
    "            with torch.no_grad():\n",
    "                dist = Categorical(logits=pred)\n",
    "                entropy_logger.append(dist.entropy().mean().item())\n",
    "    return training_loss_logger, entropy_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = TokenDrop(prob=0.1, pad_token=tokenizer.encode(\"<pad>\"), num_special=1)\n",
    "td = None\n",
    "training_loss_logger, entropy_logger = train(lstm_generator=lstm_generator, \n",
    "                                            nb_epoch=50, \n",
    "                                            data_loader_train=data_loader_train,\n",
    "                                            optimizer=opti, \n",
    "                                            loss_fn=loss_fct)\n",
    "# Display training loss and entropy\n",
    "plt.plot(training_loss_logger)\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.plot(entropy_logger)\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Entropy')\n",
    "plt.title('Entropy')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nouvelle génération\n",
    "Maintenant que notre modèle c'est entrainer, il peut générer de nouvelles chose !\n",
    "## Prompt\n",
    "Le prompt pour la nouvelle génération sera les X dernière itération. (Je n'ai pas encore d'idée fixe pour ce x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "if len(seq_token) > 10:\n",
    "    input_tokens = seq_token[-10: -1]\n",
    "else:\n",
    "    input_tokens = seq_token\n",
    "print(input_tokens)\n",
    "input_tokens = torch.tensor(input_tokens).reshape(1, -1)\n",
    "log_tokens, data_pred, df = generate_sentence(lstm_generator, input_tokens, tokenizer=tokenizer)\n",
    "plt.xticks(range(len(list_vocab)), list_vocab, fontsize=8, rotation=60, ha='right')\n",
    "plt.plot(F.softmax(data_pred/temp, -1).cpu().numpy().flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce qu'il faut retenir de ce graphique est que le modèl est très sur de lui pour chaque prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in log_tokens:\n",
    "    print(tokenizer.decode(i.item()))\n",
    "    \n",
    "actions, outcomes = run_token(log_tokens, env_test)\n",
    "print(\"Les actions tirées de la génération du modèle\")\n",
    "print(actions)\n",
    "print(\"Les outcomes réel de l'environnement\")\n",
    "print(outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_token += action_outcome_to_token(actions, outcomes)\n",
    "print(f\"\\033[0;32mLa séquence \\033[0m\")\n",
    "print(tokenizer.decode(seq_token))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boucle (1er version)\n",
    "Maintenant que nous avons vue toutes les étapes, nous pouvons tenter de faire un modèle qui comprends l'environement !  \n",
    "Il est important de noté qu'il n'y a aucune volonté de faure un certain chemin. Le modèle peut tout a fait apprendre \"forward\", \"wall\" en boucle.\n",
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(1)\n",
    "# Historique des actions et outcomes\n",
    "env_test = gridWorld(x= 1, y=1, theta=0, world= np.array([\n",
    "                [1, 1, 1, 1, 1, 1],\n",
    "                [1, 0, 0, 0, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 1],\n",
    "                [1, 1, 1, 1, 1, 1],\n",
    "            ]))\n",
    "all_actions, all_outcomes = [], []\n",
    "all_actions.append('forward') # Première action de base \n",
    "all_outcomes.append(env_test.outcome('forward')) # Première outcome de base\n",
    "# Cette première interaction nous servira de premier prompt\n",
    "seq_token = [tokenizer.encode((all_actions[0], all_outcomes[0]))]\n",
    "\n",
    "env_test.display_world()\n",
    "\n",
    "lstm_generator = LSTM_GenText(\n",
    "    num_emb=len(list_vocab),\n",
    "    hidden_size=16,\n",
    "    emb_size=16,\n",
    "    num_layers=2,\n",
    "    dropout=0.1\n",
    ")\n",
    "opti = optim.Adam(lstm_generator.parameters(), lr=0.001)\n",
    "loss_fct = nn.CrossEntropyLoss(ignore_index=tokenizer.encode(\"<pad>\"))\n",
    "\n",
    "list_vocab = ['<pad>']\n",
    "# Nous notons toutes les interactions techniquement possible\n",
    "for act in env_test.get_actions():\n",
    "    for fb in env_test.get_outcomes():\n",
    "        list_vocab.append((act, fb))\n",
    "\n",
    "# Nous pouvons suprimer des interactions qui ne sont en réalité pas possible.\n",
    "list_vocab.remove(('turn_left', 'wall'))\n",
    "list_vocab.remove(('turn_right', 'wall'))\n",
    "for element in list_vocab:\n",
    "    print(element)\n",
    "    \n",
    "tmp = create_dico_numerate_word(list_vocab)\n",
    "print(tmp)\n",
    "tokenizer = SimpleTokenizerV1(vocab=tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vérification faire au moins une fois forward empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "while seq_token[-1] != tokenizer.encode(('forward', 'empty')):\n",
    "    action_random = np.random.choice(env_test.get_actions())\n",
    "    outcome_random = env_test.outcome(action_random)\n",
    "    seq_token.append(tokenizer.encode((action_random, outcome_random)))\n",
    "    env_test.save_world(path=\"imgToGif2\")\n",
    "    \n",
    "print(f\"\\033[0;32mLa séquence \\033[0m\")\n",
    "print(tokenizer.decode(seq_token))\n",
    "print(seq_token)\n",
    "print(f\"Nombre d'interaction créée aléatoirement: {len(seq_token)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Éxecution de la boucle\n",
    "\n",
    "Pour voir étapes par étapes se qui se passe si nous laissons le modèles explorer, éxecuter plusieurs fois la cellule python suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(1)\n",
    "if len(seq_token) > 10:\n",
    "    input_tokens = seq_token[-10:]\n",
    "else:\n",
    "    input_tokens = seq_token\n",
    "    \n",
    "print(f\"\\033[0;32mLe prompt\\033[0m {input_tokens}\")\n",
    "for i in input_tokens:\n",
    "    print(tokenizer.decode(i))\n",
    "print()\n",
    "\n",
    "input_tokens = torch.tensor(input_tokens).reshape(1, -1)\n",
    "log_tokens, data_pred, df = generate_sentence(lstm_generator, input_tokens, tokenizer=tokenizer)\n",
    "df.to_csv(\"monitoring.csv\", index=False)\n",
    "interaction_pred = [tokenizer.decode(token.item()) for token in log_tokens if tokenizer.decode(token.item()) != \"<pad>\"]\n",
    "\n",
    "actions, outcomes = run_token(log_tokens, env_test, \"imgToGif2\")\n",
    "env_test.display_world()\n",
    "\n",
    "good_pred = []\n",
    "for i in range(len(interaction_pred)):\n",
    "    good_pred.append(interaction_pred[i] == (actions[i], outcomes[i]))\n",
    "\n",
    "# print(f\"\\033[0;32mLes vrai outcomes\\033[0m \\n{outcomes}\")\n",
    "# Create a DataFrame to store interactions, actions, and outcomes\n",
    "df_interactions = pd.DataFrame({\n",
    "    'Interaction générer': interaction_pred,\n",
    "    'Action appliquer': actions,\n",
    "    'Outcome réel': outcomes,\n",
    "    'verifier': ['Correct' if i else 'Incorrect' for i in good_pred]\n",
    "})\n",
    "\n",
    "print(\"\\033[0;32mDataFrame des interactions\\033[0m\")\n",
    "print(df_interactions)\n",
    "df_interactions.to_csv(\"interactions.csv\", index=False)\n",
    "print(f\"\\033[0;32mnombre de bonne prédiction : {sum(good_pred)} sur {len(good_pred)} et {len(log_tokens)} générer\\033[0m\")\n",
    "\n",
    "all_actions += actions\n",
    "all_outcomes += outcomes\n",
    "\n",
    "seq_token += action_outcome_to_token(all_actions, all_outcomes)\n",
    "print('seq token', seq_token)\n",
    "print(f\"Nombre d'interaction total : {len(seq_token)}\")\n",
    "data_set = CustomDataSetTextGenByToken(\n",
    "    token=seq_token,\n",
    "    id_pad=tokenizer.encode(\"<pad>\"),\n",
    "    context_lenght=20,\n",
    "    min=10)\n",
    "\n",
    "print(f\"\\033[0;32mtaille du jeu de donnée \\033[0m{len(data_set)}\")\n",
    "\n",
    "data_loader_train = DataLoader(\n",
    "        data_set,\n",
    "        batch_size=64,\n",
    "        shuffle=True,\n",
    "        num_workers=8\n",
    "    )\n",
    "\n",
    "td = TokenDrop(prob=0.1, pad_token=tokenizer.encode(\"<pad>\"), num_special=1)\n",
    "training_loss_logger, entropy_logger = train(lstm_generator=lstm_generator, td=td,\n",
    "                                            nb_epoch=20, optimizer=opti,loss_fn=loss_fct,\n",
    "                                            data_loader_train=data_loader_train)\n",
    "\n",
    "plt.plot(training_loss_logger)\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()\n",
    "\n",
    "windows_means = []\n",
    "window_size = 100\n",
    "for i in range(0, len(entropy_logger), window_size):\n",
    "    windows_means.append(np.mean(entropy_logger[i:i + window_size]))\n",
    "plt.plot(windows_means)\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.title('Training Loss windows_means')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(entropy_logger)\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Entropy')\n",
    "plt.title('Entropy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise \"Fin de la première méthode\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résulats\n",
    "\n",
    "Voir [monitoring.csv](./monitoring.csv) et [interactions.csv](./interactions.csv) pour plus de détail sur la dérnière application de la cellule\n",
    "\n",
    "### Result\n",
    "Au bout d'un certain nombre d'interactions, le modèle arrive a comprendre l'environement. Mais il essaye d'overfit et n'a aucune notion de valence. Cela n'empeche pas de voir des séquences courte d'interactions menant à forward, empty\n",
    "\n",
    "\n",
    "### Old resulat\n",
    "Première remarque, depuis le comportement a changer **TODO REMOVE**  \n",
    "Avec cette première façon d'utiliser la génération de texte nous voyons que le modèle ne forme que deux séquence qui sont :  \n",
    "1. turn_left, empty; turn_right, empty; **feel_front, wall; feel_front, wall**; turn_left, empty; forward, empty\n",
    "2. turn_left, empty; turn_right, empty; **feel_front, wall; feel_front, empty**; turn_left, empty; forward, empty\n",
    "\n",
    "On remarque que se sont les mêmes actions, le modèle change juste le token feel_front, wall pour eel_front, empty. Ce qui est logique car dans son jeu de train, il a les deux version de séquence. Mais au vue de sont trop petit jeu de données, le modèl ne peut pas créer d'autre séquence. Nous pouvons remarquer aussi que le modèl n'arrive pas a prédire quand il faut générer feel_front, wall ou feel_front, empty. Nous pouvons émetre l'hypothèse qu'un context lenght et/ou prompt plus grand permetrais de prédire corectement ces deux séquences.\n",
    "\n",
    "# Autre environement\n",
    "Notre environement actuel permet de répeter ces deux séquences sans avoir de variation. Mais que ce passerait t'il si l'environement n'était pas aussi simple ?\n",
    "\n",
    "L'enironement du small loop (voir travaux d'Olivier Georgon).\n",
    "```py\n",
    "env_test = gridWorld(x= 1, y=1, theta=0, world= np.array([\n",
    "                [1, 1, 1, 1, 1, 1],\n",
    "                [1, 0, 0, 0, 1, 1],\n",
    "                [1, 0, 1, 0, 0, 1],\n",
    "                [1, 0, 1, 1, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 1],\n",
    "                [1, 1, 1, 1, 1, 1],\n",
    "            ]))\n",
    "```\n",
    "\n",
    "En gardant le même context lenght et même longeur de prompt pour cet environement :\n",
    "```py\n",
    "env_test = gridWorld(x= 1, y=1, theta=0, world= np.array([\n",
    "                [1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "                [1, 0, 0, 0, 1, 0, 0, 0, 1],\n",
    "                [1, 1, 1, 0, 1, 0, 1, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 0, 1, 0, 1],\n",
    "                [1, 0, 1, 1, 1, 1, 0, 0, 1],\n",
    "                [1, 0, 1, 1, 0, 0, 0, 1, 1],\n",
    "                [1, 0, 0, 0, 0, 1, 1, 1, 1],\n",
    "                [1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "            ]))\n",
    "```\n",
    "Nous remarquons que le modèle tente beaucoup d'action pour arriver à l'interaction forward, empty. Mais même si cela dois générer un jeu de données plus complet, nous pouvons remarquer que le modèle n'a pas assez d'information pour traiter comme il faut l'environement. Il y a deux points a revoir dans cette boucle :\n",
    "1. La taille du context lenght et du prompt, nous pouvons passer a 50, puis 100 en fonction des résulats\n",
    "2. Générer petit a petit, si le modèl se trompe a un moment dans la séquence, la suite de ca génération ne devrais pas être bon. Pour pallier ce problème et essayer d'obtenir une meilleur compréhension de la par du modèle, nous pouvons faire l'action et remplacer par la vrai interaction.  \n",
    "\n",
    "La boucle suivante va juste augmenter la taille du prompt et du context lenght, le code suivant cette boucle essayera la deuxième solution avec les résulats de la premirèe solution.\n",
    "\n",
    "# Deuxième boucle\n",
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_test = gridWorld(x= 1, y=1, theta=0, world= np.array([\n",
    "                [1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "                [1, 0, 0, 0, 1, 0, 0, 0, 1],\n",
    "                [1, 1, 1, 0, 1, 0, 1, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 0, 1, 0, 1],\n",
    "                [1, 0, 1, 1, 1, 1, 0, 0, 1],\n",
    "                [1, 0, 1, 1, 0, 0, 0, 1, 1],\n",
    "                [1, 0, 0, 0, 0, 1, 1, 1, 1],\n",
    "                [1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "            ]))\n",
    "\n",
    "list_vocab = ['<pad>']\n",
    "# Nous notons toutes les interactions techniquement possible\n",
    "for act in env_test.get_actions():\n",
    "    for fb in env_test.get_outcomes():\n",
    "        list_vocab.append((act, fb))\n",
    "\n",
    "# Nous pouvons suprimer des interactions qui ne sont en réalité pas possible.\n",
    "list_vocab.remove(('turn_left', 'wall'))\n",
    "list_vocab.remove(('turn_right', 'wall'))\n",
    "for element in list_vocab:\n",
    "    print(element)\n",
    "    \n",
    "tmp = create_dico_numerate_word(list_vocab)\n",
    "print(tmp)\n",
    "tokenizer = SimpleTokenizerV1(vocab=tmp)\n",
    "\n",
    "all_actions, all_outcomes = [], []\n",
    "all_actions.append('forward') # Première action de base \n",
    "all_outcomes.append(env_test.outcome('forward')) # Première outcome de base\n",
    "# Cette première interaction nous servira de premier prompt\n",
    "seq_token = [tokenizer.encode((all_actions[0], all_outcomes[0]))]\n",
    "\n",
    "env_test.display_world()\n",
    "\n",
    "lstm_generator = LSTM_GenText(\n",
    "    num_emb=len(list_vocab),\n",
    "    hidden_size=16,\n",
    "    emb_size=16,\n",
    "    num_layers=2,\n",
    "    dropout=0.1\n",
    ")\n",
    "opti = optim.Adam(lstm_generator.parameters(), lr=0.001)\n",
    "loss_fct = nn.CrossEntropyLoss(ignore_index=tokenizer.encode(\"<pad>\"))\n",
    "\n",
    "SIZE_CONTEXT = 20\n",
    "SIZE_PROMPT = SIZE_CONTEXT\n",
    "SIZE_CONTEXT_MIN = 2\n",
    "TEMPERATURE = 5.0\n",
    "MAX_DATA_TRAINING = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vérification, action aléatoire jusqu'à forward empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while seq_token[-1] != tokenizer.encode(('forward', 'empty')):\n",
    "    action_random = np.random.choice(env_test.get_actions())\n",
    "    outcome_random = env_test.outcome(action_random)\n",
    "    seq_token.append(tokenizer.encode((action_random, outcome_random)))\n",
    "    \n",
    "print(f\"\\033[0;32mLa séquence \\033[0m\")\n",
    "print(tokenizer.decode(seq_token))\n",
    "print(seq_token)\n",
    "print('taille de la séquence aléatoire', len(seq_token))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execusion deuxième boucle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPERATURE = 5.0\n",
    "\n",
    "if len(seq_token) > MAX_DATA_TRAINING:\n",
    "    seq_to_data_set = seq_token[-SIZE_CONTEXT:]\n",
    "else:\n",
    "    seq_to_data_set = seq_token\n",
    "data_set = CustomDataSetTextGenByToken(\n",
    "    token=seq_to_data_set,\n",
    "    id_pad=tokenizer.encode(\"<pad>\"),\n",
    "    context_lenght=SIZE_CONTEXT,\n",
    "    min=SIZE_CONTEXT_MIN)\n",
    "\n",
    "print(f\"\\033[0;32mtaille du jeu de donnée \\033[0m{len(data_set)}\")\n",
    "\n",
    "data_loader_train = DataLoader(\n",
    "        data_set,\n",
    "        batch_size=1,\n",
    "        shuffle=True,\n",
    "        num_workers=8\n",
    "    )\n",
    "\n",
    "training_loss_logger, entropy_logger = train(\n",
    "    lstm_generator=lstm_generator, data_loader_train=data_loader_train, nb_epoch=20, optimizer=opti, loss_fn=loss_fct, td=None)\n",
    "\n",
    "plt.plot(training_loss_logger)\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()\n",
    "\n",
    "windows_means = []\n",
    "window_size = 100\n",
    "for i in range(0, len(entropy_logger), window_size):\n",
    "    windows_means.append(np.mean(entropy_logger[i:i + window_size]))\n",
    "plt.plot(windows_means)\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.title('Training Loss windows_means')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(entropy_logger)\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Entropy')\n",
    "plt.title('Entropy')\n",
    "plt.show()\n",
    "\n",
    "if len(seq_token) > SIZE_PROMPT:\n",
    "    input_tokens = seq_token[-SIZE_PROMPT:]\n",
    "else:\n",
    "    input_tokens = seq_token\n",
    "    \n",
    "print(f\"\\033[0;32mLe prompt\\033[0m {input_tokens}\")\n",
    "for i in input_tokens:\n",
    "    print(tokenizer.decode(i))\n",
    "print()\n",
    "\n",
    "input_tokens = torch.tensor(input_tokens).reshape(1, -1)\n",
    "log_tokens, data_pred, df = generate_sentence(lstm_generator=lstm_generator,\n",
    "                                            input_tokens=input_tokens, tokenizer=tokenizer, temp=TEMPERATURE, max_len=20, end_token=tokenizer.encode(('forward', 'empty')))\n",
    "df.to_csv(\"monitoring.csv\", index=False)\n",
    "interaction_pred = [tokenizer.decode(token.item()) for token in log_tokens if tokenizer.decode(token.item()) != \"<pad>\"]\n",
    "\n",
    "actions, outcomes = run_token(log_tokens, env_test)\n",
    "env_test.display_world()\n",
    "\n",
    "\n",
    "good_pred = []\n",
    "for i in range(len(interaction_pred)):\n",
    "    good_pred.append(interaction_pred[i] == (actions[i], outcomes[i]))\n",
    "\n",
    "# print(f\"\\033[0;32mLes vrai outcomes\\033[0m \\n{outcomes}\")\n",
    "# Create a DataFrame to store interactions, actions, and outcomes\n",
    "df_interactions = pd.DataFrame({\n",
    "    'Interaction générer': interaction_pred,\n",
    "    'Action appliquer': actions,\n",
    "    'Outcome réel': outcomes,\n",
    "    'verifier': ['Correct' if i else 'Incorrect' for i in good_pred]\n",
    "})\n",
    "\n",
    "print(\"\\033[0;32mDataFrame des interactions\\033[0m\")\n",
    "print(df_interactions)\n",
    "df_interactions.to_csv(\"interactions.csv\", index=False)\n",
    "print(f\"\\033[0;32mnombre de bonne prédiction : {sum(good_pred)} sur {len(good_pred)} et {len(log_tokens)} générer\\033[0m\")\n",
    "\n",
    "all_actions += actions\n",
    "all_outcomes += outcomes\n",
    "\n",
    "seq_token += action_outcome_to_token(all_actions, all_outcomes)\n",
    "print('seq token', seq_token)\n",
    "print(f\"Nombre d'interaction total : {len(seq_token)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Juste de la génération\n",
    "if len(seq_token) > SIZE_PROMPT:\n",
    "    input_tokens = seq_token[-SIZE_PROMPT:]\n",
    "else:\n",
    "    input_tokens = seq_token\n",
    "    \n",
    "print(f\"\\033[0;32mLe prompt\\033[0m {input_tokens}\")\n",
    "for i in input_tokens:\n",
    "    print(tokenizer.decode(i))\n",
    "print()\n",
    "\n",
    "input_tokens = torch.tensor(input_tokens).reshape(1, -1)\n",
    "log_tokens, data_pred, df = generate_sentence(lstm_generator=lstm_generator,\n",
    "                                            input_tokens=input_tokens, tokenizer=tokenizer, temp=TEMPERATURE)\n",
    "df.to_csv(\"monitoring.csv\", index=False)\n",
    "interaction_pred = [tokenizer.decode(token.item()) for token in log_tokens if tokenizer.decode(token.item()) != \"<pad>\"]\n",
    "# print(\"\\033[0;32m Génération du modèle :\\033[0m\")\n",
    "# for i in log_tokens:\n",
    "#     print(tokenizer.decode(i.item()))\n",
    "\n",
    "actions, outcomes = run_token(log_tokens, env_test)\n",
    "env_test.display_world()\n",
    "\n",
    "good_pred = []\n",
    "for i in range(len(interaction_pred)):\n",
    "    good_pred.append(interaction_pred[i] == (actions[i], outcomes[i]))\n",
    "\n",
    "# print(f\"\\033[0;32mLes vrai outcomes\\033[0m \\n{outcomes}\")\n",
    "# Create a DataFrame to store interactions, actions, and outcomes\n",
    "df_interactions = pd.DataFrame({\n",
    "    'Interaction générer': interaction_pred,\n",
    "    'Action appliquer': actions,\n",
    "    'Outcome réel': outcomes,\n",
    "    'verifier': ['Correct' if i else 'Incorrect' for i in good_pred]\n",
    "})\n",
    "\n",
    "print(\"\\033[0;32mDataFrame des interactions\\033[0m\")\n",
    "print(df_interactions)\n",
    "df_interactions.to_csv(\"interactions.csv\", index=False)\n",
    "print(f\"\\033[0;32mnombre de bonne prédiction : {sum(good_pred)} sur {len(good_pred)} et {len(log_tokens)} générer\\033[0m\")\n",
    "\n",
    "all_actions += actions\n",
    "all_outcomes += outcomes\n",
    "\n",
    "seq_token += action_outcome_to_token(all_actions, all_outcomes)\n",
    "print('seq token', seq_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultat\n",
    "Voir les [probabilités de chaque intérations](./monitoring.csv) et [l'application sur l'environement](./interactions.csv) de la dernière cellule éxecuter.\n",
    "Le modèl finit pat boucler sur une séquence d'interaction.\n",
    "\n",
    "### Prompt 1\n",
    "```txt\n",
    "Le prompt [4, 2, 2, 7, 4, 7, 4, 2, 2, 7, 4, 7, 4, 2, 2, 7, 4, 7, 4, 2]\n",
    "('turn_right', 'empty')\n",
    "('forward', 'empty')\n",
    "('forward', 'empty')\n",
    "('feel_left', 'wall')\n",
    "('turn_right', 'empty')\n",
    "('feel_left', 'wall')\n",
    "('turn_right', 'empty')\n",
    "('forward', 'empty')\n",
    "('forward', 'empty')\n",
    "('feel_left', 'wall')\n",
    "('turn_right', 'empty')\n",
    "('feel_left', 'wall')\n",
    "('turn_right', 'empty')\n",
    "('forward', 'empty')\n",
    "('forward', 'empty')\n",
    "('feel_left', 'wall')\n",
    "('turn_right', 'empty')\n",
    "('feel_left', 'wall')\n",
    "('turn_right', 'empty')\n",
    "('forward', 'empty')\n",
    "```\n",
    "\n",
    "| \\<pad\\> | ('forward', 'wall') | ('forward', 'empty') | ('turn_left', 'empty') | ('turn_right', 'empty') | ('feel_front', 'wall') | ('feel_front', 'empty') | ('feel_left', 'wall') | ('feel_left', 'empty') | ('feel_right', 'wall') | ('feel_right', 'empty') | interactions choisies |\n",
    "| ----- | ------------------- | -------------------- | ---------------------- | ----------------------- | ---------------------- | ----------------------- | --------------------- | ---------------------- | ---------------------- | ----------------------- | --------------------- |\n",
    "| 0.0   | 0.0                 | 0.982                | 0.0                    | 0.0                     | 0.0                    | 0.0                     | 0.018                 | 0.0                    | 0.0                    | 0.0                     | ('forward', 'empty')  |\n",
    "|       |                     |                      |                        |                         |                        |                         |                       |                        |                        |                         |                       |\n",
    "\n",
    "### Prompt 2\n",
    "```txt\n",
    "Le prompt [2, 2, 7, 4, 7, 4, 2, 2, 7, 4, 7, 4, 2, 2, 7, 4, 7, 4, 2, 2]\n",
    "('forward', 'empty')\n",
    "('forward', 'empty')\n",
    "('feel_left', 'wall')\n",
    "('turn_right', 'empty')\n",
    "('feel_left', 'wall')\n",
    "('turn_right', 'empty')\n",
    "('forward', 'empty')\n",
    "('forward', 'empty')\n",
    "('feel_left', 'wall')\n",
    "('turn_right', 'empty')\n",
    "('feel_left', 'wall')\n",
    "('turn_right', 'empty')\n",
    "('forward', 'empty')\n",
    "('forward', 'empty')\n",
    "('feel_left', 'wall')\n",
    "('turn_right', 'empty')\n",
    "('feel_left', 'wall')\n",
    "('turn_right', 'empty')\n",
    "('forward', 'empty')\n",
    "('forward', 'empty')\n",
    "```\n",
    "\n",
    "| <pad> | ('forward', 'wall') | ('forward', 'empty') | ('turn_left', 'empty') | ('turn_right', 'empty') | ('feel_front', 'wall') | ('feel_front', 'empty') | ('feel_left', 'wall') | ('feel_left', 'empty') | ('feel_right', 'wall') | ('feel_right', 'empty') | interactions choisies   |\n",
    "| ----- | ------------------- | -------------------- | ---------------------- | ----------------------- | ---------------------- | ----------------------- | --------------------- | ---------------------- | ---------------------- | ----------------------- | ----------------------- |\n",
    "| 0.0   | 0.037               | 0.227                | 0.0                    | 0.0                     | 0.0                    | 0.0                     | 0.736                 | 0.0                    | 0.0                    | 0.0                     | ('feel_left', 'wall')   |\n",
    "| 0.0   | 0.0                 | 0.0                  | 0.0                    | 1.0                     | 0.0                    | 0.0                     | 0.0                   | 0.0                    | 0.0                    | 0.0                     | ('turn_right', 'empty') |\n",
    "| 0.0   | 0.0                 | 0.0                  | 0.0                    | 0.0                     | 0.0                    | 0.0                     | 1.0                   | 0.0                    | 0.0                    | 0.0                     | ('feel_left', 'wall')   |\n",
    "| 0.0   | 0.0                 | 0.0                  | 0.0                    | 1.0                     | 0.0                    | 0.0                     | 0.0                   | 0.0                    | 0.0                    | 0.0                     | ('turn_right', 'empty') |\n",
    "| 0.0   | 0.0                 | 1.0                  | 0.0                    | 0.0                     | 0.0                    | 0.0                     | 0.0                   | 0.0                    | 0.0                    | 0.0                     | ('forward', 'empty')    |\n",
    "|       |                     |                      |                        |                         |                        |                         |                       |                        |                        |                         |                         |\n",
    "\n",
    "### Répétition ?\n",
    "La séquence qui se répète est la suivante :  \n",
    "('feel_left', 'wall') | ('turn_right', 'empty') | ('feel_left', 'wall') | ('turn_right', 'empty') | ('forward', 'empty') | ('forward', 'empty')  \n",
    "Nous ne pouvons pas dire que le modèle \"comprenne\" l'environement, il ne fait que répéter en boucle une séquence possible.\n",
    "\n",
    "### old Résultat\n",
    "Ancian résulat\n",
    "\n",
    "DataFrame des interactions\n",
    "| Interaction (Action, Perception) | Action appliquée | Outcome réel | Vérification |\n",
    "|----------------------------------|------------------|--------------|-------------|\n",
    "| (forward, wall)                  | forward          | wall         | Correct     |\n",
    "| (feel_left, wall)                | feel_left        | empty        | Incorrect   |\n",
    "| (turn_right, empty)              | turn_right       | empty        | Correct     |\n",
    "| (feel_front, wall)               | feel_front       | wall         | Correct     |\n",
    "| (turn_left, empty)               | turn_left        | empty        | Correct     |\n",
    "| (forward, empty)                 | forward          | wall         | Incorrect   |\n",
    "\n",
    "Avec ces intérations proposé par le modèl, nous ne pouvons savoir si il a compris l'environement et ces actions. Mais il est a noté que nous ne voulons pas forcément déviner les interactions de feel. Nous voulons que le modèle s'en servent pour trouver une séquence menant a forward Empty. Ce qui me ramène a la deuxième solution, corigé en pendant la génération.\n",
    "\n",
    "## Variation de la génération\n",
    "Pandant que le modèl génére une phrase (qui est cencé être cohérant avec l'environement) il se peut qu'il se trompe. Sauf que cela implique potentielement que toutes la suite de la génération se base sur une mauvaise intéraction. Pour éviter qu'à la moindre erreur tout deviennent faux, je propose une modification sur la fonction de génération. A la place de donner systématiquement le mot généré, nous prennons l'action du token générer et nous l'appliquons dans l'environement. Ainsi nous avons une séquence correct sur l'environement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence_with_env(lstm_generator:nn.Module, input_tokens:torch.Tensor, env_apply:env, tokenizer:SimpleTokenizerV1, temp:int=1.0, max_len:int=50, end_token:int|None=2, path:str|None=None):\n",
    "    \"\"\"Generate a sequence of tokens using the LSTM generator and apply them to the environment.\n",
    "    Args:\n",
    "        lstm_generator (nn.Module): The LSTM generator model.\n",
    "        input_tokens (torch.Tensor): The input tokens to start the generation.\n",
    "        env_apply (env): The environment to apply the actions.\n",
    "        tokenizer (SimpleTokenizerV1): The tokenizer to decode the tokens.\n",
    "        temp (int, optional): Temperature for sampling. Defaults to 1.0.\n",
    "        max_len (int, optional): Maximum length of the generated sequence. Defaults to 50.\n",
    "        end_token (int|None, optional): Token indicating the end of the sequence. Defaults to 2.\n",
    "        path (str|None, optional): Path to save the environment state. Defaults to None.\n",
    "    Returns:\n",
    "        list: The generated tokens.\n",
    "        torch.Tensor: The last prediction from the LSTM generator.\n",
    "        pd.DataFrame: DataFrame containing the interactions, actions, outcomes, and correctness.\n",
    "    \"\"\"\n",
    "    lstm_generator.eval()\n",
    "    log_tokens = []\n",
    "    # Disable gradient calculation\n",
    "    with torch.no_grad():\n",
    "        # Initialize hidden and memory states\n",
    "        hidden = torch.zeros(lstm_generator.num_layers, 1, lstm_generator.hidden_size)\n",
    "        memory = torch.zeros(lstm_generator.num_layers, 1, lstm_generator.hidden_size)\n",
    "\n",
    "        # Monitor number of good and bad predictions\n",
    "        good = []\n",
    "        actions = []\n",
    "        outcomes = []\n",
    "        pred_out_list = []\n",
    "        generation_special_token = 0\n",
    "        probability = {}\n",
    "        for i in range(tokenizer.size_vocab):\n",
    "            probability[tokenizer.decode(i)] = []\n",
    "            \n",
    "        for i in range(max_len): # On met une limite de 100 tokens\n",
    "            # Forward pass through LSTM generator\n",
    "            data_pred, hidden, memory = lstm_generator(input_tokens, hidden, memory)\n",
    "\n",
    "            # Sample from the distribution of probabilities (with temperature)\n",
    "            dist = Categorical(logits=data_pred[:, -1] / temp)\n",
    "            input_tokens = dist.sample().reshape(1, 1)\n",
    "            \n",
    "            if tokenizer.decode(input_tokens.item()) not in [\"<pad>\"]: # Vérifier que le token n'est pas un padding ou token spécial\n",
    "                pred_out = tokenizer.decode(input_tokens.item())[1]\n",
    "                real_out = env_apply.outcome(tokenizer.decode(input_tokens.item())[0])\n",
    "                env_apply.save_world(path=\"imgToGif2\")\n",
    "                input_tokens = torch.tensor(tokenizer.encode((tokenizer.decode(input_tokens.item())[0], real_out))).reshape(1, -1)\n",
    "                good.append(real_out == pred_out)\n",
    "                actions.append(tokenizer.decode(input_tokens.item())[0])\n",
    "                outcomes.append(real_out)\n",
    "                pred_out_list.append(pred_out)\n",
    "                proba_tmp = F.softmax(data_pred/temp, -1).cpu().numpy().flatten()\n",
    "                for i in range(tokenizer.size_vocab):\n",
    "                    probability[tokenizer.decode(i)].append(round(float(proba_tmp[i]), 3))\n",
    "                    \n",
    "                if path is not None:\n",
    "                    env_apply.save_world(path=path)\n",
    "            else:\n",
    "                generation_special_token += 1\n",
    "\n",
    "            # Append generated token to log_tokens\n",
    "            log_tokens.append(input_tokens.cpu())\n",
    "            \n",
    "            # Check for end-of-sentence token\n",
    "            if input_tokens.item() == end_token:\n",
    "                break\n",
    "    tmp = probability\n",
    "    tmp.update({'Action': actions,\n",
    "        'Prediciton': pred_out_list,\n",
    "        'Outcome Réel': outcomes,\n",
    "        'verifier': ['Correct' if i else 'Incorrect' for i in good]})\n",
    "    df_interactions = pd.DataFrame(tmp, index=range(1, len(good) + 1))\n",
    "    print(f'nb de génération {len(log_tokens)}')\n",
    "    print(f'nb de bonne prédiction {sum(good)} sur {len(good)} nombre de spécial token {generation_special_token}')\n",
    "    return log_tokens, data_pred, df_interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autre boucle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(1)\n",
    "# Historique des actions et outcomes\n",
    "env_test = gridWorld(x= 1, y=1, theta=0, world= np.array([\n",
    "                [1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "                [1, 0, 0, 0, 1, 0, 0, 0, 1],\n",
    "                [1, 1, 1, 0, 1, 0, 1, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 0, 1, 0, 1],\n",
    "                [1, 0, 1, 1, 1, 1, 0, 0, 1],\n",
    "                [1, 0, 1, 1, 0, 0, 0, 1, 1],\n",
    "                [1, 0, 0, 0, 0, 1, 1, 1, 1],\n",
    "                [1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "            ]))\n",
    "\n",
    "list_vocab = ['<pad>']\n",
    "# Nous notons toutes les interactions techniquement possible\n",
    "for act in env_test.get_actions():\n",
    "    for fb in env_test.get_outcomes():\n",
    "        list_vocab.append((act, fb))\n",
    "\n",
    "# Nous pouvons suprimer des interactions qui ne sont en réalité pas possible.\n",
    "list_vocab.remove(('turn_left', 'wall'))\n",
    "list_vocab.remove(('turn_right', 'wall'))\n",
    "for element in list_vocab:\n",
    "    print(element)\n",
    "    \n",
    "tmp = create_dico_numerate_word(list_vocab)\n",
    "print(tmp)\n",
    "tokenizer = SimpleTokenizerV1(vocab=tmp)\n",
    "\n",
    "all_actions, all_outcomes = [], []\n",
    "all_actions.append('forward') # Première action de base \n",
    "all_outcomes.append(env_test.outcome('forward')) # Première outcome de base\n",
    "# Cette première interaction nous servira de premier prompt\n",
    "seq_token = [tokenizer.encode((all_actions[0], all_outcomes[0]))]\n",
    "\n",
    "env_test.display_world()\n",
    "\n",
    "lstm_generator = LSTM_GenText(\n",
    "    num_emb=len(list_vocab),\n",
    "    hidden_size=16,\n",
    "    emb_size=16,\n",
    "    num_layers=2,\n",
    "    dropout=0.1\n",
    ")\n",
    "opti = optim.Adam(lstm_generator.parameters(), lr=0.001)\n",
    "loss_fct = nn.CrossEntropyLoss(ignore_index=tokenizer.encode(\"<pad>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(2)\n",
    "SIZE_CONTEXT = 20\n",
    "SIZE_PROMPT = SIZE_CONTEXT\n",
    "SIZE_CONTEXT_MIN = 10\n",
    "\n",
    "i = 0\n",
    "while i < SIZE_CONTEXT or seq_token[-1] != tokenizer.encode(('forward', 'empty')):\n",
    "    i += 1\n",
    "    action_random = np.random.choice(env_test.get_actions())\n",
    "    outcome_random = env_test.outcome(action_random)\n",
    "    seq_token.append(tokenizer.encode((action_random, outcome_random)))\n",
    "    \n",
    "print(f\"\\033[0;32mLa séquence \\033[0m\")\n",
    "print(tokenizer.decode(seq_token))\n",
    "print(seq_token)\n",
    "print('taille de la séquence aléatoire', len(seq_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(1)\n",
    "if len(seq_token) > SIZE_PROMPT:\n",
    "    input_tokens = seq_token[-SIZE_PROMPT:]\n",
    "else:\n",
    "    input_tokens = seq_token\n",
    "    \n",
    "print(f\"\\033[0;32mLe prompt\\033[0m {input_tokens}\")\n",
    "for i in input_tokens:\n",
    "    print(tokenizer.decode(i))\n",
    "print()\n",
    "\n",
    "input_tokens = torch.tensor(input_tokens).reshape(1, -1)\n",
    "log_tokens, data_pred, df_interactions = generate_sentence_with_env(\n",
    "    lstm_generator=lstm_generator, input_tokens=input_tokens, env_apply=env_test, \n",
    "    tokenizer=tokenizer, temp=1.0, path=\"imgToGif2\", max_len=30, end_token=tokenizer.encode(('forward', 'empty'))\n",
    ")\n",
    "df_interactions.to_csv(\"interactions.csv\", index=False)\n",
    "\n",
    "interaction_pred = [token.item() for token in log_tokens if tokenizer.decode(token.item()) != \"<pad>\"]\n",
    "seq_token += interaction_pred\n",
    "\n",
    "print('seq token', seq_token)\n",
    "print(f\"Nombre d'interaction total : {len(seq_token)}\")\n",
    "data_set = CustomDataSetTextGenByTokenV2(\n",
    "    token=seq_token,\n",
    "    id_pad=tokenizer.encode(\"<pad>\"),\n",
    "    context_lenght=SIZE_CONTEXT,\n",
    "    min=SIZE_CONTEXT_MIN)\n",
    "\n",
    "print(f\"\\033[0;32mtaille du jeu de donnée \\033[0m{len(data_set)}\")\n",
    "\n",
    "data_loader_train = DataLoader(\n",
    "        data_set,\n",
    "        batch_size=1,\n",
    "        shuffle=True,\n",
    "        num_workers=8\n",
    "    )\n",
    "\n",
    "td = TokenDrop(prob=0.1, pad_token=tokenizer.encode(\"<pad>\"), num_special=1)\n",
    "training_loss_logger, entropy_logger = train(lstm_generator=lstm_generator, data_loader_train=data_loader_train,\n",
    "                                            nb_epoch=20, optimizer=opti, loss_fn=loss_fct, td=td)\n",
    "\n",
    "plt.plot(training_loss_logger)\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()\n",
    "\n",
    "windows_means = []\n",
    "window_size = 100\n",
    "for i in range(0, len(entropy_logger), window_size):\n",
    "    windows_means.append(np.mean(entropy_logger[i:i + window_size]))\n",
    "plt.plot(windows_means)\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.title('Training Loss windows_means')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(entropy_logger)\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Entropy')\n",
    "plt.title('Entropy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Résultat\n",
    "Le modèle est très bon, mais il n'arrive pas à trouver de séquence qui amène a l'interaction voulut.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "Pour l'instant je n'utilise pas le pad. Je triche en obligant une certain de taille lors du train. Modifions la fonction de train pour calculer la loss que sur les vrai token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction non utilisé, non vraiment tester\n",
    "def train_without_pad(lstm_generator, nb_epoch:int, optimizer, loss_fn, td:TokenDrop|None):\n",
    "    # Monitor training loss and entropy\n",
    "    training_loss_logger = []\n",
    "    entropy_logger = []\n",
    "\n",
    "    for _ in tqdm(range(nb_epoch)):\n",
    "        # Set LSTM generator model to training mode\n",
    "        lstm_generator.train()\n",
    "        # Iterate over batches in training data loader\n",
    "        for text in tqdm(data_loader_train, desc=\"Training\", leave=False):\n",
    "            # Transform text tokens using training transform and move to device\n",
    "            bs = text.shape[0]\n",
    "            \n",
    "            # Randomly drop input tokens\n",
    "            if td is not None:\n",
    "                input_text = td(text[:, 0:-1])\n",
    "            else:\n",
    "                input_text = text[:, 0:-1]\n",
    "            output_text = text[:, 1:]\n",
    "            mask = (output_text != tokenizer.encode(\"<pad>\")).float()\n",
    "            \n",
    "            # Or not drop tokens\n",
    "            # input_text = text[:, 0:-1]\n",
    "            # output_text = text[:, 1:]\n",
    "            \n",
    "            # Initialize the memory buffers\n",
    "            hidden = torch.zeros(lstm_generator.num_layers, bs, lstm_generator.hidden_size)\n",
    "            memory = torch.zeros(lstm_generator.num_layers, bs, lstm_generator.hidden_size)\n",
    "            \n",
    "            # Forward pass through the LSTM generator\n",
    "            pred, hidden, memory = lstm_generator(input_text, hidden, memory)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = loss_fn(pred.transpose(1, 2), output_text) * mask\n",
    "            loss = loss.sum() / mask.sum()\n",
    "            \n",
    "            # Zero gradients, perform backward pass, and update weights\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Log training loss\n",
    "            training_loss_logger.append(loss.item())\n",
    "            \n",
    "            # Log entropy during training (for monitoring)\n",
    "            with torch.no_grad():\n",
    "                dist = Categorical(logits=pred)\n",
    "                entropy_logger.append(dist.entropy().mean().item())\n",
    "    return training_loss_logger, entropy_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(1)\n",
    "# Historique des actions et outcomes\n",
    "env_test = gridWorld(x= 1, y=1, theta=0, world= np.array([\n",
    "                [1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "                [1, 0, 0, 0, 1, 0, 0, 0, 1],\n",
    "                [1, 1, 1, 0, 1, 0, 1, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 0, 1, 0, 1],\n",
    "                [1, 0, 1, 1, 1, 1, 0, 0, 1],\n",
    "                [1, 0, 1, 1, 0, 0, 0, 1, 1],\n",
    "                [1, 0, 0, 0, 0, 1, 1, 1, 1],\n",
    "                [1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "            ]))\n",
    "\n",
    "list_vocab = ['<pad>']\n",
    "# Nous notons toutes les interactions techniquement possible\n",
    "for act in env_test.get_actions():\n",
    "    for fb in env_test.get_outcomes():\n",
    "        list_vocab.append((act, fb))\n",
    "\n",
    "# Nous pouvons suprimer des interactions qui ne sont en réalité pas possible.\n",
    "list_vocab.remove(('turn_left', 'wall'))\n",
    "list_vocab.remove(('turn_right', 'wall'))\n",
    "for element in list_vocab:\n",
    "    print(element)\n",
    "    \n",
    "tmp = create_dico_numerate_word(list_vocab)\n",
    "print(tmp)\n",
    "tokenizer = SimpleTokenizerV1(vocab=tmp)\n",
    "\n",
    "all_actions, all_outcomes = [], []\n",
    "all_actions.append('forward') # Première action de base \n",
    "all_outcomes.append(env_test.outcome('forward')) # Première outcome de base\n",
    "# Cette première interaction nous servira de premier prompt\n",
    "seq_token = [tokenizer.encode((all_actions[0], all_outcomes[0]))]\n",
    "\n",
    "env_test.display_world()\n",
    "\n",
    "lstm_generator = LSTM_GenText(\n",
    "    num_emb=len(list_vocab),\n",
    "    hidden_size=16,\n",
    "    emb_size=16,\n",
    "    num_layers=2,\n",
    "    dropout=0.1\n",
    ")\n",
    "opti = optim.Adam(lstm_generator.parameters(), lr=0.001)\n",
    "loss_fct = nn.CrossEntropyLoss(ignore_index=tokenizer.encode(\"<pad>\")) # Ajout de ignore_index pour ne pas prendre en compte le padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(2)\n",
    "SIZE_CONTEXT = 10\n",
    "SIZE_CONTEXT_MIN = 5\n",
    "SIZE_PROMPT = SIZE_CONTEXT\n",
    "TEMPERATURE = 10\n",
    "\n",
    "i = 0\n",
    "while i < SIZE_CONTEXT_MIN or seq_token[-1] != tokenizer.encode(('forward', 'empty')):\n",
    "    i += 1\n",
    "    action_random = np.random.choice(env_test.get_actions())\n",
    "    outcome_random = env_test.outcome(action_random)\n",
    "    env_test.save_world(path=\"imgToGif2\")\n",
    "    seq_token.append(tokenizer.encode((action_random, outcome_random)))\n",
    "    \n",
    "print(f\"\\033[0;32mLa séquence \\033[0m\")\n",
    "print(tokenizer.decode(seq_token))\n",
    "print(seq_token)\n",
    "print('taille de la séquence aléatoire', len(seq_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(1)\n",
    "if len(seq_token) > SIZE_PROMPT:\n",
    "    input_tokens = seq_token[-SIZE_PROMPT:]\n",
    "else:\n",
    "    input_tokens = seq_token\n",
    "    \n",
    "print(f\"\\033[0;32mLe prompt\\033[0m {input_tokens}\")\n",
    "for i in input_tokens:\n",
    "    print(tokenizer.decode(i))\n",
    "print()\n",
    "\n",
    "input_tokens = torch.tensor(input_tokens).reshape(1, -1)\n",
    "log_tokens, data_pred, df_interactions = generate_sentence_with_env(lstm_generator, input_tokens, env_test, tokenizer, 1)\n",
    "interaction_pred = [tokenizer.decode(token.item()) for token in log_tokens if tokenizer.decode(token.item()) != \"<pad>\"]\n",
    "# save dataframe\n",
    "df_interactions.to_csv(\"interactions.csv\", index=False)\n",
    "\n",
    "no_pad = [token.item() for token in log_tokens if token.item() != tokenizer.encode(\"<pad>\")]\n",
    "print(no_pad)\n",
    "seq_token += no_pad\n",
    "\n",
    "print('seq token', seq_token)\n",
    "data_set = CustomDataSetTextGenByToken(\n",
    "    token=seq_token,\n",
    "    id_pad=tokenizer.encode(\"<pad>\"),\n",
    "    context_lenght=SIZE_CONTEXT,\n",
    "    min=SIZE_CONTEXT_MIN)\n",
    "\n",
    "print(f\"\\033[0;32mtaille du jeu de donnée \\033[0m{len(data_set)}\")\n",
    "\n",
    "data_loader_train = DataLoader(\n",
    "        data_set,\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        num_workers=8\n",
    "    )\n",
    "\n",
    "td = TokenDrop(prob=0.1, pad_token=tokenizer.encode(\"<pad>\"), num_special=1)\n",
    "training_loss_logger, entropy_logger = train(lstm_generator=lstm_generator,data_loader_train=data_loader_train, nb_epoch=20,\n",
    "                                             optimizer=opti, loss_fn=loss_fct, td=td)\n",
    "\n",
    "plt.plot(training_loss_logger)\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()\n",
    "\n",
    "windows_means = []\n",
    "window_size = 100\n",
    "for i in range(0, len(entropy_logger), window_size):\n",
    "    windows_means.append(np.mean(entropy_logger[i:i + window_size]))\n",
    "plt.plot(windows_means)\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.title('Training Loss windows_means')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(entropy_logger)\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Entropy')\n",
    "plt.title('Entropy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Résulat\n",
    "Avec context lenght de 50 et min de 10, PROMPt de 50, le modèle finit (rapidement <50 itération) par donner des séquences d'une dizaine d'itérations. Ces prédictions sont très largement bonnes, il ne se trompe que rarement. Les actions éfféctuer ne sont pas forcément cohérente (turn right suivit de turn left).\n",
    "\n",
    "Voir :\n",
    "\n",
    "![gif](./gentText.gif)  \n",
    "\n",
    "ou la vidéo  \n",
    "\n",
    "![movie](./generationTexte.mp4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vérifier les connaissances du model\n",
    "Pour vérifier si le modèl est bon ou non, nous pouvons le faire générer un grand nombre d'intéractions (1000) et les faire pas à pas. Pour au final voir si il arrive a toujours prédire de bonne intéraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(lstm_generator, input_tokens, env_apply, temp:int=1.0):\n",
    "    lstm_generator.eval()\n",
    "    log_tokens = []\n",
    "    # Disable gradient calculation\n",
    "    with torch.no_grad():\n",
    "        # Initialize hidden and memory states\n",
    "        hidden = torch.zeros(lstm_generator.num_layers, 1, lstm_generator.hidden_size)\n",
    "        memory = torch.zeros(lstm_generator.num_layers, 1, lstm_generator.hidden_size)\n",
    "\n",
    "        # Monitor number of good and bad predictions\n",
    "        good = []\n",
    "        actions = []\n",
    "        outcomes = []\n",
    "        pred_out_list = []\n",
    "        generation_special_token = 0\n",
    "        for i in range(1000): # On met une limite de 100 tokens\n",
    "            # Forward pass through LSTM generator\n",
    "            data_pred, hidden, memory = lstm_generator(input_tokens, hidden, memory)\n",
    "\n",
    "            # Sample from the distribution of probabilities (with temperature)\n",
    "            dist = Categorical(logits=data_pred[:, -1] / temp)\n",
    "            input_tokens = dist.sample().reshape(1, 1)\n",
    "            \n",
    "            if tokenizer.decode(input_tokens.item()) not in [\"<pad>\"]: # Vérifier que le token n'est pas un padding ou token spécial\n",
    "                pred_out = tokenizer.decode(input_tokens.item())[1]\n",
    "                real_out = env_apply.outcome(tokenizer.decode(input_tokens.item())[0])\n",
    "                env_apply.save_world(path=\"imgToGif2\")\n",
    "                input_tokens = torch.tensor(tokenizer.encode((tokenizer.decode(input_tokens.item())[0], real_out))).reshape(1, -1)\n",
    "                good.append(real_out == pred_out)\n",
    "                actions.append(tokenizer.decode(input_tokens.item())[0])\n",
    "                outcomes.append(real_out)\n",
    "                pred_out_list.append(pred_out)\n",
    "            else:\n",
    "                generation_special_token += 1\n",
    "\n",
    "            # Append generated token to log_tokens\n",
    "            log_tokens.append(input_tokens.cpu())\n",
    "            \n",
    "    df_interactions = pd.DataFrame({\n",
    "        'Action': actions,\n",
    "        'Prediciton': pred_out_list,\n",
    "        'Outcome Réel': outcomes,\n",
    "        'verifier': ['Correct' if i else 'Incorrect' for i in good]\n",
    "    })\n",
    "    # print(f'nb de génération {len(log_tokens)}')\n",
    "    print(f'nb de bonne prédiction {sum(good)} sur {len(good)} nombre de spécial token {generation_special_token}')\n",
    "    return log_tokens, data_pred, df_interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokens = seq_token[-SIZE_PROMPT:]\n",
    "input_tokens = torch.tensor(input_tokens).reshape(1, -1)\n",
    "log_tokens, data_pred, df_interactions = verify(lstm_generator, input_tokens, env_test, temp=0.1)\n",
    "df_interactions.to_csv(\"interactions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "nb de bonne prédiction 948 sur 1000 nombre de spécial token 0. Donc 95% d'accuracie\n",
    "## Mais ?\n",
    "Voici la séquence que le modèl répète en boucle :\n",
    "![gif](./Verify.gif)\n",
    "\n",
    "On ne peut pas dire que le modèle a compris son environement. Il a juste réussit à faire une séquence de manière sûr."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = ['forward']\n",
    "outcomes = [env_test.outcome('forward')]\n",
    "seq_token = tokenizer.encode([(actions[-1], outcomes[-1])])\n",
    "print(seq_token)\n",
    "lstm_generator = LSTM_GenText(\n",
    "    num_emb=len(list_vocab),\n",
    "    hidden_size=16,\n",
    "    emb_size=16,\n",
    "    num_layers=num_layers,\n",
    "    dropout=0.1\n",
    ")\n",
    "opti = optim.Adam(lstm_generator.parameters(), lr=0.001)\n",
    "loss_fct = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokens = seq_token[-10:]\n",
    "print(f\"\\033[0;32mLe prompt\\033[0m {input_tokens}\")\n",
    "for i in input_tokens:\n",
    "    print(tokenizer.decode(i))\n",
    "print()\n",
    "env_test.display_world()\n",
    "input_tokens_tok = torch.tensor(input_tokens).reshape(1, -1)\n",
    "log_tokens, data_pred = generate_sentence_with_env(lstm_generator, input_tokens_tok, env_test, tokenizer)\n",
    "# print(\"\\033[0;32m Génération du modèle :\\033[0m\")\n",
    "# for i in log_tokens:\n",
    "#     print(tokenizer.decode(i.item()))\n",
    "\n",
    "print('test mm')\n",
    "no_pad = [token.item() for token in log_tokens if token.item() != tokenizer.encode(\"<pad>\")]\n",
    "print([tokenizer.decode(i) for i in no_pad])\n",
    "print('size compute : ', len(log_tokens))\n",
    "\n",
    "seq_token += no_pad\n",
    "data_set = CustomDataSetTextGenByToken(\n",
    "    token=seq_token,\n",
    "    id_pad=tokenizer.encode(\"<pad>\"),\n",
    "    context_lenght=21,\n",
    "    min=21)\n",
    "\n",
    "print(f\"\\033[0;32mtaille du jeu de donnée \\033[0m{len(data_set)}\")\n",
    "\n",
    "data_loader_train = DataLoader(\n",
    "        data_set,\n",
    "        batch_size=1,\n",
    "        shuffle=True,\n",
    "        num_workers=8\n",
    "    )\n",
    "\n",
    "td = TokenDrop(prob=0.1, pad_token=tokenizer.encode(\"<pad>\"), num_special=1)\n",
    "training_loss_logger, entropy_logger = train(lstm_generator, 20, opti, loss_fct, td)\n",
    "\n",
    "plt.plot(training_loss_logger)\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(entropy_logger)\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Entropy')\n",
    "plt.title('Entropy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception(\"Fin du programme\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loss\n",
    "On peut se rendre compte que le modèle n'arrive pas a s'entrainner de cette manière."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_sentence_with_env(lstm_generator, input_tokens, env_apply):\n",
    "#     lstm_generator.eval()\n",
    "#     log_tokens = []\n",
    "#     # Disable gradient calculation\n",
    "#     with torch.no_grad():\n",
    "#         # Initialize hidden and memory states\n",
    "#         hidden = torch.zeros(lstm_generator.num_layers, 1, lstm_generator.hidden_size)\n",
    "#         memory = torch.zeros(lstm_generator.num_layers, 1, lstm_generator.hidden_size)\n",
    "\n",
    "#         # Generate text\n",
    "#         good = 0\n",
    "#         bad = 0\n",
    "#         for i in range(100): # On met une limite de 100 tokens\n",
    "#             # Forward pass through LSTM generator\n",
    "#             data_pred, hidden, memory = lstm_generator(input_tokens, hidden, memory)\n",
    "\n",
    "#             # Sample from the distribution of probabilities (with temperature)\n",
    "#             dist = Categorical(logits=data_pred[:, -1] / temp)\n",
    "#             input_tokens = dist.sample().reshape(1, 1)\n",
    "            \n",
    "#             if input_tokens.item() != tokenizer.encode(\"<pad>\"):\n",
    "#                 pred_out = tokenizer.decode(input_tokens.item())[1]\n",
    "#                 real_out = env_apply.outcome(tokenizer.decode(input_tokens.item())[0])\n",
    "#                 input_tokens = torch.tensor(tokenizer.encode((tokenizer.decode(input_tokens.item())[0], real_out))).reshape(1, -1)\n",
    "#                 if real_out == pred_out:\n",
    "#                     good += 1\n",
    "#                 else:\n",
    "#                     bad += 1\n",
    "               \n",
    "\n",
    "#             # Append generated token to log_tokens\n",
    "#             log_tokens.append(input_tokens.cpu())\n",
    "            \n",
    "#             # Check for end-of-sentence token\n",
    "#             if input_tokens.item() == tokenizer.encode(('forward', 'empty')): # Si le token est ('forward', 'empty') on s'arrête\n",
    "#                 break\n",
    "#         print(f\"good : {good} bad : {bad}\")\n",
    "#     return log_tokens, data_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_tokens)\n",
    "generate_sentence_with_env(lstm_generator, input_tokens, env_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_test = gridWorld(x= 1, y=1, theta=0, world= np.array([\n",
    "                [1, 1, 1, 1, 1, 1],\n",
    "                [1, 0, 0, 0, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 1],\n",
    "                [1, 1, 1, 1, 1, 1],\n",
    "            ]))\n",
    "\n",
    "all_actions, all_outcomes = [], []\n",
    "actions = ['forward']\n",
    "outcomes = [env_test.outcome('forward')]\n",
    "opti = optim.Adam(lstm_generator.parameters(), lr=0.0001)\n",
    "loss_fct = nn.CrossEntropyLoss()\n",
    "lstm_generator = LSTM_GenText(\n",
    "    num_emb=len(list_vocab),\n",
    "    hidden_size=32,\n",
    "    emb_size=32,\n",
    "    num_layers=num_layers,\n",
    "    dropout=0.25\n",
    ")\n",
    "td = TokenDrop(prob=0.1, pad_token=tokenizer.encode(\"<pad>\"), num_special=1)\n",
    "seq_token = [tokenizer.encode(('forward', outcomes[-1]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_generator = LSTM_GenText(\n",
    "    num_emb=len(list_vocab),\n",
    "    hidden_size=16,\n",
    "    emb_size=16,\n",
    "    num_layers=num_layers,\n",
    "    dropout=0.1\n",
    ")\n",
    "opti = optim.Adam(lstm_generator.parameters(), lr=0.001)\n",
    "loss_fct = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(seq_token) >= 10:\n",
    "    input_tokens = seq_token[-10:]\n",
    "else:\n",
    "    input_tokens = seq_token\n",
    "    \n",
    "print(f\"\\033[0;32mLe prompt\\033[0m {input_tokens}\")\n",
    "for i in input_tokens:\n",
    "    print(tokenizer.decode(i))\n",
    "print()\n",
    "env_test.display_world()\n",
    "input_tokens_tensor = torch.tensor(input_tokens).reshape(1, -1)\n",
    "log_tokens, data_pred = generate_sentence_with_env(lstm_generator, input_tokens_tensor, env_test, tokenizer)\n",
    "\n",
    "print([tokenizer.decode(i.item()) for i in log_tokens])\n",
    "\n",
    "seq_token += [i.item() for i in log_tokens if i.item() != tokenizer.encode(\"<pad>\")]\n",
    "data_set = CustomDataSetTextGenByToken(\n",
    "    token=seq_token,\n",
    "    id_pad=tokenizer.encode(\"<pad>\"),\n",
    "    context_lenght=11,\n",
    "    min=11)\n",
    "\n",
    "print(f\"\\033[0;32mtaille du jeu de donnée \\033[0m{len(data_set)}\")\n",
    "\n",
    "data_loader_train = DataLoader(\n",
    "        data_set,\n",
    "        batch_size=1,\n",
    "        shuffle=True,\n",
    "        num_workers=8\n",
    "    )\n",
    "\n",
    "training_loss_logger, entropy_logger = train(lstm_generator, 20, opti, loss_fct, td)\n",
    "\n",
    "plt.plot(training_loss_logger)\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(entropy_logger)\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Entropy')\n",
    "plt.title('Entropy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data_loader_train:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autre idée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not use interaction token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence_no_end(lstm_generator, input_tokens):\n",
    "    lstm_generator.eval()\n",
    "    log_tokens = []\n",
    "    # Disable gradient calculation\n",
    "    with torch.no_grad():\n",
    "        # Initialize hidden and memory states\n",
    "        hidden = torch.zeros(lstm_generator.num_layers, 1, lstm_generator.hidden_size)\n",
    "        memory = torch.zeros(lstm_generator.num_layers, 1, lstm_generator.hidden_size)\n",
    "\n",
    "        # Generate text\n",
    "        for i in range(20): # On met une limite de 100 tokens\n",
    "            # Forward pass through LSTM generator\n",
    "            data_pred, hidden, memory = lstm_generator(input_tokens, hidden, memory)\n",
    "\n",
    "            # Sample from the distribution of probabilities (with temperature)\n",
    "            dist = Categorical(logits=data_pred[:, -1] / temp)\n",
    "            input_tokens = dist.sample().reshape(1, 1)\n",
    "\n",
    "            # Append generated token to log_tokens\n",
    "            log_tokens.append(input_tokens.cpu())\n",
    "\n",
    "            # Check for end-of-sentence token\n",
    "            # if input_tokens.item() == end_token:\n",
    "            #     break\n",
    "    return log_tokens, data_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_vocab = ['<pad>']\n",
    "for act in env_test.get_actions():\n",
    "    list_vocab.append(act)\n",
    "\n",
    "for fb in env_test.get_outcomes():\n",
    "    list_vocab.append(fb)\n",
    "\n",
    "for element in list_vocab:\n",
    "    print(element)\n",
    "    \n",
    "tmp = create_dico_numerate_word(list_vocab)\n",
    "print(tmp)\n",
    "tokenizer = SimpleTokenizerV1(vocab=tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historique des actions et outcomes\n",
    "all_actions, all_outcomes = [], []\n",
    "actions = ['forward']\n",
    "outcomes = [env_test.outcome('forward')]\n",
    "opti = optim.Adam(lstm_generator.parameters(), lr=0.001)\n",
    "loss_fct = nn.CrossEntropyLoss()\n",
    "lstm_generator = LSTM_GenText(\n",
    "    num_emb=len(list_vocab),\n",
    "    hidden_size=16,\n",
    "    emb_size=16,\n",
    "    num_layers=num_layers,\n",
    "    dropout=0.1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataSetActFb(Dataset):\n",
    "    def __init__(self, actions, outcomes, context_lenght, min, id_pad, tokenizer):\n",
    "        self.actions = actions\n",
    "        self.outcomes = outcomes\n",
    "        self.tokenizer = tokenizer\n",
    "        self.context_lenght = context_lenght\n",
    "        self.min = min\n",
    "        self.padding = id_pad\n",
    "        self.data = self.create_data()\n",
    "    \n",
    "    def create_data(self):\n",
    "        \"\"\"\n",
    "        Create the data\n",
    "        \"\"\"\n",
    "        interaction = []\n",
    "        for i in range(len(self.actions)):\n",
    "            interaction += self.tokenizer.encode([self.actions[i], self.outcomes[i]])\n",
    "        print(\"first debug\")\n",
    "        print(interaction)\n",
    "        \n",
    "        sentences = []\n",
    "        for range_cut in range(self.min, self.context_lenght +1):\n",
    "            for i in range(0, len(interaction) + 1 - range_cut, 1):\n",
    "                sentences.append(interaction[i:i + range_cut])\n",
    "                sentences[-1] = sentences[-1] + \\\n",
    "                                [self.padding] * (self.context_lenght - len(sentences[-1]))\n",
    "        if len(sentences) == 0:\n",
    "            sentences = [interaction + [self.padding] * (self.context_lenght - len(interaction))]\n",
    "        \n",
    "        print(\"debug\")\n",
    "        print(sentences)\n",
    "        return sentences\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.data[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_test = gridWorld(x= 1, y=1, theta=0, world= np.array([\n",
    "                [1, 1, 1, 1, 1, 1],\n",
    "                [1, 0, 0, 0, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 1],\n",
    "                [1, 1, 1, 1, 1, 1],\n",
    "            ]))\n",
    "\n",
    "actions, outcomes = [], []\n",
    "\n",
    "for i in range(100):\n",
    "    actions.append(str(np.random.choice(env_test.get_actions())))\n",
    "    outcomes.append(env_test.outcome(actions[-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train \n",
    "data_set = dataSetActFb(\n",
    "    actions=actions,\n",
    "    outcomes=outcomes,\n",
    "    id_pad=tokenizer.encode(\"<pad>\"),\n",
    "    context_lenght=50,\n",
    "    min=49,\n",
    "    tokenizer=tokenizer)\n",
    "\n",
    "print(f\"\\033[0;32mtaille du jeu de donnée \\033[0m{len(data_set)}\")\n",
    "\n",
    "data_loader_train = DataLoader(\n",
    "        data_set,\n",
    "        batch_size=1,\n",
    "        shuffle=True,\n",
    "        num_workers=8\n",
    "    )\n",
    "\n",
    "td = TokenDrop(prob=0.1, pad_token=tokenizer.encode(\"<pad>\"), num_special=1)\n",
    "training_loss_logger, entropy_logger = train(lstm_generator, 20, opti, loss_fct, td)\n",
    "\n",
    "plt.plot(training_loss_logger)\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(entropy_logger)\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Entropy')\n",
    "plt.title('Entropy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from environnement.environnement3Str import Environnement3\n",
    "\n",
    "env_test = Environnement3()\n",
    "print(env_test.outcome('a'))\n",
    "print(env_test.outcome('b'))\n",
    "\n",
    "actions, outcomes = [], []\n",
    "for i in range(100):\n",
    "    actions.append(str(np.random.choice(env_test.get_actions())))\n",
    "    outcomes.append(env_test.outcome(actions[-1]))\n",
    "    \n",
    "tokenizer = SimpleTokenizerV1(vocab={'<pad>': 0, 'a': 1, 'b': 2, 'x': 3, 'y': 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "data_set = dataSetActFb(\n",
    "    actions=actions,\n",
    "    outcomes=outcomes,\n",
    "    id_pad=tokenizer.encode(\"<pad>\"),\n",
    "    context_lenght=50,\n",
    "    min=49,\n",
    "    tokenizer=tokenizer)\n",
    "\n",
    "print(f\"\\033[0;32mtaille du jeu de donnée \\033[0m{len(data_set)}\")\n",
    "\n",
    "data_loader_train = DataLoader(\n",
    "        data_set,\n",
    "        batch_size=1,\n",
    "        shuffle=True,\n",
    "        num_workers=8\n",
    "    )\n",
    "\n",
    "lstm_generator = LSTM_GenText(\n",
    "    num_emb=tokenizer.size_vocab,\n",
    "    hidden_size=16,\n",
    "    emb_size=16,\n",
    "    num_layers=2,\n",
    "    dropout=0.1\n",
    ")\n",
    "    \n",
    "\n",
    "opti = optim.Adam(lstm_generator.parameters(), lr=0.001)\n",
    "loss_fct = nn.CrossEntropyLoss()\n",
    "td = TokenDrop(prob=0.1, pad_token=tokenizer.encode(\"<pad>\"), num_special=1)\n",
    "training_loss_logger, entropy_logger = train(lstm_generator, 20, opti, loss_fct, td)\n",
    "\n",
    "plt.plot(training_loss_logger)\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(entropy_logger)\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Entropy')\n",
    "plt.title('Entropy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise NotImplementedError\n",
    "print(f\"\\033[0;32mLe prompt\\033[0m {input_tokens}\")\n",
    "for i in input_tokens:\n",
    "    print(tokenizer.decode(i))\n",
    "print()\n",
    "env_test.display_world()\n",
    "input_tokens = torch.tensor(input_tokens).reshape(1, -1)\n",
    "log_tokens, data_pred = generate_sentence_no_end(lstm_generator, input_tokens)\n",
    "print(\"\\033[0;32m Génération du modèle :\\033[0m\")\n",
    "for i in log_tokens:\n",
    "    print(tokenizer.decode(i.item()))\n",
    "\n",
    "actions, outcomes = run_token(log_tokens, env_test)\n",
    "print(f\"\\033[0;32mLes vrai outcomes\\033[0m \\n{outcomes}\")\n",
    "all_actions += actions\n",
    "all_outcomes += outcomes\n",
    "\n",
    "seq_token = action_outcome_to_token(all_actions, all_outcomes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception\n",
    "# Je vais considérer que nous avons une seul séquence (ce qui est en soit le cas)\n",
    "# Pour l'entrainement je vais cacher certain token de la séquence et demander au modèle de les prédire\n",
    "# Je vais ensuite comparer les prédictions du modèle avec les vrais tokens caché\n",
    "# Pour cela je vais utiliser un mask qui va cacher les tokens\n",
    "\n",
    "# Pour les tokens je vais d'abord essayer en reprenant un token pour chaque action et outcome\n",
    "# Et non les interactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_vocab = ['<pad>']\n",
    "for act in env_test.get_actions():\n",
    "    list_vocab.append(act)\n",
    "\n",
    "for fb in env_test.get_outcomes():\n",
    "    list_vocab.append(fb)\n",
    "\n",
    "\n",
    "for element in list_vocab:\n",
    "    print(element)\n",
    "    \n",
    "tmp = create_dico_numerate_word(list_vocab)\n",
    "print(tmp)\n",
    "tokenizer = SimpleTokenizerV1(vocab=tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Je vais reprendre le tokenDrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenDrop(nn.Module):\n",
    "    def __init__(self, prob=0.1, pad_token=0, num_special=1):\n",
    "        self.prob = prob\n",
    "        self.num_special = num_special\n",
    "        self.pad_token = pad_token\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        mask = torch.bernoulli(self.prob * torch.ones_like(sample)).long()\n",
    "        \n",
    "        can_drop = (sample >= self.num_special).long()\n",
    "        mask = mask * can_drop\n",
    "        \n",
    "        replace_with = (self.pad_token * torch.ones_like(sample)).long()\n",
    "        \n",
    "        sample_out = (1 - mask) * sample + mask * replace_with\n",
    "        \n",
    "        return sample_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Génetation d'une séquence\n",
    "env_test = gridWorld(x= 1, y=1, theta=0, world= np.array([\n",
    "                [1, 1, 1, 1, 1, 1],\n",
    "                [1, 0, 0, 0, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 1],\n",
    "                [1, 1, 1, 1, 1, 1],\n",
    "            ]))\n",
    "\n",
    "all_actions, all_outcomes = [], []\n",
    "actions = ['forward']\n",
    "outcomes = [env_test.outcome('forward')]\n",
    "sequence = actions + outcomes\n",
    "\n",
    "for i in range(100):\n",
    "    actions.append(str(np.random.choice(env_test.get_actions())))\n",
    "    outcomes.append(env_test.outcome(actions[-1]))\n",
    "    sequence += [actions[-1], outcomes[-1]]\n",
    "    \n",
    "print(f\"\\033[0;32mLa séquence\\033[0m {sequence}\")\n",
    "\n",
    "seq_token = torch.tensor(tokenizer.encode(sequence))\n",
    "\n",
    "\n",
    "data = []\n",
    "\n",
    "for i in range(10):\n",
    "    tmp = td(seq_token)\n",
    "    data.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataSet(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "data_set = SimpleDataSet(data)\n",
    "data_loader_train = DataLoader(\n",
    "    data_set,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = optim.Adam(lstm_generator.parameters(), lr=0.001)\n",
    "loss_fct = nn.CrossEntropyLoss()\n",
    "lstm_generator = LSTM_GenText(\n",
    "    num_emb=len(list_vocab),\n",
    "    hidden_size=16,\n",
    "    emb_size=16,\n",
    "    num_layers=num_layers,\n",
    "    dropout=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(lstm_generator, 20, opti, loss_fct, td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_without_td(lstm_generator, nb_epoch:int, optimizer, loss_fn):\n",
    "    # Monitor training loss and entropy\n",
    "    training_loss_logger = []\n",
    "    entropy_logger = []\n",
    "\n",
    "    for epoch in tqdm(range(nb_epoch)):\n",
    "        # Set LSTM generator model to training mode\n",
    "        lstm_generator.train()\n",
    "        steps = 0\n",
    "        # Iterate over batches in training data loader\n",
    "        for text in tqdm(data_loader_train, desc=\"Training\", leave=False):\n",
    "            # Transform text tokens using training transform and move to device\n",
    "            bs = text.shape[0]\n",
    "            # output_text = text_tokens[:, 1:]\n",
    "            input_text = text[:, 0:-1]\n",
    "            output_text = text[:, 1:]\n",
    "            \n",
    "            # Initialize the memory buffers\n",
    "            hidden = torch.zeros(lstm_generator.num_layers, bs, lstm_generator.hidden_size)\n",
    "            memory = torch.zeros(lstm_generator.num_layers, bs, lstm_generator.hidden_size)\n",
    "            \n",
    "            # Forward pass through the LSTM generator\n",
    "            pred, hidden, memory = lstm_generator(input_text, hidden, memory)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = loss_fn(pred.transpose(1, 2), output_text)\n",
    "            \n",
    "            # Zero gradients, perform backward pass, and update weights\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Log training loss\n",
    "            training_loss_logger.append(loss.item())\n",
    "            \n",
    "            # Log entropy during training (for monitoring)\n",
    "            with torch.no_grad():\n",
    "                dist = Categorical(logits=pred)\n",
    "                entropy_logger.append(dist.entropy().mean().item())\n",
    "    return training_loss_logger, entropy_logger\n",
    " \n",
    "td = TokenDrop(prob=0.1, pad_token=tokenizer.encode(\"<pad>\"), num_special=1)\n",
    "training_loss_logger, entropy_logger = train_without_td(lstm_generator, 50, opti, loss_fct)\n",
    "# Display training loss and entropy\n",
    "plt.plot(training_loss_logger)\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(entropy_logger)\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Entropy')\n",
    "plt.title('Entropy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Stage (torch)",
   "language": "python",
   "name": "dpt_transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
